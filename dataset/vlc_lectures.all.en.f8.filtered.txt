17 en Grobelnik Marko Analyse the portugese statistical office website 
26 en Bioinformatic Structural Biology and Structure Based Ligand Design Drug discovery During the lecture will shown the principles which the modern development and drug discovery with emphasis optimization compounds with the use three dimensional structures the receptor Also the use bioinformatics will shown and computer supported planning ligands together with the implications the understanding detailed interactions between the protein and the ligand the transfiguration the enzyme inhibitors into medicines the context modern challenges 
27 en Comparisson Technologies For Connecting Business Processes Among Enterprises
30 en Pogodbe Slovenija okvirnem programu 
41 en Decision Support for Everyone Olap Excel
52 en Adaptation cllasical rule learning algorhytm for subgroup discovery and application this modified algorhytm real life domain
56 en Poliamids BASF chains added value the chemical products market
64 en Adapting Proactive Mobile Agents Dynamically Reconfigurable Networks – Report Current Research
65 en Design Thinking Problem Solving Tool technology and life Design thinking process for practical creative resolution problems issues The stages this process are suggested Define Research Ideate Prototype Choose Implement Learnn Within these seven steps problems can framed the right questions can asked more ideas can created and the best answers can chosen The steps aren linear they can occur simultaneously repeated Although design always subject personal taste design thinkers share common set values that drive innovation these values are mainly creativity ambidextrous thinking teamwork end user focus curiosity There considerable academic interest understanding design thinking design cognition including ongoing series symposia research design thinking 
66 en Social Constructivism Philosophy Mathematics
67 en Learning User Profiles Intelligent Systems
68 en Kernel Based Methods for Pattern Recognition
71 en Lexical Semantics the Age the Semantic Web
79 en Symmetry the works Escher Introductory References about Tessellations tilings and Sources for Illustrations http www geom uiuc edu software tilings TilingBibliography html link 
82 en The Sol Net Project Data mining Lessons Learned
85 en Describing Decision Support Darta Mining and Text Web Mining Studies SolEuNet
86 en Time series analysis traffic accident data
90 en Web User Behavior Characterization Techniques Applications And Research Directions
94 en Developing Software Across Time Zones Exploratory Empirical Study
96 en Science Policy Slovenia Nagovor avnega sekretarja
98 en Discovering interesting rules from financial data
99 en Functional visualisation proteoliosys the influence the micro environment
101 en Introduction welcome conference presentation Nagovor direktorja
102 en Qualitative Clustering Short Time Series Case Study Firms Reputation Data
121 en Parallel Manipulators Biomechanics and Robotics the lecture will shown the newest discoveries the field parallel manipulators Parallel manipulators are mechanisms which contain more closed parallel cinematic loops where only few are driven motors The attention will focused the influence different parameters air the joints constructional defects cinematic singularities and isotropy the activity the manipulator especially from the biomechanics and robotic point view 
123 en Monodispersed particles technologies and medicine the last decades witnessed the development different techniques for the manufacturing monodispersed systems with particle size from few micrometers few nanometers These particles are different sizes and forms their chemical structure can complex simple the beginning the focus research these systems was the search different physical and chemical properties which can strongly dependent from the size the particles and their morphology Later the interest was pointed towards their use the making materials with specific and repeated properties This use specially accelerated today’ trends miniaturizing technology and medicine They enable large progress the transmission laboratory techniques preparative arrangements monodispersed colloid systems the economy The lecturer will focus the role monodispersive colloid systems the manufacturing cheramics and pigments photography chemical polishing and especially the making monodispersive medicines will show how colloid particles are useful the transmission medicines with delayed effect the advance chosen part the human body They are also used diagnostics especially ray examinations Their use different because the differences the properties nano and micro dispersions 
134 en Surface plasmon resonance imagery and single molecule approaches proteo nucleic complex self assembly The presentation will illustrate the use use surface plasmon resonance imagery and single molecule approaches based quantum dot labelling for the analysis the dynamic and structure proteo nucleic assemblies Semi synthetic complexes PDAs encompassing protein part embedding electro active redox cofactors and nucleic acid part allowing highly controlled self organisation the protein domains were designed and constructed This approach allows the building large and fully defined chain electron transport centres with tuneable spatial organization Association with quantum dot offering single molecule monitoring power opens the route the use self assembled bio molecules molecular wire for bioelectronics 
136 en  situ Fabrication Manipulation and Property Measurements Single Nanotubes and Nanowires with Near Atomic Resolution Carbon nanotube CNT and nanowire materials are important building
137 en Self assembly Nematic colloids Nematic colloids are dispersions micrometric particles nematic liquid crystals which show unusual properties self assembly into regular geometrical patterns The reason for this type behavior the pressure the liquid crystal among the particles These pressures are called structures and are the consequence the orientation the liquid crystals and the deformation the structure the crystal near the colloid particles has been known for quite while that the nematic colloids are unifying into one dimensional chain also know about two dimensional structures the border liquid crystals and isotropic liquids Latest research has shown progress the understanding the nature self assembly nematic colloids they have shown that nematic colloids can spontaneously make also regular two dimensional structures which are very tightly bounded With these facts new path has been laid for the self assembly colloids dimensional crystals There are also interesting possibilities the manufacturing materials with the self arranging nanoparticles 
139 en Liquid Crystal Elastomers Rubber elasticity unique feature polymer networks elastomers formed from long polymer chains connected one another crosslinkages implanting rod like mesogenic monomer units into the network chains can induce the liquid crystalline state the elastomers The interplay between network chain conformation and liquid crystalline phase creates material with remarkable properties Detailed investigations proved direct coupling between chain conformation and anisotropic state order the liquid crystalline phase Introducing anisotropic chain conformation priori suitable synthesis concept networks can obtained that are macroscopic uniformly ordered liquid single crystal elastomers LSCE Depending the liquid crystalline phase structure LSCE exhibit exceptional properties nematic LSCE change their macroscopic dimensions when the state order modified external stimuli This effect can applied novel thermo and opto mechanical actuators 
140 en Spectroscopy This week are hosting Stan Terras the representative the Ranishw Company from the expert the field spectroscopy will introduce the latest results with the Raman spectrometer and with the AFM SEM that are used nanotechnology 
142 en Cambridge fenomenon new technologies transfer into the economy Smeets will introduce the experiences the university town Cambridge one the most important European centers for the transfer new technologies into the economy will focus the development the Cambridge phenomenon new technologies transfer into the economy and the conditions that influenced the success this concept the basis the above listed facts will discuss the mechanisms for achieving this phenomenon The lecture being organized the Slovenian Technology Park Ljubljana cooperation with the Jozef Stefan Institute and the British Embassy Slovenia 
164 en How protein synthesis catalyzed The Cassiopeia synchrotron stations for protein crystallography MAX 
165 en The simulation structures modern materials with the theory density functional calculations With the theory density functional calculations can study the connection between the crystal structure electronic structure and the properties connected with these With the comparison complete energies different structures can establish the relative stability individual structures With the minimizing inter atomic powers can optimize the position atoms ions the crystal With this method can accurately calculate also the phonic structure the super cell which contains 100 atoms example use TGF will introduce the study Y2Nb2O7 which can crystallize the pyrochlore structure and the same time works isolator 
167 en Laser Manipulation Atoms and Spins Two the most important themes modern magnetism are the making magnetic structures and the switching magnetization ultra fast time scale With the help the interaction between photons and electrical states atoms can achieve both Nanofabrication with the help atomic optics can provide tool for the production magnetic nanostructures where femtoseconds laser shots can provide coherent control magnetization ultra light picoseconds timescale 
169 en Bioinformatic Structural Biology and Structure Based Ligand Design Drug discovery During the lecture will shown the principles which the modern development and drug discovery with emphasis optimization compounds with the use three dimensional structures the receptor Also the use bioinformatics will shown and computer supported planning ligands together with the implications the understanding detailed interactions between the protein and the ligand the transfiguration the enzyme inhibitors into medicines the context modern challenges 
170 en Enzyme synthesis new dna nanostructures have developed new technique for the enzyme synthesis equally long micrometric structures made double chains polyG polyC triple chains poly poly poly and quadruple chains were studying the structure molecules and the mechanism their synthesis With the use absorbed and spectroscopy FRET and new highly dissoluble microscopy’ atomic force AFM 
171 en Architecture for humananoid robots emulation biological processes achieve better understanding the processing information with humans which processing the brain can help with the construction and study robotic systems which are human like Three views this topic will presented this lecture behaviorist integration systems the organization flow and processing information The suggested architecture based decentralized and cooperative processing information These processes can serial parallel with forward and backward links From here complex network between interlinked and dependent process elements can established the basis the sensory input and output movements the system generates more complex operations and decisions The results the research which will presented during the lecture are based the research many other disciplines humanoid robotics for integration and implementation the system neuroscience for the organization the flux the processing information and nevropsychology for the evaluation the systems behavior 
176 en Sustainability concept energy water and environmental systems This review first introduces the historical background for the sustainability concept development Special reference given the energy resource depletion and its forecast the assessment global energy resources attention focused the resource consumption and its relevancy the future demand The recent assessment sustainability reflecting the normative and strategic dimension sustainability Special attention devoted the most recent development the concept sustainability science new field sustainability science emerging that seeks understand the fundamental character interactions between nature and society With view toward promoting research necessary achieve such advances initial set core questions for sustainability science was proposed The real lecture English part starts around within video 
179 en Expression Profiling Developmental Processes the Social Amoeba Dictyostelium
198 en Mining Relational Model Trees Multi Relational Data Mining MRDM refers the process discovering implicit previously unknown and potentially useful information from data scattered multiple tables relational database MRDM necessary face the substantial complexity added data mining tasks when properties units analysis investigated are potentially affected attributes related units analysis eventually different types and naturally modeled yield many tables the number object types Regression fundamental task MRDM where the goal examine samples past experience with known continuous answers response and generalize future cases throughan inductive process Following the mainstream MRDM research SMOTI resorts the structural approach order recursively partition data stored tightly coupled database and build multi relational model tree that captures the linear dependence between the response variable and one more explanatory variables both the reference objects and task relevant objects The model tree top down induced choosing each step either partition the training space split nodes introduce regression variable the linear models associated with the leaves regression nodes Internal regression nodes contribute the definition multiple models and capture global effects while straight line regressions with leaves capture only local effects The tight coupling with the database makes the knowledge data structures foreign keys available free charge guide the search the multi relational pattern space 
201 en Semantic Web Usage Mining – Overview and Case Studies this tutorial will review fundamentals web usage mining theory case studies and related topics Web usage mining topic which became the late 90ties one the first profitable areas data mining and which was necessity for the succesful commerce companies understand better their customers their behaviour and optimize the services accordingly this tutorial lecture will show several case studies which show approaches techniques and results coming out this area 
203 en KDD CUP 2004 Decision trees are intelligible but they perform well enough that you should use them Have SVMs replaced neural nets are neural nets still best for regression and SVMs best for classification Boosting maximizes margins similar SVMs but can boosting compete with SVMs And does compete better boost weak models theory might suggest boost stronger models Bagging simpler than boosting how well does bagging stack against boosting Breiman said Random Forests are better than bagging and good boosting Was right And what about old friends like logistic regression KNN and naive bayes Should they relegated the history books they still fill important niches this talk compare the performance ten supervised learning methods nine criteria Accuracy score Lift Precision Recall Break Even Point Area under the ROC Average Precision Squared Error Cross Entropy and Probability Calibration The results show that one learning method does all but some methods can repaired that they very well across all performance metrics particular show how obtain the best probabilities from max margin methods such SVMs and boosting via Platt Method and isotonic regression then describe new ensemble method that combines select models from these ten learning methods yield much better performance Although these ensembles perform extremely well they are too complex for many applications describe what doing try fix that Finally time permits discuss how the nine performance metrics relate each other and which them you probably should shouldn use During this talk briefly describe the learning methods and performance metrics help make the lecture accessible non specialists machine learning 
204 en Some Operations the Lattice Equivalence Relations Equivalence relations have played fundamental role through the History Mathematics These special relations are omnipresent everyday life that often forget about their proactive existence Though according some authors still much unknown about them this talk will studdy independence and permutability the context equivalence relations lattice given set refering the interpretation these mathematical concepts the Information Theory point view then present equivalence pairs finite type due Jónsson and introduce the operation star defined within equivalences rewrithing Dubreil important theorem describing permutable equivalences 
205 en Predicting Rare Extreme Values recent developments Predicting rare extreme values continuous variable key importance several important real world applications finance ecology etc this seminar start presenting the problem and its motivation and then through series existing approaches the problem highlighting their main limitations result this analysis then describe series recent developments our work this area that has lead the introduction the notions cost and benefit surfaces present these two new notions and their intuition the context handling regression problems with differentiated importance observations the case predicting rare extreme values formalize both notions and explain how they can used the context our target applications finish providing some initial results the use these notions the context evaluating models tasks related the prediction rare extreme values continuous variable 
212 en Telematic management Diabetes current European experiences The recent advances Information and Communication Technologies have transformed telemedicine into mature field that the research results collected over years can nowadays translated into clinical practice Diabetes management represents sort natural field for the application new distributed model care that fully exploits currently available telemedicine solutions For example the Health Care Financing Administration HCFA has recently funded the IDEATel project with million grant IDEATel the largest telemedicine effort ever funded the federal government Also Europe there are several projects that are testing innovative based services for supporting diabetes management Within the framework research programme the European Commission about projects have been devoted home care telemedicine applications them dealt with the application the management Diabetes The talk will divided into two parts the first part will given introduction the current status the European research telemedicine applications Diabetes care the second part will presented the M2DM project together with the some results obtained its clinical evaluation 
217 en Differential Evolution and Particle Swarm Optimization Partitional Clustering recent years many partitional clustering algorithms based genetic algorithms have been proposed tackle the problem finding the optimal partition data set Surprisingly very few studies considered alternative stochastic search heuristics other than GAs simulated annealing Two promising algorithms for numerical optimization which are hardly known outside the heuristic search field are particle swarm optimisation PSO and differential evolution this study compared the performance GAs with PSO and for medoid evolution approach clustering Moreover compared these results with the nominal classification means and random search lower bound Our results show that clearly and consistently superior compared GAs and PSO for hard clustering problems both respect precision well robustness reproducibility the results Only for trivial problems all algorithms can obtain comparable results Apart from superior performance very easy implement and requires hardly any parameter tuning compared substantial tuning for GAs and PSOs Our study shows that rather than GAs should receive primary attention partitional cluster algorithms 
226 en Comparison information retrieval techniques Latent semantic indexing LSI and Concept indexing Information retrieval the vector space model based literal matching terms the documents and the queries The model implemented creating the term document matrix which formed the base frequencies terms documents Literal matching terms does not necessarily retrieve all relevant documents Synonymy multiple words having the same meaning and polysemy words having multiple meaning are two major obstacles for efficient information retrieval Latent semantic indexing LSI and concept indexing are information retrieval techniques embedded the vector space model which address the problem synonymy and polysemy The method LSI information retrieval technique using low rank singular value decomposition SVD the term document matrix Although the LSI method has empirical success suffers from the lack interpretation for the low rank approximation and consequently the lack controls for accomplishing specific tasks information retrieval The method uses centroids clusters called concept decomposition for lowering the rank the term document matrix Here compare SVD LSI and terms matrix approximations and precision information retrieval 
230 en Can diagrammatic reasoning automated Theorems automated theorem proving are usually proved formal logical proofs However there subset problems which humans can prove the use geometric operations diagrams called diagrammatic proofs Insight often more clearly perceived these proofs than the corresponding algebraic proofs they capture intuitive notion truthfulness that humans find easy see and understand are investigating and automating such diagrammatic reasoning about mathematical theorems Concrete rather than general diagrams are used prove particular concrete instances the universally quantified theorem The diagrammatic proof captured the use geometric operations the diagram These operations are the inference steps the proof abstracted schematic proof the universally quantified theorem induced from these proof instances The constructive omega rule provides the mathematical basis for this step from schematic proofs theoremhood this way avoid the difficulty treating general case diagram One method confirming that the abstraction the schematic proof from the proof instances sound proving the correctness schematic proofs the meta theory diagrams These ideas have been implemented the system called DIAMOND which presented here 
240 en Distance based learning relational algebra representations will present general framework based concepts relationalnalgebra for distance based learning over relational schemata Thenadvantage the proposed framework that requires nontransformation the representation data that come the form ofnrelational databases directly applicable any relationalndatabase without the need type and mode definitions and conversionsnto logic programming the case with most relational learningnsystems based Inductive Logic Programming nnOur framework builds the notions tuples relations and sets ofntuples show how exploiting these elementary building blocks ournlearning examples are represented via tree like structures order tondefine distances between relational examples will explore twonavenues Both them are based the definition simple operators onntuples and sets tuples which are subsequently combined order tonprovide global operator the full relational structure The firstnapproach based the use classical distances over tuples and setsnof tuples and the second one the definition kernels nnThe user the system has his disposal number possible distancenoperators from which can choose alternatively what amounts tonsomething like model selection can let the system perform the selectionnautomatically Some results well known relational datasets will benpresented 
244 en FP6 IST behind the scenes The presentation will focus future research supported the European Union general and within the field Networked Organisations particular possible outlook future research this area will shown given its evolution during the past decade The presentation will cover overview past research the area well synopsis the challenges researchers are currently dealing with Furthermore insight will offered the work the remaining part FP6 and Work Programme 2005 2006 Finally some preliminary ideas towards the next Framework Programme FP7 will presented regarding its contents constituency and procedures 
249 en Object Identification Statistical Methods Numerical data fusion merging overlapping data files becomes hard problem global unique identifying keys exist the corresponding data sets Typical examples are the linkage address files supplied from different sources for commercial purposes money making area the merging special offers various media duplicate detection administrative record census ARC planed Germany where several autonomous heterogeneous registers are merged present three step procedure consisting the steps conversion attributes comparison values pair objects and classification matching problem pairs either same matched and not same not matched pay special attention the quality and the efficiency the methodology briefly discuss questions like correctness and completeness well pre selection techniques like blocking reduce the computational complexity pairwise comparisons The approach illustrated data from carefully composed benchmark data sets assume some basic knowledge computer science and classification supervised learning 
250 en Fast Exact Nearest Neighbor Arbitrary Dimensions with Cover Tree Given only metric between points how quickly can the nearest neighbor point found the worst case this time When these points happen obey dimensionality constraint more speed possible The cover tree space datastructure which allows answer queries log time given fixed intrinsic dimensionality also very practical algorithm yielding speedups between factor and 1000 all datasets tested This speedup has direct implications for several learning algorithms simulations and some systems
267 en Which Supervised Learning Method Works Best for What Empirical Comparison Learning Methods and Metrics Decision trees are intelligible but they perform well enough that you should use them Have SVMs replaced neural nets are neural nets still best for regression and SVMs best for classification Boosting maximizes margins similar SVMs but can boosting compete with SVMs And does compete better boost weak models theory might suggest boost stronger models Bagging simpler than boosting how well does bagging stack against boosting Breiman said Random Forests are better than bagging and good boosting Was right And what about old friends like logistic regression KNN and naive bayes Should they relegated the history books they still fill important niches this talk compare the performance ten supervised learning methods nine criteria Accuracy score Lift Precision Recall Break Even Point Area under the ROC Average Precision Squared Error Cross Entropy and Probability Calibration The results show that one learning method does all but some methods can repaired that they very well across all performance metrics particular show how obtain the best probabilities from max margin methods such SVMs and boosting via Platt Method and isotonic regression then describe new ensemble method that combines select models from these ten learning methods yield much better performance Although these ensembles perform extremely well they are too complex for many applications describe what doing try fix that Finally time permits discuss how the nine performance metrics relate each other and which them you probably should shouldn use During this talk briefly describe the learning methods and performance metrics help make the lecture accessible non specialists machine learning 
268 en The Dynamics Viral Marketing present analysis person person recommendation network consisting million people who made million recommendationsn half million products observed the propagation ofn recommendations and the cascade sizes which can explained stochastic model then established how the recommendation networkn grows over time and how effective from the viewpoint then sender and receiver the recommendations While averagen recommendations are not very effective inducing purchases and don not spread very far there are product and pricing categories forn which viral marketing seems very effective This joint work with Lada Adamic and Bernardo Huberman from Labs 
270 en Object Oriented Natural Language RequirementsSpecification Recent advances software technology such the development the Unified Modeling Language UML have not reduced the need for betterrequirements specification Natural language remains the method ofchoice for producing such documents These informal specifications mustbe turned into more formal designs the way completeimplementation These formal requirements are necessary not only for therapid prototyping the evolving software systems but also provide astandard reference model upon which all successive implementationsshould constructed This presentation describes going research inautomating the construction software systems from natural language requirements specification building upon the theories Two LevelGrammar TLG object oriented design and the Vienna Development Methodfor formal specification 
277 en Simulating the Evolution Language using Multi Agent Systems While have good understanding how life evolves have little idea how evolution occurs cultural systems particular interest this area the development language spoken words leave physical remains are unable find historical evidence this development Therefore alternative approach needed The approach many have taken simulation conducting simulations can test hypotheses different models the evolution communication comparing simulated results with those see language today Multi agent systems lend themselves naturally this approach with each entity the simulation being modelled different agent This ensures the mind each entity can kept private from all others and data can only transferred amongst entities language acts will present overview the most important approaches and results this field followed outline the research that currently engaged which seeks address the act communication artificial life environment within altruistic framework 
281 en Learning predictive clustering rules Predictive clustering based ideas from two machine learning subareas predictive modeling and clustering Methods for predictive clustering enable construct models for predicting multiple target variables which are normally simpler and more comprehensible than the corresponding collection models each predicting single variable this end predictive clustering has been restricted decision tree methods Our goal extend this approach methods for learning rules have developed generalized version the covering algorithm that enables learning ordered unordered rules single multiple target classification regression domains Performance the new method compares favorably existing methods Comparison single target and multiple target prediction models shows that multiple target models offer comparable performance and drastically lower complexity than the corresponding collections single target models 
294 en WWW Challenges Publishing Searching and Browsing the Web Web highly distributed and dynamic environment that poses number challenges designers and users Web services and applications our research promote user centric approach studying Web related issues and designing solutions that would improve the user experience show how exploratory study users behaviour led new opportunities for modifying and improving Web publishing practices and browser features present the findings from quantitative and qualitative analyses the users logs and the impact they had the prototype design point the depth problem understanding that has been achieved through the combined approach statistical analysis user logs and user interviews 
299 en Subgroup discovery experiments functional genomics Functional genomics typical scientific discovery domain characterized very large number attributes genes relative the number examples observations The danger data overfitting crucial such domains avoid this pitfall and achieve predictor robustness state art approaches construct complex classifiers that combine relatively weak contributions thousands genes attributes classify disease The complexity such classifiers limits their transparency and consequently the biological insight they can provide The goal this study apply this domain the methodology constructing simple yet robust logic based classifiers amenable direct expert interpretation The approach based the subgroup discovery rule learning methodology enhanced methods restricting the hypothesis search space exploiting the relevancy features that enter the rule construction process well their combinations that form the rules multi class functional genomics problem classifying fourteen cancer types based more than 16000 gene expression values used illustrate the methodology Some the discovered rules allow for novel biological interpretations 
301 en Privilege Management using 509 Attribute Certificates upravljanje digitalnimi pooblastili 
309 en Searching the Web Discovering and Clustering Related Terms The amount information the web growing fast that becoming more and more difficult for classical search engines find relevant information Indeed due the frenetic increase webpages written different languages and sometimes mis interpreted languages the degree ambiguity the human language has been constantly evolving levels unseen far However people still query the systems with more than words average consequence new information retrieval systems need proposed decrease the level ambiguity the queries Such systems usually make use query expansion techniques solve this problem this talk will present system based the automatic discovery terms that are related the query means helping the user search for relevant information This technique can classified within Interactive Query Expansion systems However unlike other systems use Web Mining Techniques discover related terms based different features such association measures document similarity document relevance etc the second part talk will present the future extensions our retrieval systems based the automatic discovery relations between related terms using agglomerative clustering techniques and auto fed WebWarehouse hope able propose less ambiguous query expansion terms than present systems where the user needs sort out the terms interested http webspy ubi Web spider Web Spider system that returns all related terms and links from given URL and given query The Spider has been developped using machine learning algorithm 
330 en Constructive Adaptive User Interfaces and Active Mining propose method locate relations and constraints between music score and its impressions which show that machine learning techniques may provide powerful tool for composing music and analyzing human feelings examine its generality modifying some arrangements provide the subjects with specified impression This paper introduces some user interfaces which are capable predicting feelings and creating new objects based seed structures such spectrums and their transition for sounds that have been extracted and are perceived favorable the test subject would like discuss role such interfaces the Active Mining project 
331 en Towards formal understanding object database query languages this seminar cover work have done whilst Ljubljana been studying various proposals for query languages for object databases particular the language OQL proposed the ODMG developed type system and operational semantics for this language and have proved some correctness properties There are some interesting complications with this language which justify the need for formality cover this material and try explain the formal techniques that have used type systems and operational semantics These are dominant themes programming language research This seminar should interesting people who use database query languages and are interested proposals for future generation databases try keep the talk self contained hopefully people wont need know operational semantics before coming 
332 en Information Dynamics Networked World The shift communication the internet particular email weblogs blogs and online communities presents opportunity study the information dynamics social networks large scale Blogs now numbering the millions are web pages updated using blogging software that makes easy for authors share new content online the form time stamped posts One can track how piece information spreads observing when appears different blogs The exact route the information takes not obvious since most blog authors will not explicitly identify the source the information when they write about Likely routes can inferred however analyzing timing information blogs past entries and the explicit network blogs linking one another through blogrolls posts While one can gain insights from observing how information passes from one individual another one can also analyze networks see how easily one can actively navigate them locate needed information individuals One test the navigability network the classic small world experiment where subjects attempt reach target individual through their chain acquaintances Examining email network within organization reveals how individuals are capable routing messages locally even though their knowledge the organization global social network limited 
337 en  short Tutorial Semantic Web The availability electronically stored information increased drastically through the development the World Wide Web Currently the WWW contains more than billion documents but support for accessing and precessing information limited Most information only presentable but not understandable computers Tim Berners Lee envisioned the Semantic Web that aims providing automated access information due machine processable semantics data Ontologies formalize shared understanding domain and therefore play crucial role for communication among human beings and software agents will present the underlying ideas the Semantic Web and will shortly introduce ontologies the backbone the Semantic Web Further will show how much effort necessary setup the Semantic Web and how tools can support this process Additionally Web and Data Mining techniques can used bootstrap the Semantic Web The idea Semantic Web Mining improve the results Web Mining exploiting the new semantic structures the web 
342 en Challenges the Computational Discovery Explanatory Scientific Models The growing amount scientific data has led the increased use computational discovery methods understand and interpret them However most work has relied knowledge lean techniques like clustering and classification learning which produce descriptive rather than explanatory models and has utilized formalisms developed statistics that results seldom make contact with current theories scientific notations this talk present new approach computational discovery that encodes explanatory scientific models sets quantitative processes simulates these models behavior over time incorporates background knowledge constrain model construction and induces these models from time series data robust manner illustrate this framework data and models from Earth science and microbiology two domains which explanatory process accounts occur frequently closing describe our progress toward interactive software environment for the construction evaluation and revision such explanatory scientific models This talk describes joint work with Kevin Arrigo Stephen Bay Lonnie Chrisman Dileep George Andrew Pohorille Javier Sanchez Dan Shapiro and Jeff Shrager 
360 en Spooky Stuff Metric Space Decision trees are intelligible but they perform well enough that you should use them Have SVMs replaced neural nets are neural nets still best for regression and SVMs best for classification Boosting maximizes margins similar SVMs but can boosting compete with SVMs And does compete better boost weak models theory might suggest boost stronger models Bagging simpler than boosting how well does bagging stack against boosting Breiman said Random Forests are better than bagging and good boosting Was right And what about old friends like logistic regression KNN and naive bayes Should they relegated the history books they still fill important niches this talk compare the performance ten supervised learning methods nine criteria Accuracy score Lift Precision Recall Break Even Point Area under the ROC Average Precision Squared Error Cross Entropy and Probability Calibration The results show that one learning method does all but some methods can repaired that they very well across all performance metrics particular show how obtain the best probabilities from max margin methods such SVMs and boosting via Platt Method and isotonic regression then describe new ensemble method that combines select models from these ten learning methods yield much better performance Although these ensembles perform extremely well they are too complex for many applications describe what doing try fix that Finally time permits discuss how the nine performance metrics relate each other and which them you probably should shouldn use During this talk briefly describe the learning methods and performance metrics help make the lecture accessible non specialists machine learning 
361 en Model Compression Decision trees are intelligible but they perform well enough that you should use them Have SVMs replaced neural nets are neural nets still best for regression and SVMs best for classification Boosting maximizes margins similar SVMs but can boosting compete with SVMs And does compete better boost weak models theory might suggest boost stronger models Bagging simpler than boosting how well does bagging stack against boosting Breiman said Random Forests are better than bagging and good boosting Was right And what about old friends like logistic regression KNN and naive bayes Should they relegated the history books they still fill important niches this talk compare the performance ten supervised learning methods nine criteria Accuracy score Lift Precision Recall Break Even Point Area under the ROC Average Precision Squared Error Cross Entropy and Probability Calibration The results show that one learning method does all but some methods can repaired that they very well across all performance metrics particular show how obtain the best probabilities from max margin methods such SVMs and boosting via Platt Method and isotonic regression then describe new ensemble method that combines select models from these ten learning methods yield much better performance Although these ensembles perform extremely well they are too complex for many applications describe what doing try fix that Finally time permits discuss how the nine performance metrics relate each other and which them you probably should shouldn use During this talk briefly describe the learning methods and performance metrics help make the lecture accessible non specialists machine learning 
370 en Direct Control Dynamic Systems with Evolutionary Algorithms Evolutionary algorithms for optimization dynamic problems have recently received increasing attention though moderately few investigations have been carried out real world problems From optimization point view online control particularly interesting class dynamic problems because the interactions between the controller and the controlled system this seminar introduce the technique called direct control with evolutionary algorithms and various aspects related this approach The aspects are exemplified empirical study greenhouse control 
371 en Subgroup discovery and rule evaluation ROC space Traditionally machine learning has focussed induction classification and prediction rules More recently non predictive descriptive induction gaining substantial interest machine learning researchers Two major trends descriptive induction are association rule learning and subgroup discovery this seminar present our recent work descriptive induction also argue that accuracy not always appropriate evaluation measure the descriptive induction framework and propose quality measures designed for subgroup evaluation ROC space After brief presentation the APRIORI and algorithm give detailed presentation the CN2 algorithm which includes new weighted covering algorithm new search heuristic weighted relative accuracy probabilistic classification instances and new measure for evaluating the results subgroup discovery area under ROC curve The presented work was done collaboration with Jovanoski APRIORI Gamberger algorithm Kavsek and Todorovski CN2 algorithm Our research was supported the Slovenian Ministry Education Science and Sport the IST 1999 11495 project Data Mining and Decision Support for Business Competitiveness European Virtual Enterprise and the British Council project Partnership Science PSP 
410 en  Tutorial Introduction Stochastic Differential Equations Continuous time Gaussian Markov Processes
412 en  SMO like algorithm for Kernel Conditional Random Fields
414 en Using features probability distributions achieve covariate shift
415 en Semantic text features from small world graphs present set methods for creating semantic representation from collection textual documents Given document collection use simple algorithm connect the documents into tree graph Using the imposed topology define feature and document similarity measures use the kernel alignment compare the quality various similarity measures Results show that the document similarity defined over the topology gives better alignment than standard cosine similarity measure bag words document representation 
416 en The Empirical Bayes Estimation Instantaneous Spike Rate with Gaussian Process Prior
417 en Optimal Support Vector Selection for Kernel Perceptrons
418 en Coevolution has been century and half since Darwin provided the first mechanistic explanation for the complexity the living things see around Only the last years have computational systems been employed try out natural selection complex artificial problems There have been some successes but the complexity artificially evolved systems remains very long way short the complexity that easy find biology Why this our understanding natural evolution missing something important How can improve our artificial problem solving methods make them work better large scale complex problems 
419 en Special Session Projects Multimodal Interaction VACE
420 en Some aspects Latent Structure Analysis Latent structure models involve real potentially observable variables and latent unobservable variables Depending the nature these variables whether they discrete continuous the framework includes various particular types model such factor analysis latent class analysis latent trait analysis latent profile models mixtures factor analysers state space models and others The simplest scenario single discrete latent variable includes finite mixture models hidden Markov chain models and hidden Markov random field models The talk will give overview the application maximum likelihood and Bayesian approaches the estimation parameters within these models emphasising especially the fact that computational complexity varies greatly among the different scenarios the case single discrete latent variable the issue assessing its cardinality will discussed the context questions such the appropriate number mixture components included mixture model the interests parsimony the minimum plausible cardinality such latent variable Techniques such the algorithm Markov chain Monte Carlo methods and variational approximations will featured the talk 
421 en XML structure mapping key problem for automating the processing semi structured resources the format heterogeneity among data sources For dealing with heterogeneous semi structured data the correspondence between the different formats has established The multiplicity and the rapid growth information sources have motivated researchers develop machine learning technologies for helping automate those transformations 
422 en TecnoVision ROBIN benchmarking object retrieval algorithms Technovision recent program the French Ministry Research and Technology that will fund evaluation projects the area computer vision Many vision algorithms have been proposed the past but comparing their performance has been difficult owing the lack common datasets Technovision aims correct this funding the creation large representative image datasets ROBIN Technovision proposal covering the evaluation object retrieval algorithms
423 en Fast SVM Approximations for Object Detection state the art accuracies object detection However for real time applications standard SVMs are usually too slow this work propose method for approximating SVM detector terms small number separable nonlinear filters are building work Romdhani ICCV 2001 where SVM face detector was approximated using the called reduced set algorithm and evaluated cascade However when using plain gray values features found more effective reduce the high computational cost for the pixel wise comparisons rather than focusing sparsity the detectors alone our approach constrain the reduced set optimization class nonlinear convolution filters which can evaluated more efficiently instead where and are the patch dimensions respectively demonstrate prototype our system which runs real time standard 
424 en Going beyond bag words dealing with text graph triples
425 en Dimensionality Reduction Gaussian Process Models
426 en Convergence MDL and Bayesian Methods introduce complexity measure which call complexity Based this concept present general information exponential inequality that measures the statistical complexity some deterministic and randomized estimators show that simple and clean finite sample convergence bounds can obtained from this approach particular are able improve some classical results concerning the convergence MDL density estimation and Bayesian posterior distributions
427 en Fast Learning Rates for Support Vector Machines establish learning rates the Bayes risk for support vector machines with hinge loss SVM Since theorem Devroye states that learning algorithm can learn with uniform rate the Bayes risk for all probability distributions have restrict the class considered distributions order obtain fast rates assume noise condition recently proposed Tsybakov and approximation condition terms the distribution and the reproducing kernel Hilbert space used the SVM For Gaussian RBF kernels with varying widths propose geometric noise assumption the distribution which ensures the approximation condition This geometric assumption not terms smoothness but describes the concentration the marginal distribution near the decision boundary particular are able describe nontrivial classes distributions for which SVM using Gaussian kernel can learn with almost linear rate 
428 en Universal Coding Prediction and Statistical consistency Bayesian inference Part this talk based results Barron 1986 and recent joint work with Langford 2004 introduce the information theoretic concepts universal coding and prediction Under weak conditions the prior Bayesian sequential prediction universal This means that code based the Bayesian predictive distribution allows one substantially compress data give simple proof the fact that universality implies consistency the Bayesian posterior follows that Bayesian inconsistency nonparametric settings Diaconis Freedman can only occur priors are used that not allow for data compression This gives frequentist rationale for Rissanen Minimum Description Length Principle also show that under misspecification the Bayesian predictions can substantially outperform the predictions the best distribution the model Ironically this implies that the Bayesian posterior can become inconsistent some sense good predictive performance implies inconsistency 
429 en Learning Reconstruct Human Pose and Motion from Silhouettes will describe our ongoing work learning based methods for recovering human body pose and motion from single images and from monocular image sequences The methods work directly with raw image observations and require neither explicit body model nor prior labelling body parts the image Instead they recover the body pose motion direct nonlinear regression against shape descriptors extracted automatically from image silhouettes contours 
431 en Object categorization with SVM kernels for local features will focus object categorization The basic idea combine the nice invariance propreties local features with the robustness SVM and the ability control generalization this framework 
432 en Probabilistic account for multi view stereo This paper describes method for dense depth reconstruction from wide baseline images wide baseline setting inherent difficulty which complicates the stereo correspondence problem self occlusion Also have consider the possibility that image pixels different images which are projections the same point the scene will have different colour values due non Lambertian effects discretization errors propose Bayesian approach tackle these problems this framework the images are regarded noisy measurements underlying true image function Also the image data considered incomplete the sense that not know which pixels from particular image are occluded the other images describe algorithm which iterates between estimating values for all hidden quantities and optimising the current depth estimates The algorithm has few free parameters displays stable convergence behaviour and generates accurate depth estimates 
433 en Special Session Projects Multimodal Interaction AMI
434 en Linear Projections and Gaussian Process Reconstructions
435 en Auxillary Variational Information Maximization for Dimensionality Reduction Mutual Information long studied measure formation content and many attempts apply feature extraction and stochastic coding have been made However general com putationally intractable compute and most previous studies redefine the criterion forms approximations Recently described proper ties simple lower bound and discussed its links some the popular dimensionality reduction techniques Here introduce richer family the auxiliary variational bounds which gener alize our previous approximations Our specific focus then apply ing the bound extracting informative lower dimensional projections the presence irreducible Gaussian noise show that our method produces significantly tighter bounds compared with the Gaussian approximation also show that learning projections multinomial auxiliary spaces may facilitate reconstructions the sources from noisy lower dimensional representations 
436 en Latent Semantic Variable Models the context information retrieval and natural language processing latent variable models are quite useful modeling and discovering hidden structure that often leads semantic data representations This talk will provide overview the most popular approaches and discuss the range possible applications for such models including language modeling hoc retrieval text categorization and collaborative filtering 
438 en Speaker Localization introduction system evaluation
439 en Searching Speech Research Agenda
440 en The “FAME” Interactive Space This paper describes the “FAME” multi modal demonstrator which integrates multiple communication modes – vision speech and object manipulation – combining the physical and virtual worlds provide support for multi cultural multi lingual communication and problem solving The major challenges are automatic perception human actions and understanding dialogs between people from different cultural linguistic backgrounds The system acts information butler which demonstrates context awareness using computer vision speech and dialog modeling The integrated computerenhanced human human communication has been publicly demonstrated the FORUM2004 Barcelona and IST2004 The Hague Specifically the “Interactive Space” described features “Augmented Table” for multi cultural interaction which allows several users the same time perform multi modal cross lingual document retrieval audio visual documents previously recorded “Intelligent Cameraman” during week long seminar 
441 en  update Information IST Call and FP7
444 en Hierarchical Multi Stream Posterior Based Speech Recognition System this paper present initial results towards boosting posterior based speech recognition systems estimating more informative posteriors using multiple streams features and taking into account acoustic context available the whole utterance well possible prior information such topological constraints These posteriors are estimated based state gamma posterior —nition typically used standard HMMs training extended the case multi stream HMMs This approach provides new principled theoretical framework for hierarchical estimation use posteriors multi stream feature combination and integrating appropriate context and prior knowledge posterior estimates the present work used the resulting gamma posteriors features for standard HMM GMM layer the OGI Digits database and reduced vocabulary version 1000 words the DARPA Conversational Telephone Speech text CTS task this resulted signi—cant performance improvement compared the stateof the art Tandem systems 
445 en Dynamic Bayesian Networks for Multimodal Interaction Dynamic Bayesian networks DBNs offer natural upgrade path beyond classical hidden Markov models and become especially relevant when temporal data contains higher order structure multiple modalities multi person interaction describe several instantiations dynamic Bayesian networks that are useful for modeling temporal phenomena spanning audio video and haptic channels single two person and multi person activity These models include input output hidden Markov models switched Kalman filters and most generally dynamical systems trees DSTs These models are used learn audio video interaction social activities video interaction multi person game playing and haptic video interaction robotic laparoscopy Model parameters are estimated from data unsupervised setting using generalized expectation maximization methods Subsequently these models can predict synthesize and classify various types rich multimodal human activity Experiments gesture interaction audio video conversation football game playing and surgical drill evaluation are shown 
447 en Gender issues user interfaces Most areas the computing sciences consider themselves either gender neutral they aim acknowledging physiologically based differences between women and men While the first standpoint draws the traditional ideal science rational objective and value free project the second one does not refer gender but sex differences – general tendency that supported recent interpretations brain research popular media 
448 en Physical Substrates All life forms rely information processing maintain their highly organised state Macromolecules and supramolecular structures are key the special properties that set living systems apart from dead matter The course will adopt engineering perspective introduce the molecular biology proteins RNA DNA and the physics thermodynamics kinetics dynamics required for understanding the operation the molecularmachinery work living cells this basis the role andthe processing information the molecular level will discussed covering topics such noise molecular motors conformational switching and intracellular networks leading decision making cells chemotaxis development Throughout the course the potential transfer concepts from nature artificial systems will explored robustness self repair nano engineering molecular computing 
451 en Random Walks All life forms rely information processing maintain their highly organised state Macromolecules and supramolecular structures are key the special properties that set living systems apart from dead matter The course will adopt engineering perspective introduce the molecular biology proteins RNA DNA and the physics thermodynamics kinetics dynamics required for understanding the operation the molecularmachinery work living cells this basis the role andthe processing information the molecular level will discussed covering topics such noise molecular motors conformational switching and intracellular networks leading decision making cells chemotaxis development Throughout the course the potential transfer concepts from nature artificial systems will explored robustness self repair nano engineering molecular computing 
453 en Genomic Repeat Visualisation Using Suffix Arrays Repeat analysis important technique for understanding the structure genomic sequences Here present visualisation for describing the repeat character sequence the repeat score plot This visualisation allows the identification all repeats within sequence 
456 en Modelling Intra Speaker Variability for Improved Speaker Recognition this paper present speaker recognition algorithm that models explicitly intra speaker inter session variability Such variability which caused channel noise and temporary speaker characteristics mood fatigue etc not modeled explicitly the state the art speaker recognition algorithms define session space which each session either train test spoken utterance vector then calculate rotation the session space for which the estimated intra speaker subspace trivially isolated and can modeled explicitly Due the high dimensionality the session space impossible use standard orthogonalization methods therefore used factorization based Givens rotations calculate the projection the NIST 2004 evaluation corpus recognition error rate was reduced compared the classic GMM state the art algorithm 
457 en  Numerical Characterization DNA Proteins Proteomics Maps and Proteome from their Graphical Representations will outline calculation selection mathematical invariants that can extracted from matrices associated with various graphical representations DNA Proteins Proteomics Maps and Proteome the case with proteome maps one can construct zigzag line connecting ordered spots map one may construct the partial order graph one may construct the cluster graph one may construct the nearest neighbor graph the sequential neighbor graph and one may construct the minimal spanning tree 
460 en Online Learning and Bregman Divergences Introduction Online Learning Predicting good the best expert Predicting good the best linear combination experts Additive versus multiplicative family updates Bregman divergences and Loss bounds Introduction Bregman divergences Relative loss bounds for the linear case Nonlinear case matching losses Duality and relation exponential families Extensions interpretations applications Online Batch Conversions Prior information the weight vector Some applications 
461 en  Social networks with overview graph drawing with demo system Pajek Network Graph Data The data can measured computed derived from the network The graph drawing already well established field with its own conference http www gd2005 org started 1992 ’traditional’ graph drawing the goal produce ’the best’ layout given graph SNA Social Network Analysis part data analysis Its goal get insight into the structure and characteristics given network 
462 en Kernel Methods this short course will discuss exponential families density estimation and conditional estimators such Gaussian Process classification regression and conditional random fields The key point that will providing unified view these estimation methods the second part will discuss how moment matching techniques Hilbert space can used design two sample tests and independence tests statistics will describe the basic principles and show how they can used correct covariate shift select features merge databases 
464 en Unifying Divergence Minimization and Statistical Inference via Convex Duality unify divergence minimization and statistical inference means convex duality the process doing prove that the dual approximate maximum entropy estimation maximum posteriori estimation Moreover our treatment leads stability and convergence bounds for many statistical learning problems 
465 en Identifying Temporal Patterns and Key Players Document Collections consider the problem analyzing the development document collection over time without requiring meaningful citation data Given collection timestamped documents formulate and explore the following two questions First what are the main topics and how these topics develop over time Second gain insight into the dynamics driving this development what are the documents and who are the authors that are most influential this process Unlike prior work citation analysis propose methods addressing these questions without requiring the availability citation data The methods use only the text the documents input Consequentially they are applicable much wider range document collections email blogs etc most which lack meaningful citation data evaluate our methods the proceedings the Neural Information Processing Systems NIPS conference Even with the preliminary methods that implemented the results show that the methods are effective and that addressing the questions based the text alone feasible fact the text based methods sometimes even identify influential papers that are missed citation analysis 
466 en Facial expression recognition and emotion recognition from speech The presentation tackles the problem recognizing the emotions based video and audio data analysis fully automatic facial expression recognition system based three components face detection facial characteristic point extraction and classification Face detection employed boosting simple rectangle Haar like features that give decent representation the face These features also allow the differentiation between face and non face The boosting algorithm combined with Evolutionary Search speed the overall search time Facial characteristic points FCP are extracted from the detected faces The same technique applied faces utilized for this purpose Additionally FCP extraction using corner detection methods and brightness distribution has also been considered Finally after retrieving the required FCPs the emotion the facial expression can determined 
467 en Visualization text document corpus From the automated text processing point view natural language very redundant the sense that many different words share common similar meaning For computer this can hard understand without some background knowledge Latent Semantic Indexing LSI technique that helps extracting some this background knowledge from corpus text documents 
469 en Discrete PCA Methods for analysis principal components discrete data have existed for some time under various names such grade membership modelling probabilistic latent semantic indexing genotype inference with admixture non negative matrix factorization latent Dirichlet allocation multinomial PCA and Gamma Poisson models Statistical methodologies for developing algorithms are equally varied although this talk will focus the Bayesian framework The most well published application genetype inference but text analysis now increasingly seeing use because the algorithms cope with very large sparse matrices This talk will present the general model discrete version both PCA and ICA present alternative representations and several algorithms mean field and Gibbs 
471 en Machine Learning Reductions There are several different classification problems commonly encountered real world applications such importance weighted classification cost sensitive classification reinforcement learning regression and others Many these problems can related each other simple machines reductions that transform problems one type into problems another type Finding reduction from your problem more common problem allows the reuse simple learning algorithms solve relatively complex problems also induces organization learning problems — problems that can easily reduced each other are nearby and problems which can not reduced are not close 
473 en Coevolution has been century and half since Darwin provided the first mechanistic explanation for the complexity the living things see around Only the last years have computational systems been employed try out natural selection complex artificial problems There have been some successes but the complexity artificially evolved systems remains very long way short the complexity that easy find biology Why this our understanding natural evolution missing something important How can improve our artificial problem solving methods make them work better large scale complex problems 
475 en  search Non Gaussian Components High Dimensional Distribution high dimensional data analysis finding non Gaussian components important preprocessing step for efficient information processing This article proposes new linear method identify the non Gaussian subspace within very general semi parametric framework Our proposed method NGCA Non Gaussian Component Analysis essentially based the theoretical fact that via arbitrary nonlinear function vector which approximately belongs the low dimensional non Gaussian subspace can constructed Since different nonlinear functions yield different directions one can obtain approximate subspace from set different nonlinear functions PCA then applied identify the non Gaussian subspace numerical study demonstrates the usefulness our method 
476 en How Teach Support Vector Machine Learn Vector Outputs
477 en Structured Linear Models Over the last five years have been able extend the theory linear classifiers structure prediction problems combining the benefits discriminative learning and structured probabilistic models like hidden Markov models will review these models and their learning algorithms and exemplify their use text processing with focus information extraction from biomedical text 
478 en Machine Learning for Sequential Data Comparative Study with Applications Natural Language Processing
487 en Information Retrieval and Text Mining This four hour course will provide overview applications machine learning and statistics problems information retrieval and text mining More specifically will cover tasks like document categorization concept based information retrieval question answering topic detection and document clustering information extraction and recommender systems The emphasis showing how machine learning techniques can help automatically organize content and provide efficient access information textual form 
491 en Top down bottom methods for hierarchical classification deal with hierarchical classification the general case when instance could associated with multiple and partial paths given taxonomy approach the problem from different perspectives ”top down bottom ” but also ” line batch” and ”theoretical experimental” this talk briefly present our recent research experience this subject matter 
492 en Exponential Families Feature Space this introductory course will discuss how log linear models can extended feature space These log linear models have been studied statisticians for long time under the name exponential family probability distributions provide unified framework which can used view many existing kernel algorithms special cases Our framework also allows derive many natural generalizations existing algorithms particular show how can recover Gaussian Processes Support Vector Machines multi class discrimination and sequence annotation via Conditional Random Fields also show deal with missing data and perform MAP estimation Conditional Random Fields feature space The requisite background for the course will covered briskly the first two lectures Knowledge linear algebra and familiarity with functional analysis will helpful 
498 en Learning with Kernels The course will cover the basics Support Vector Machines and related kernel methods Kernel and Feature Spaces Large Margin Classification Basic Ideas Learning Theory Support Vector Machines Other Kernel Algorithms
502 en Evolution Complexity has been century and half since Darwin provided the first mechanistic explanation for the complexity the living things see around Only the last years have computational systems been employed try out natural selection complex artificial problems There have been some successes but the complexity artificially evolved systems remains very long way short the complexity that easy find biology Why this our understanding natural evolution missing something important How can improve our artificial problem solving methods make them work better large scale complex problems 
505 en Probabilistic Non Linear Principal Component Analysis with Gaussian Process Latent Variables known that Principal Component Analysis has underlying probabilistic representation based latent variable model Principal component analysis PCA recovered when the latent variables are integrated out and the parameters the model are optimised maximum likelihood less well known that the dual approach integrating out the parameters and optimising with respect the latent variables also leads PCA The marginalised likelihood this case takes the form Gaussian process mappings with linear Covariance functions from latent space observed space which refer Gaussian Process Latent Variable Model GPLVM This dual probabilistic PCA still linear latent variable model but looking beyond the inner product kernel for covariance function can develop non linear probabilistic PCA 
507 en Research Problems applaying Interactive Systems Towards Taxonomy 
508 en Special Session Projects Multimodal Interaction CHIL
512 en The exploration and exploitation tradeoff Strategy learning and queries
513 en Overview Results Pump Priming Project
517 en Exponential Families Feature Space this introductory course will discuss how log linear models can extended feature space These log linear models have been studied statisticians for long time under the name exponential family probability distributions provide unified framework which can used view many existing kernel algorithms special cases Our framework also allows derive many natural generalizations existing algorithms particular show how can recover Gaussian Processes Support Vector Machines multi class discrimination and sequence annotation via Conditional Random Fields also show deal with missing data and perform MAP estimation Conditional Random Fields feature space The requisite background for the course will covered briskly the first two lectures Knowledge linear algebra and familiarity with functional analysis will helpful 
519 en Kernel Methods for Higher Order Image Statistics The conditions under which natural vision systems evolved show statistical regularities determined both the environment and the actions the organism Many aspects biological vision can understood evolutionary adaptations these regularities This demonstrated the recent sucess explaining properties retinal and cortical neurons from the statistics natural images the same time observe increasing interest statistical modeling techniques the computer vision community Here the motivation comes from the need for powerful image models image processing tasks such super resolution denoising the literature the statistical analysis natural images has mainly been done with linear techniques such Principal Component Analysis PCA Fourier analysis These techniques capture only the second order statistics image ensemble large part the interesting image structure however contained the higher order statistics Unfortunately the estimation these statistics involves huge number terms which makes their explicit computation for images infeasible practice Kernel methods provide implicit access higher order statistics that avoids this combinatorial explosion the course start with overview existing approaches image statistics The need beyond the usual linear second order techniques will lead the classical higher order statistics such Wiener series higher order cumulants and spectra will see that the exponential number terms involved these statistics prevents them from being applied images This motivates the introduction kernel techniques Here will discuss two approaches The Wiener series can estimated implicitly via polynomial kernel regression will use this technique decompose image into components that are characterized pixel interactions given order Kernel PCA image patches provides powerful image model that takes higher order statistics into account will show applications this model various image processing tasks 
520 en Exponential Families Feature Space Part this introductory course will discuss how log linear models can extended feature space These log linear models have been studied statisticians for long time under the name exponential family probability distributions provide unified framework which can used view many existing kernel algorithms special cases Our framework also allows derive many natural generalizations existing algorithms particular show how can recover Gaussian Processes Support Vector Machines multi class discrimination and sequence annotation via Conditional Random Fields also show deal with missing data and perform MAP estimation Conditional Random Fields feature space The requisite background for the course will covered briskly the first two lectures Knowledge linear algebra and familiarity with functional analysis will helpful 
521 en Exponential Families Feature Space Part this introductory course will discuss how log linear models can extended feature space These log linear models have been studied statisticians for long time under the name exponential family probability distributions provide unified framework which can used view many existing kernel algorithms special cases Our framework also allows derive many natural generalizations existing algorithms particular show how can recover Gaussian Processes Support Vector Machines multi class discrimination and sequence annotation via Conditional Random Fields also show deal with missing data and perform MAP estimation Conditional Random Fields feature space The requisite background for the course will covered briskly the first two lectures Knowledge linear algebra and familiarity with functional analysis will helpful 
522 en Evolutionary Algorithms has been century and half since Darwin provided the first mechanistic explanation for the complexity the living things see around Only the last years have computational systems been employed try out natural selection complex artificial problems There have been some successes but the complexity artificially evolved systems remains very long way short the complexity that easy find biology Why this our understanding natural evolution missing something important How can improve our artificial problem solving methods make them work better large scale complex problems 
523 en Uncertainty Dynamics and Multimodal interaction
524 en Audio Visual Processing Meetings Seven Questions and Current AMI Answers
525 en Elie two level boundary classification approach adaptive information extraction
527 en Pascal Challenge Evaluating Machine Learning for Information Extraction Goals Results and Conclusions
528 en Selective Sampling for Information Extraction with Committee Classifiers
529 en Template Sampling for Leveraging Domain Knowledge Information Extraction
531 en Rectifaying Fluctuations All life forms rely information processing maintain their highly organised state Macromolecules and supramolecular structures are key the special properties that set living systems apart from dead matter The course will adopt engineering perspective introduce the molecular biology proteins RNA DNA and the physics thermodynamics kinetics dynamics required for understanding the operation the molecularmachinery work living cells this basis the role andthe processing information the molecular level will discussed covering topics such noise molecular motors conformational switching and intracellular networks leading decision making cells chemotaxis development Throughout the course the potential transfer concepts from nature artificial systems will explored robustness self repair nano engineering molecular computing 
532 en Visualisation Cost Landscapes Combinatorial Optimisation Problems Understanding the structure the cost landscape optimisation problems important for algorithm design this talk discuss one approach based Barrier Trees which captures the structure the local minima and barriers between minima for search spaces with states This structure allows visualisation heuristic search strategies Furthermore the visualisation can used construct model the problem which captures many the relevant features the real problem but with vastly reduced number states The model can used for investigating optimal heuristic strategies 
533 en Time Distance – New Generic Approach for Analysis and Visualiziation Time Related Data The art handling different views data crucial for discovering the relevant patterns and for providing broader framework for policy analysis The new generic time distance approach with associated novel statistical measure time distance offers new view data that exceptionally easy understand and communicate and allows for developing and exploring new hypotheses and perspectives 
534 en Regret the Best Regret the Average study regret minimization algorithms focusing not only their regret the best expert but also their regret the average all experts and the worst expert show that any algorithm that achieves only regret the best expert must the worst case suffer regret the average and that for wide class update rules that includes many existing regret algorithms such weighted majority exponential weights follow the perturbed leader and others the product the regret the best and the regret the average describe and analyze new algorithm based the exponential weights algorithm that achieves cumulative regret only log the best expert and has constant regret the average with dependence either also give simple algorithm whose payoff always better equal the worst expert and has regret the best expert 
535 en Use variance estimation the multi armed bandit problem important aspect most decision making problems concerns the appropriate balance between exploitation acting optimally according the partial knowledge acquired far and exploration the environment acting sub optimally order refine the current knowledge and improve future decisions typical example this called exploration versus exploitation dilemma the multi armed bandit problem for which many strategies have been developed Here investigate policies based the choice the arm having the highest upper confidence bound where the bound takes into account the empirical variance the different arms Such algorithm was found earlier outperform its peers series numerical experiments The main contribution this paper the theoretical investigation this algorithm Our contribution here twofold First prove that with probability least the regret after plays variant the UCB algorithm called UCB upper bounded constant that scales linearly with log but which independent from also analyse variant which closer the algorithm suggested earlier prove logarithmic bound the expected regret this algorithm and argue that the bound scales favourably with the variance the suboptimal arms 
536 en Finite horizon exploration for path integral control problems have recently developed path integral method for solving class non linear stochastic control problems the continuous domain Path integral control can applied for timedependent finite horizon tasks motor control coordination between agents and static tasks which behave similar discounted reward reinforcement learning this control formalism the cost togo value function can solved explicitly function the environment and rewards path integral Thus for control one does not need solve the Bellman equation The computation the path integral can also complex but one can use methods and concepts from statistical physics such Monte Carlo sampling the Laplace approximation obtain efficient approximations One can also generalize this control formalism multiple agents that jointly solve task this case the agents need coordinate their actions not only through time but also among each other was recently shown that the problem can mapped graphical model inference problem and can solved using the junction tree algorithm Exact control solutions can computed for instance with hundreds agents depending the complexity the cost function 
538 en Evidence Integration Bioinformatics Biologists frequently use databases for example when biologist encounters some unfamiliar proteins will use databases get preliminary idea what known about them The databases can often interpreted lists assertions example protein protein interaction database each entry pair proteins that are asserted interact along with the supporting evidence Often candidate for inclusion such database can supported variety fundamentally different ways methodological challenge how effectively combine these different sources evidence make accurate aggregate predictions Ideas from machine learning are useful for this will describe some the special properties problems like this and relevant methods from machine learning including algorithms based bayesian networks boosting and SVMs 
539 en Semi supervised Learning Manifold Methods
541 en Empirical Comparisons Learning Methods Case Studies Decision trees may intelligible but can they cut the mustard Have SVMs replaced neural nets are neural nets still best for regression and SVMs best for classification Boosting maximizes margin much like SVMs but can boosting compete with SVMs And better boost weak models theory suggests boost stronger models Bagging much easier than boosting how well does bagging stack against boosting Bagging supposed best with low bias high variance methods like decision trees bag lower variance models like neural nets are they good bagged trees What happens bagging with steroids switch random forests And what about old friends like nearest neighbor — should they just put out pasture this lecture compare the performance variety popular machine learning methods nine performance criteria Accuracy score Lift Precision Recall Break Even Point Area under the ROC Average Precision Squared Error Cross Entropy and Probabilistic Calibration show that while one learning method does all possible repair some them that they well all metrics then describe NACHOS new ensemble method that does even better building top these other learning methods Finally discuss how the nine performance metrics relate each other and look few case studies show why important use the right metric for each problem 
542 en Trees for Regression and Classification Tree models are widely used for regression and classification problems with interpretability and ease implementation being among their chief attributes Despite the widespread use tree models comprehensive theoretical analysis their performance has only begun emerge recent years This lecture provides overview tree modeling theory and methods with emphasis risk bounds oracle inequalities approximation theory and rates convergence variety contexts Special attention devoted decision trees and wavelet based regression methods two the most well known examples tree models The choice loss function squared error absolute error error plays pivotal role both theory and methods particular optimal tree selection rules vary dramatically depending the loss function employed Despite these differences suitable tree based models coupled with appropriate selection rules can provide fast algorithms and near minimax optimal performance very broad range regression and classification problems Examples from image reconstruction and pattern classification will demonstrate the effectiveness trees practice 
543 en Boosting Boosting general method for producing very accurate classification rule combining rough and moderately inaccurate rules thumb While rooted theoretical framework machine learning boosting has been found perform quite well empirically This tutorial will introduce the boosting algorithm AdaBoost and explain the underlying theory boosting including explanations that have been given why boosting often does not suffer from overfitting well some the myriad other theoretical points view that have been taken this algorithm Some recent applications and extensions boosting will also described 
544 en Energy based models Learning for Invariant Image Recognition
545 en Algorithms for Learning and their Estimates will try give elementary account bounds for regularized least squares that reflects our current knowledge The framework for the discussion that Reproducing Kernel Hilbert Spaces with regression point view corollary these ideas will see some estimates for the binary classification problem The talk will based joint work with Felipe Cucker and Ding Xuan Zhou 
546 en Online Learning with Kernels Online learning concerned with the task making decisions the fly observations are received describe and analyze several online learning tasks through the same algorithmic prism start with online binary classification and show how build simple yet efficient and effective online algorithms that incorporate kernel functions describe how analyze the algorithms the mistake bound model for both separable and inseparable settings then describe numerous generalizations online learning with kernels other often more complex problems Specifically discuss learning algorithms for uniclass prediction regression multiclass problems and sequence prediction conclude with discussion implications batch learning and generalization Based joint works with Koby Crammer Ofer Dekel Vineet Gupta Joseph Keshet Andrew Shai Shalev Shwartz Lavi Shpigelman 
557 en Optimisation has been century and half since Darwin provided the first mechanistic explanation for the complexity the living things see around Only the last years have computational systems been employed try out natural selection complex artificial problems There have been some successes but the complexity artificially evolved systems remains very long way short the complexity that easy find biology Why this our understanding natural evolution missing something important How can improve our artificial problem solving methods make them work better large scale complex problems 
558 en The Sparse Grid Method The sparse grid method special discretization technique which allows cope with the curse dimensionality some extent based hierarchical basis and sparse tensor product decompositon Sparse grids have been successfully used solve partial differential equations the past and more recently have been shown competitive for learning problems well The lecture will provide general introduction the major properties sparse grids and present the sparse grid combination technique for classification and regression 
563 en Nonparametric Bayesian Models Machine Learning Bayesian methods make possible handle uncertainty principled manner sidestep the problem overfitting and incorporate domain knowledge However most parametric models are too limited adequately model complex real world problems Thus interest has shifted nonparametric models which can capture much richer and more complex probability distributions This talk will review some the core nonparametric tools for regression and classification Gaussian processes GPs and density estimation Dirichlet process mixtures will then focus extensions these basic tools such mixtures GPs warped GPs and GPs for ordinal regression and approximation methods which allow efficient inference these models such expectation propagation 
564 en Applications Bayesian Sensitivity and Uncertainty Analysis the Statistical Analysis Computer Simulators for Carbon Dynamics Uncertainties about the dynamics carbon forest ecosystems have major impact defining and verifying policies evident from the difficulties ratifying the Kyoto protocol Quantifying and reducing this uncertainty requires the combination mathematical models for ecological processes and earth observation data within unifying statistical framework The Centre for Terrestrial Carbon Dynamics CTCD developing several computer codes simulate the relevant processes different spatial and temporal scales Inputs theses codes given site describe the characteristics the vegetation grown there Soil and climate data are also used drive the model talk will illustrate the use efficient Bayesian tools both the development these codes and their use for prediction and uncertainty reduction The first step build emulator the computer code The emulator statistical representation the code output based Gaussian process prior model From this can derive inferences about range sensitivity and uncertainty measures Sensitivity analysis performed find out the level influence each input group inputs have the output This can lead efficiency gains revealing inactive inputs Examination the expected response curve the output function individual inputs has also uncovered number coding errors Uncertainty analysis employed assess the uncertainty the prediction resulting from the various uncertain input conditions also tells where concentrate research effort reducing uncertainties inputs want reduce the total uncertainty the output Conventional approaches sensitivity analysis and uncertainty analysis involve Monte Carlo sampling code outputs This highly inefficient and not feasible for complex models Bayesian methods can reduce the required number simulator runs several orders magnitude will also mention some extensions the methodology that are being developed handle the dynamic and multivariate nature the CTCD vegetation models 
565 en Accessing Multimodal Meeting Data Systems Problems and Possibilities the amount multimodal meetings data being recorded increases does the need for sophisticated mechanisms for accessing this data This process complicated the different informational needs users well the range data collected from meetings This paper examines the current state the art meeting browsers examine both systems specifically designed for browsing multimodal meetings data and those designed browse data collected from different environments for example broadcast news and lectures result this analysis highlight potential directions for future research semantic access filtered presentation limited display environments browser evaluation and user requirements capture 
566 en  research initiatives multimodal interaction overview recent research initiatives the area multimodal interfaces and natural interactivity with examples funded projects Plans for the remainder FP6 and outline the roadmap FP7 2007 will presented 
567 en Confidence Measures Speech Recognition confidence measure number between and that applied speech recognition output gives indication how confident are that the unit which has been applied phrase word phone correct Confidence measures are extremely useful any speech application that involves dialogue because they can guide the system towards more intelligent dialogue that faster and less frustrating for the user 
568 en Browsing Recorded Meetings With Ferret Finding elements interest within recorded meeting time consuming describe work progress the Ferret meeting browser which aims support this process displaying many types data These include media transcripts and processing results such speaker segmentations Users interact with these visualizations observe and control synchronized playback the recorded meeting 
569 en Machine Learning Uncertain Information and the Inevitability Negative Probabilities The only difference between probabilistic classical world and the equations the quantum world that somehow other appears the probabilities would have negative that the fundamental problem don know the answer but wanted explain that try best make the equations look near possible what would imitable classical probabilistic computer get into trouble These are the words Richard Feynman famous keynote talk Simulating Physics with Computers was pointing out that have face intrinsic conceptual difficulty want understand the world through mimicking its behaviour with computational systems Actually not have esoteric quantum physics see some the same issues Machine Learning and inference from probabilistic estimators data driven modelling And the same way that Feynman did not know the resolution his problem are only just starting become aware some our own problems machine intelligence The principled approach Machine Intelligence that have now come accept through probabilistic viewpoint The Bayesian view inference subjective one and our knowledge the universe derives from observation But will argue that the use Machine Learning represent simulate the universe only allows generically non positive probabilities course can fudge some the more uncomfortable aspects that some these issues raise but still should make think about whether have got the correct working framework this talk want question parts our working machinery use Machine Learning its heart want challenge the assumption that probabilities have positive want give several arguments descriptive and formal indicate why the use positive probabilities ideal which both overly restrictive and unrealisable Indeed will argue that the use non positive probabilities both inevitable and natural this will need use some old mathematical ideas from classical statistics and some more modern ideas from information theory will use some simple examples and proofs from Machine Learning applied regression and classification tasks and draw parallels with some basic quantum theory ideas The core the argument that modelling the universe through Machine Learning are obliged make inferences based finite and hence typically less than complete information can never know everything about situation and this gives our link between quantum mechanics and statistical inference through machine learning will try make case that inference through any finite data driven computation leads this apparent problem with probabilities the issue not just connected with quantum mechanics but more generic problem related trying simulate even classical probabilities Machine Learning ideas have enough time will also discuss the consequences this for information measures such Entropy and make the case for Fisher Information being more appropriate measure for our state knowledge about system instead 
570 en Probabilistic user interfaces Gaussian process priors have recently been applied control problems The GPs bring advantages their representation model prediction uncertainty and because the derivative Gaussian process Gaussian process they can also incorporate derivative information and analytically provide the uncertainty model derivatives This can used bring natural regularization control effort resulting appropriately cautious control can also used provide ‘quickened’ display which takes account model uncertainty will describe our work ambiguous probabilistic user interfaces and demonstrate some the techniques have developed for combining probabilistic models with continuous control and for providing feedback system uncertainty the user 
575 en Adaptive Behaviour and Emergence Continuing advances information and communications technology ICT are increasing the scale and connectivity today engineered systems Managing the resultant complexity becoming the central challenge for industry and government from software cities and even stock exchanges Across the wide range internationally leading research groups are addressing this challenge many cases they draw inspiration from biology which provides innumerable examples systems that cope with complexity From cells ecosystems biology achieves scalability adaptability self repair and robustness often exploiting emergent system level behaviours Achieving equivalent success engineered systems the root problem that face the first our short courses introduce the core concepts complexity the context both natural and engineered systems and explore the ways which new computational systems models and simulations are taking part complexity science through series lectures and workshop activities 
576 en Evolution Sex has been century and half since Darwin provided the first mechanistic explanation for the complexity the living things see around Only the last years have computational systems been employed try out natural selection complex artificial problems There have been some successes but the complexity artificially evolved systems remains very long way short the complexity that easy find biology Why this our understanding natural evolution missing something important How can improve our artificial problem solving methods make them work better large scale complex problems 
577 en Complexity Scale and Connectivity Continuing advances information and communications technology ICT are increasing the scale and connectivity today engineered systems Managing the resultant complexity becoming the central challenge for industry and government from software cities and even stock exchanges Across the wide range internationally leading research groups are addressing this challenge many cases they draw inspiration from biology which provides innumerable examples systems that cope with complexity From cells ecosystems biology achieves scalability adaptability self repair and robustness often exploiting emergent system level behaviours Achieving equivalent success engineered systems the root problem that face the first our short courses introduce the core concepts complexity the context both natural and engineered systems and explore the ways which new computational systems models and simulations are taking part complexity science through series lectures and workshop activities 
580 en Searching for People the Personal Work Space
581 en Measuring the Quality Multi document Cluster Headlines
582 en Engineered Complexity Continuing advances information and communications technology ICT are increasing the scale and connectivity today engineered systems Managing the resultant complexity becoming the central challenge for industry and government from software cities and even stock exchanges Across the wide range internationally leading research groups are addressing this challenge many cases they draw inspiration from biology which provides innumerable examples systems that cope with complexity From cells ecosystems biology achieves scalability adaptability self repair and robustness often exploiting emergent system level behaviours Achieving equivalent success engineered systems the root problem that face the first our short courses introduce the core concepts complexity the context both natural and engineered systems and explore the ways which new computational systems models and simulations are taking part complexity science through series lectures and workshop activities 
583 en Iterative Algorithms for Collaborative Filtering with Mixture Models
585 en Bootstrapping Ontology Evolution with Multimedia Information Extraction
586 en Proactive Information Retrieval User Modeling from Eye Tracking
587 en Convex transduction with the normalized cut
588 en Gaussian Process Basics How earth can plain old Gaussian distribution useful for sophisticated regression and machine learning tasks 
589 en Quasi Random Resamplings with Applications Rule Extraction Cross Validation and Bagging
590 en Visual Categorization with Bags Keypoints present novel method for generic visual categorization the problem identifying the object content natural images while generalizing across variations inherent the object class This bag keypoints method based vector quantization affine invariant descriptors image patches propose and compare two alternative implementations using different classifiers Naive Bayes and SVM The main advantages the method are that simple computationally efficient and intrinsically invariant present results for simultaneously classifying several semantic visual categories These results clearly demonstrate that the method robust background clutter and produces good categorization accuracy even without exploiting geometric information 
592 en The NIST Meeting Room Phase Corpus
594 en Unified Loss Function and Estimating Function Based Learning Current applications genomics and epidemiology concern high dimensional and possibly time dependent data structures and the questions interest correspond typically with high dimensional parameters interest such problems typically not possible priory pose model allowing estimation parametric rate and thereby requiring estimators non pathwise differentiable parameters will present general loss based estimation procedure which grounded theory minimax adaptive and generalizes existing estimation problems application this methodology yields data adaptive algorithms for conditional mean estimation conditional hazard density estimation based censored and uncensored data addition present general estimating function based estimation procedure for pathwise and non pathwise differentiable parameters Both methodologies involve loss based and estimating function based cross validation tool select among candidate estimators the parameter interest illustrate the methodology with some applications genomics and epidemiology 
595 en How classifieres can use solve any reasonable loss
596 en Penalized empirical risk minimization the estimation thresholds
597 en Generalization Error under Covariate Shift Input Dependent Estimation Generalization Error under Covariate Shift
599 en Faster Rates via Active Learning Traditional sampling and statistical learning theories deal with data collection processes that are completely independent the target function estimated aside from possible priori specifications reflective assumed properties the target refer such processes passive learning methods Alternatively one can envision sequential adaptive data collection procedures that use information gleaned from previous observations guide the process refer such feedback driven processes active learning methods While there have been many successful practical applications active learning there scant theoretical evidence support the effectiveness active over passive learning This talk covers some the most encouraging theoretical results date and focuses new results regarding the capabilities active methods for learning nonparametric smooth and piecewise smooth functions Significantly faster rates error convergence are achieved active learning compared passive learning cases involving functions whose complexity highly concentrated within small regions its domain functions that are smoothly varying apart from highly localized abrupt changes such jumps edges This joint work with Rui Castro and Rebecca Willett Please see our line technical report for further details http www ece wisc edu nowak ECE pdf
600 en Nonparametric Tests between Distributions Reproducing Kernel Hilbert Spaces have been mainly used for estimation Distributional tests this area were mainly concerned with tests for independence random variables give concentration measure bounds for the latter using easy compute criterion between spaces observations addition show that similar criterion can used easily for the purpose testing the identity between two distributions both cases prove necessary and sufficient conditions for the tests 
601 en The Limit One Class SVM this talk will present analysis the asymptotic behaviour the One Class support vector machine SVM popular algorithm for outlier detection will show that One Class SVM asymptotically estimates truncated version the density the distribution generating the data the case where the Gaussian kernel used with well calibrated decreasing bandwidth parameter and the regularization parameter involved the algorithm held fixed the training sample size goes infinity long version this work can found www lri vert Publi regularizeGaussianKernel which extensions the class case and more general convex loss functions are considered 
602 en  line learning competitive with reproducing kernel Hilbert spaces this talk will describe new technique for designing competitive line prediction algorithms and proving loss bounds for them The goal such algorithms perform almost well the best decision rules wide benchmark class with assumptions made about the way the observations are generated However standard algorithms this area can only deal with finite dimensional often countable benchmark classes The new technique gives similar results for decision rules ranging over infinite dimensional function spaces based recent game theoretic approach the foundations probability and more specifically recent results about defensive forecasting Given the probabilities produced defensive forecasting algorithm which are known well calibrated and have good resolution the long run the expected loss minimization principle used find suitable prediction 
609 en Learning Causal Graphical Models with Latent Variables
610 en Letter Phoneme Conversion Challenge and Discussion
613 en Large Scale Genomic Sequence Support Vector Machines
614 en Output kernel tree this paper generalize tree based methods the prediction structured output space The extension based kernelization the algorithm that allows one grow trees soon kernel can defined the output space The resulting algorithm called output kernel trees OK3 generalizes classification and regression trees principled way 
615 en First order logic for learning user models the semantic web why need this paper claim that learning first order logic framework crucial for the future user modeling applications the context the Semantic Web the remaining the paper first present some works that have currently been done for designing first order logic based languages for reasoning the the context user modeling the would then relevant use such languages model user’ behaviors and preferences show that discovering knowledge the context such languages could done using multi relational data mining that has already provided efficient prototypes Nevertheless some work remains done order use them that context and give some directions for that purpose 
616 en Organisational Resources Biological System All life forms rely information processing maintain their highly organised state Macromolecules and supramolecular structures are key the special properties that set living systems apart from dead matter The course will adopt engineering perspective introduce the molecular biology proteins RNA DNA and the physics thermodynamics kinetics dynamics required for understanding the operation the molecularmachinery work living cells this basis the role andthe processing information the molecular level will discussed covering topics such noise molecular motors conformational switching and intracellular networks leading decision making cells chemotaxis development Throughout the course the potential transfer concepts from nature artificial systems will explored robustness self repair nano engineering molecular computing 
620 en How Predict Sequences with Bayes MDL and Experts
621 en Large scale parallel implementations SVMs
622 en Working Set Selection Using the Second Order Information for SVMs
623 en Implementing SVM RDBMS Improved Scalability and Usability
624 en Online Learning with Memory Harness
629 en Ranking Individuals Group Comparisons discuss the problem ranking individuals from their group competition results Many real world problems are this type For example ranking players from team games important some sports machine learning this closely related multi class classification and probability estimates propose new models for estimating individuals abilities and hence rankings individuals develop easy and effective solution procedures Experiments real bridge records and multi class classification demonstrate the viability the proposed models 
630 en Protein Subcellular Localization Prediction Based Compartment Specific Biological Features Prediction subcellular localization proteins important for genome annotation protein function prediction and drug discovery present prediction method for Gram negative bacteria that uses ten one versus one support vector machine SVM classifiers where compartment specific biological features are selected input each SVM classifier The final prediction localization sites determined inte grating the results from ten binary classifiers using combination majority votes and probabilistic method The overall accuracy reaches which better than the state the art system ten fold cross validation evaluation bench mark data set demonstrate that feature selection guided biological knowledge and insights one versus one SVM classifiers can lead significant improvement the prediction performance Our model also used produce highly accurate prediction overall accuracy for proteins dual localizations 
632 en Kernel Methods Computational Biology Many problems computational biology and chemistry can formalized classical statistical problems pattern recognition regression dimension reduction with the caveat that the data are often not vectors Indeed objects such gene sequences small molecules protein structures phylogenetic trees name just few have particular structures which contain relevant information for the statistical problem but can hardly encoded into finite dimensional vector representations Kernel methods are class algorithms well suited for such problems Indeed they extend the applicability many statistical methods initially designed for vectors virtually any type data without the need for explicit vectorization the data The price pay for this extension non vectors the need define positive definite kernel between the objects formally equivalent implicit vectorization the data 
640 en  based relaxations for sparsity recovery and graphical model selection the high dimensional regime The problem estimating sparse signal embedded noise arises various contexts including signal denoising and approximation well graphical model selection The natural optimization theoretic formulation such problems involves norm constraints penalties the number non zero coefficients which leads hard problems general natural approach consider the use the norm computationally tractable surrogate has been pursued both signal processing and statistics 
650 en Greedy Feature Grouping for Optimal Discriminant Subspaces
651 en Constructing visual models with latent space approach
656 en Learning patterns omic data applications learning theory
657 en  introduction grammars and parsing From The following fairly advanced summary the material covering talk Don dismayed you find hard understand now hope that after talk will much clearer 
658 en Sex and has been century and half since Darwin provided the first mechanistic explanation for the complexity the living things see around Only the last years have computational systems been employed try out natural selection complex artificial problems There have been some successes but the complexity artificially evolved systems remains very long way short the complexity that easy find biology Why this our understanding natural evolution missing something important How can improve our artificial problem solving methods make them work better large scale complex problems 
659 en Inferring Latent Functions with Gaussian Processes Differential Equations
660 en The Shannon Entropy Metric Consumer Behavior
661 en Nonparametric Additive Models for Panels Time Series
664 en Principal Component and the Long Run
665 en Convergence Rate the Prokhorov Metric for Illposed Problems
666 en Regularization Quadratic Versus Sparsity enforcing and Deterministic Versus Stochastic Methods
667 en  path integral approach stochastic optimal control Many problems machine learning use probabilistic description Examples are pattern recognition methods and graphical models consequence this uniform description one can apply generic approximation methods such mean field theory and sampling methods Another important class machine learning problems are the reinforcement learning problems aka optimal control problems Here also probabilistic description used but now efficient mean field approximations have not been obtained this presentation consider linear quadratic control arbitrary dynamical system and show that for this class stochastic control problems the non linear Hamilton Jacobi Bellman equation can transformed into linear equation The transformation similar the transformation used relate the Schrödinger equation the Hamilton Jacobi formalism The computation can performed efficiently means forward diffusion process that can computed stochastic integration that can described path integral For this path integral expected that variational mean field approximation could derived 
668 en Measures behavior from periodic orbits
669 en Sequential Superparamagnetic Clustering Network Self organisation Process Clustering methods are useful tools for the unsupervised classification and analysis the elements set scene visual auditory scene Such methods can seen integral part cognition like operations performed artificial systems The problematic that usually priori information available about the structure the size the number classes Therefore unbiased methods that are able provide natural classification are interest has been shown Blatt Wiseman Domany superparamagnetic clustering promising algorithm that comes close ideal unbiased method gives the option choosing different classes different resolution levels however does not directly provide intrinsic criterion for the choice the most natural levels for finding the most natural classes 
670 en Leave one out prediction error diagnostic tool consider here predictability Systolic Blood Pressure SAP time series under paced respiration Akselrod 1985 and show that suitable index separates healthy subjects from Chronic Heart Failure CHF patients Systolic blood pressure SAP the maximal pressure within the cardiovascular system the heart pumps blood into the arteries Paced respiration breathing synchronized with some external signal well established tool for relaxation and for the treatment chronic pain and insomnia dental and facial pain etc Freedman and Woodward 1992 Entrainment between heart and respiration rate cardiorespiratory synchronization has been detected subjects undergoing paced respiration Pomortsev 1998 Paced breathing can prevent vasovagal syncope during head tilt testing healthy subjects under paced respiration the synchronization between the main processes governing cardiovascular system stronger than the synchronization the case spontaneous respiration Prokhorov 2003 However number important questions remain open about paced breathing including the dependence the frequency respiration and whether affects the autonomic balance 
671 en Simulation Modeling Issues Part Continuing advances information and communications technology ICT are increasing the scale and connectivity today engineered systems Managing the resultant complexity becoming the central challenge for industry and government from software cities and even stock exchanges Across the wide range internationally leading research groups are addressing this challenge many cases they draw inspiration from biology which provides innumerable examples systems that cope with complexity From cells ecosystems biology achieves scalability adaptability self repair and robustness often exploiting emergent system level behaviours Achieving equivalent success engineered systems the root problem that face the first our short courses introduce the core concepts complexity the context both natural and engineered systems and explore the ways which new computational systems models and simulations are taking part complexity science through series lectures and workshop activities 
672 en Simulation Modeling Part Continuing advances information and communications technology ICT are increasing the scale and connectivity today engineered systems Managing the resultant complexity becoming the central challenge for industry and government from software cities and even stock exchanges Across the wide range internationally leading research groups are addressing this challenge many cases they draw inspiration from biology which provides innumerable examples systems that cope with complexity From cells ecosystems biology achieves scalability adaptability self repair and robustness often exploiting emergent system level behaviours Achieving equivalent success engineered systems the root problem that face the first our short courses introduce the core concepts complexity the context both natural and engineered systems and explore the ways which new computational systems models and simulations are taking part complexity science through series lectures and workshop activities 
673 en Interdisciplinarity Continuing advances information and communications technology ICT are increasing the scale and connectivity today engineered systems Managing the resultant complexity becoming the central challenge for industry and government from software cities and even stock exchanges Across the wide range internationally leading research groups are addressing this challenge many cases they draw inspiration from biology which provides innumerable examples systems that cope with complexity From cells ecosystems biology achieves scalability adaptability self repair and robustness often exploiting emergent system level behaviours Achieving equivalent success engineered systems the root problem that face the first our short courses introduce the core concepts complexity the context both natural and engineered systems and explore the ways which new computational systems models and simulations are taking part complexity science through series lectures and workshop activities 
674 en Science Models and Theories Continuing advances information and communications technology ICT are increasing the scale and connectivity today engineered systems Managing the resultant complexity becoming the central challenge for industry and government from software cities and even stock exchanges Across the wide range internationally leading research groups are addressing this challenge many cases they draw inspiration from biology which provides innumerable examples systems that cope with complexity From cells ecosystems biology achieves scalability adaptability self repair and robustness often exploiting emergent system level behaviours Achieving equivalent success engineered systems the root problem that face the first our short courses introduce the core concepts complexity the context both natural and engineered systems and explore the ways which new computational systems models and simulations are taking part complexity science through series lectures and workshop activities 
676 en Short interviews MLSS05 Chicago John Langford
677 en Simulation Modeling Examples Continuing advances information and communications technology ICT are increasing the scale and connectivity today engineered systems Managing the resultant complexity becoming the central challenge for industry and government from software cities and even stock exchanges Across the wide range internationally leading research groups are addressing this challenge many cases they draw inspiration from biology which provides innumerable examples systems that cope with complexity From cells ecosystems biology achieves scalability adaptability self repair and robustness often exploiting emergent system level behaviours Achieving equivalent success engineered systems the root problem that face the first our short courses introduce the core concepts complexity the context both natural and engineered systems and explore the ways which new computational systems models and simulations are taking part complexity science through series lectures and workshop activities 
678 en Designing Simulation Model Continuing advances information and communications technology ICT are increasing the scale and connectivity today engineered systems Managing the resultant complexity becoming the central challenge for industry and government from software cities and even stock exchanges Across the wide range internationally leading research groups are addressing this challenge many cases they draw inspiration from biology which provides innumerable examples systems that cope with complexity From cells ecosystems biology achieves scalability adaptability self repair and robustness often exploiting emergent system level behaviours Achieving equivalent success engineered systems the root problem that face the first our short courses introduce the core concepts complexity the context both natural and engineered systems and explore the ways which new computational systems models and simulations are taking part complexity science through series lectures and workshop activities 
679 en Learning Structured Data Discriminative learning framework one the very successful fields machine learning The methods this paradigm such Boosting and Support Vector Machines have significantly advanced the state the art for classification improving the accuracy and increasing the applicability machine learning methods One the key benefits these methods their ability learn efficiently high dimensional feature spaces either the use implicit data representations via kernels explicit feature induction However traditionally these methods not exploit dependencies between class labels where more than one label predicted Many real world classification problems involve sequential temporal structural dependencies between multiple labels will investigate recent research generalizing discriminative methods learning structured domains These techniques combine the efficiency dynamic programming methods with the advantages the state the art learning methods 
682 en Learning Structured Data Discriminative learning framework one the very successful fields machine learning The methods this paradigm such Boosting and Support Vector Machines have significantly advanced the state the art for classification improving the accuracy and increasing the applicability machine learning methods One the key benefits these methods their ability learn efficiently high dimensional feature spaces either the use implicit data representations via kernels explicit feature induction However traditionally these methods not exploit dependencies between class labels where more than one label predicted Many real world classification problems involve sequential temporal structural dependencies between multiple labels will investigate recent research generalizing discriminative methods learning structured domains These techniques combine the efficiency dynamic programming methods with the advantages the state the art learning methods 
685 en Bayesian Learning Bayes Rule provides simple and powerful framework for machine learning This tutorial will organised follows will give motivation for the Bayesian framework from the point view rational coherent inference and highlight the important role the marginal likelihood Bayesian Occam Razor will discuss the question how one should choose sensible prior When Bayesian methods fail often because thought has gone into choosing reasonable prior Bayesian inference usually involves solving high dimensional integrals and sums will give overview numerical approximation techniques Laplace BIC variational bounds MCMC will talk about more recent work non parametric Bayesian inference such Gaussian processes Bayesian kernel machines Dirichlet process mixtures etc 
686 en  the Borders Statistics and Computer Science Machine learning computer science and prediction and classification statistics are essentially equivalent fields will try illustrate the relation between theory and practice this huge area few examples and results particular will try address apparent puzzle Worst case analyses using empirical process theory seem suggest that even for moderate data dimension and reasonable sample sizes good prediction supervised learning should very difficult the other hand practice seems indicate that even when the number dimensions very much higher than the number observations can often very well also discuss new method dimension estimation and some features cross validation 
688 en Context changes detection one class svms For system that aims taking into account the user need consider that there are many different behaviors well many different users Hence need adaptative unsupervised semi supervised learning methods Our idea take advantage wearable computers and wearable sensors indeed their use realistic least for certain categories people such pilots retrieve the current context the user Wearable sensors can physiological EMG ECG blood volume pressure physical accelerometers microphone Contexts are depending the application using the system and can behaviors affective states combinations these Since this problem context retrieval very complex choose detect changes first place instead labeling directly Indeed this way can apply unsupervised and fast methods which saves time for labeling the labeling task then applied only when changes are detected Our interest lies low level treatments and present non parametric change detection algorithm This algorithm meant provide sequences unlabeled contexts analyzed higher level applications Detection made from signals given non invasive sensors the user wearing Note that the methods presented here could well adapted external sensors 
689 en Automatically building domain model hypermedia applications This paper deals with the automatic building personalized hypermedia build upon ideas developed for educational hypermedia standard way build adaptive educational hypermedia relies the definition domain model and the use overlay user models Since much work has been done learning user models and adapting hypermedia based such user models the core problem lies the automatic definition domain model for static hypermedia describe approach automatically learn from the hypermedia content such domain model This model concept hierarchy where concepts are identified sets keywords learned from the collection propose the use visualization techniques such treemaps order monitor and analyze efficiently user and domain models 
690 en Feature Learning from Pairs Examples Collections Supervised Learning Tasks present algorithm which uses example pairs equal unequal class labels select projection kernel induced Hilbert space representation nite dimensional projections bounded lin ear functionals space Hilbert Schmidt operators exploited give bounds the Rademacher complexity the class hypotheses searched leading PAC type performance guarantees for the resulting feature maps The proposed algorithm returns the projection onto the span the principal eigenvectors empirical operator constructed terms the example pairs Experiments demonstrate ective trans fer knowledge between erent but related learning tasks 
691 en Identifying Feature Relevance using Random Forest Many feature selection algorithms are limited that they attempt identify relevant feature subsets examining the features individually This paper introduces technique for determining feature relevance using the average information gain achieved during the construction decision tree ensembles The technique introduces node complexity measure and statistical method for updating the feature sampling distribution based upon confidence intervals control the rate convergence Experiments demonstrate the potential this method for feature selection and subspace identification 
692 en Online feature selection for contextual time series data propose simple and eficient method for online feature selection from time series data Our method based calculating characteristics the erent features and calculating similarity values for feature pairs using Gaussian kernels Our motivation has been design method that can used select the most relevant context features for activity recognition Namely traditional feature selection methods have been designed for offline use and thus are not applicable our setting The eficiency our method evaluated using toy data and real context data gathered using accelerometer 
694 en Introduction and overview FMRI concepts and terminology
695 en Models for Trading Exploration and Exploitation using Upper Confidence Bounds
696 en Building and Employing Probabilistic User Models
697 en Activity modelling using email and web page classification This work explores the modelling user’ current activity using single document and very small collection classified documents describe the WeMAC approach for combining evidence from heterogeneous sources give prdict the user’ activity report evaluation the WeMAC model using two different document types emails and web pages assess its performance both tiny document sets and larger sets and assess its performance against “one bag” approach report promising results with average value 
698 en Overview decoding mental states and processes
704 en Statistical Learning Theory This course will give detailed introduction learning theory with focus the classification problem will shown how obtain pobabilistic bounds the generalization error for certain types algorithms The main themes will probabilistic inequalities and concentration inequalities union bounds chaining measuring the size function class Vapnik Chervonenkis dimension shattering dimension and Rademacher averages classification with real valued functions  Some knowledge probability theory would helpful but not required since the main tools will introduced 
705 en Monte Carlo Simulation methods The course provides introduction independent component analysis and source separation start from simple statistical principles examine connections information theory and sparse coding give overview available algorithmics also show how several key ideas ICA are illuminated information geometry 
708 en Hierarchical Gaussian Naive Bayes Classifier for Multiple Subject fMRI Data The Gaussian ¨ıve Bayes GNB classifier has been successfully applied fMRI data However not specifically designed account for data from multiple subjects and usually applied data from single subject referred GNB indiv extension the GNB classifier has been proposed referred GNB pooled which the data from all the subjects are combined together ¨ıvely assuming that they all come from the same subjects However this extension ignores subject specific variations that might exist Here describe another extension the GNB classifier—the hierarchical GNB classifier —that can account for subject specific variations and addition has the flexibility increase reduce the weight the contribution the data from the other subjects based the number examples available from the test subject 
709 en fMRI based decoding the modified default mode network mild cognitive impairment The diagnostic tool detect early stages Alzheimer’ Disease progressive neurodegenerative disease lacking until today FDG PET Fluorodeoxyglucose Positron Emission Tomography shows hypometabolic areas the brains pre demented patients suffering from mild cognitive impairment MCI The reduced activity may attributed disrupted connectivity the resting default mode network the brain this contribution study the detection such network using the framework blind signal processing technique identify hidden sources within multivariate mixture using source characteristics such statistical independence sparseness The results are compared FDG PET data 
710 en Learning Compare using Operator Valued Large Margin Classifiers The proposed method uses homonymous and heteronymous examplepairs train linear preprocessor kernel induced Hilbert space The algorithm seeks optimize the expected performance elementary classifiers generated from single future training examples The method justified PAC style generalization guarantees and the resulting algorithm has been tested problems geometrically invariant pattern recognition and face verification 
711 en Conformal Multi Instance Kernels the multiple instance learning setting each observation bag feature vectorsn which one more vectors indicates membership class The primaryn task identify any vectors the bag indicate class membership while ignoringn vectors that not describe here kernel based technique that definesn parametric family kernels via conformal transformations and jointly learnsn discriminant function over bags together with the optimal parameter settings ofn the kernel Learning conformal transformation effectively amounts weightingn regions the feature space according their contribution classification accuracy regions that are discriminative will weighted higher than regions that aren not This allows the classifier focus regions contributing classificationn accuracy while ignoring regions that correspond vectors found both positiven and negative bags show how parameters this transformation cann learned for support vector machines posing the problem multiple kerneln learning problem The resulting multiple instance classifier gives competitiven accuracy for several multi instance benchmark datasets from different domains 
712 en Learning Similarity Metrics with Invariance Properties
713 en Tutorial Statistical Machine Learning with Applications Multimodal Processing
714 en Neighbourhood Components Analysis and Metric Learning Say you want Nearest Neighbour classification Besides selecting you also have chose distance function order define ”nearest” ’ talk about method for learning – from the data itself – distance measure used KNN classification The learning algorithm Neighbourhood Components Analysis NCA directly maximizes stochastic variant the leave one out KNN score the training set course the resulting classification model non parametric making assumptions about the shape the class distributions the boundaries between them will also discuss variant the method which generalization Fisher’ discriminant and defines convex optimization problem trying collapse all examples the same class single point and trying push examples other classes infinitely far away approximating the metric with low rank matrix these learning algorithms can also used obtain low dimensional linear embedding the original input features allowing that can used for data visualization and very fast classification high dimensions 
715 en Fast Discriminative Component Analysis for Comparing Examples Two recent methods Neighborhood Components Analysis NCA and Informative Discriminant Analysis IDA search for class discriminative subspace discriminative components data equivalent learning distance metrics invariant changes perpendicular the subspace Constraining metrics subspace useful for regularizing the metrics and for dimensionality reduction introduce variant NCA and IDA that reduces their computational complexity from quadratic linear the number data samples replacing their purely non parametric class density estimates with semiparametric mixtures Gaussians terms accuracy the method shown perform well NCA benchmark data sets outperforming several popular linear dimensionality reduction methods 
717 en Improved Risk Tail Bounds for line Algorithms
718 en Application expectation consistent approximate inference will discuss two types applications approximate inference technique expectation consistent recently developed together with Ole Winther The method extension the TAP Thouless Anderson Palmer approach which originated the field disordered materials and which has been further developed become applicable variety scenarios probabilistic modelling machine laerning first application joint work with Doerthe Malzahn deals with approximation resampling methods such the bootstrap which allows estimate generalization errors supervised learning While the exact resampling approach requires the drawing many samples from the training data and costly repeated retraining the model the approximation attempts analytic average which combines the replica trick and inference method which can performed much faster the second application ongoing work discuss the scenario many solutions the framework and the possibility averaging them using Parisi hierarchical scheme 
719 en Expectation Consistent Approximate Inference propose novel framework for approximations intractable probabilistic models The method based free energy formulation inference and allows for simultaneous computation marginal expectations and the log partition function for continuous and discrete random variables Using exact perturbative representation the free energy around tractable model the approximation uses two tractable probability distributions which are consistent set moments and encode different features the original intractable distribution such way are able include nontrivial correlations which are neglected factorized variational Bayes approach test the framework toy benchmark problems for binary variables fully connected graphs and grids and compare with other methods such loopy belief propagation Good performance already achieved using single nodes tractable substructures Significant improvements are obtained when spanning tree used instead 
723 en Brain Computer Interfaces Brain Computer Interfacing BCI aims making use brain signals for the control objects spelling gaming and This tutorial will first provide brief overview the current BCI research activities and provide details recent developments both invasive and non invasive BCI systems second part taking physiologist point view the necessary neurological neurophysical background provided and medical applications are discussed The third part now from machine learning and signal processing perspective shows the wealth the complexity and the difficulties the data available truely enormous challenge real time multi variate very noise contaminated data stream processed and classified Main emphasis this part the tutorial placed feature extraction selection and preprocessing which includes among other techniques CSP and also ICA methods Finally report more detail about the Berlin Brain Computer BBCI Interface that based EEG signals and take the audience all the way from the measured signal the preprocessing and filtering the classification the respective application BCI communication discussed clincial setting and for gaming 
724 en Kikuchi free energies with weak consistency constraints change point learning switching linear dynamical systems Exact inference probabilistic models often infeasible due complicated conditional independence structure and troublesome local integrals Most challenging inference problems found physics such the computation the partition function Ising model Boltzmann machine are examples problems that suffer from complex structure All variables are binary but the cycles the model prevent efficient recursive formulation inference algorithm 
725 en Estimating MAP configurations graphical models exploiting structure The max product algorithm can used obtain approximate MAP assignments the probability distribution defined graphical model tree structured graphical models the MAP assignment exact and the max product algorithm equivalent the Viterbi algorithm general models one may run into the following problems The algorithm does not converge the single node marginals are not unique The first problem can solved using provably convergent double loop algorithm the second case not straightforward how obtain global assignment from the locally defined marginals due loops the graph obvious solution the second problem use the approximate marginals for pairs any tractable number nodes and use the correlations estimate global MAP assignment simple strategy define satisfiability problem which entails that the global MAP assignment should MAP assignment each local marginal This should principle solve the problem non unique marginals However this satisfiability problem not guaranteed have solution The existence solution depends critically the nature the interactions between the nodes the graphical model 
726 en Replica symmetry breaking the small world spin glass apply the cavity method Ising spin glass model small world lattice random bond graph super imposed upon dimensional ferromagnetic ring Using the scheme developed Mézard Parisi for the Bethe lattice evaluate observables for model with fixed connectivity and long range bonds Furthermore determine the stability the solution making ansatz the form the functional 1RSB order parameters 
727 en Generalized Belief Propagation Receiver for Near Optimal Detection Two Dimensional Channels with Memory propose generalized belief propagation GBP receiver for two dimensional channels with memory which applicative inter symbol interference ISI equalization and multi user detection MUD Our experimental study demonstrates that under non trivial interference conditions the performance this fully tractable GBP receiver almost identical the performance the optimal maximum posteriori MAP receiver 
728 en Approximations with Reweighted Generalized Belief Propagation Wainwright 2002 new general class upper bounds the log partition function arbitrary undirected graphical models has been developed This bound constructed taking convex combinations tractable distributions The experimental results published far concentrates combinations tree structured distributions leading convexified Bethe free energy which minimized the tree reweighted belief propagation algorithm One the favorable properties this class approximations that increasing the complexity the approximation guaranteed increase the precision The lack this guarantee notorious standard generalized belief propagation increase the complexity the approximating distributions taking combinations junction trees leading convexified Kikuchi free energy which minimized reweighted generalized belief propagation Experimental results for Ising grids well for fully connected Ising models are presented illustrating advantages and disadvantages the reweighting method approximate inference 
729 en Modified Belief Propagation Algorithm for Optimization Problems Belief propagation well known algorithm solve various optimization problems such error correcting codes graph colouring and satisfiability problems generally works well areas where the replica symmetric approximation holds but breaks down when replica symmetry breaking occurs Alternatives such Survey Propagation have been proposed with great success but are generally limited the zero temperature limit propose simple modification Belief Propagation that can also successfully deal with finite temperature scenarios and illustrate its efficiency several examples 
730 en Cluster Variation Method from statistical mechanics message passing algorithms The cluster variation method CVM hierarchy approximate variational techniques for discrete Ising like models equilibrium statistical mechanics improving the mean field approximation and the Bethe Peierls approximation which can regarded the lowest level the CVM The foundations the CVM are briefly reviewed considering different derivations the method and related techniques like for instance TAP equations and the cavity method Issues realizability and exactness are also addressed 
731 en Unified survey belief propagation approach for satisfiability this talk shall discuss modified message passing Belief Propagation procedure which can generally used minimize variational Bethe free energies statistical physics straightforward mapping this algorithm can easily applied combinatorial optimization problems such satisfiability the prototype hard problems show that the method can also extended the framework Survey Propagation recently proposed algorithm which still making use techniques borrowed from statistical physics overcomes problems encountered local search algorithms hard instances close the SAT UNSAT transition This allows obtain unified and quite stable message passing scheme which can used both the full replica symmetry breaking region where ordinary Belief Propagation usually does not converge and the hard region near the sat unsat transition where allows solve subformulae generated survey inspired decimation 
732 en Path Integral Method for Estimation Time Series
742 en  Unified Approach Deduction and Induction
744 en Trainable visual models for object classification The general theme the tutorial will trainable visual models for object classification will cover the difficulty the problem few approaches Perona and Welling Pictorial structures Felzenszwalb and Huttenlocher Borenstein and Ullman Agarwal and Roth Leibe and Schiele covering the method invariance data preparation and then into detail the constellation model end with research challenges
745 en Visual Categorization with Bags Keypoints present novel method for generic visual categorization the problem identifying the object content natural images while generalizing across variations inherent the object class This bag keypoints method based vector quantization affine invariant descriptors image patches propose and compare two alternative implementations using different classifiers Naïve Bayes and SVM The main advantages the method are that simple computationally efficient and intrinsically invariant present results for simultaneously classifying several semantic visual categories These results clearly demonstrate that the method robust background clutter and produces good categorization accuracy even without exploiting geometric information 
747 en Challenges Learning the Appearance Faces for Automated Image Analysis Part The variability images the human face challenges research machine vision since its beginning Sources variability not only include individual appearance but also cover external parameters such perspective and illumination that influence the image formation process heavily Research the analysis face images currently splits into the directions face detection and face recognition Approaches and problem setting this two areas are still quite different despite the common goal compensate for the large variability faces images both areas machine learning strategies are used learn from example faces general model the appearance human faces the first part our presentation would like review the current state the art face detection and face recognition second part will compare the different strategies used and try describe the requirements general image model that could serve basis detection well recognition research For face detection will focus methods based the estimation the probability distribution large number features computed face examples After selecting the subset features which appear most relevant the task faces are detected combining the outcome suitably defined statistical tests This method which based positive examples only seems give very promising results compared state the art techniques based both positive and negative examples face recognition will concentrate methods that use analysis synthesis framework such morphable models active appearance shape models Currently these approaches seem the most promising methods able account for variations perspective and illumination 
748 en Large scale multiclass classification based linear optimization One the most hard tasks image classification find method being applicable large scale multi class problems where the sample size and number the features are huge Linear discriminant analysis classica method for multi class classification which was introduced Fisher 1936 plays important role the machine learning society recently The kernelized version this method are discussed several papers however they generally deal with the two class version this approach Bartlett recognised 1938 there strong relationship between the Fisher Discriminant and the Canonical Correlation Analysis and this statement valid for the multi class case well Based this work Barker 2003 and Rosipal 2003 discuss the details about this relationship and show the appropriate kernel approach this problem Using Canonical Correlation for multi class classification large scale problem suffers from the numerical difficulty solve the generalised eigenvalue problem provide the optimum present analogue classificationprocedure based linear optimisation which able extend the scale range the solvable problems and give sparse solution Our method exploits the relationship between the norm SVM and the boosting approach which were presented Bennett 2000 Mangasarian 1999 and Meir 2003 Additionally the formulation based the soft margin SVM can solve the problem when the number the features are less than the number the observations given sample 
749 en Learning Sprites simple and efficient way model much image and video data decompose into set dimensional objects layers Each object characterized its shape and appearance with sprite computer graphics Following earlier work layer decompositions computer vision Wang and Adelson 1994 Frey and Jojic 1999 stated the sprite learning problem terms transformation invariant clustering using mixture models and This was later extended Jojic and Frey 2001 learning multiple sprites objects from video sequence The approach building knowledge about allowable transformations into the clustering algorithm important way that machine learning algorithm clustering needs tailored the computer vision domain Frey and Jojic approach learning multiple sprites uses variational inference simultaneously all sprites also discuss recent work Williams and Titsias 2004 who describe greedy sequential algorithm for this task 
750 en Challenges Learning the Appearance Faces for Automated Image Analysis Part The variability images the human face challenges research machine vision since its beginning Sources variability not only include individual appearance but also cover external parameters such perspective and illumination that influence the image formation process heavily Research the analysis face images currently splits into the directions face detection and face recognition Approaches and problem setting this two areas are still quite different despite the common goal compensate for the large variability faces images both areas machine learning strategies are used learn from example faces general model the appearance human faces the first part our presentation would like review the current state the art face detection and face recognition second part will compare the different strategies used and try describe the requirements general image model that could serve basis detection well recognition research For face detection will focus methods based the estimation the probability distribution large number features computed face examples After selecting the subset features which appear most relevant the task faces are detected combining the outcome suitably defined statistical tests This method which based positive examples only seems give very promising results compared state the art techniques based both positive and negative examples face recognition will concentrate methods that use analysis synthesis framework such morphable models active appearance shape models Currently these approaches seem the most promising methods able account for variations perspective and illumination 
751 en Adaptive Feature Selection Image Segmentation Most practical image segmentation algorithms optimize some mathematical similarity criterion derived from several low level image features One possible way combining different types features color and texture features different scales and different orientations simply stack all the individual measurements into one high dimensional feature vector Due the nature such stacked vectors however only very few components those which are defined suitable scale will carry information that relevant for the actual segmentation task present novel approach combining segmentation and feature selection that capable overcoming this relevance determination problem implements wrapper strategy for feature selection the sense that the features are directly selected optimizing thediscriminative power the used partitioning algorithm the technical side present efficient optimization algorithm with guaranteed local convergence property All free model parameters this method are selected resampling based stability analysis Experiments for both toy examples and real world images demonstrate that the built feature selection mechanism leads stable and meaningful partitions the images 
752 en Learning issues image segmentation Image segmentation often defined partitioning pixels image blocks into homogeneous groups These groups are characterized prototypical vector feature space the space Gabor filter responses prototypical histograms features pairwise dissimilarities between image blocks For all three data formats cost functions have been proposed measure distortion and thereby encode the quality partition Learning image segmentation can defined the inference prototypical descriptors segments like codebook vectors average feature probability within segment Contrary classification regression the empirical risk image segmentation often composed sums dependent random variables like Normalized Cut Pairwise Clustering means clustering with smoothness constraints One the core challenges for machine learning discover what kind information can learned from these data sources assuming MRF cost functions image models The validation procedure for image segmentations strongly depends this issue will demonstrate the learning and validation issue the context image analysis based color and texture features 
753 en Building local part models for category level recognition This talk addresses the problem building models for category level recognition The starting point set local invariant features which have been shown support the robust recognition specific objects and scenes the category level object recognition context longer sufficient use individual features and becomes necessary model intra class variations select discriminant features and model spatial relations Furthermore important use shape information many cases objects given category are different grey level appearance but similar shape This leads part based approach category level recognition that will illustrate with several examples including feature selection local affine invariant part models and contour based shape description This joint work with Gyuri Dorko Frederic Jurie Svetlana Lazebnik and Jean Ponce 
754 en What the Optimal Number Features learning theoretic perspective this paper discuss the problem feature selection for supervised learning from the standpoint statistical machine learning inquire what subset features will lead the best classification accuracy clear that the statistical model known there are unlimited number training samples any additional feature can only improve the accuracy However explicitly show that when the training set finite using all the features may suboptimal even all the features are independent and carry information the label analyze one setting analytically and show how feature selection can increase accuracy also find the optimal number features function the training set size for few specific examples This perspective feature selection different from the common approach that focuses the probability that specific algorithm will pick completely irrelevant redundant feature 
755 en Mutual Spectral Clustering Microarray Experiments Versus Text Corpus This work studies machine learning technique designed for exploring relations between microarray experiment data and the corpus gene related literature available via PubMed The use this task found that provides better clusters genes fusing both information sources together while can also used guide the expert through the large corpus gene related literature based insights into microarray experiments and vice versa 
756 en The Development the AMI System for the Transcription Speech Meetings The automatic processing speech collected conference style meetings has attracted considerable interest with several large scale projects devoted this area This paper describes the development baseline automatic speech transcription system for meetings the context the AMI Augmented Multiparty Interaction project present several techniques important processing this data and show the performance terms word error rates WERs important aspect transcription this data the necessary flexibility terms audio pre processing Real world systems have deal with flexible input for example using microphone arrays randomly placed microphones room Automatic segmentation and microphone array processing techniques are described and the effect WERs discussed The system and its components presented this paper yield compettive performance and form baseline for future research this domain 
757 en Multimodal Integration for Meeting Group Action Segmentation and Recognition address the problem segmentation and recognition sequences multimodal human interactions meetings These interactions can seen asa rough structure meeting and can used either input for meeting browser first step towards higher semantic analysis the meeting common lexicon multimodal group meeting actions shared meeting data set and common evaluation procedure enable compare the different approaches compare three different multimodal feature sets and four modelling infrastructures higher semantic feature approach multi layer HMMs multistream DBN well multi stream mixed state DBN for disturbed data 
758 en The Rich Transcription 2005 Spring Meeting Recognition Evaluation
760 en Multi modal Authoring Tool for Populating Database Emotional Reactive Animations aim create model emotional reactive virtual mans large set pre recorded animations will used obtain such model have defined knowledge based system store animations reflex movements taking into account personality and emotional state Populating such database complex task this paper describe multimodal authoring tool that provides solution this problem Our multimodal tool makes use motion capture equipment handheld device and large projection screen 
761 en University Karlsruhe Acoustic Speaker Tracking System
762 en The AMI Meeting Corpus Pre Announcement The AMI Meeting Corpus multi modal data set consisting 100 hours meeting recordings being created the context project that developing meeting browsing technology and will eventually released publicly Some the meetings contains are naturally occurring and some are elicited particularly using scenario which the participants play different roles design team taking design project from kick off completion over the course day The corpus being recorded using wide range devices including close talking and far field microphones individual and room view video cameras projection whiteboard and individual pens all which produce output signals that are synchronized with each other also being hand annotated for many different phenomena including orthographic transcription discourse properties such named entities and dialogue acts summaries emotions and some head and hand gestures describe the data set including the rationale behind using elicited material and explain how the material being recorded transcribed and annotated 
764 en VACE Multimodal Meeting Corpus this paper report the infrastructure have veloped support our research multimodal cues for understanding meetings With our focus multimodality investigate the interaction among speech gesture posture and gaze meetings For this purpose high quality multimodal corpus being produced 
765 en Automatic Speech Recognition and Speech Activity Detection the CHIL Smart Room important step bring speech technologies into wide deployment functional component man machine interfaces free the users from close talk desktop microphones and enable far field operation various natural communication environments this work consider far field automatic speech recognition and speech activity detection conference rooms The experiments are conducted the smart room platform provided the CHIL project 160 The first half the paper addresses the development speech recognition systems for the seminar transcription task particular look into the effect combining parallel recognizers both single channel and multi channel settings nbsp the second half the paper describe novel algorithm for speech activity detection based fusing phonetic likelihood scores and energy features shown that the proposed technique able handle non stationary noise events and achieves good performance the CHIL seminar corpus 
767 en Constructing Framework for the Analysis Complex Geographical Systems
772 en Exploring Spatially Embedded Artificial Neural Networks
773 en Understanding Spatiality the Brain does Spatiality matter 
775 en Adaptive Modelling via Pattern Analysis and the Kernel Methods approach There dramatic growth the availability complex data from wide range different applications The challenge the data analyzer extract knowledge from the raw data identifying the useful patterns and structures that underlie This module introduces adaptive and probabilistic approaches modeling such complex data first consider finding structure high dimensional data The kernel methods approach identifying non linear patterns introduced while addressing the issues statistical reliability inferences made from limited data Subspace identification considered and correlations across different data modalities are shown provide useful approach eliciting semantic representations The final section the course will introduce learning probabilistic models biological sequence data fusing prior knowledge and data complex and approximate inference 
777 en Grammatical Inference Tutorial The leactures will introduce the key ideas grammatical inference and concentrate specially the algorithmic aspects Some algorithms that will described are The State merging family Gold Rpni Edsm The Window languages Local and testable Learning with queries 
779 en Pattern Analysis with Graphs and Trees Spectral representations graphs Pattern spaces from graph spectra Spectral approaches matching Heat kernel methods Probabilistic and spectral methods for graph matching and clustering Applications computer vision 
781 en Trees Arrays Networks and Optimization for Finding Patterns Biological Sequences The use suffix trees and integer programming for finding optimal virus signatures current treatment suffix arrays and their uses the last several years simple linear time algorithms for building suffix arrays have been developed making explicit suffix trees mostly obsolete Algorithms for finding signatures patterns historical recombination and gene conversion SNP binary sequences The techniques here relate graph theory 
782 en Patterns sets points the myriad virtues eigenproblems Patterns sets points the myriad virtues eigenproblems the second hour one specific powerful type optimization problem will highlighted the eigenvalue problem brief discussion the computational aspects and overview its applications finding patterns point sets will provided The talk will cover principal component analysis canonical correlation analysis Fisher discriminant partial least squares and spectral clustering will emphasize connections between these algorithms where appropriate 
783 en  statistical mechanics analysis ncoded CDMA with regular LDPC codes obstaja
784 en Learning with structured inputs will present novel approach semi supervised learning that employs method which refer structural learning aka multi task learning The idea learn predictive structures from many auxiliary problems that are created from the unlabeled data and are related the target problem and then transfer the learned structure the supervised target problem 
785 en Clustering overview Clustering finding groups data old machine learning itself not older However more people use clustering variety settings the last few years have brought unprecedented developments this field This tutorial will survey the most important clustering methods use today from unifying perspective will then present some the current paradigms shifts data clustering 
788 en Finding frequent patterns from data Discovery frequent patterns finding positive conjunctions that are true for given fraction the observations this basic idea can instantiated many ways finding frequent sets from data association mining finding frequent episodes sequences finding frequent subgraphs graphs etc efficient algorithms exist the levelwise approach theoretical analysis the algorithms not trivial leads connections hypergraph transversals etc the second part how can the patterns used sometimes interesting themselves can used approximate the joint distribution maximum entropy approaches combining information from several patterns ordering patterns
791 en Probabilistic and Bayesian Modelling There dramatic growth the availability complex data from wide range different applications The challenge the data analyzer extract knowledge from the raw data identifying the useful patterns and structures that underlie This module introduces adaptive and probabilistic approaches modeling such complex data first consider finding structure high dimensional data The kernel methods approach identifying non linear patterns introduced while addressing the issues statistical reliability inferences made from limited data Subspace identification considered and correlations across different data modalities are shown provide useful approach eliciting semantic representations The final section the course will introduce learning probabilistic models biological sequence data fusing prior knowledge and data complex and approximate inference 
793 en Information Retrieval and Text Mining This four hour course will provide overview applications machine learning and statistics problems information retrieval and text mining More specifically will cover tasks like document categorization concept based information retrieval question answering topic detection and document clustering information extraction and recommender systems The emphasis showing how machine learning techniques can help automatically organize content and provide efficient access information textual form 
795 en Learning shared representations for object recognition
796 en Sparsity analsysis term weighting schemes and application text classification revisit the common practice feature selection for dimensionality and noise reduction This typically involves scoring and ranking features based some weighting scheme and selecting top ranked features for further processing Experiments show that the performance text classification methods sensitive characteristics the used feature sets For example the size the feature sets that yield the same performance level for given classification method can very different depending the feature scoring method used expand this exploration considering representations individual document vectors that result from particular feature set particular observe the average number features per document vector the vector sparsity density and introduce sparsity curves illustrate how the vector density increases with the feature set for different weighting schemes show that selecting feature specifying the vector density parameter instead feature set size yields comparable results the commonly adopted practice However has the added benefit understanding the effect feature selection document vector representation and system parameters such memory consumption the classification operations Furthermore the corresponding classification performance curves link the sparsity and performance measures and provide further insight how the feature specificity distribution the feature across documents the corpus accounted for the classification method 
797 en Efficient max margin Markov learning via conditional gradient and probabilistic inference present general and efficient optimisation methodology for for max margin sructured classification tasks The efficiency the method relies the interplay several techiques marginalization the dual the structured SVM max margin Markov problem partial decomposition via gradient formulation and finally tight coupling max likelihood inference algorithm into the optimization algorithm opposed using inference working set maintenance mechanism only 
798 en Matching Point Sets with respect the Earth Mover’ Distance Shape matching fundamental problem computer vision given two shapes and one wants determine how closely resembles according some distance measure between the shapes order measure the similarity and independently trans formations such translations and rotations one wants find transformed version say that attains the minimum possible distance 
808 en Machine Learning Flavor Random Matrices
812 en Graphical Models and Variational Methods this course will discuss how exponential families standard tool statistics can used with great success machine learning unify many existing algorithms and invent novel ones quite effortlessly particular will show how they can used feature space recover Gaussian Process classification for multiclass discrimination sequence annotation via Conditional Random Fields and how they can lead Gaussian Process Regression with heteroscedastic noise assumptions 
818 en Topology and geometry molecular graphs All geometrical information missing topological graph theoretical description connectivity molecules However part molecular geometry could recovered some existing graph drawing algorithms invoked One these algorithms models graph system balls and springs while the second models graph physical system attractive and repulsive forces 
822 en When Logical Inference Helps Determining Textual Entailment and When Doesn´ compare and combine two methods approach the second textual entailment challenge RTE shallow method based mainly word overlap and method based logical inference using first order theorem proving and model building techniques use machine learning technique combine features both methods submitted two runs one using only the shallow features yielding accuracy and one using features both methods performing with accuracy score These figures suggest that logical inference didn´ help much Closer inspection the results revealed that only for some the subtasks logical inference played significant role performance try explain the reason for these results 
823 en COGEX the Second Recognizing Textual Entailment Challenge This paper proposes knowledge representation model and logic proving setting with axioms demand which proved very successful for the recognizing textual entailment task LCC´ submission the Second RTE Challenge exploits the logical entailment between deep semantics and syntax and well shallow lexical alignment the two texts 
824 en Approaching Textual Entailment with LFG and FrameNet Frames present baseline system for modeling textual entailment that combines deep syntactic analysis with structured lexical meaning descriptions the FrameNet paradigm Textual entailment approximated degrees structural and semantic overlap text and hypothesis which measure match graph The encoded measures similarity are processed machine learning setting 
825 en Coping with Semantic Uncertainty with VENSES the previous RTE Challenge present linguistically based approach for semantic inference which built around neat division labour between two main components grammatically driven subsystem which responsible for the level predicate arguments well formedness and works the output deep parser that produces augmented head dependency structures second subsystem tries allowed logical and lexical inferences the basis different types structural transformation intended produce semantically valid meaning corrispondence Grammatical relations and semantic roles are used generate weighted score the current challenge number additional modules have been added cope with fine grained inferential triggers which were not present the previous datset 
827 en  Max Margin Markov Networks Hierarchical Document Classification
828 en Mining XML documents Bridging the gap between Machine Learning and Information Retrieval
832 en Machine Learning Probability and Graphical Models
841 en Better than Being There Intel Research Collaboratory
842 en Visual Lexicons The Quest for Data Driven Decision Making The eternal quest can machines think well man seems quaint today compared the question how can machines help man think True Deep Blue can beat the world best chess player not thinking but exhaustively examining all permutations and combinations blinding time against predetermined outcome set rules The questions for mankind though seem the form where rules are imprecise best and essentially unknowable perhaps learnable and knowable even many other constraints exist that mitigate against data driven decision making This presentation assesses some these constraints and offers some perspective the value using visual dynamics and analytics help overcome such issues 
843 en Tricks the trade for training SVMs
844 en Learning interpretable SVMs for biological sequence classification
845 en Data analysis and support vector machines recognition sleep stages
846 en Kernel based learning hierarchial multilabel classification models
847 en  MCD approach novelty detection
848 en MarkusSparse Grid Methods The search for interesting variable stars the discovery relations between geomorphological properties satellite observations and mineral concentrations and the analysis biological networks all require the solution large number complex learning problems with large amounts data major computational challenge faced these investigations posed the curse dimensionality well known aspect this curse the exponential dependence the size regular grids the dimension the domain This makes traditional finite element approaches infeasible for high dimensional domains less known that this curse also affects computations radial basis function approximations slightly more subtle way Sparse grid functions can deal with the major problems the curse dimensionality they are the superposition traditional finite element spaces many well known algorithms can generalized the sparse grid context Sparse grids have been successfully used solve partial differential equations the past and more recently have been shown competitive for learning problems well The talk will provide general introduction the major properties sparse grids and will discuss connections with kernel based methods and parallel learning algorithms will conclude with short review over some recent work algorithms based the combination technique 
852 en Reinforcement Learning Reinforcement learning about learning good control policies given only weak performance feedback occasional scalar rewards that might delayed from the events that led good performance Reinforcement learning inherently deals with feedback systems rather than data class data samples providing more flexible control like framework than many standard machine algorithms These lectures will summarise reinforcement learning along axes Learning with without knowledge the system dynamics Using state values intermediate solution learning policy directly Learning with without fully observable system states 
854 en Graph Matching Algorithms Graph matching plays key role many areas computing from computer vision networks where there need determine correspondences between the components vertices and edges two attributed structures recent years three new approaches graph matching have emerged replacements more traditional heuristic methods These new methods are Least squares where the optimal correspondence determined terms deriving the best fitting permutation matrix between sets Spectral methods where optimal correspondences are derived via subspace projections the graph eigenspaces Graphical models where algorithms such the junction tree algorithm are used infer the optimal labeling the nodes one graph terms the other and that satisfy similarity constraints between vertices and edges this lecture review and compare these methods and demonstrate examples where this applies point set and line matching 
858 en Introduction the line Trading Exploration and Exploitation Workshop
859 en  Divergence Prior for Adaptive Learning 
860 en Learning when test and Trainig Imputs have different distributions
861 en Active Learning Model Selection and Covariate Shift
862 en Visualizing Pairwise Similarity via Semidefinite Programming
867 en Learning Nonparametric Priors from Multiple Tasks
869 en Dimensionality Reduction Feature Selection Machine Learning Dimensionality reduction commonly used step machine learning especially when dealing with high dimensional space features The original feature space mapped onto new reduced dimensioanllyity space and the examples used machine learning algorithms are represented that new space The mapping usually performed either selecting subset the original features and constructing some new features This persentation deals with the first approach feature subset selection provide brief overview the feature subset selection techniques that are commonly used machine learning and give more detailed description feature subset selection used machine learning text data Performance some methods used document categorization illustrated providing experimental comparison real world data collected from the Web 
870 en Random Exploration and Stabilisation Cellular Architecture All life forms rely information processing maintain their highly organised state Macromolecules and supramolecular structures are key the special properties that set living systems apart from dead matter The course will adopt engineering perspective introduce the molecular biology proteins RNA DNA and the physics thermodynamics kinetics dynamics required for understanding the operation the molecularmachinery work living cells this basis the role andthe processing information the molecular level will discussed covering topics such noise molecular motors conformational switching and intracellular networks leading decision making cells chemotaxis development Throughout the course the potential transfer concepts from nature artificial systems will explored robustness self repair nano engineering molecular computing 
872 en Feasible Language Learning This talk will consider how some recent models feasible learning might apply human language learning with attention how these results complement traditional linguistic perspectives 
874 en The Dynamics AdaBoost One the most successful and popular learning algorithms AdaBoost which classification algorithm designed construct strong classifier from weak learning algorithm Just after the development AdaBoost nine years ago scientists derived margin based generalization bounds explain AdaBoost unexpectedly good performance Their result predicts that AdaBoost yields the best possible performance always achieves maximum margin solution Yet does AdaBoost achieve maximum margin solution Empirical and theoretical studies conducted within this period conjecture the answer yes order answer this question look toward AdaBoost dynamics simplify AdaBoost reveal nonlinear iterated map then analyze the convergence AdaBoost for cases where cyclic behavior found this cyclic behavior provides the key answering the question whether AdaBoost always maximizes the margin turns out the answer this question turns out the opposite what was thought true this talk will introduce AdaBoost describe our analysis AdaBoost when viewed dynamical system briefly mention new boosting algorithm which always maximizes the margin with fast convergence rate and time permits will reveal surprising new result about AdaBoost and the problem bipartite ranking 
875 en Fingerprints Rhthm Natural Language This talk reviews list recent results the rhythmic classes hypothesis produced the Tycho Brahe Project start with results the rhythmic classification speech data based the speech sonority Then address the question the identification fingerprints rhythm Brazilian and European written texts conclude discussing the role fingerprints rhythm may play language acquisition and change 
876 en Diffusion Maps Spectral Clustering and Reaction Coordinates Dynamical Systems central problem data analysis the low dimensional representation high dimensional data and the concise description its underlying geometry and density the analysis large scale simulations complex dynamical systems where the notion time evolution comes into play important problems are the identification the slow variables and the representation the reaction coordinates that parameterize them this paper provide unifying view these apparently different tasks considering family diffusion maps defined the embedding complex data onto low dimensional Euclidian space via the eigenvectors suitably normalized random walks defined the given datasets show both theoretically and examples how this embedding can used for dimensionality reduction manifold learning geometric analysis complex data sets and fast simulations stochastic dynamical systems Joint work with Coifman Lafon Maggioni and Kevrekidis
881 en Robustness and Adaptation Biochemical Networks Bacterial Chemotaxis All life forms rely information processing maintain their highly organised state Macromolecules and supramolecular structures are key the special properties that set living systems apart from dead matter The course will adopt engineering perspective introduce the molecular biology proteins RNA DNA and the physics thermodynamics kinetics dynamics required for understanding the operation the molecularmachinery work living cells this basis the role andthe processing information the molecular level will discussed covering topics such noise molecular motors conformational switching and intracellular networks leading decision making cells chemotaxis development Throughout the course the potential transfer concepts from nature artificial systems will explored robustness self repair nano engineering molecular computing 
883 en Game Dynamics with Learning and Evolution Universal Grammar will present model language evolution based population game dynamics with learning Specifically consider the case two genetic vari ants universal grammar the heart the human language faculty assuming each admits two possible grammars The dynamics are driven communication game prove using dynamical systems techniques that the payoff matrix obeys certain constraints then the two UGs are stable against invasion each other that they are evolutionarily stable These constraints are independent the learning process Intuitively muta tion results grammars that are incompatible with the established languages then will die out because individuals with the mutation will unable communicate and therefore unable realize any potential benefit the mutation example for which the proofs not apply shows that compatible mutations may may not able invade depending the population history and the learning process These results suggest that the genetic history language constrained the need for compatibility and that mutations the language faculty may have died out taken over depending more historical accident than any simple notion relative fitness Further results language game dynamics will require more detailed knowledge the acquisition process Following that line thought will also sketch some recent work more detailed simulation for studying lan guage change historical rather than geological timescales Preliminary results suggest that the human race may have only explored small part the space possible languages 
885 en Bayesian Data Fusion with Gaussian Process Priors Application Protein Fold Recognition Various emerging quantitative measurement technologies are producing genome transcriptome and proteome wide data collections which has motivated the velopment data integration methods within inferential framework has been demonstrated that for certain prediction tasks within computational biol ogy synergistic improvements performance can obtained via integration number possibly heterogeneous data sources six different parameter representations proteins were employed for fold recognition proteins using Support Vector Machines SVM 
886 en Probabilistic and Bayesian Modelling There dramatic growth the availability complex data from wide range different applications The challenge the data analyzer extract knowledge from the raw data identifying the useful patterns and structures that underlie This module introduces adaptive and probabilistic approaches modeling such complex data first consider finding structure high dimensional data The kernel methods approach identifying non linear patterns introduced while addressing the issues statistical reliability inferences made from limited data Subspace identification considered and correlations across different data modalities are shown provide useful approach eliciting semantic representations The final section the course will introduce learning probabilistic models biological sequence data fusing prior knowledge and data complex and approximate inference 
888 en When Training and Test Distributions are Different Characterising Learning Transfer
889 en Randomized PCA Algorithms with Regret Bounds that are Logarithmic the Dimension design line algorithm for Principal Component Analysis The instances are projected into probabilistically chosen low dimensional subspace The total expected quadratic approximation error equals the total quadratic approximation error the best subspace chosen hindsight plus some additional term that grows linearly dimension the subspace but logarithmically the dimension the instances 
890 en Presenting the Evaluating Predictive Uncertainty Challenge
892 en Lost Translation from Genes Organisms Data mining genomes and developmental genetics provides information for building mathematical gene network models development These models can used provide insilico predictions about processes such developmental expression and regulation genes 
893 en Redundant Bit Vectors for Searching High Dimensional Regions Many multimedia applications reduce the problem searching database high dimensional regions see whether any overlap query point There large literature indexing techniques based trees all which break down given high enough dimension stored regions have created new data structure called redundant bit vectors RBVs that can effectively index high dimensional regions Using RBVs can search database 240K dimensional hyperspheres each with different radius times faster than optimized learning scan RBVs are general purpose and may useful for machine learning applications 
894 en Tractable Inference for Probabilistic Models Free Energy Approximations Probabilistic models explain complex observed data set unobserved hidden random variables based the joint distribution the variables Statistical inference requires the evaluation high dimensional sums integrals Hence one has deal with vast computational complexity when the number hidden variables large and important develop tractable approximations will discuss ideas for such approximations which are based variational formulation inference Quantities interest like marginal moments the distribution are found minima entropic quantity often called the Gibbs Free Energy While exact computation the Free Energy computationally intractable sensible approximations often provide quite accurate results will discusss applications these techniques the estimation wind fields from satellite measurements model error correcting code telecommunication and approximate resampling methods 
896 en Learning Structured Outputs via Kernel Dependency Estimation and Stochastic Grammars
897 en Speaker Diarization For Multi Microphone Meetings Using Only Between Channel Differences
902 en Convolutional Object Finder Neural Architecture for Fast and Robust Object Detection
903 en Textual Entailment Recognition Based Dependency Analysis and WordNet
904 en Recognizing Textual Entailment with Edit Distance Algorithms
905 en What Syntax can Contribute Entailment Task
906 en Application the Bleu Algorithm for Recognizing Textual Entailments
908 en Textual Entailment Syntactic Graph Distance rule based and SVM based approach
909 en Effects Stress and Genotype Exploration Exploitation Dynamics Reinforcement Learning Stress and genetic background regulate different aspects behavioral learning through the action stress hormones and neuromodulators Similarly reinforcement learning models exploitation exploration factor and other meta parameters control learning dynamics and performance found that many different measures animal learning and performance can reproduced simple models using dynamic control the meta parameters study the effects stress and genotype carried out hole box light conditioning and Morris water maze experiments with different genetic strains mice exposing them different stressors Then used models simulate their behavior For each experimental session estimated set model meta parameters that produced the best fit between the model and the animal performance Exploration exploitation factors had similar characteristic dynamics for the two simulated experiments and there were statistically significant differences between different genetic strains and stress conditions 
912 en Information Access Challenges the Blogspace
913 en Dealing with Heterogeneity Profiles for Personalized Information Retrieval
914 en Personalized Web Search Engine for Mobile Devices
915 en BulkFS Distributed Fault Tolerant File System for Massive Data Applications
917 en Experiences with the Nutch search engine Nutch open source software that implements web search engine has been used variety applications vertical search engines archival web search search engines that incorporate novel metadata etc Nutch itself implemented using Hadoop open source platform for scalable computing Hadoop facilitates the development and management applications that run large numbers computers and very large datasets Hadoop has been demonstrated clusters with hundreds computers and designed scale thousands computers This talk will present the architecture capabilities and current status these two projects 
918 en Gaussian Process Model for Inferring the Regulatory Activity Transcription Factor Proteins Inferring the concentration transcription factors proteins from the expression levels target genes very active area research computational biology Usually the dynamics the gene expression levels are modelled using differential equations where the transcription factor protein concentrations are treated parameters subsequently estimated using MCMC show how this inference problem can solved more elegantly placing prior over the latent functions obtaining comparable results the standard MCMC approach fraction the time 
919 en Touch Clarity Exploration versus Exploitation Challenge
921 en Analysing Gene Expression Data Using Gaussian Processes Complex gene regulatory mechanisms ensure the proper functioning biological cells New high throughput experimental techniques such microarrays provide snapshot gene expression levels thousands genes the same time repeated sample synchronized cells time series profiles gene activity can obtained The aim reconstruct the complex gene regulatory network underlying these profiles Genes often influence each other nonlinear fashion and with intricate interaction patterns Linear models are often unsuited capture such relationships Gaussian processes the other hand are ideal for representing nonlinear relationships particular attraction the automatic relevance determination effect removing unused inputs and resulting sparse gene networks 
922 en Simulation Modeling Hints and Tips Continuing advances information and communications technology ICT are increasing the scale and connectivity today engineered systems Managing the resultant complexity becoming the central challenge for industry and government from software cities and even stock exchanges Across the wide range internationally leading research groups are addressing this challenge many cases they draw inspiration from biology which provides innumerable examples systems that cope with complexity From cells ecosystems biology achieves scalability adaptability self repair and robustness often exploiting emergent system level behaviours Achieving equivalent success engineered systems the root problem that face the first our short courses introduce the core concepts complexity the context both natural and engineered systems and explore the ways which new computational systems models and simulations are taking part complexity science through series lectures and workshop activities 
924 en Simulation Modeling Group Work Continuing advances information and communications technology ICT are increasing the scale and connectivity today engineered systems Managing the resultant complexity becoming the central challenge for industry and government from software cities and even stock exchanges Across the wide range internationally leading research groups are addressing this challenge many cases they draw inspiration from biology which provides innumerable examples systems that cope with complexity From cells ecosystems biology achieves scalability adaptability self repair and robustness often exploiting emergent system level behaviours Achieving equivalent success engineered systems the root problem that face the first our short courses introduce the core concepts complexity the context both natural and engineered systems and explore the ways which new computational systems models and simulations are taking part complexity science through series lectures and workshop activities 
925 en Learn Weight Term Information Retrieval Using Category Information
926 en Evaluating Machine Learning for Information Extraction
927 en Dirichlet Processes Chinese Restaurant Processes and all that Bayesian approaches learning problems have many virtues including their ability make use prior knowledge and their ability link related sources information but they also have many vices notably the strong parametric assumptions that are often invoked willy nilly practical Bayesian modeling Nonparametric Bayesian methods offer way make use the Bayesian calculus without the parametric handcuffs this talk describe several recent explorations nonparametric Bayesian modeling and inference including various versions Chinese restaurant process priors that allow flexible structures learned and allow sharing statistical strength among sets related structures discuss applications problems bioinformatics and information retrieval 
928 en Efficient discriminative learning Bayesian network classifier via Boosted Augmented Naive Bayes The use Bayesian networks for classification problems has received significant recent attention Although computationally efficient the standard maximum likelihood learning method tends suboptimal due the mismatch between its optimization criteria data likelihood and the actual goal for classification label prediction Recent approaches optimizing the classification performance during parameter structure learning show promise but lack the favorable computational properties maximum likelihood learning this paper present the Boosted Augmented Naive Bayes BAN classifier show that combination discriminative data weighting with generative training intermediate models can yield computationally efficient method for discriminative parameter learning and structure selection 
929 en Near Optimal Sensor Placements Gaussian Processes
930 en Statistical Relational Learning Part Statistical relational learning raises many new challenges and opportunities Because the statistical model depends the domain relational structure parameters the model are often tied This has advantages for making parameter estimation feasible but complicates the model search Because the features involve relationships among multiple objects there often need intelligently construct aggregates and other relational features 
931 en How Predict Sequences with Bayes MDL and Experts
932 en BayesANIL Bayesian Model for Handling Approximate Noisy Incomplete Labeling Text Classification
933 en Semi supervised Graph Clustering Kernel Approach
935 en How choose the covariance for Gaussian process regression independently the basis Gaussian process regression both the basis functions and their prior distribution are simultaneously specified the choice the covariance function certain problems one would like choose the covariance independently the basis functions polynomial signal processing Wiener and Volterra analysis propose solution this problem that approximates the desired covariance function finite set input points for arbitrary choices basis functions Our experiments show that this additional degree freedom can lead improved regression performance 
937 en Interpreting Covariance Functions Classification
939 en Reinforcement Learning MDPs learning proof lambda Function approximation options PSRs
940 en Inductive transfer via embeddings into common feature space consider the situation which there basic learning task but different sub tasks define different data generating distributions Examples include learning identify spam for various different email users parts speech tagging for different text corpora Our goal allow the use training data coming from one sub task for prediction under another sub task distribution 
941 en  Introduction Network Theory and Spatial Networks
942 en Improving the Caenorhabditis elegans Genome Annotation using Machine Learning
943 en Flexible and efficient Gaussian process models will briefly describe our work the sparse pseudo input Gaussian process SPGP where refine the sparse approximation selecting pseudo inputs using gradient methods will then describe several extensions this framework Firstly incorporate supervised dimensionality reduction deal with high dimensional input spaces Secondly develop version the SPGP that can handle input dependent noise These extensions allow methods applied wider variety modelling tasks than previously possible 
946 en Predictive methods for Text mining will give general overview using prediction methods text mining applications including text categorization information extraction summarization and question answering will then discuss some the more advanced issues encountered real applications such structured and complicated output classification the use unlabeled data modeling link structures collective inference and community effect and transfer learning under changing environment etc 
948 en Graphical Models Variational Methods and Message Passing
949 en Intel Research User Activity based Adaptive Power Management APM Adaptive Power Management APM for mobile computers attempts reduce power consumption placing components into low power states with low impact perceived performance The state the art commercial solutions are timeout policies Research APM has focussed modeling system dynamics and not usage patterns describe system that learns when turn off components based usage patterns and context 
950 en Learning RoboCup Keepaway with Kernels give another success story using kernel based methods solve dificult reinforcement learning problem namely that 3vs2 keepaway RoboCup simulated soccer Key challenges keepaway are the high dimensionality the state space rendering conventional grid based function approximation like tilecoding infeasable and the stochasticity due noise and multiple learning agents needing operate use approximate policy iteration with sparsified regular ization networks carry out policy evaluation Preliminary results indicate that the behavior learned through our approach clearly out performs the best results obtained with tilecoding Stone 
952 en Exponential Families this introductory course will discuss how log linear models can extended feature space These log linear models have been studied statisticians for long time under the name exponential family probability distributions provide unified framework which can used view many existing kernel algorithms special cases Our framework also allows derive many natural generalizations existing algorithms particular show how can recover Gaussian Processes Support Vector Machines multi class discrimination and sequence annotation via Conditional Random Fields also show deal with missing data and perform MAP estimation Conditional Random Fields feature space The requisite background for the course will covered briskly the first two lectures Knowledge linear algebra and familiarity with functional analysis will helpful 
954 en Support Vector Machines Support vector machines SVM and kernel methods are important machine learning techniques this short course will introduce their basic concepts then focus the training and optimization procedures SVM Examples demonstrating the practical use SVM will also discussed Basically focus classification time allowed will also touch SVM regression 
956 en  Exchanging based Refinement Sparse Gaussian Process Regression propose backward deletion procedure Sparse Gaussian Process Regression SGPR model which can used refine number quential forward selection algorithms addressed recently Some experi mental results demonstrate the effectiveness our approach 
969 en  Optimal Estimators Learning Theory This talk addresses some problems supervised learning the setting formulated Cucker and Smale Supervised learning learning from examples refers process that builds the base available data inputs and outputs function that best represents the relation between the inputs and the corresponding outputs The goal find estimator the base given data that approximates well the regression function defined assume that are independent and distributed according There are several important ingredients the mathematical formulation this problem follow the way that has become standard approximation theory and has been used recent papers this approach first choose function class hypothesis space work with After selecting class have the following two ways The first one based the idea studying approximation the projection onto Here the marginal probability measure This setting known the improper function learning problem the projection learning problem this case not assume that the regression function comes from specific say smoothness class functions The second way based the assumption This setting known the proper function learning problem For instance may assume that has some smoothness will give some upper and lower estimates both settings 
972 en Adventures with Camille computational simulation minimalist language learner
973 en Multiscale analysis graphs Analysis graphs has recently been shown lead powerful algorithms learning particular for regression classification andclustering Eigenfunctions the Laplacian graph are natural basis for analyzing functions graph have seen presentations recent work partecipants this conference this talk introduce new flexible set basis functions called Diffusion Wavelets that allow for multiscale analysis functions graph very much the same way classical wavelets perform multiscale analysis Euclidean spaces They allow efficient representation compression denoising functions the graph and are very well suited for learning well unsupervised algorithms They are also associated with multiscale decomposition the graph which has applications itself will discuss this construction with several examples going from signal processing manifolds and graphs some recent preliminary applications clustering and learning 
974 en Categorical Perception Linear Learning Shared Culture group entities who learn observing one another behavior some simple assumptions about the nature perception the nature individual beliefs and the nature learning lead naturally collective convergence random set shared beliefs without any structure authority any explicit collective decision process This process will exemplified the case simple model for developing word pronunciations 
975 en Some Aspects Learning Rates for SVMs present some learning rates for support vector machine classification particular discuss recently proposed geometric noise assumption which allows bound the approximation error for Gaussian RKHSs Furthermore show how noise assumption proposed Tsybakov can used obtain learning rates between sqrt and Finally describe the influence the approximation error the overall learning rate 
982 en Robust Speaker Segmentation for Meetings The ICSI SRI Spring 2005 Diarization System address the problem segmentation and recognition sequences
983 en Can Chimeric Persons Used Multimodal Biometric Authentication Experiments 
984 en Tracking Multiple Simultaneous Speakers with Probabilistic Data Associaton Filters
986 en Generic dialogue modeling for multi application dialogue systems present novel approach developing interfaces for
987 en Projective Kalman Filter Multiocular Tracking Locations Towards Scene Understanding This paper presents novel approach the problem estimating and tracking locations multiple targets scene using measurements gathered from multiple calibrated cameras Estimation and tracking jointly achieved newly conceived computational process the Projective Kalman —lter PKF allowing the problem treated single uni— framework The projective nature observed data and information redundancy among views exploited PKF order overcome occlusions and spatial ambiguity demonstrate the ®ectiveness the proposed algorithm the authors present tracking results people SmartRoom scenario and compare these results with existing methods well 
988 en  serial architectures for multiple classifier systems One the recently emerged paradigms machine learning multiple classifier fusion large number methods for constructing multiple classifier systems MCS have been suggested the literature The majority these draw parallel architecture involving fusion multiple classifiers via some form linear nonlinear combination rule Intuitively one can look parallel fusion attempt improve the performance combining several independent estimates class aposteriori probability and thereby reducing the variance the combined estimate For given probability margin between two competing hypotheses this reduced variance then results lower probability incurring additional classification error over and above the Bayes error Much less attention has been paid multiple classifier system schemes that aim enhance the performance manipulating the margin between competing hypotheses increased margin can normally achieved class grouping This approach often leads serial multiple classifier system architectures Depending whether the grouping structure fixed created dynamically the resulting multiple classifier either decision tree chain like multistage system this paper the theory underpinning this MCS approach will overviewed and its implications discussed will shown that the theory leads diverse class grouping margin manipulation strategies Their relative advantages will discussed The effectiveness some these strategies will illustrated practical problem object recognition 
990 en Multimodal Input for Meeting Browsing and Retrieval Interfaces Preliminary Findings
992 en Universal Modeling Introduction modern MDL give tutorial introduction the modern Minimum Description Length MDL Principle taking into account the many refinements and developments that have taken place the 1990s These not seem widely known outside the information theory community will especially emphasize the use MDL classification also consider the connections between MDL Bayesian inference maximum entropy inference and structural risk minimization 
996 en Information Retrieval and Language Technology The course will give overview how statistical learning can help organize and access information that represented textual form particular will cover tasks like text classification information retrieval information extraction topic detection and topic tracking The course will introduce the basic techniques for representing text and analyze their statistical properties emphasis the course will giving overview interesting learning problems this area providing starting points for future research 
999 en Working with Systems Continuing advances information and communications technology ICT are increasing the scale and connectivity today engineered systems Managing the resultant complexity becoming the central challenge for industry and government from software cities and even stock exchanges Across the wide range internationally leading research groups are addressing this challenge many cases they draw inspiration from biology which provides innumerable examples systems that cope with complexity From cells ecosystems biology achieves scalability adaptability self repair and robustness often exploiting emergent system level behaviours Achieving equivalent success engineered systems the root problem that face the first our short courses introduce the core concepts complexity the context both natural and engineered systems and explore the ways which new computational systems models and simulations are taking part complexity science through series lectures and workshop activities 
1000 en Engineered Complexity Continuing advances information and communications technology ICT are increasing the scale and connectivity today engineered systems Managing the resultant complexity becoming the central challenge for industry and government from software cities and even stock exchanges Across the wide range internationally leading research groups are addressing this challenge many cases they draw inspiration from biology which provides innumerable examples systems that cope with complexity From cells ecosystems biology achieves scalability adaptability self repair and robustness often exploiting emergent system level behaviours Achieving equivalent success engineered systems the root problem that face the first our short courses introduce the core concepts complexity the context both natural and engineered systems and explore the ways which new computational systems models and simulations are taking part complexity science through series lectures and workshop activities 
1003 en Combinatory Hybrid Elementary Analysis Text propose CHEAT approach the MorphoChallenge contest Combinatory Hybrid Elementary Analysis Text The idea acquire results from number other candidate systems CHEAT will read the output files each the other systems and then line line select the majority vote analysis the analysis which most systems have gone for there tie take the result produced the system with the highest measure the other systems´ output files are ordered best first then this achieved simply taking the first the tied results justify our approach need show that this really unsupervised learning defined the MorphoChallenge website arguably the CHEAT approach involves super sized unsupervised learning combines three different layers unsupervised learning 
1004 en Morphological Learning Principled Argument develop morphological learner that evaluates evidence supporting specific claims that string letters distributional meaningful unit The distributional evidence evaluated selectional properties morphs while evidence towards meaning modelled looking the relationship between stems and words assess proposed affix gets probability measure meaning comparing all the possible stems the affix occur with the particular subset that also occur words Since for stem word counts evidence towards its meaning the ratio formed taking stems that are words the whole set possible stems for affix gives predictive probability measure for the affix that measures the chance that has combined with meaningful stem This measure taken conjunction with the selectional statistics stems and affixes provides basis for deciding the best morphological structure for given word The results for English show combined precision and recall 
1005 en Introduction Complexity Science Continuing advances information and communications technology ICT are increasing the scale and connectivity today engineered systems Managing the resultant complexity becoming the central challenge for industry and government from software cities and even stock exchanges Across the wide range internationally leading research groups are addressing this challenge many cases they draw inspiration from biology which provides innumerable examples systems that cope with complexity From cells ecosystems biology achieves scalability adaptability self repair and robustness often exploiting emergent system level behaviours Achieving equivalent success engineered systems the root problem that face the first our short courses introduce the core concepts complexity the context both natural and engineered systems and explore the ways which new computational systems models and simulations are taking part complexity science through series lectures and workshop activities 
1006 en Introduction Continuing advances information and communications technology ICT are increasing the scale and connectivity today engineered systems Managing the resultant complexity becoming the central challenge for industry and government from software cities and even stock exchanges Across the wide range internationally leading research groups are addressing this challenge many cases they draw inspiration from biology which provides innumerable examples systems that cope with complexity From cells ecosystems biology achieves scalability adaptability self repair and robustness often exploiting emergent system level behaviours Achieving equivalent success engineered systems the root problem that face the first our short courses introduce the core concepts complexity the context both natural and engineered systems and explore the ways which new computational systems models and simulations are taking part complexity science through series lectures and workshop activities 
1007 en Normalized Alignment Dependency Trees for Detecting Textual Entailment this paper investigate the usefulness normalized alignment dependency trees for entailment prediction Overall our approach yields accuracy the RTE2 test set which significant improvement over the baseline Results vary substantially across the different subsets with peak performance the summarization data conclude that normalized alignment useful for detecting textual entailment but robust approach will probably need include additional sources information 
1009 en Chronological Sampling for Email Filtering User models for email filtering should developed from appropriate training and test sets fold cross validation commonly presented the literature method mixing old and new messages produce these data sets show that this results overly optimistic estimates the email filter’ accuracy classifying future messages because the test set has higher probability containing messages that are similar those the training set propose the fold chronological cross validation method that preserves the chronology the email messages the test set 
1010 en User models from implicit feedback for proactive information retrieval Our research consortium develops user modeling methods for proactive applications this project use machine learning methods for predicting users’ preferences from implicit relevance feedback Our prototype application information retrieval where the feedback signal measured from eye movements user’ behavior Relevance read text extracted from the feedback signal with models learned from collected data set Since hard define relevance general have constructed experimental setting where relevance known priori 
1011 en Improving Infoville XXI using Machine Learning Techniques Infoville XXI citizen web portal Valencia Spain This paper presents several approaches based Machine Learning that help improving the site Three ways improvement are taken into account user clickstream forecasting user profiling clustering and iii recommendation services users being the last two techniques part methodological framework with general applicability that tries useful for range web sites wide possible Results obtained with data sets from this web portal show that the most appropriate techniques for user clickstream forecasting become Support Vector Machines and Multilayer Perceptrons whilst Adaptive Resonance Theory and Self Organizing Maps appear the most suitable techniques for clustering Final recommendation and adaptation the recommender system currently being developed using Learning Vector Quantization and Reinforcement Learning 
1013 en Log pre processing and grammatical inference for Web usage mining this paper propose WEB USAGE MINING pre processing method retrieve missing data from the server log files Moreover propose two levels evaluation directly reconstructed data but also after machine learning step evaluating inferred grammatical models conducted some experiments and showed that our algorithm improves the quality user data Keywords log pre processing web usage mining grammatical inference evaluation
1018 en Unsupervised fMRI Analysis Recently machine learning methodology has been used increasing analyze the relationship between stimulus categories and fMRI responses Here introduce new unsupervised machine learning approach fMRI analysis approach which the simple categorical description stimulus type type task replaced more informative vector stimulus features compared this new approach with standard Support Vector Machine SVM analysis fMRI data using categorical description stimulus type The following study differs from conventional unsupervised approaches that make use the stimulus characteristics use kernel Canonical Correlation Analysis KCCA learn the correlation between the fMRI volume and the corresponding stimulus features presented particular time point CCA can seen the problem finding basis vectors for two sets variables such that the correlation the projections the variables onto these basis vectors are mutually maximised KCCA first projects the data into higher dimensional feature space before performing CCA the new feature space 
1019 en Hidden Process Models Decoding Overlapping Cognitive States with Unknown Timing use Hidden Process Models HPMs evaluate different models functional Magnetic Resonance Imaging fMRI study which subjects decide whether stimuli match demonstrate the ability HPMs simultaneously estimate the hemodynamic response functions and the onset times set cognitive processes underlying fMRI time series and compare different models principled way 
1020 en What Mental States Exploring How Dimensionality Reduction Might Contribute the Refinement Cognitive Models Questions cognitive neuroscience are often framed terms correspondences between known types How brain state related cognitive state What are the correlations mappings between particular structures and functions Such framings are well suited for confirmatory testing coarse grained hypotheses They are not necessarily informative however for the purpose exploring finer physical and functional structure the contrary physical states are typically aggregated over anatomical regions interest while tasks are designed optimize one few functional contrasts interest rather than cover fuller behavioral cognitive range 
1021 en Enhancing functional magnetic resonance imaging with supervised learning This paper reports novel applications supervised learning methods intended directly impact fMRI technology with the aim improving data acquisition and analysis 
1022 en Classifying single trial fMRI What can machine learning learn describe three experiments combining neuroimaging and machine learning The first experiment compares the performance maximum likelihood and neural net classifiers for brain reading fMRI data the visual cortex The second experiment applies the optimal classifier measure the development the face region children and adolescents While the previous experiments used block designs the third experiment describes event related experiment where the classification algorithm learned something real but not what was planned The corroboration and validation the classification results with brain images will demonstrated 
1023 en Exploring human object vision with res fMRI and information based analysis
1024 en Challenges and limitations interpreting learnt classifiers
1025 en Implications decoding for theories neural representation
1027 en Condition numbers regularisation and uncertainty principles linear algebraic equations There exist several condition numbers for the linear least squares problem minx These range from simple normwise measure that may overestimate the true numerical condition several orders magnitude refined sharp bounds These different condition numbers will compared and will shown that the computational implementation the refined measures problematic but the simplest measure easy compute accurately Examples are used illustrate the differences between the condition numbers The implications these properties for the regularisation ill conditioned linear algebraic equations considered and shown that emphasizes the role the prior The problem occurs frequently regression and this operation plays the same role the analysis stage filter bank Similarly the matrix vector product equivalent the synthesis stage filter bank because corresponds the reconstruction the signal from the basis functions The final section the talk will consider the condition numbers the problem and product and will shown that the condition number large then these two operations cannot simultaneously ill conditioned simultaneously well conditioned that they obey uncertainty principle 
1028 en From clustering algorithms this talk firstly provide rigorous probabilistic proof the clustering phenomenon taking place the space solution random combinatorial problems Secondly will discuss generalization the survey propagation equations efficiently exploring the clustered geometry Finally discuss the computational consequences the possibility finding single clusters describing physical lossy compression scheme Performance are optimized when the number well separated clusters maximal the underlying physical model 
1032 en  Objective Evaluation Criterion for Clustering
1034 en Probabilistic Graphical Models lectures will cover the basics graphical models also known Bayes ian Belief Net work will cover the basic motivations for using probabilities represent and reason about uncertain knowledge machine learning and introduce graphical models qualitative and quantitative specification large joint probability distributions will see how many common classification regression and clustering models can cast this framework will cover the basic algorithm called belief propagation for inference graphical model structures will also cover the major approaches learning models from data parameter estimation The course will focus directed models and the basic algorithms but time and student desire permitting will also try give some preliminary explanations undirected models approximate inference and learning structure discovery and current applications 
1036 en Self Adapting Architecture SAA New tools and concepts for manipulation objects architecture are presented The concepts include manipulation local coordinate systems and objects contained them well performing boolean operations them Growing cellular automata GCA are used build and manipulate large amount data and relations which occur during the process construction 
1037 en Visualization graphs using their product structure Graphs are combinatorial structures given set vertices and set edges giving the adjacencies between pairs vertices Drawing graphs nicely challenging task graph has some particular structure often very useful use the knowledge about this for visualizing the object many cases there are polynomial time algorithms for recognition product graphs and graph bundles provide several examples and give short survey results and open problems 
1038 en Approximate Graph Products Products graphs allow rather compressed coding from the data structure point view and often transparent graphical representations Graphs that differ little from products the sense that addition deletion small number edges turns them into product offer similar advantages 
1039 en Women Science Slovenia the new Member State Slovenia Central European country and has history always been between the East and West Europe which determined many the state political and social activities These reflect also the situation women science 
1042 en Bounds and estimates for convergence binary undirected graphical models Belief Propagation has become popular method for inference graphical models Accurate approximations for intractable quantities single node marginals can obtained within rather modest computation times However for large interaction strengths potentials that are highly dependent their arguments densely connected graphs can fail converge This can remedied damping the iteration equations using sequential update schemes using entirely different algorithms such double loop algorithms that directly minimize the Bethe free energy However the value this approach questionable since there empirical evidence that failure convergence often indicates low quality the Bethe approximation 
1043 en Advanced message passing techniques for distributed storage Distributed storage plays important role networks where individual nodes are limited their storage capabilities and where files are infrequently required The scenario examined one where file information encoded and then divided number segments which are then distributed over graph representing the network Nodes requesting particular file collect the required number file segments from neighbouring nodes retrieve the original information 
1045 en Using upper confidence bounds control exploration and exploitation
1046 en Gradient Based Estimates Return Distributions
1047 en Data Mining Tool for Analysing Environmental Systems
1049 en The NITE XML Toolkit meets the ICSI Meeting Corpus import annotation and browsing The NITE XML Toolkit NXT provides library support for working with multimodal language corpora describe work progress explore its potential for the AMI project applying the ICSI Meeting Corpus discuss converting existing data into the NXT data format using NXT’ query facility explore the corpus hand annotation and automatic indexing and the integration data obtained applying NXT external processes such parsers 
1050 en Tandem Connectionist Feature Extraction for Conversational Speech Recognition Multi Layer Perceptrons MLPs can used automatic speech recognition many ways particular application this tool over the last few years has been the Tandem approach described Hermansky number publications Here discuss the characteristics the MLP based features used for the Tandem approach and conclude with report their application conversational speech recognition The paper shows that MLP transformations yield variables that have regular distributions which can further modified using logarithm make the distribution easier model Gaussian HMM Two more vectors these features can easily combined without increasing the feature dimension also report recognition results that show that MLP features can significantly improve recognition performance for the NIST 2001 Hub evaluation set with models trained the Switchboard Corpus even for complex systems incorporating MMIE training and other enhancements 
1051 en Automatic pedestrian tracking using discrete choice models and image correlation techniques this paper deal with the multi object tracking problem with specific reference the visual tracking pedestrians assuming that the pedestrian detection step already done use Bayesian framework combine the visual information provided simple image correlation algorithm with behavioral model discrete choice model for pedestrian dynamic calibrated real data aim show how the combination the image information with model pedestrian behavior can provide appreciable results real and complex scenarios 
1052 en Mountains Exploration Education Rich Media and Design want talk about some things that feel passionate about mountains exploration history learning and design particular want talk about learning and understanding within our society which becoming increasingly difficult function much less influence largely due technology induced complexity have believe that the objective good design render the world more manageable not less believe that the more technology developed apart from social context and specific problem domains the less likely will meet this test have chosen domain mountaineering and exploration the area surrounding the Himalaya Using examples want put forward the case that have the potential design tools that could have much impact education and learning tomorrow the introduction the blackboard had when was introduced Canada the mid 1800s will also argue that doing represents proposition which hard easy say – that worthy year project believe that the current slump the technology sector largely self induced and deserved consequence bad design applied poorly thought out problems Through examples want argue that there way out this and point particular path said ’ about exploration good place start establish some appropriate bearings 
1053 en Zakim multimodal sofware system for large scale teleconferencing This paper describes Zakim the multimodal teleconference system used the World Wide Web Consortium cite W3C While the system presented here does not make use advanced research work the technology presented have been developed with robustness mind used almost round the clock several hundred people The context and requirements are introduced first followed description the system features Lastly describe how the structure W3C teleconferences has been modified the use this system and discuss some issues and possible improvements 
1054 en  Programming Model for Next Generation Multimodal Applications Multimodal interfaces are becoming essential for the next generation conversational collaborative and mobile device solutions Until now however their development has been hampered the lack standards based means for authoring them for their programming model addition the programming model the underlying technologies used these applications such synchronization and modality fusion techniques are still early stage development 
1055 en  Efficient Online Algorithm for Hierarchical Phoneme Classification present algorithmic framework for supervised classification learning where the set labels organized predefined hierarchical structure This structure encoded rooted tree which induces metric over the label set Our approach combines ideas from large margin kernel methods and Bayesian analysis Following the large margin principle associate prototype with each label the tree and formulate the learning task optimization problem with varying margin constraints the spirit Bayesian methods impose similarity requirements between the prototypes corresponding adjacent labels the hierarchy describe new online algorithm for solving the hierarchical classification problem and derive worst case loss bound for the algorithm demonstrate the merits our approach with series experiments synthetic data and speech data 
1056 en Immersive Conferencing Directions Palo Alto Laboratory Palo Alto Laboratory have been recording and reusing meetings for five years and have been developing technologies support meeting recording collaboration and videoconferencing will briefly summarize our experience and results and will then present and demonstrate few our more interesting research directions Some our work uses video image interface allowing devices and information accessed through the screen 
1057 en Recognition Isolated Complex Mono and Manual Hand Gestures using Discrete IOHMM this paper address the problem the recognition isolated complex mono and manual hand gestures the proposed system hand gestures are represented the trajectories blobs Blobs are obtained tracking colored body parts real time using the algorithm most the studies hand gestures only small vocabularies have been used this paper study the results obtained more complex database mono and manual gestures These results are obtain processing algorithm namely Input Output Hidden Markov Model IOHMM implemented within the framework open source machine learning library 
1058 en Using Static Documents Structured and Thematic Interfaces Multimedia Meeting Archives Documents play central role multimodal applications such meeting recording and browsing They provide variety structures particular thematic for segmenting meetings structures that are often hard extract from audio and video this article present four steps for creating strong link between documents and multimedia meeting archives First document centric meeting environment presented then document analysis tool which builds multi layered representation documents and creates indexes that are further used document speech and document video alignment methods 
1059 en Evolution and Evolvability has been century and half since Darwin provided the first mechanistic explanation for the complexity the living things see around Only the last years have computational systems been employed try out natural selection complex artificial problems There have been some successes but the complexity artificially evolved systems remains very long way short the complexity that easy find biology Why this our understanding natural evolution missing something important How can improve our artificial problem solving methods make them work better large scale complex problems 
1061 en Slow subspace learning from stationary processes The talk presents method unsupervised learning from stationary vector valued processes The method selects subspace the basis objective which can used bound the expected classification error for family tasks posessing temporal continuity property prove bounds the objective’ estimation error terms mixing coefficients and consistency for absolutely regular processes Experiments with image processing demonstrate the algorithms ability learn geometrically invariant feature maps 
1062 en Graphical Models for Structural Pattern Recognition the structural paradigm for visual pattern recognition what some call strong pattern recognition one not satisfied with simply assigning class label input object but instead aim finding exactly which parts the template object correspond which parts the scene This much harder problem principle because inherently combinatorial the number parts features involved both the template object and the scene This talk describes summary our research efforts setting this mathematical optimization problem and solving efficiently exploiting geometric constraints The key insight involves encoding geometric constraints conditional independency assumptions probabilistic graphical model Due some geometric facts possible show that such models are very well behaved they allow for exact probabilistic inference polynomial time The result unified framework for structural visual pattern recognition that able handle principled way variety problems including point pattern matching its many instances invariant translations isometries scalings affine projective transformations Attributed graph matching problems such matching road networks can also solved within such framework Limitations and future directions will discussed 
1066 en Optimization for Kernel Methods Optimization methods play crucial role kernel methods such Support Vector Machines and Kernel Logistic Regression variety scenarios different optimization algorithms are better suited than others The aims the six lectures this topic are introduce range optimization problems that arise the solution classification problems kernel methods briefly review the relevant optimization algorithms and point out some detail which optimization methods are suited for these varied problems 
1072 en Rapid Stochastic Gradient Descent Accelerating Machine Learning The incorporation online learning capabilities into real time computing systems has been hampered lack efficient scalable optimization algorithms for this purpose second order methods are too expensive for large nonlinear models conjugate gradient does not tolerate the noise inherent online learning and simple gradient descent evolutionary algorithms etc are unacceptably slow converge addressing this problem developing new ways accelerate stochastic gradient descent using second order gradient information obtained through the efficient computation curvature matrix vector products the stochastic meta descent SMD algorithm this cheap curvature information built iteratively into stochastic approximation Levenberg Marquardt second order gradient steps which are then used adapt individual gradient step sizes SMD handles noisy correlated non stationary signals well and approaches the rapid convergence second order methods only linear cost per iteration thus scaling extremely large nonlinear systems date has enabled new adaptive techniques computational fluid dynamics and computer vision Our most recent development version SMD operating reproducing kernel Hilbert space 
1074 en  line linear learning algorithms Prediction with expert advice Learning with linear experts The Perceptron algorithm and its extensions line learning with kernels Mistake bounds From mistake bounds risk bounds 
1076 en Patterns Randomness and Information Information Complexity Patterns Randomness and Compression And how these ideas can traced back through Hermann Weyl Leibniz 1686 and connect them with Godel amp Turing and with the question how math compares amp contrasts with physics and with biology 
1077 en Learning Hierarchical Multi Category Text Classification Models
1080 en Algorithmic and Combinatorial Foundations Pattern Discovery
1087 en Introduction Boosting This course provides introduction theoretical and practical aspects Boosting and Ensemble Learning will begin with short description the learning theoretical foundations weak learners and their linear combination Then point out the useful connection between Boosting and the Theory Optimization which facilitates the understanding Boosting and later enables move new Boosting algorithms applicable broader spectrum problems the course will discuss tricks the trade algorithmic issues experimental results and few applications 
1088 en The stability good clustering have found good clustering data set can prove that not far from the unknown best clustering this data set Perhaps surprisingly the answer this question sometimes yes can show bounds the distance for two clustering cost functions the Normalized Cut and the squared distance cost means clustering These bounds exist the case when the data admits good clustering for the given cost 
1094 en Analysis Support Vector Machine Classification
1099 en Using Unlabeled Data Generalization Error Bounds
1100 en Dirichlet Processes and Nonparametric Bayesian Modelling Bayesian modeling principled approach updating the degree belief hypothesis given prior knowledge and given available evidence Both prior knowledge and evidence are combined using Bayes rule obtain the posterior hypothesis most cases interest machine learning the prior knowledge formulated prior distribution over parameters and the evidence corresponds the observed data applying Bayes formula can perform inference about new data Having observed sufficient data the posteriori parameter distribution increasingly concentrated and the influence the prior distribution diminishes Under some assumptions particular that the likelihood model correct and that the true parameters have positive priori probability the posteriori distribution converges point distribution located the true parameters The challenges Bayesian modeling are first find suitable application specific statistical models and second approximately solve the resulting inference equations 
1101 en Numerical Methods for Solving Least Squares Problems with Constraints this talk discuss the problem solving linear least squares problems and Total Least Squares problems with linear constraints and quadratic constraint are particularly interested developing stable numerical methods when the data matrix singular near singular particular interest are matrices which are large and sparse and for which iterative methods must employed The quadratically constrained problems arise problems where regularization required For such problems Lagrange multiplier required and that calculation may quite intensive The method propose will quickly yield estimate the parameter and allow for finding the least squares solution 
1104 en Panel Perspectives Textual Entailment
1105 en Two Related Lexico Syntactic Approaches Entailment Two approaches Textual Entailment are presented They both rely lexico syntactic information The two approaches differ mainly the way the syntactic relationships are derived one approach the syntactic relationships are drawn from phrase based parse tree the other use information provided dependency parser The first approach performs precision and 6047 average precision The second system´ performance 5837 precision and 5785 average precision 
1107 en Learning Distinguish Valid Textual Entailments This paper proposes new architecture for textual inference which finding good alignment separated from evaluating entailment Current approaches semantic inference question answering and textual entailment have approximated the entailment problem that computing the best alignment the hypothesis the text using locally decomposable matching score While this formulation adequate for representing local word level phenomena such synonymy incapable representing global interactions such that between verb negation and the addition removal qualifiers which are often critical for determining entailment 
1109 en Recognizing Textual Entailment with LCC´ GROUNDHOG System introduce new system for recognizing textual entailment known GROUNDHOG which utilizes classification based approach combine lexico semantic information derived from text processing applications with large collection paraphrases acquired automatically from the WWW Trained 200 000 examples textual entailment extracted from newswire corpora our system managed classify more than the pairs the 2006 PASCAL RTE Test Set correctly 
1111 en Gaussian Processes for Principal Component Analysis show how the supervised method Gaussian Processes may used for Principal Component Analysis using two intuitions about the nature the ¯rst principal component ¯lters 
1112 en Gaussian Processes for Prediction Intensive Care this paper present the use Gaussian Processes for regression the application prediction Intensive Care propose preliminary solution predicting the evolution patient state during his stay intensive care means deffined patient speciffic characteristics 
1113 en Gaussian Process Implicit Surfaces Many applications computer vision and computer graphics require the definition curves and surfaces Implicit surfaces are popular choice for this because they are smooth can appropriately constrained known geometry and require special treatment for topology changes this paper use Gaussian processes for this and derive covariance function equivalent the thin plate spline regularizer which has desirable properties for shape modelling demonstrate our approach for both curves and surfaces The benefit using Gaussian process for this the meaningful probabilistic representation the function 
1114 en Learning the prior for the PAC Bayes bound
1115 en Learning Human Pose and Motion Models for Animation Computer animation extraordinarily labor intensive process obtaining high quality motion models could make the process faster and easier will describe methods for learning models human poses and motion from motion capture data will begin with pose model based the Gaussian Process Latent Variable Model GPLVM and the application this model Inverse Kinematics posing will then describe the Gaussian Process Dynamical Model GPDM for modeling motion dynamics may also mention few other extensions the GPLVM for modeling motion data will discuss the properties these models both good and bad and potential directions for future work 
1116 en Gaussian Processes for Monocular People tracking advocate the use Gaussian Processes GPs learn prior models human pose and motion for people tracking The Gaussian Process Latent variable model GPLVM provides low dimensional embedding the human pose and defines density function that gives higher probability poses close the training data The Gaussian Process Dynamical Model GPDM provides also complex dynamical model terms another With the use Bayesian model averaging both GPLVM and GPDM can learned from relatively small amounts training data and they generalize gracefully motions outside the training set show that such priors are effective for tracking range human walking styles despite weak and noisy image measurements and very simple image likelihood Tracking formulated terms MAP estimator short sequences poses within sliding temporal window 
1117 en Microphone Array Driven Speech Recognition Influence Localization the Word Error Rate Interest within the automatic speech recognition research community has recently focused the recognition speech where the microphone located the medium field rather than being mounted headset and positioned next the speakers mouth realize the long term goal ubiquitous computing This natural application for beamforming techniques using microphone array crucial ingredient for optimal performance beamforming techniques the speaker location Hence apply such techniques source localization algorithm required prior work proposed using extended Kalman filter directly update position estimates speaker localization system based time delays arrival also have enhanced our audio localizer with video information this work investigate the influence the speaker position the word error rate automatic speech recognition system operating the output beamformer and compare this error rate with that obtained with close talking microphone Moreover compare the effectiveness different localization algorithms tested our algorithm data set consisting seminars held actual speakers Our experiments revealed that accurate speaker tracking crucial for minimizing the errors farfield speech recognition system 
1118 en Analysing Meeting Records Ethnographic Study and Technological Implications Whilst there has been substantial research into technology support meetings there has been relatively little study how meeting participants currently make records and how these records are used direct collective and individual actions outside the meeting This paper empirically investigates current meeting recording practices determine how these might better supported technology Our main findings were that participants create two types meeting record Public records are collectively negotiated contract decisions and commitments Personal records contrast are highly personalised reminding tool recording both actions and the context surrounding these actions These observations are then used critique current meeting support technology and suggest new directions for research 
1119 en Toward joint segmentation and classification dialog acts multiparty meetings present baseline results for the joint segmentation and classification dialog acts DAs the ICSI Meeting Corpus Two simple approaches based word information are investigated and compared with previous work the same task also describe several metrics assess the quality the segmentation alone well the joint performance segmentation and classification DAs 
1120 en Mistake bounds and risk bounds for line learning algorithms statistical learning theory risk bounds are typically obtained via the manipulation suprema empirical processes measuring the largest deviation the empirical risk from the true risk class models this talk describe the alternative approach deriving risk bounds for the ensemble hypotheses obtained running arbitrary learning algorithm line fashion This allows replace the uniform large deviation argument with simpler argument based the analysis the empirical process engendered the line learner The large deviations such empirical processes are easily controlled single application Bernstein inequality for martingales and the resulting risk bounds exhibit strong data dependence 
1121 en Suboptimality MDL and Bayes Classification under Misspecification show that forms Bayesian and MDL learning that are often applied classification problems can statistically inconsistent present large family classifiers and distribution such that the best classifier within the model has generalization error expected prediction loss almost Nevertheless matter how many data are observed both the classifier inferred MDL and the classifier based the Bayesian posterior will behave much worse than this best classifier the sense that their expected prediction loss substantially larger Our result can interpreted showing that under misspecification Bayes and MDL not always converge the distribution the model that closest divergence the data generating distribution compare this result with earlier results Bayesian inconsistency Diaconis Freedman and Barron 
1122 en Robustness properties support vector machines and related methods The talk brings together methods from two disciplines machine learning theory and robust statistics argue that robustness important aspect and show that many existing machine learning methods based convex risk minimization have besides other good properties also the advantage being robust the kernel and the loss function are chosen appropriately Our results cover classification and regression problems Assumptions are given for the existence the influence function and for bounds the influence function Kernel logistic regression support vector machines least squares and the AdaBoost loss function are treated special cases also consider Robust Learning from Bites simple method make some methods from convex risk minimization applicable for huge data sets for which currently available algorithms are much slow example use data set from German insurance companies 
1123 en Universal Principles Approximation and Model Choices Universal principles are ones which make reference the subject matter the data and include Maximum Likelihood Bayes AIC and MDL this talk criticize the use such principles solve the problem model choice The criticism will mainly directed against MDL but corresponding arguments can made against the other principles concept approximation will introduced and its use choosing model illustrated examples from non parametric statistics 
1124 en  minimax estimation infinite dimensional vector binomial proportions consider the problem minimax estimation infinite dimensional vector binomial proportions Under some conditions derive the asymptotic behavior the minimax risk over some nonparametric classes Further discuss the issue adaptation and the problem optimal allocation observations 
1125 en Invariance kernel methods distance and integration kernels
1126 en Independent Component Analysis The course provides introduction independent component analysis and source separation start from simple statistical principles examine connections information theory and sparse coding give overview available algorithmics also show how several key ideas ICA are illuminated information geometry 
1131 en Extensions Gaussian Processes for Ranking Semi Supervised and Active Learning
1132 en Online Learning and Game Theory consider online learning and its relationship game theory online decision making problem Singer lecture one typically makes sequence decisions and receives feedback immediately after making each decision far back the 1950 game theorists gave algorithms for these problems with strong regret guarantees Without making statistical assumptions these algorithms were guaranteed perform nearly well the best single decision where the best chosen with the benefit hindsight discuss applications these algorithms complex learning problems where one receives very little feedback Examples include online routing online portfolio selection online advertizing and online data structures also discuss applications learning Nash equilibria zero sum games and learning correlated equilibria general two player games 
1134 en Welcome Chicago and brief introduction machine learning
1135 en Generalization bounds When learning algorithm produces classifier natural question ask How well will the future make statements about the future given the past some assumption must made make only assumption that all examples are drawn independently and identically from some unknown distribution can answer the question The answer this question directly applicable classifier testing and confidence reporting also provides simple general explanation overfitting and influences algorithm design 
1139 en Semi supervised Learning Manifold Methods
1150 en Estimation gradients and coordinate covariation classification introduce algorithm that simultaneously estimates classification function well its gradient the supervised learning framework The motivation for the algorithm find salient variables and estimate how they covary efficient implementation with respect both memory and time given 
1151 en Optimality Bayesian Transduction Implications for Input Non stationarity
1152 en Learning Classifiers Distribution and Cost sensitive Environments
1153 en Estimating the Joint AUC Labelled and Unlabelled Data
1156 en  Domain Adaptation Formal Framework Addressing the Training Test Distribution Gap
1157 en Risk Hull Method for Inverse Problems
1161 en  Statistical View Some Regularization Methods for Ill posed Problem
1162 en Methods and Convergence Results for Non Linear Inverse Problems
1164 en Inverse Problems with Error the Operator
1165 en Some Key Challenges Web Crawlers and Content Based Search Engines
1166 en AdaBoost Universally Consistent consider the risk probability error the classifier produced AdaBoost and particular the stopping strategy used ensure universal consistency classification method universally consistent the risk the classifiers produces approaches the Bayes risk the minimal risk the sample size grows Several related algorithms regularized versions AdaBoost have been shown universally consistent but AdaBoost universal consistency has not been established Jiang has demonstrated that for each probability distribution satisfying certain smoothness conditions there stopping time for sample size that AdaBoost stopped after iterations its risk approaches the Bayes risk for that distribution Our main result that AdaBoost stopped after iterations universally consistent where the sample size and 
1170 en Morfessor the Morpho Challenge this work Morfessor morpheme segmentation model and algorithm developed the organizers the Morpho Challenege outlined and references are made earlier work Although Morfessor does not take part the official Challenge competition report experimental results for the morpheme segmentation English Finnish and Turkish words The obtained results are very good Morfessor outperforms the other algorithms the Finnish and Turkish tasks and comes second the English task the Finnish speech recognition task Morfessor achieves the lowest latter error rate 
1171 en Unsupervised Morphological Segmentation Based Segment Predictability and Word Segments Alignment Word segments are relevant cues for the automatic acquisition semantic relationships from morphologically related words Indeed morphemes are the smallest meaning bearing units present unsupervised method for the segmentation words into sub units devised for this objective The system relies segment predictability discover set prefixes and suffixes and performs word segments alignment detect morpheme boundaries 
1172 en  Sample Complexity Analysis Learning from Labeled and Unlabeled Data
1178 en Two step Approach Unsupervised Morpheme Segmentation This paper describes two steps morpheme boundary segmentation algorithm The task solely find boundaries between morphemes bar and any further analysis such phoneme deletions insertions alternations that may occur between within morphemes The algorithm presented here was designed under the premise that not supposed utilize any knowledge about the language should analyse Neither supposed rely any kind human supervision The first step use high precision low recall algorithm find relatively small number mostly correct segmentations see Bordag 2005 the second step these segmentations are used train classification which then applied all words find morpheme boundaries within them 
1179 en  Simpler Intuitive Approach Morpheme Induction present simple psychologically plausible algorithm perform unsupervised learning morphemes The algorithm most suited Indo European languages with concatenative morphology and particular English will describe the two approaches that work together detect morphemes finding words that appear substrings other words and detecting changes transitional probabilities This algorithm yields particularly good results given its simplicity and conciseness evaluated set 532 human segmented English words the 252 line program achieved score Precision Recall 
1180 en Machine Learning for Games The course gives introduction the application machine learning techniques games The course will consist two parts part dealing with computer video games part dealing with traditional board strategy games Alongside will introduce necessary background material including aspects neural networks reinforcement learning and graphical models recent years various aspects computer games have been developed near perfection These include high performance graphics realistic surround sound and detailed physical simulations However the control non player characters NPCs also known game has fallen behind the point that the resulting gaming experience often suffers Machine learning offers framework for making NPCs adaptive both the environment and the human player This technology has therefore the potential greatly enhance gaming experience Furthermore development time machine learning techniques can employed automate the creation intelligent NPC behavior thereby replacing the current standard scripting and trial and error The examples presented include imitation learning for avatars and reinforcement learning fighting games Classical board games such Chess and Backgammon have been traditional theme artificial intelligence While chess has essentially been solved traditional approaches world class Backgammon engines could only developed based machine learning techniques originally the combination neural networks and reinforcement learning For the traditional board game neither the two approaches has been successful far this part the course will explain and discuss the machine learning approach Backgammon will then give introduction the game and discuss what machine learning may able contribute the field computer with particular focus modeling the uncertainty that emerges from the game overwhelming complexity 
1182 en Information Theoretic Metric Learning formulate the metric learning problem that minimizing the differential relative entropy between two multivariate Gaussians under constraints the Mahalanobis distance function Via surprising equivalence show that this problem can solved low rank kernel learning problem Specifically minimize the Burg divergence low rank kernel input kernel subject pairwise distance constraints Our approach has several advantages over existing methods First present natural information theoretic formulation for the problem Second the algorithm utilizes the methods developed Kulis which not involve any eigenvector computation particular the running time our method faster than most existing techniques Third the formulation offers insights into connections between metric learning and kernel learning 
1183 en Multitask learning the Bayesian way Multi task learning lends itself particularly well Bayesian approach Cross inference between tasks can implemented sharing parameters the likelihood model and the prior for the task specific model parameters Choosing different priors one can implement task clustering and task gating Throughout presentation predicting single copy newspaper sales will serve running example 
1184 en  Bayesian Probability Calculus for Density Matrices One the main concepts quantum physics density matrix which symmetric positive definite matrix trace one Finite probability distributions can seen special case when the density matrix restricted diagonal develop probability calculus based these more general distributions that includes definitions joints conditionals and formulas that relate these including analogs the Theorem Total Probability and various Bayes rules for the calculation posterior density matrices The resulting calculus parallels the familiar conventional probability calculus and always retains the latter special case when all matrices are diagonal 
1185 en Multi task feature learning present method for learning low dimensional representation which shared across set multiple related tasks The method builds upon the well known norm regularization problem using new regularizer which controls the number learned features common for all the tasks show that this problem equivalent convex optimization problem and develop iterative algorithm for solving 
1187 en  Efficient Sequential Decision Making Structured Problems
1190 en Teaching Data Mining Specific Experience
1191 en Multiarmed Bandits and Partial Monitoring Exploration and Exploitation using Upper Confidence Bounds
1193 en Exploration Exploitation for Statistical Software Testing
1194 en Mutual Cuts Graphs Learning Bioinformatics
1195 en Discriminative Training for Object Recognition Using Image Patches
1196 en The UoS LAVA group Approach Generic Image Categorisation
1197 en Kernel Based Classification Visual Objects using Sparse Image Representation
1198 en Linear SVM Classification Visual Objects using Dense Image Representation
1199 en 101 Visual object classes Introduction
1200 en Overview the Challenge and Results
1201 en Many are Better than One Improving probabilistic estimates decision trees using Ensembles
1202 en Lessons Learned the Challenge Making Predictions and Scoring Them
1206 en Clustering from Optimization viewpoint Exploration and Exploitation using Upper Confidence Bounds
1212 en Textual Entailment Recognition Based Inversion Transduction Grammar
1213 en MITRE’ Submissions the Pascal RTE Challenge
1215 en VENSES – Linguistically Based System for Semantic Evaluation
1216 en UCD IIRG Approach the Textual Entailment Challenge
1217 en Robust Textual Inference Using Diverse Knowledge Sources
1218 en Textual Entailment Resolution via Atomic Propositions
1219 en Combining Shallow and Deep NLP Methods for Recognizing Textual Entailment
1223 en Learning Visual Distance Function for Object Identification from one Example Comparing images essential several computer vision problems like image retrieval object identification The comparison two images heavily relies the definition good distance function Standard functions the euclidean distance the original feature space are too generic and fail encode the domain specific information this paper propose learn similarity measure specific given category cars This distance learned from training set pairs images labeled “same” “different” indicating the two images represent the same object same car model not After learning this measure used predict how similar two images never seen objects are 
1224 en Gradient Methods for Machine Learning Gradient methods locally optimize unknown differentiable function and thus provide the engines that drive much machine learning Here take look under the hood beginning with brief overview classical gradient methods for unconstrained optimization Steepest descent Newton method Levenberg Marquardt BFGS Conjugate gradient cope with the flood data find ourselves today stochastic approximation the gradient from subsamples data becomes necessity Unfortunately the noise this introduces into the gradient not tolerated well the classical gradient methods with the exception steepest descent which however very slow converge see how local step size adaptation can used accelerate the convergence stochastic gradient descent culminating the recent stochastic meta descent SMD algorithm SMD requires certain Hessian vector products which can computed efficiently via algorithmic automatic differentiation set techniques that help automate the correct implementation gradient methods general discuss the basic concepts and learn simple ways implement the forward mode and with the fast Hessian vector product 
1230 en RNA Structure Prediction Including Pseudoknots Based Stochastic Multiple Context Free Grammar Several grammars have been proposed for modeling RNA pseudoknotted structure this paper focus multiple contextfree grammars MCFGs which are natural extension context free grammars and can represent pseudoknots and extend specific subclass MCFGs probabilistic model called SMCFG 
1231 en Plains Brains and Automobiles Continuing advances information and communications technology ICT are increasing the scale and connectivity today engineered systems Managing the resultant complexity becoming the central challenge for industry and government from software cities and even stock exchanges Across the wide range internationally leading research groups are addressing this challenge many cases they draw inspiration from biology which provides innumerable examples systems that cope with complexity From cells ecosystems biology achieves scalability adaptability self repair and robustness often exploiting emergent system level behaviours Achieving equivalent success engineered systems the root problem that face the first our short courses introduce the core concepts complexity the context both natural and engineered systems and explore the ways which new computational systems models and simulations are taking part complexity science through series lectures and workshop activities 
1232 en Building blocks for semantic search engines Ranking and compact indexing entity relation graphs see evolutionary path supporting semantic search over text facilitated extractors and annotators for ever growing collections entity and relation types and search systems that exploit smooth continuum between structured entities and relations one hand and uninterpreted text the other The extractors and annotators will imperfect and incomplete 
1233 en Part Novel Bayesian Approach for Uncovering Potential Spectroscopic Counterparts for Clinical Variables NMR Metabonomic Applications Metabonomic approaches based spectroscopic data are their infancy biomedicine key challenge clinical metabonomics uncovering and understanding the relations between the multidimensional spectroscopic data and the clinical measures currently used for disease risk assessment and diagnostics novel Bayesian approach for revealing clinically relevant signals presented here for real NMR metabonomics data set The results are not only mathematically superior but also biochemically fully coherent 
1235 en Improved Functional Prediction Proteins Learning Kernel Combinations Multilabel Setting Kernel methods have been successfully applied variety biological data analysis problems One problem using kernels however the lacking interpretability the decision functions has been proposed address this problem using multiple kernels together with some combination rules where each the kernels measures different aspects the data Methods for learning sparse kernel combinations have the potential extract relevant measurements for given task 
1236 en The Challenge Predicting Gene Function The biological sciences are undergoing explosion the amount available data New data analysis methods are needed deal with the data central problem bioinformatics the assignment function sequenced open reading frames ORFs The most common approach based inferred homology using statistically based quence similarity SIM method PSI BLAST 
1238 en Hierarchical Multilabel Classification Trees for Gene Function Prediction Prediction gene function called hierarchical multilabel classification HMC task single instance can labelled with multiple classes rather than just one gene can have multiple functions and these classes are organized hierarchy Many machine learning methods focus learning predictive models with single target variable One can then learn predict all classes separately and combine the predictions afterwards 
1239 en Objective Bayesian Nets for Breast Cancer Prognosis According objective Bayesianism agent’ degrees belief should determined probability function out all those that satisfy constraints imposed background knowledge that maximises entropy Bayesian net offers way efficiently representing probability function and efficiently drawing inferences from that function 
1240 en Context dependent visualization protein function Assignment protein function nontrivial task due the fact that the same proteins may involved different biological processes depending the state the biological system and protein localization Therefore protein function context dependent and textual annotations commonly utilized describe protein function lack the flexibility address such contextuality 
1241 en Support vector machines loss with penalty consider sample from where feature and binary label say with values use high dimensional linear approximation the regression and support vector machine loss with penalty the regression coefficients This procedure does not depend the unknown noise level the unknown sparseness approximations Bayes rule but nevertheless its prediction error smaller for smaller noise levels and sparser approximations Thus adapts unknown properties the underlying distribution example show that terms logarithmic the sample size the procedure yields minimax rates for the excess risk 
1243 en Automatic Cluster Complexity and Quantity Selection Towards Robust Speaker Diarization
1245 en Statistical Aspects Pattern Analysis Abstract The lectures will introduce the role statistics pattern analysis with discussion the difference between pattern significance and pattern stability will discuss composite hypothesis testing and the Bonferroni correction Concentration inequalities will introduced and used assess the statistical reliability empirical estimates move consider uniform convergence order analyse pattern stability Rademacher complexity will discussed theoretical tool for the bounding uniform convergence 
1248 en The Complexity Learning Verification Informally one branch learning theory focuses making statements the form this learned classifier least good common intuition underlying many bounds this form that some form prior bias must exist the set all classifiers order make such statements This intuition can made precise few forms discuss the ways which bias and prior allow verifiable learning well the limitations prior addressing this problem 
1250 en Suffix tree and Hidden Markov techniques for pattern analysis Suffix tree construction Mention the new linear time array constructions using suffix trees for finding motifs with gaps some new observations hours finding cis regulatory motifs comparative genomics hour Hidden Markov techniques for haplotyping
1254 en Statistical Relational Learning Part Problems that arise from linkage and autocorrelation among objects must taken into account Because instances are linked together classification typically involves complex inference arrive collective classification which the labels predicted for the test instances are determined jointly rather than individually Unlike iid problems where the result learning single classifier relational learning often involves instances that are heterogeneous where the result learning set multiple components classifiers probability distributions etc that predict labels objects and logical relationships between objects 
1255 en Statistical Relational Learning Part Statistical machine learning the midst relational revolution After many decades focusing independent and identically distributed iid examples many researchers are now studying problems which the examples are linked together into complex networks These networks can simple sequences and meshes such those arising part speech tagging and remote sensing complex citation graphs the world wide web and relational data bases 
1257 en Supervised Clustering with Support Vector Machines Supervised clustering the problem training clustering algorithm produce desirable clusterings given sets items and complete clusterings over these sets learn how cluster future sets items Example applications include noun phrase coreference clustering and clustering news articles whether they refer the same topic this paper present SVM algorithm that trains clustering algorithm adapting the item pair similarity measure The algorithm may optimize variety different clustering functions variety clustering performance measures empirically evaluate the algorithm for noun phrase and news article clustering 
1258 en Origins Sex has been century and half since Darwin provided the first mechanistic explanation for the complexity the living things see around Only the last years have computational systems been employed try out natural selection complex artificial problems There have been some successes but the complexity artificially evolved systems remains very long way short the complexity that easy find biology Why this our understanding natural evolution missing something important How can improve our artificial problem solving methods make them work better large scale complex problems 
1259 en Probing Landscapes has been century and half since Darwin provided the first mechanistic explanation for the complexity the living things see around Only the last years have computational systems been employed try out natural selection complex artificial problems There have been some successes but the complexity artificially evolved systems remains very long way short the complexity that easy find biology Why this our understanding natural evolution missing something important How can improve our artificial problem solving methods make them work better large scale complex problems 
1262 en Privacy and Background Knowledge The digitization our daily lives has led explosion the collection data governments corporations and individuals Protection confidentiality this data utmost importance However knowledge statistical properties private data can have significant societal benefit for example decisions about the allocation public funds based Census data the analysis medical data from different hospitals understand the interaction drugs will start introducing two application scenarios privacy preserving data analysis and privacy preserving data publishing will show how simple models background knowledge can lead severe breaches privacy both applications and will describe how proper modeling background knowledge can avoid privacy breaches will outline first algorithmic steps towards privacy preserving data analysis and data publishing with background knowledge and will conclude with open problems 
1263 en Easy Learning Theory for Highly Scalable Algorithms
1264 en Game theoretic models molecular biology There are many challenges computational modeling biological processes Few processes such signaling pathways operate dependently others but rather involve substantial coordination and shared resources The level abstraction appropriate for understand ing different processes viewing pathway filter molecular cascade varies context and the type predictions sought 
1265 en Reinforcement Learning Theory The tutorial several new pieces Reinforcement learning theory developed the last years This includes Sample based analysis including and sparse sampling Generalization based analysis including conservative policy iteration and Classification reductions For each these forms theory cover the basic results and cover the weaknesses and strengths the approach context 
1266 en Generative Models for Decoding Real Valued Natural Experience FMRI Functional Magnetic Resonance Imaging FMRI provides unprecedented window into the complex functioning the human brain typically detailing the activity thousands voxels for hundreds time points The interpretation FMRI complicated however because the unknown connection between the hemodynamic response and neural activity and the unknown spatiotemporal characteristics the cognitive patterns themselves Recent work has exploited techniques from machine learning find patterns voxel activity related brain processes see Many these techniques involve decoding inferring the value category class stimulus given pattern voxel activations Decoding can generally split into two approaches discriminative and generative With discriminative model one learns the conditional distribution directly minimizing loss such minimum classification error Alternatively the generative approach obtains this conditional probability through Bayes rule one posits and fits models for and instead Both approaches can reliably establish the existence sufficient decoding information 
1275 en Fitness Landscapes has been century and half since Darwin provided the first mechanistic explanation for the complexity the living things see around Only the last years have computational systems been employed try out natural selection complex artificial problems There have been some successes but the complexity artificially evolved systems remains very long way short the complexity that easy find biology Why this our understanding natural evolution missing something important How can improve our artificial problem solving methods make them work better large scale complex problems 
1277 en Random projection margins kernels and feature selection Random projection simple technique that can often provide insight into questions such why good have large margin what are kernels really doing and how are they similar feature selection this talk will describe some simple learning algorithms using random projection will then discuss how given kernel black box function can use various forms random projection extract explicit small feature space that captures much the power the given kernel function 
1279 en Large Margin Thresholded Ensembles for Ordinal Regression propose thresholded ensemble model for ordinal regression problems The model consists weighted ensemble confidence functions and ordered vector thresholds Using such model could theoretically and algorithmically reduce ordinal regression problems binary classification problems the area ensemble learning Based the reduction derive novel large margin bounds common error functions such the classification error and the absolute error addition also design two novel boosting approaches for constructing thresholded ensembles Both our approaches have comparable performance the state the art algorithms but enjoy the benefit faster training Experimental results benchmark datasets demonstrate the usefulness our boosting approaches 
1284 en Agnostic Active Learning The great promise active learning that via interaction the number samples required can reduced logarithmic the number required for standard batch supervised learning methods achieve this promise active learning must able cope with noisy data show how possible cope with even malicious noise active learning setting removing noise obstacle regular application active learning 
1285 en Neighbourhood Components Analysis Say you want Nearest Neighbour classification Besides selecting you also have chose distance function order define nearest talk about novel method for learning from the data itself distance measure used KNN classification The learning algorithm Neighbourhood Components Analysis NCA directly maximizes stochastic variant the leave one out KNN score the training set can also learn low dimensional linear embedding labeled data that can used for data visualization and very fast classification high dimensions course the resulting classification model non parametric making assumptions about the shape the class distributions the boundaries between them time permits also talk about newer work learning the same kind distance metric for use inside Gaussian Kernel SVM classifier 
1286 en Triple jump acceleration for the algorithm and its extrapolation based variants The Aitken acceleration one the most commonly used method speed the fixed point iteration computation including the algorithm However requires compute approximate the Jacobian the mapping matrix which can intractable for complex models will present our current research topic the triple jump acceleration accelerate the and some its extrapolation based variants approximating their Jacobians One advantage the triple jump framework that can directly use the and its extrapolation based variants black boxes and achieve acceleration easily can update parameter vectors globally with the same approximated Jacobian locally based each decomposable component with different Jacobians Experimental results show that the triple jump methods consistently accelerate parameterized pEM and adaptive aEM for variety probabilistic models 
1288 en Introduction Learning Theory The goal this course introduce the key concepts learning theory will not restricted Statistical Learning Theory but will mainly focus statistical aspects Instead giving detailed proofs and precise statements this course will aim providing some useful conceptual tools and ideas useful for practitioners well for theoretically driven people 
1291 en Compositional Evolution has been century and half since Darwin provided the first mechanistic explanation for the complexity the living things see around Only the last years have computational systems been employed try out natural selection complex artificial problems There have been some successes but the complexity artificially evolved systems remains very long way short the complexity that easy find biology Why this our understanding natural evolution missing something important How can improve our artificial problem solving methods make them work better large scale complex problems 
1294 en Learning and Regularization Using non Positive Kernels
1296 en Tutorial Machine Learning Reductions There are several different classification problems commonly encountered real world applications such importance weighted classification cost sensitive classification reinforcement learning regression and others Many these problems can related each other simple machines reductions that transform problems one type into problems another type Finding reduction from your problem more common problem allows the reuse simple learning algorithms solve relatively complex problems also induces organization learning problems — problems that can easily reduced each other are nearby and problems which can not reduced are not close 
1298 en Information Geometry This tutorial will focus entropy exponential families and information projection start seeing the sense which entropy the only reasonable definition randomness will then use entropy motivate exponential families distributions — which include the ubiquitous Gaussian Poisson and Binomial distributions but also very general graphical models The task fitting such distribution data convex optimization problem with geometric interpretation information projection the projection prior distribution onto linear subspace defined the data minimize particular information theoretic distance measure This projection operation which more familiar other guises core optimization task machine learning and statistics study the geometry this problem and discuss two popular iterative algorithms for 
1299 en Exponential Families Feature Space this course will discuss how exponential families standard tool statistics can used with great success machine learning unify many existing algorithms and invent novel ones quite effortlessly particular will show how they can used feature space recover Gaussian Process classification for multiclass discrimination sequence annotation via Conditional Random Fields and how they can lead Gaussian Process Regression with heteroscedastic noise assumptions 
1300 en Robust heteroscedastic linear discriminant analysis and LCRC posterior features meeting data recognition
1302 en Speech Speech Translation Services for the Olympic Games 2008
1303 en Coevolution has been century and half since Darwin provided the first mechanistic explanation for the complexity the living things see around Only the last years have computational systems been employed try out natural selection complex artificial problems There have been some successes but the complexity artificially evolved systems remains very long way short the complexity that easy find biology Why this our understanding natural evolution missing something important How can improve our artificial problem solving methods make them work better large scale complex problems 
1304 en Content Analysis Marriage Signal Processing and Machine Learning
1305 en  Multimodal Analysis Floor Control Meetings
1306 en Overlap Meetings ASR Effects and Analysis Dialog Factors Speakers and Collection Site
1308 en Detecting Action Items Multi Party Meetings Annotation and Initial Experiments
1310 en Juicer Weighted Finite State Transducer speech decoder
1311 en Multistream Recognition Dialogue Acts Meetings
1313 en Wifi Localization with Gaussian Processes Estimating the location mobile device from wireless signal strength interesting research problem especially given the complexity signal propagation through space the presence obstacles such buildings walls people Gaussian processes have already been used solve such signal strength localization problems extend this work indoor WiFi localization and present novel kernel functions which increase the accuracy the Gaussian process model especially when faced with sparse training data additionally present preliminary results simultaneous mapping and localization using Gaussian process latent variable modeling 
1316 en Concentration Inequalities with Machine Learning Applications
1324 en Sum what has been done PASCAL
1327 en Some Mathematical Tools for Machine Learning These are lectures some fundamental mathematics underlying many approaches and algorithms machine learning They are not about particular learning algorithms they are about the basic concepts and tools upon which such algorithms are built Often students feel intimidated such material there vast amount classical mathematics and can hard find the wood for the trees The main topics these lectures are Lagrange multipliers functional analysis some notes matrix analysis and convex optimization concentrated things that are often not dwelt typical coursework Lots examples are given green puzzle for the student think about These lectures are far from complete perhaps the most significant omissions are probability theory statistics for learning information theory and graph theory hope eventually turn all this into series short tutorials Please let know any errors etc from Chris Burges homepage http research microsoft com cburges Lecture contains Lagrange multipliers Lagrange the Mathematician Lagrange multipliers indirect approach can easier Multiple Equality Constraints Multiple Inequality Constraints Two points sphere The Largest Parallelogram Resource allocation convex combination numbers maximized choosing the largest The Isoperimetric problem For fixed mean and variance which univariate distribution has maximum entropy exact solution for SVM living simplex Notes some Basic Statistics Probabilities can Counter Intuitive Simpson paradox the Monty Hall puzzle IID ness Measurement Error decreases sqrt Correlation versus Independence The Ubiquitous Gaussian Product Gaussians Gaussian Convolution two Gaussians Gaussian Projection Gaussian Gaussian Sum Gaussian random variables Gaussian random variables Uncorrelated Gaussian variables are also independent Maximum Likelihood Estimates for mean and covariance prove required matrix identities Aside For dim Laplacian max likelihood gives the median Using cumulative distributions derive densities Principal Component Analysis and Generalizations Ordering Variance Does Grouping Change Things PCA Decorrelates the Samples PCA gives Reconstruction with Minimal Mean Squared Error PCA preserves Mutual Information Gaussian data PCA directions lie the span the data PCA second order moments only The Generalized Rayleigh Quotient Non orthogonal principal directions OPCA Fisher Linear Discriminant Multiple Discriminant Analysis Elements Functional Analysis High Dimensional Spaces Winning Transitive Most the Volume Near the Surface Cubes Spheres dimensions Banach Spaces Hilbert Spaces Compactness Norms Useful Inequalities Minkowski and Holder Vector Norms Matrix Norms The Hamming Norm infty norms norm Example Using Norm Constraint Kernel Algorithms
1329 en Learning with Kernels The Course Learning with Kernels covers Elements Statistical Learning Theory Kernels and feature spaces Support vector algorithms and other kernel methods Applications
1330 en Sex and Units Selection has been century and half since Darwin provided the first mechanistic explanation for the complexity the living things see around Only the last years have computational systems been employed try out natural selection complex artificial problems There have been some successes but the complexity artificially evolved systems remains very long way short the complexity that easy find biology Why this our understanding natural evolution missing something important How can improve our artificial problem solving methods make them work better large scale complex problems 
1334 en  Gaussian Approximation for Stochastic Nonlinear Dynamical Processes with Annihilation
1335 en Using Maximal Embedded Syntatic Subtrees for Textual Entailment Recognition this paper address the textual entailment task using tree mining and matching technique Our results show that accuracy can improved when using combination lexical entailment with syntactic matching The best result received combinig two components the following recall and precision the test set 
1336 en UNED PASCAL RTE Challenge This paper reports the description the developed system and the results obtained the participation the UNED the Second Recognizing Textual Entailment RTE Challenge New techniques and tools have been added enriched queries WordNet detection numeric expresions and their entailment and Support Vector Machine classification SVM are the more relevant The accuracy performed slightly higher than the one from the previous edition system 
1337 en Exploration exploitation UCT for Monte Carlo 
1338 en Challenge results PASCAL Exploration Exploitation challenge results for phase 
1340 en Semantic Annotation the Alvis Project
1341 en Variational Bayes for Continuous time Nonlinear State space Models
1342 en How Random Coin Toss Bayesian Inference and the Symbolic Dynamics Deterministic Chaos
1343 en The Gaussian Variational Approximation Stochastic Differential Equations
1344 en Learning Textual Entailment from Examples this paper present novel approach for learning entailment relations from positive and negative examples define similarity between two text hypothesis pairs based syntatic and lexical information experimented our model within the RTE 2006 challenge obtaining the accuracy 88and for the two submissions 
1346 en Independent Component Analysis independent component analysis ICA the purpose linearly decompose multidimensional data vector into components that are statistically independent possible For nongaussian random vectors this decomposition not equivalent decorrelation done principal component analysis but something considerably more sophisticated ICA allows one separate nongaussian source signals from their linear mixtures blindly using other information than the congaussianity the source signals ICA can also used extract features from image and sound signals according the principle redundancy reduction that has its origins the neurosciences talks will review the basic theory and theoretical background ICA together with some recent theoretical developments 
1348 en Analysis Dynamics has been century and half since Darwin provided the first mechanistic explanation for the complexity the living things see around Only the last years have computational systems been employed try out natural selection complex artificial problems There have been some successes but the complexity artificially evolved systems remains very long way short the complexity that easy find biology Why this our understanding natural evolution missing something important How can improve our artificial problem solving methods make them work better large scale complex problems 
1349 en Representations graphs graph mathematical structure that sometimes hard separate from its visualization important branch graph theory studies graph drawing problems Recently mathematical approach graph visualization has been developed under the name graph representations this tutorial present outline the theory graph representations 
1350 en Visualizing Cauchy’ Interlacing Property for Line Distance Matrices the paper proven that line distance matrices size have one positive and negative eigenvalues Visual representation Cauchy interlacing property for line distance matrices considered 
1351 en  Integrated framework for the management video collection Video document retrieval now active part the domain multimedia retrieval However unlike for other media the management collection video documents adds the problem efficiently handling overwhelming volume temporal data Challenges include balancing efficient content modeling and storage against fast access various levels this paper detail the framework have built accommodate our developments content based multimedia retrieval show that not only our framework facilitates the developments processing and indexing algorithms but also opens the way several other possibilities such rapid interface prototyping retrieval algorithms benchmarking this respect discuss our developments relation wider contexts such MPEG and The TREC Video Track 
1354 en How predict with Bayes MDL and Experts Most passive Machine Learning tasks can stated sequence prediction problems This includes pattern recognition classification time series forecasting and others Moreover the understanding passive intelligence also serves basis for active learning and decision making the recent past rich theories for sequence prediction have been developed and this still ongoing process the other hand are arriving the stage where some important results are already termed classical While much the current Learning Theory formulated under the assumption independent and identically distributed observations this lecture series focusses situations without this prerequisite weather stock market time series 
1358 en Generalized Principal Component Analysis GPCA Data segmentation usually though chicken and egg problem order estimate mixture models one needs first segment the data and order segment the data one needs know the model parameters Therefore data segmentation usually solved two stages Data clustering and Model fitting Other iterative methods use the Expectation Maximization algorithm This talk will show that for wide class segmentation problems with multi linear structure including clustering subspaces unknown and varying dimensions the chicken and egg dilemma can tackled follows Fit set polynomials all data points without clustering the data Obtain the model parameters for each group from the derivatives these polynomials Applications GPCA image video motion segmentation face clustering and identification hybrid dynamical models systems will also presented 
1360 en Text Categorization This course will cover the principal topics important creating working text categorization system will focus the components such system and processes required create based the practical experiences the Scamseek project The role machine learning will the center the discussion but the surrounding tasks language modeling computational linguistics and software engineering will all discussed varying degrees Discussion some aspects the Scamseek project are restricted under secrecy agreements with ASIC 
1361 en Multi stream modeling with applications speech and multimodal processing After brief discussion the problem arising from the processing and modeling multiple stream multi channel multi sensor signals will discuss few statistical structures such multi stream HMM and asynchronous HMM that can accommodate multiple asynchnonous observation streams possibly exhibiting different frame rates Indeed will shown different speech recognition and multimodal fusion tasks that might sometimes good idea able desynchronize the streams order maximize their joint likelihood Different applications speech recognition such multi band and multi stream speech processing will discussed Finally multimodal applications significantly benefiting from this multi stream paradigm will also discussed including audio visual speech recognition and modeling human interaction meetings modeling the joint behaviours participants through multiple audio and visual features 
1362 en Toward Dependency Path based Entailment present our submission the RTE2 challenge which takes steps the direction dynamically entailing hypotheses via their dependency paths evaluate semantic similarity between sentences utilizing corpus occurence estimates various dependency path features and show improvement the RTE1 dataset 
1363 en Testing Parametric Models Statistical Inverse Problems
1364 en Acquisition Knowledge About Spatial Location Rats the Associative Mechanism
1365 en Learning Control Octopus Arm with Gaussian Process Temporal Difference Methods The Octopus arm highly versatile and complex limb How the Octopus controls such hyper redundant arm not mention eight them yet unknown Robotic arms based the same mechanical principles may render present day robotic arms obsolete this talk will describe how tackle this problem using online reinforcement learning algorithm based Bayesian approach policy evaluation known Gaussian process temporal difference GPTD learning 
1369 en Artificial Companions What will artificial Companion like Who will need them and how much good harm will they Will they change our lives and social habits the radical way technologies have the past just think trains phones and television Will they force changes the law that things that are not people will liable for damages till now the case that machine goes wrong always the maker the programmer their company which fault 
1370 en  Mixed lingual Phonological Component Polyglot TTS Synthesis Polyglot text speech synthesis the synthesis sentences containing one more inclusions from other languages primarily depends accurate morpho syntactic analyzer for such mixed lingual texts From the output this analyzer mixed lingual phonological component can derive correct pronunciation application language specific phonological transformation rules that are restricted syntactic graphemic and phonological context constraints
1371 en Meeting Modelling The paper presents framework for corpus based multimodal research Part this framework applied the context meeting modelling generic model for different aspects meetings discussed This model leads layered description meetings where each layer adds level interpretation for distinct aspects based information provided lower layers This model should provide starting point for selecting annotation schemes for layers the meeting and for defining hierarchy between individual layers 
1372 en  SEER Multimodal Office Activity Recognition System with Selective Perception will present the use layered probabilistic representations for modeling the activities people system named SEER will describe how use the representation sensing learning and inference multiple levels temporal granularity and abstraction The approach centers the use cascade Hidden Markov Models HMMs named Layered Hidden Markov Models LHMMs diagnose states user activity based real time streams evidence from video audio and computer keyboard and mouse interactions 
1373 en Mixture SVMs for Face Class Modeling present method for face detection which uses new SVM structure trained expert manner the eigenface space This robust method has been introduced post processing step real time face detection system The principle train several parallel SVMs subsets some initial training set and then train second layer SVM the margins the first layer SVMa This approach presents number advantages over the classical SVM firstly the training time considerably reduced and secondly the classification performance improved will present some comparisions with the single SVM approach for the case human face class modeling 
1374 en Towards Computer Understanding Human Interactions People meet order interact disseminating information making decisions and creating new ideas Automatic analysis meetings therefore important from two points view extracting the information they contain and understanding human interaction processes Based this view this article presents approach which relevant information content meeting identified from variety audio and visual sensor inputs and statistical models interacting people 
1375 en  the Adequacy Baseform Pronunciations and Pronunciation Variants This paper presents approach automatically extract and evaluate the stability pronunciation variants adequacy the model accommodate this variability based multiple pronunciations each lexicon words and the knowledge reference baseform pronunciation Most approaches toward modelling pronunciation variability speech recognition are based the inference through ergodic HMM model pronunciation graph including all pronunciation variants usually followed smoothing Bayesian the resulting graph 
1377 en Tree Edit Distance for Recognizing Textual Entailment Estimating the Cost Insertion The focus our participation PASCAL RTE2 was estimating the cost the information the hypothesis which missing the text and can not matched with entailment rules have tested different system settings for calculating the importance the words the hypothesis and investigated the possibility combining them with machine learning algorithm 
1378 en Tandem Connectionist Feature Extraction for Conversational Speech Recognition Multi Layer Perceptrons MLPs can used automatic speech recognition many ways particular application this tool over the last few years has been the Tandem approach described Hermansky number publications Here discuss the characteristics the MLP based features used for the Tandem approach and conclude with report their application conversational speech recognition The paper shows that MLP transformations yield variables that have regular distributions which can further modified using logarithm make the distribution easier model Gaussian HMM Two more vectors these features can easily combined without increasing the feature dimension also report recognition results that show that MLP features can significantly improve recognition performance for the NIST 2001 Hub evaluation set with models trained the Switchboard Corpus even for complex systems incorporating MMIE training and other enhancements 
1379 en  the Adequacy Baseform Pronunciations and Pronunciation Variants This paper presents approach automatically extract and evaluate the stability pronunciation variants adequacy the model accommodate this variability based multiple pronunciations each lexicon words and the knowledge reference baseform pronunciation Most approaches toward modelling pronunciation variability speech recognition are based the inference through ergodic HMM model pronunciation graph including all pronunciation variants usually followed smoothing Bayesian the resulting graph 
1380 en Gaussian Processes for Active Sensor Management this paper study the active sensor management problem using continuous optimal experimental design OED framework This task comprises the determination allocation for limited number sensors over the spatial domain and the number repetitive measurements these locations order improve the overall system performance present principled approach active sensor management with repetitive measurements for Gaussian Processes GPs using generalised optimality criteria and soft margin constrains The resulting optimum the convex optimization the optimal experimental design for generally sparse the sense that measurements should taken only limited set possible sensor locations demonstrate the use our method arti¯cial dataset 
1382 en Statistical Translation Heat Kernels and Expected Distances High dimensional structured data such text and images often poorly understood and misrepresented statistical modeling The standard histogram representation suffers from high variance and performs poorly general explore novel connections between statistical translation heat kernels manifolds and graphs and expected distances These connections provide new framework for unsupervised metric learning for text documents Experiments indicate that the resulting distances are generally superior their more standard counterparts 
1385 en Minimum Likelihood Image Feature and Scale Detection Based the Brownian Image Model present novel approach image feature and scale detection based the fractional Brownian image model which images are realisations Gaussian random process the plane Image features are points interest usually sparsely distributed images propose detect such points and their intrinsic scale detecting points scale space that locally minimises the likelihood under the model 
1386 en Verification Facts across Document Boundaries
1387 en Automated Text Summarization using MEAD Experience with the IMF Staff Reports
1388 en Integrate Text Clustering Features Text Categorization System
1389 en Active Semi Supervised Learning for Textual Information Access
1390 en Cross lingual Linking News Clusters Various Languages Avoiding the Usage Bilingual Linguistic Resources
1391 en Telugu English Dictionary Based Cross Language Query Focused Multi Document Summarization
1393 en Modularity has been century and half since Darwin provided the first mechanistic explanation for the complexity the living things see around Only the last years have computational systems been employed try out natural selection complex artificial problems There have been some successes but the complexity artificially evolved systems remains very long way short the complexity that easy find biology Why this our understanding natural evolution missing something important How can improve our artificial problem solving methods make them work better large scale complex problems 
1394 en  Self Organizing Map for Relation Extraction from Wikipedia using Structured Data Representations
1398 en Ranking Stealing Human Cycles Ranking objects challenging task for machines The main difficulty that some characteristics interest lack objective criteria the Internet becomes more widely used possible integrate the human capability evaluating unmeasurable properties with the computational power machines good example the Internet voting for photos foods and many others this talk propose paired comparison framework which users are asked show preferences pair objects Experiments photo ranking task show that the paired method outperforms the commonly used scoring method 
1408 en Bayesian Inference Principles and Practice The aim this course two fold convey the basic principles Bayesian machine learning and describe practical implementation framework Firstly will give introduction Bayesian approaches focussing the advantages probabilistic modelling the concept priors and the key principle marginalisation Secondly will exploit these ideas realise practical algorithms for sparse linear regression and classification exemplified models such the relevance vector machine 
1415 en Constrained Hidden Markov Models for Population based Haplotyping Analysis genetic variation human populations critical the understanding the genetic basis for complex diseases Although genomes several species have been sequenced still too expensive sequence genomes several individuals analyze genetic variation Furthermore most the genome invariant among individuals 
1417 en Predicting evolving pairs Pfam using information theory where entropy determined phylogenetic mutation events The accurate prediction evolving pairs protein sequences plays important role tertiary protein structure prediction and protein engineering Using information theory detect evolving pairs impacted the phylogenetic effect entropy measurements Mutual Information used detect evolving pairs protein family sampling based mutation events the phylogenetic tree RPE 
1418 en Estimation human endogeneous retrovirus activities from expressed sequence databases Human endogenous retroviruses HERVs are remnants ancient retrovirus infections and now reside within the human DNA Recently HERV expression has been detected both normal tissues and diseased patients However the activities expression levels individual HERV sequences are mostly unknown 
1419 en Sparse Log Gaussian Processes via MCMC for Spatial Epidemiology Log Gaussian processes LGP are attractive manner construct intensity surfaces for the purposes spatial epidemiology The intensity surfaces are naturally smoothed placing prior over the relative log Poisson rate this work fully independent training conditional FITC sparse approximation used speed computations The sampling the latent values sped with transformations taking into account the approximate conditional posterior precision 
1421 en Probabilistic Inference for Graph Classification Graph data getting increasingly popular bioinfor matics and text processing main dificulty graph data processing lies the intrinsic high dimensionality graphs namely when graph represented binary feature vector indicators all possible sub graphs the dimensionality gets too large for usual statistical methods 
1423 en Large Scale Ranking Problem some theoretical and algorithmic issues The talk divided into two parts The first part focuses web search ranking for which discuss training relevance models based DCG discounted cumulated gain optimization Under this metric the system output quality naturally determined the performance near the top its rank list will mainly focus various theoretical issues for this learning problem The second part discusses related algorithmic issues the context optimizing the scoring function statistical machine translation system according the BLEU metric standard measure translation quality Our approach treats machine translation black box and can optimize millions system parameters automatically This has not been attempted before this context will present our method and some initial results 
1424 en Model based identification transcription factor activity from microarray data With the increase volume gene expression data available from high throughput microarray experiments much research interest has been directed building mathematical models the process gene regulation Such models have primarily been used for the called reverse engineering regulatory networks inferring possible regulatory interactions directly from microarray data for example – using microarray data all these techniques make the implicit assumption that there direct relationship between the level mRNA genes coding for transcription factors TFs and the mRNA levels their gene targets 
1426 en Exploration Exploitation Challenge Framework
1431 en Advanced Statistical Learning Theory This set lectures will complement the statistical learning theory course and focus recent advances the domain classification PAC Bayesian bounds simple derivation comparison with Rademacher averages Local Rademacher complexity with classification loss Talagrand inequality Tsybakov noise conditions Properties loss functions for classification influence approximation and estimation relationship with noise conditions Applications SVM Estimation and approximation properties role eigenvalues the Gram matrix 
1434 en Least Squares Filtering Speech Signals for Robust ASR
1435 en Developing consistent view emotion oriented computing The network excellence HUMAINE currently making ordinated interdisciplinary effort develop consistent view emotion oriented computing This overview paper proposes “map” the research area distinguishing core technologies from applicationoriented and psychologically oriented work First results from the ongoing research the thematic workpackages are reported 
1437 en Automatic Dominance Detection Meetings Using Support Vector Machines show that using Support Vector Machine classifier possible determine with success rate who dominated particular meeting the basis few basic features discuss the corpus have used the way had people judge dominance and the details the classifier and features that were used 
1440 en Detection and Resolution References Meeting Documents This article proposes method for document speech align ment based explicit references made speech documents and parts documents the context multimodal meetings The motivation and the main components the method are —rst described brie° Then the article focuses the two main stages dialogue processing the detec tion the expression referring documents transcribed speech and the recognition the documents and document elements that they refer The detailed evaluation the implemented modules —rst separately and then pipeline shows that results are well above the baseline and that the various features the proposed algorithms are all relevant The integration this document speech alignment technique with other ones —nally discussed 
1447 en Variational Bayesian methods for audio indexing
1452 en Learning from Network Traffic Computing Kernels over Connection Content
1453 en Spectral Clustering and Transductive Inference for Graph Data
1455 en Exploiting Hyperlinks Learn Retrieval Model
1456 en Object Correspondence Machine Learning Problem
1459 en The Pyramid Match Kernel Efficient Learning with Sets Features
1461 en What the future 
1462 en Piecewise Dim Self Organizing Map P1D SOM
1466 en Iterative Regularization Scheme and Early Stopping Learning from Examples
1467 en Empirical Bayesian test for the smoothness the context adaptive nonparametric curve estimation problem common assumption that the function signal estimate belongs nested family functional classes parameterized quantity which often has meaning smoothness amount has already been realized that the problem estimating the smoothness meaningless What can then inferred about the smoothness try answer this question and discuss the implications our results for the hypothesis testing problem for the smoothness parameter The imbedded model structure nested family classes accounts for the fact that consistent test can constructed only for the one sided hypothesis The test statistic based the marginalized maximum likelihood estimator the smoothness for the appropriate choice the prior distribution the unknown signal 
1468 en Learning techniques Planning this lecture aim provide overview the learning techniques that have found use automated planning Unlike most the clustering and classification tasks that have dominated the recent machine learning literature learning planning requires handling relational and first order representations and foregrounds the need for knowledge intensive learning techniques will start with brief review the planning models and discuss the opportunities for learning planning will then provide survey the explanation based case based and inductive learning techniques that have been successfully used tackle them 
1469 en Asymptotic Normality Nonparametric Instrumental Variables Estimator
1471 en Nonparametric Estimation the Regression Function Errors variables
1472 en Introduction convex programming interior point methods and semi definite programming
1473 en Statistical Analysis Non Injective Inverse Problems
1474 en Estimation the Solution Differential Equation Inverse Problem
1477 en PASCAL Visualisation Challenge Part 
1479 en Introduction Kernel Methods The course will cover the basics Support Vector Machines and related kerne methods Kernels and Feature Spaces Large Margin Classification Basic Ideas Learning Theory Support Vector Machines Examples Other Kernel Algorithms
1480 en  simple feature extraction for high dimensional image representations investigate method find local clusters low dimensional subspaces high dimensional data high dimensional image descriptions Using cluster centers instead the full set data will speed the performance learning algorithms for object recognition and will possibly also improve performance because overfitting might avoided 
1481 en Markov Chain Monte Carlo Methods fundamental theorem simulation Markov chain basics Slice sampling Gibbs sampling Metropolis Hastings algorithms Variable dimension models and reversible jump MCMC Perfect sampling Adaptive MCMC and population Monte Carlo
1488 en  study visual focus attention modeling using head pose
1489 en Classification high dimensional data High Dimensional Discriminant Analysis propose new method discriminant analysis called High Dimensional Discriminant Analysis HHDA Our approach based the assumption that high dimensional data live erent subspaces with low dimensionality Thus HDDA reduces the dimension for each class independently and regularizes class conditional covariance matrices order adapt the Gaussian framework high dimensional data This regularization achieved assuming that classes are spherical their eigenspace HDDA applied recognize objects real images and its performances are compared classical classi cation methods 
1490 en Integrating two features kernels within one SVM classifier
1491 en Letter Phoneme Conversion Challenge Part 
1492 en  statistical learning approach subspace identification dynamical systems Among the different approaches identification linear dynamical systems subspace identification has become increasingly popular the last decade The reasons are the algorithmic simplicity thanks the absence non convex optimization problems the numerical stabil ity and the statistical properties Interestingly concerning the statistical side research subspace identification has been concentrated proving properties related asymptotic unbiasedness this extended abstract motivate how the use appropriate regularization can helpful the small sample case Furthermore this regularization allows one use the kernel trick identify systems where the input term the state and output equations nonlinear function the input variables 
1494 en Learning structured data via flow represented actions support vector machines
1500 en Statistical Learning Theory and Empirical Processes
1506 en PASCAL Visualisation Challenge Part 
1507 en Pattern Classification and Large Margin Classifiers These lectures will provide introduction the theory pattern classification methods They will focus relationships between the minimax performance learning system and its complexity There will four lectures The first will review the formulation the pattern classification problem and several popular pattern classification methods and present general risk bounds terms Rademacher averages measure the complexity class functions The second lecture will consider pattern classification minimax setting and show that this setting the Vapnik Chervonenkis dimension the key measure complexity The third lecture will focus theme computational complexity will present the elegant relationship between the complexity class measured its dimension and the computational complexity functions from the class This lecture will also review general results the computational complexity the pattern classification problem and its tight relationship with that associated empirical risk optimization problems The fourth lecture will consider large margin classification methods such AdaBoost support vector machines and neural networks viewing them convex relaxations intractable empirical minimization problems will review several statistical properties these large margin methods particular characterization the convex optimization problems that lead accurate classifiers and relationships between these methods and probability models 
1509 en Kernels histograms through the transportation polytope For two integral histograms and equal sum the Monge Kantorovich distance between and parameterized cost matrix the minimum all costs taken over matrices the transportation polytope Recent results suggest that this distance not negative definite and hence through Schoenberg well known result may not positive definite kernel for all Rather than using directly define similarity between and present this talk kernels and based the whole transportation polytope prove that when and have binary counts which equivalent stating that and depict clouds points equal size the permanent their Gram matrix induced the cost matrix positive definite kernel under favorable conditions also show that the volume the polytope that the number integral transportation plans positive definite quantity and through the Robinson Schensted Knuth correspondence between transportation matrices and Young Tableaux 
1510 en Predicting Electricity Distribution Feeder Failures Using Boosting and Online Learning
1511 en Selection Basis Functions Regression Search Guided the Evidence
1512 en  Simple and Efficient Algorithm for Variable Ranking and Redundancy Detection
1514 en Clustering Brain Tumours Through Constrained Manifold Learning Using Class Information
1515 en Splice form prediction using Machine Learning Accurate initio gene finding still major challenge computational biology employ state the art machine learning techniques based Hidden Semi Markov SVMs assay and improve the accuracy genome annotations applied our system called mSplicer the Caenorhabditis elegans genome and were able drastically improve its annotation 
1516 en Multi Classification Using Tri class SVM
1518 en Patterns sets points overview Patterns sets points overview illustrate the importance optimization principles the search for interesting patterns more particular for patterns sets points embedded metric space This talk will journey along the types patterns point sets that can efficiently searched for and general principles will outlined provide examples from dimensionality reduction classification clustering and others The emphasis will patterns that can expressed terms linear functions the data 
1519 en The Acquisition Propositional Logic Syntax
1520 en Preliminary Experiments with Line Adaptive GARCH Models
1521 en Bioinformatics Challenge Learning Very High Dimensions with Very Few Samples Dedicated machine learning procedures have already become integral part modern genomics and proteomics However these very high dimensional and low learning sample tasks often stretch these procedures well beyond natural boundaries their applicability few such challenges will subject this series lectures will start with brief overview classification genomics microarray data particular shall discuss some detail examples applications cancer genomics and proteomics Then concentrate phenomenon anti learning case supervised classification where standard supervised learning techniques systematically produce classifiers perfect learning sample but with independent test error rates higher than that the default random classification rule The examples natural and synthetic anti learning data will given and analysed from the stand point implications practical supervised and unsupervised classification series practical tutorials will organized parallel Participants will exposed classification microarray data including first hand experience with anti learning 
1526 en Anti Learning The Biological domain poses new challenges for statistical learning the talk shall analyze and theoretically explain some counter intuitive experimental and theoretical findings that systematic reversal classifier decisions can occur when switching from training independent test data the phenomenon anti learning demonstrate this both natural and synthetic data and show that distinct from overfitting The natural datasets discussed will include prediction response chemo radio therapy for esophageal cancer from gene expression measured cDNA microarrays prediction genes affecting the aryl hydrocarbon receptor pathway yeast The main synthetic classification problem will the approximation samples drawn from high dimensional distributions for which theoretical explanation will outlined 
1531 en Measures Statistical Dependence number important problems signal processing depend measures statistical dependence For instance this dependence minimised the context instantaneous ICA which linearly mixed signals are separated using their assumed pairwise independence from each other number methods have been proposed measure this dependence however they generally assume particular parametric model for the densities generating the observations Recent work suggests that kernel methods may used find estimates that adapt according the signals they compare These methods are currently being refined both yeild greater accuracy and permit the use the signal properties over time improving signal separability addition these methods can applied cases where the statistical dependence between observations must maximised which true for certain classes clustering algorithms 
1533 en Support Vector and Kernel Methods The lectures will introduce the kernel methods approach pattern analysis through the particular example support vector machines for classification The presentation touches generalization optimization dual representation kernel design and algorithmic implementations then broaden the discussion consider general kernel methods introducing different kernels different learning tasks and subspace methods such kernel PCA The aim give view the subject that will enable newcomer the field gain his bearings that they can move apply develop the techniques for their particular application 
1535 en Distributed Data Mining Data mining the automated analysis large volumes data looking for relationships and knowledge that are implicit data Data mining and knowledge discovery large amounts data can benefit from the use parallel and distributed computational environments improve both performance and quality data selection The goal this tutorial provide researchers and practitioners with introduction mining large data sets exploiting techniques from high performance parallel and distributed computing This tutorial organized two parts the first part introduction high performance parallel and distributed computing provided Different forms parallelism that can exploited data mining techniques and algorithms are analyzed The second part presents review distributed data mining approaches For each data mining technique different ways for parallel implementation are presented and discussed Furthermore parallel and distributed data mining systems and algorithms are discussed Finally current research issues and perspectives high performance data mining are outlined 
1537 en Parallel session Hands section Data mining with 
1538 en Student sessions The Ecolead Project
1540 en Bayesian Methods the last decade probabilistic graphical models particularn Bayes networks and Markov networks became very popular toolsn for structuring uncertain knowledge about domain interest andn for building knowledge based systems that allow sound and efficientn inferences about this domain The core idea graphical models isn that usually certain independence relations hold between the attributesn that are used describe domain interest most uncertaintyn calculi and particular probability theory the structure ofn these independence relations very similar properties concerningn the connectivity nodes graph consequence triedn capture the independence relations graph which each noden represents attribute and each edge direct dependence betweenn attributes addition provided that the graph captures only validn independences prescribes how probability distribution then usually high dimensional space that spanned the attributesn can decomposed into set smaller marginal conditional distributions This decomposition can exploited derive evidencen propagation methods and thus enables sound and efficient reasoningn under uncertainty The lecture gives brief introduction into then core ideas underlying graphical models starting from their relationaln counterparts and highlighting the relation between independence andn decomposition Furthermore the basics model construction andn evidence propagation are discussed with emphasis join junctionn tree propagation substantial part the lecture then devotedn learning graphical models from data which quantitative learningn parameter estimation well the more complex qualitative orn structural learning model selection are studied The lecture closesn with brief discussion example applications 
1541 en Stochastic Search Methods Knowledge discovery can regarded exploration high dimensional and multi modal search spaces However finding the global optimum objective function with many degrees freedom and numerous local optima computationally demanding Systems capable learning and adaptivity therefore fundamentally rely search techniques These should sample the search space such way that there high probability finding near optimal solutions Many search techniques have been developed and most them are specialized solve specific types problems important class search techniques are stochastic algorithms where certain steps are based random choice Most stochastic search algorithms were shown effective and efficient finding near optimal solutions complex problems but with guarantee finding true global optima The presentation covers stochastic search techniques inspired phenomena found nature simulated annealing and evolutionary algorithms Simulated annealing popular stochastic algorithm designed analogy with the physical process cooling molten substance where condensing matter into crystalline solid takes place this context searching for optimal solution like finding configuration the cooled system with minimum free energy Because its ability escaping from local optima simulated annealing powerful algorithm for numerical and combinatorial optimization Evolutionary algorithms are simplified models the search processes natural evolution They simulate collective learning within population individuals that represent potential solutions the considered problem The population evolves towards better regions the search space means stochastic transformations individuals and feedback their performance from the environment Three variants evolutionary algorithms are discussed evolution strategies genetic algorithms and genetic programming Evolution strategies were proposed technique evolutionary experimentation engineering design and are nowadays used numerical optimization algorithms Genetic algorithms are general purpose search and optimization algorithms based string representation candidate solutions and variation operators mimicking genetic processes nature Genetic programming extension genetic algorithms designed evolve not simple solutions given problems but computer programs solve the problems important step towards automatic programming computers and has already reached the stage producing human competitive solutions wide range application domains 
1543 en Analysis Time Series The study time series essential aspect Intelligent Data Analysis The field very broad and has been treated with very different methodological approaches ranging from differential equations stochastic models and based systems The lesson will present time series analysis part the general problem modelling dynamical systems The framework systems’ theory will provide general view such problem and will permit coherently overview the majority the time series analysis approaches more detail the principles systems theory will first discussed the concept “dynamical system” will investigated and some results systems theory will presented The notions state equilibrium linearity observability and reachability will discussed Some modelling tools will then introduced ranging from black box structural models Stochastic linear and non linear models will briefly described including and ARMAX models Moreover method obtain structural information from input output data will introduced The lesson will finally show how the knowledge systems dynamics can effectively exploited the time series clustering problem Distance based model based and template based will revisited order account for information the systems dynamics 
1546 en Fuzzy Logic The tutorial will introduce the basics fuzzy logic for data analysis Fuzzy Logic can used model and deal with imprecise information such inexact measurements available expert knowledge the form verbal descriptions will first introduce the concepts fuzzy sets degrees membership and fuzzy set operators After discussions fuzzy numbers and arithmetic operations using them the focus will shift fuzzy rules and how such systems rules can derived from available data 
1549 en Statistical Methods These two sessions give introduction classical statistics The first talk brief coverage some basic statistical theory that feel might useful during the week The topics included are probability likelihood inference Bayesian inference and the concept the bias variance tradeoff The second talk covers two main areas statistics namely linear modelling and exploratory multivariate analysis Linear modelling has elaborate set procedures for determining which the potential inputs should included model for predicting output The inputs can any data type categorical numerical can the output some extent This sort modelling has been used successfully for many years what would considered quite small sets data Some linear models are now being used much larger problems for example the construction scorecards for deciding whether approve somebody’ application for credit card This the primary type statistical model that would used scientific research Exploratory multivariate analysis collection techniques that are all based the same sort mathematical background vectors matrix algebra They are also all intended investigate the structure observations that are vectors Some these techniques are being used massive scale business for example hierarchical cluster analysis used build offline classifications all the postal codes each code represents about houses system such Mosaic which then used for targeting marketing The specific techniques covered are principal components analysis correspondence analysis scaling cluster analysis 
1550 en Opening the ACAI Summer School
1551 en Data Mining and Decision Support Integration The aim this presentation twofold introduce the field Decision Support and provide overview possible approaches and benefits combining with Data Mining solving real life decision and data analysis problems Related define the concepts decision problem and decision making introduce the taxonomy disciplines related overview the approach decision analysis introduce the method multi attribute modeling and illustrate through real life examples housing loan allocation and risk assessment medicine the main part investigate the ways combine and integrate and which generally involve the following categories for for then then and and Each category illustrated practical example Two categories are investigated greater detail The category “ for ” represented method for selecting best induced classifier based ROC space exploration For the category “ and ” explore approach developing qualitative multi attribute models combining the systems DEX and HINT DEX tool for expert based “hand crafted” development models whereas HINT tool that develops models from data method based function decomposition 
1552 en Evaluation Methodology There variety learning methods capable inducing predictive models from data order able decide which method use particular data set interest need systematic way evaluate and compare the performance different methods This talk describes and illustrates the key criteria and methods for performance assessment and comparison first introduces predictive error the most widely used criteria for evaluating predictive models Since want evaluate predictive error the model independent test data unseen the learning process the first part the talk focuses methods for evaluating predictive error test data and resolving the well known bias variance trade off machine learning also overview techniques for pair wise comparison learning methods performance While first part the talk deals with classification task predicting discrete variables only the second part the talk provides wider perspective evaluating methods for predicting class probability distribution numeric variables and dealing with situations where the error depends type the misclassification Finally learn how assess other aspects predictive performance such complexity the induced models and their comprehensibility 
1557 en Link analysis with pajek Pajek program for Windows for large network analysis and visualization freely available for noncommercial use http vlado fmf uni pub networks pajek http vlado fmf uni pub networks pajek Besides ordinary networks Pajek supports also multi relational and temporal networks large network analysis are often interested important parts given network There are several ways how determine them The islands approach based importance measure vertices lines Let network with vertex property and let real number delete all vertices and corresponding links with the property value less than get subnetwork called vertex cut level The number and sizes its components depend Often consider only components size least and not exceeding The components size smaller than are discarded noninteresting while the components size larger than are cut again some higher level Vertex island connected subnetwork which vertices have greater property value than the vertices its neighborhood easy see that the components vertex cuts are all vertex islands developed efficient algorithm that identifies all maximal vertex islands sizes the interval given network For networks with weighted lines can similarly define line islands The line islands algorithm based line cuts Both algorithms are very general they can applied for any vertex line importance measure Their complexity for sparse networks subquadratic they can applied very large networks will illustrate them applying different importance measures selected large networks will also present the use pattern searching analysis genealogies and some approaches analysis multi relational temporal networks 
1558 en Handling noisy data the practice machine learning learning data typically contain errors Imperfections data can due various often unavoidable causes measurement errors human mistakes errors expert judgement classifying training examples etc refer all these noise Noise can also come from the treatment missing values when example with unknown attribute value replaced set weighted examples corresponding the probability distribution the missing value The typical consequences noise learning data are low prediction accuracy induced hypotheses new data and large hypotheses that are hard interpret and understand the user For example decision trees with hundreds thousands nodes are not suitable for interpretation the domain expert say that such complex hypotheses overfit the data Overfitting occurs when the hypothesis not only reflects the genuine regularities the domain but also traces noise data alleviate the harmful effects noise have prevent overfitting this one common idea simplify induced hypotheses the learning rules decision trees this leads tree pruning rule truncation The main question hypothesis simplification How can know that our hypothesis “the right size” not too simple and not too complex For example tree pruning when should stop the pruning The decision can based the estimated accuracy hypothesis before pruning and after pruning and then the estimated accuracy maximised However estimating the accuracy can difficult and involves the problem estimating probabilities from small samples Several methods for this will discussed this lecture and the effects simplification will illustrated somewhat related approach deciding about the “right size” hypothesis based the minimum description length principle MDL Another way reducing the effects noise use background prior knowledge about the domain learning For example the learning from numerical data useful idea make the learning algorithm respect the known qualitative properties the target concept 
1559 en Attribute estimation One crucial tasks machine learning the evaluation the quality attributes For that purpose number measures have been developed that estimate the usefulness the attribute for predicting the target variable will describe separately measures for classification which are appropriate also for relational problems and for regression Most the measures estimate the quality one attribute independently the context other attributes However algorithm ReliefF and its regressional version RReliefF take into account also the context other attributes and are therefore appropriate for problems with strong dependencies between attributes The following measures will described Measures for guiding the search classification and relational problems are information gain Gain ratio distance measure minimum description length MDL measure Gini index and ReliefF The quality attributes regression can evaluated using the following measures expected change variance regressional ReliefF and minimum description length principle MDL 
1573 en Feature extraction content description 
1577 en Machine learning for access and retrieval 
1579 en Feature extraction content description 
1589 en Machine learning for access and retrieval 
1606 en Existing Living Lab Initiatives Best Practice overview Our Example and Experience
1607 en CORELABS support European RTD projects initiatives and stakeholders
1614 en The Emerging discipline Collaborative Networks
1616 en Portfolio Tools Application
1619 en VBE Scenario presentation Demonstration Activities ITESM IECOS
1629 en Graph Theory contributions forCNOs modeling and analysis
1631 en Distributed Loosely Controlled and Evolving Ontology Engineering
1632 en CNO successful case study – Treviso Technologie Cluster
1640 en Virtual Breeding Environment Support Collaboration the Aeronautical Supplie Chain
1641 en Interactive Session Barriers and Solutions 
1643 en Formal Theories and modeling CNOs
1644 en  Formal Theory Virtual Enterprises Structures
1645 en  Distributed Knowledge Base For Manufacturing Scheduling
1646 en Efficiently Managing Virtual Organizations Through Distributed Innovation Management Processes
1648 en Model based Integration Business and technology
1649 en Sme Service Networks For Cooperative Operation Robot Installations
1650 en Chaordic Systems Thinking Introduction Chaos and Complexity Organisations and Management
1651 en Experimential Learning Session – Parallel working groups
1652 en The aim this workshop Multipliers
1655 en EVCN Engeneer Virtual Community Network PVC for Local Developement
1656 en  overview trust and trust building networks
1657 en Innovative working environment Network Oasis project
1658 en  CORELABS Living Labs definition and concept
1659 en  VEN The Story Far
1661 en Trust building models and self organizing systems complexity theory
1662 en ICT support for Virtual Organization Management
1671 en ECOLEAD PVC Management for AIESEC AlumniAIESEC Demonstration Scenario WP4
1674 en Welcome Training Brussels 
1684 en Virtual Organizations Breeding Environment Concepts expected results intermediate results
1686 en Virtual Organizations Management Concepts expected results intermediate results
1693 en Knowledge Based Virtual Communities for Collaborative work the Vehicle Repair Works
1696 en One Class formula Human Robot interaction
1699 en Presentation the future CNO research
1700 en Introducing time horizons enterprise networking architecture
1701 en The “Concurrent Innovation” paradigm for Integrated Product Service Organisation PSO Development
1702 en AMI communities Living Labs collaborative working environments and ICTs for enterprises birth development and future
1704 en Principles Benchmarking and Application the Context
1707 en Summary Main Challenges for Stram VBE The Virtual Factory´ Practical Experience
1708 en Towards meta methodology for collaborative networked organisations
1709 en The typed domain recipe for creating Virtual Enterprises
1712 en SLO ITA cross border clustering opportunities
1714 en Integrated Project Validation approaches the sense Living Labs Collaboration rural
1716 en Emerging technologies for CNO supporting infrastructures
1717 en VOM relation VBE PVC
1718 en Social protocols Professional Virtual Communitie
1719 en PVC basic concepts typologies
1729 en Java library for support text mining and retrieval
1731 en Debate ECOLEAD Brussels meeting
1739 en Professional Virtual Communities Concepts expected results intermediate results
1740 en Sumatra Towards universal data preprocessor
1743 en CNO trends and emerging collaborative forms
1746 en  Breeding Environments competency management
1747 en Cross border collaboration strenghtening the europen competitiveness
1749 en  Operation Management CeBeNetwork GmbH
1750 en ORONA Innovation Network OIN Part Introduction the network
1751 en CNO successful case study Virtuelle Fabrik
1752 en Conceptual Framework for Collaborative Design and Operations
1753 en Automotive Cluster Slovenia Presentation collaborative opportunities
1755 en ISOIN VBE Demonstration the Andalusian Aeronautical cluster
1759 en Data Integration using Semantic Technology Use Case
1760 en Integrated Access Biological Data Use Case
1762 en Toward Large Scale Shallow Semantics for Higher Quality NLP Building the successes the past decade’ work statistical methods there are signs that continued quality improvement for summarization information extraction and possibly even machine translation require more elaborate and possibly even shallow semantic representations text meaning But how can one define large scale shallow semantic representation system and contents adequate for NLP applications and how can one create the corpus shallow semantic representation structures that would required train machine learning algorithms This talk addresses the components required including symbol definition ontology and corpus shallow meaning representations and the resources and methods one needs build them including existing ontologies human annotation procedures and verification methodology illustrate these aspects several existing and recent projects and applicable resources are described and research programme for the near future outlined Should NLP willing face this challenge may the not too distant future find ourselves working with whole new order knowledge namely shallow and doing increasing collaboration after years separation with specialists from the Knowledge Representation and reasoning community 
1763 en  Infrastructure for Acquiring High Quality Semantic Metadata
1764 en Extracting Instances Relations From Web Documents Using Redundancy
1765 en Empiric Merging Ontologies Proposal Universal Uncertainty Representation Framework
1767 en Knowledge Management the Petroleum Industry
1768 en Contextual Intelligence for Mobile Services through Semantic Web Technology
1769 en Semantic Laboratory Notebook Managing biomedical research notes and experimental data
1772 en News Agency needs XML News
1774 en Use Ontology for production access systems Legislation Jurisprudence and Comments
1786 en Semantic Web Service Systems Part The proposed tutorial presents the Web Service Execution Environment WSMX and the Internet Reasoning Server IRS integrated environment for development and execution Semantic Web Services basis the Web Service Modeling Ontology WSMO 
1787 en Automatic Extraction from Hierarchical Relations From Text This tutorial will cover the hot topic multimedia and the Semantic Web with focus multimedia search engines automatic semantic annotation multimedia and use semantic web tools the production new media formats The tutorial will also cover some open source tools thus enabling the participants put easily their newly learned skills into practice The material presented will include the latest research results from several European projects multimedia and semantically enabled knowledge technologies Prestospace NM2 MediaCampaign and SEKT 
1788 en Dinamic Assembly personalised Learning Content the Semantic web
1790 en  Semantic Web technology ready for Healthcare 
1791 en Issues and strategies for digitization and preservation the digital content
1793 en Usability and the Semantic Web addition its technical implications the semantic web vision gives rise some challenges concerning usability and interface design What difficulties can arise when persons with little relevant training try formulate knowledge with ontology editors annotation tools such way that can exploited semantic web technologies leverage semantic information while querying browsing What strategies have been applied effort overcome these difficulties and what are the main open issues that remain This talk will address these questions referring examples and results from variety research efforts including the project SemIPort which concerns semantic methods and tools for information portals and Halo which tools have been developed and evaluated that enable scientists formalize and query college level scientific knowledge 
1796 en Content Aggregation Knowledge Bases Using Graph Clustering
1800 en Semantic Web and Language Technology
1802 en Training Management Sistems for Aircraft Engeneering
1803 en Semantic Network Analysis Ontologies Part 
1804 en Where Does Break Why the Semantic Web Not Just Research Usual Work the Semantic Web all often phrased technological challenge how improve the precision search engines how personalise web sites how integrate weakly structured data sources etc This suggests that will able realise the Semantic Web merely applying and most refining the results that are already available from many branches Computer Science will argue this talk that instead just technological challenge the Semantic Web forces rethink the foundations many subfields Computer Science This certainly true for own field Knowledge Representation where the challenge the Semantic Web continues break many often silently held and shared assumptions underlying decades research With some caution claim that this also true for other fields such Machine Learning Natural Language Processing Databases and others For each these fields will try identify silently held assumptions which are longer true the Semantic Web prompting radical rethink many past results from these fields 
1805 en Semantic Network Analysis Ontologies Part 
1806 en Benchmark Suites for Improving the RDF Importers and Exporters Ontology Development Tools
1814 en Semantic Web Service Systems Part The proposed tutorial presents the Web Service Execution Environment WSMX and the Internet Reasoning Server IRS integrated environment for development and execution Semantic Web Services basis the Web Service Modeling Ontology WSMO 
1833 en Music the Spheres This lecture talking about Nearest Neighbours Once upon time Musica universalis music the spheres medieval philosophical concept that regards the proportions the movements the celestial bodies the Sun Moon and planets form musica the medieval Latin name for music This music was not thought audible sound but simply mathematical concept The Greek philosopher Pythagoras was frequently credited with originating the concept which stemmed from his semi mystical semi mathematical philosophy and its associated system numerology Pythagoreanism Some Surat Shabda Yoga Satgurus considered the music the spheres term synonymous with the Shabda the Audible Life Stream that tradition because they considered Pythagoras Satguru well 
1834 en Mixture Models and Collaborative Filtering Algorithms
1835 en Efficient Lazy Algorithms for Minimal Interval Semantics
1836 en Efficient Top Queries for XML Information Retrieval
1837 en Applications Influence Diagrams Information Retrieval
1838 en  Tuning Error Optimisation Hoc Retrieval
1839 en Ongoing research sentence retrieval and novelty detection
1841 en  Semantic Structure Structured Document Retrieval
1842 en Web mining for natural language engineering tasks
1843 en From query based Information Retrieval context driven Information Supply
1845 en Boosting Performance Web Search Engines Using Query Logs
1847 en Current Approaches Personalized Web Search
1849 en Using Rank Propagation and Probabilistic Counting for Link based Spam Detection
1850 en Theoretical analysis Link Analysis Ranking
1851 en Graph Fibrations graph isomorphism and PageRank
1853 en Searching the Web with Low Space Approximations
1854 en Mobile Search Ubiquitous Collaborative Annotations Space
1855 en Efficient and Decentralized PageRank Approximation P2P Web Search Network
1856 en Semantic Overlay Networks for P2P Web Search
1857 en Exploiting Temporal Features for Structured Queries
1859 en GATE and IBM´ UIMA interoperability layer
1860 en Finite state transduction for Information Extraction and other tasks ANNIE JAPE Part 
1864 en Finite state transduction for Information Extraction and other tasks ANNIE JAPE Part 
1868 en Introduction GATE after years
1869 en Development eco system building components usage Eclipse unit tests
1871 en GATE API´ CREOLE lifecycle JAVA for JAPE
1875 en Finite state transduction for Information Extraction and other tasks ANNIE JAPE Part 
1883 en Web Content Mining with Human Language Technologies Acquiring Ontological Relationships from Wikipedia Using RMRS
1884 en Web Content Mining with Human Language Technologies Mining and Assessing Discussions the Web through Speech Act Analysis
1885 en The Semantic Web and Networked Governance Promise and Challenges The virtual state metaphor meant draw attention the structures and processes the state that are becoming increasingly aligned with the structures and processes the semantic web Semantic Web researchers understand the potential for information sharing enhanced search improved collaboration innovation and other direct implications contemporary informatics Yet many the broader democratic and governmental implications increasingly networked governance remain elusive even the world public policy and politics 
1886 en  Use OntoWiki Tool for Social Semantic Collaboration
1888 en Where the Social Web Meets the Semantic Web The Semantic Web ecosystem interaction among computer systems The social web ecosystem conversation among people Both are enabled conventions for layered services and data exchange Both are driven human generated content and made scalable machine readable data Yet there popular misconception that the two worlds are alternative opposing ideologies about how the web ought Folksonomy ontology Practical formalistic Humans machines This nonsense and time embrace unified view subscribe the vision the Semantic Web substrate for collective intelligence The best shot have collective intelligence our lifetimes large distributed human computer systems The best way get there harness the people power the Web with the techniques the Semantic Web this presentation will show several ways that this can and happening 
1889 en  Use Information Integration via End End Distributed Semantic Web System
1890 en  Use NEWS bringing Semantic Web Technologies into News Agencies
1891 en Research IRS III Broker for Semantic Web Services based Applications
1892 en Research Software Engineering Approach Design and Development Semantic Web Service Applications
1895 en Research Browser for Heterogeneous Semantic Web Repositories
1896 en Research RS2D Fast Adaptive Search for Semantic Web Services Unstructured P2P Networks
1897 en Learning from the Masters Understanding Ontologies found the Web Part The purpose this tutorial help attendees gain sufficient experience working with OWL and tools allow them fruitfully explore new ontologies that they may encounter other words they should able the equivalent “view source” ontology Also they will get better fluency the use and abuse OWL examining features limitations and workarounds real contexts well gaining understanding the impact future extensions OWL particular rules and the proposed revision the language called OWL 
1899 en Interview with Tom Gruber Tom Gruber innovator technologies that extend human intelligence Building early work computer mediated learning and artificial intelligence focuses creating environments for collective intelligence discussed with him International Semantic Web Conference 2006 Athens Georgia the USA 
1905 en Interview with Bijan Parsia Bijan Parsia lecturer the University Manchester the School Computer Science discussed with him the ISWC 2006 Athens the USA What your current topic research Future research Semantic web dream come true Comments the tutorial and messages the community 
1906 en Context Sensitivity Knowledge Rich Systems The main goal this tutorial provide extensive survey the past and current work the area context related topics This includes analysis the past work defining the notion “context” present logic based formalisms for dealing with contexts present probabilistic fuzzy approaches model context demonstrate “modelling the context” and “reasoning with contexts” real life applications addition the presented work will provide synthesis the past work the light unified categorization context related approaches along several dimensions which appear relevant from theoretical and practical point view 
1907 en Web Content Mining with Human Language Technologies Concept Instance Relation Extraction from Simple Noun Sequences Using Full Text Search Engine
1908 en Web Content Mining with Human Language Technologies Constructing Dictionaries for Named Entity Recognition Specific Domains from the Web
1918 en Workshop Enhancing Data and Processes Integration and Interoperability Emergency Situations SWS based Emergency Management System
1919 en Workshop Personalized Question Answering Use Case for Business Analysis
1920 en Workshop Spatial Integration Semantic Web Services the Merges Approach
1921 en Workshop Conceptual Search Incorporating Geospatial Data Into Semantic Queries
1922 en Workshop Discussions elements Geo Working Group charter
1924 en Semantic Web Rules with Ontologies and their Services Applications Rules are main emerging area the Semantic Web There has been significant progress just the last three years several aspects Semantic Web rules This includes exciting developments the underlying knowledge representation formalisms well advances integration rules with ontologies translations between heterogeneous commercial rule engines development open source tools for inferencing and interoperability standards proposals and efforts including RuleML SWRL Semantic Web Service Framework and recently W3C Rule Interchange Format proposals for rule based semantic Web services and pilot applications the emerging area services This tutorial will provide introduction these developments and will explore techniques applications and challenges will also touch upon the issues business value adoption investment and strategy considerations 
1926 en Semantic Authoring and Annotation The Dynamics and Semantics Collaborative Tagging
1927 en Semantic Authoring and Annotation Cross media Document Annotation and Enrichment
1928 en The Semantic Web Suppliers and Customers The notion the Semantic Web can coined Web data when bringing database content the Web Web enriched human readable content when encoding the semantics web resources machine interpretable form has been clear from the beginning that realizing the Semantic Web vision will require interdisciplinary research this the fifth ISWC time examine the extent which interdisciplinary work has played and can play role Semantic Web research and even how Semantic Web research can contribute other disciplines Core Semantic Web research has drawn from various disciplines such knowledge representation and formal ontologies reusing and further developing their techniques new context 
1929 en Learning from the Masters Understanding Ontologies found the Web The purpose this tutorial help attendees gain sufficient experience working with OWL and tools allow them fruitfully explore new ontologies that they may encounter other words they should able the equivalent “view source” ontology Also they will get better fluency the use and abuse OWL examining features limitations and workarounds real contexts well gaining understanding the impact future extensions OWL particular rules and the proposed revision the language called OWL rimg iswc06 parsia uofw This lecture given Bernardo Cuenca Grau combined with Bijan Parsia and will encopass Part Part Part the complete lecture Part and this lecture can found iswc06 parsia uofw Bijan Parsia lecture 
1931 en Context Sensitivity Knowledge Rich Systems The main goal this tutorial provide extensive survey the past and current work the area context related topics This includes analysis the past work defining the notion “context” present logic based formalisms for dealing with contexts present probabilistic fuzzy approaches model context demonstrate “modelling the context” and “reasoning with contexts” real life applications addition the presented work will provide synthesis the past work the light unified categorization context related approaches along several dimensions which appear relevant from theoretical and practical point view 
1933 en Learning from the Masters Understanding Ontologies found the Web The purpose this tutorial help attendees gain sufficient experience working with OWL and tools allow them fruitfully explore new ontologies that they may encounter other words they should able the equivalent “view source” ontology Also they will get better fluency the use and abuse OWL examining features limitations and workarounds real contexts well gaining understanding the impact future extensions OWL particular rules and the proposed revision the language called OWL rimg iswc06 grau uofwi This lecture given Bijan Parsia combined with Bernardo Cuenca Grau and will encopass Part Part Part Part the complete lecture Part and this lecture can found iswc06 grau uofwi Bernardo Cuenca Grau lecture 
1934 en Workshop Improving the recruitment process through ontology based querying
1935 en Workshop OntoCAT Ontology Consumer Analysis Tool and Its Use Product Services Categorization Standards
1936 en Research Extending faceted navigation for RDF data
1937 en  Use Explaining Conclusions from Diverse Knowledge Sources
1938 en Research Formal Model for Ontology Mapping Creation
1939 en  Use Semantic web technology for expert knowledge sharing and discovery
1940 en Research Three Semantics for Distributed Systems and their Relations with Alignment Composition
1941 en Research Towards Knowledge Acquisition from Information Extraction
1942 en  Use Semantic Desktop The Gnowsis Experience
1943 en Research Fresnel Browser Independent Presentation Vocabulary for RDF
1946 en Research Tree structured Conditional Random Fields for Semantic Annotation
1947 en Research Evaluating Conjunctive Triple Pattern Queries over Large Structured Overlay Networks
1948 en Research Using Ontologies for Extracting Product Features from Web Pages
1949 en Research How Perform Gold Standard Based Evaluation Ontology Learning
1950 en Research Ontology Query Answering Databases
1951 en Research Crawling and Indexing Semantic Web Data
1952 en Research Ontology driven Information Extraction with OntoSyphon
1953 en Research Framework for Schema Driven Relationship Discovery from Unstructured text
1954 en Web Content Mining with Human Language Technologies Welcoming and Introduction
1955 en Web Content Mining with Human Language Technologies Instance Classification using Occurrences the Web
1956 en Semantic Authoring and Annotation Semantic Authoring Tagging with Annotea Social Bookmarks and Topics
1957 en Semantic Authoring and Annotation Browser based Tool for Collaborative Distributed Annotation for the Semantic Web
1958 en Semantic Authoring and Annotation Semi Automatic Semantic Annotation and Authoring Tool for Library Help Desk Service
1959 en Semantic Authoring and Annotation Using WEESA Semantically Annotate Cocoon Web Applications
1960 en Research Relaxed Approach RDF Querying
1961 en Research ONTOCOM Cost Estimation Model for Ontology Engineering
1962 en Research Provenance Explorer – Tailored Provenance Views Using Semantic Inferencing
1963 en Research Semantic Metadata Generation for Large Scientific Workflows
1964 en Research Integrating and Querying Parallel Leaf Shape Descriptions
1965 en Research Automatic Annotation Web Services based Workflow Definitions
1966 en Research Mining Information for Instance Unification
1967 en Research Method for Learning Part Whole Relations
1968 en Research Extracting Relations Social Networks from Web using Similarity between Collective Contexts
1969 en Research Innovation Detection based User Interest Ontology Blog Community
1970 en Research Ontology Driven Automatic Entity Disambiguation Unstructured Text
1971 en Research Modeling Social Attitudes the Web
1972 en Web Content Mining with Human Language Technologies Coreference resolution RDF Graphs generated from Information Extraction first results
1974 en Interview with Tim Berners Lee inventor the WWW Sir Timothy John Tim Berners Lee the inventor the World Wide Web director the World Wide Web Consortium which oversees its continued development and senior researcher and holder the 3Com Founders Chair MIT Computer Science and Artificial Intelligence Laboratory CSAIL Source http wikipedia org wiki Tim Berners Lee Wikipedia 
1976 en Interview with Jane Fountain Fountain the author Building the Virtual State Information Technology and Institutional Change Brookings Institution Press 2001 which was awarded Outstanding Academic Title 2002 Choice The book has become classic text the field and has been translated into and published Chinese Japanese and Portuguese Fountain currently researching the successor volume Building the Virtual State which will examine technology based cross agency innovations the federal government and their implications for governance and democratic processes and Women the Information Age published Cambridge University Press which focuses gender information technology and institutional behavior Professor Fountain also directs the Science Technology and Society Initiative STS and the Women the Information Age Project WITIA The STS Initiative serves catalyst for collaborative multi disciplinary research partnerships among social natural and physical scientists WITIA examines the participation women computing and information technology related fields and with its partner institutions seeks increase the number women experts and designers information and communication technology fields She has served several governing bodies and advisory groups the public private and nonprofit sectors the and abroad Her executive teaching and invited lectures have taken her several developing countries and governments transition including those Saudi Arabia the United Arab Emirates Nicaragua Chile Estonia Hungary and Slovenia well countries including Japan Canada New Zealand Australia and the countries the European Union 
1977 en Semantic Authoring and Annotation Welcoming and Introduction
1978 en Semantic Authoring and Annotation Specifying the Collaborative Tagging System
1979 en  Use Ontogator Semantic View Based Search Engine Service for Web Applications
1980 en  Use Active Semantic Electronic Medical Record
1981 en  Use Mixed Initiative Semantic Web Framework for Process Composition
1983 en  Use Enabling Onlince Community for Sharing Oral Medicine Cases Using Semantice Web Technologies
1984 en  Use Towards Semantic Interoperability Clinical Trials Management System
1985 en  Use Semantically Enabled Large Scale Science Data Repositories
1986 en  Use Construction and Use Role ontology for Task based Service Navigation System
1987 en Context Sensitivity Knowledge Rich Systems The main goal this tutorial provide extensive survey the past and current work the area context related topics This includes analysis the past work defining the notion “context” present logic based formalisms for dealing with contexts present probabilistic fuzzy approaches model context demonstrate “modelling the context” and “reasoning with contexts” real life applications addition the presented work will provide synthesis the past work the light unified categorization context related approaches along several dimensions which appear relevant from theoretical and practical point view 
1988 en Industry Semantic Web W3C Activities Recommendations and State Adoption The presentation presents the status the Semantic Web from W3C perspective referring the finished and active works terms W3C groups view available tools and ideas floating around for possible future work References and examples real Semantic Web applications will also show the widening adoption the technology the industrial community 
1989 en Industry How Occurrence can Complement Semantics Analysis texts obvious way for semantic annotation and extraction structured knowledge basic task the recognition references entities people locations organizations etc next step relation extraction identifying that organization located particular city Automatic extraction such relations tough linguistic problem the solutions are either very partial expensive implement slow the other hand relationships are crucial for the usability the extracted knowledge for navigation and search purposes demonstrate how efficient occurrence analysis performed top semantic annotation can used for several purposes relation extraction faceted search and popularity timelines The faceted search interface allows easy way for augmenting full text search means entity references derived through occurrence profiling and semantic relationships Although this sort analytics can used virtually any domain their development within the KIM platform was driven the requirements for news analysis and research demonstrate the usage these interfaces top million news articles corpus the major international news for the last five years This sort occurrence analysis has the potential aiding identity resolution which recognized crucial problem for several tasks cross document reference resolution record linkage object linking and data integration 
1990 en Industry Knowledge Representation Practice Project Halo and the Semantic Web Vulcan Project Halo ambitious multiyear research program develop detailed scientific knowledge base that can answer level questions and provide explanations user appropriate manner one the largest research programs the today Halo current focus building tools that allow graduate students chemistry biology and physics author scientific knowledge adequate answer sophisticated natural language questions without relying trained knowledge engineers Halo researchers have been working link Semantic Web technology with the other knowledge representations the system This talk will lay out Halo technologies and results date and describe the technical and issues have faced getting users author scientific conceptual knowledge 
1991 en Industry Integrating Enterprise Data with Semantic Technologies The Semantic Web has reached level maturity that allows RDF and OWL adopted large commercial software companies Many the products that are based these standards promise the ability provide more effective solutions the increasing complexity that many industries are facing This presentation will describe Oracle interest being early adopter Semantic Web technologies well providing technical overview the RDF Data Model the latest release the Oracle Database Experiences gained from implementing Semantic Web technologies will also provided 
1992 en Industry From the Bench the Bedside The role Semantics enabling the vision Translational Medicine Biomedical research and healthcare clinical transactions are generating huge volumes information Biomedical research literature doubles every years and AIDS literature particular doubles every months Biomedical research now information based science marked factory scale sequencing generating huge amounts data clinician the other hand needs approximately million facts practice There critical need speed translation genomic research insights into clinical research and practice and vice versa this talk will discuss the challenges faced healthcare enterprise realizing the vision Translational Medicine this talk will discuss some these challenges such The need create structured and semantic representations genotypic and phenotypic data such orders observations molecular diagnostic test results etc The need for needed data and information integration achieved incremental and cost efficient manner The need for actionable decision support for suggesting molecular diagnostic tests response phenotypic information and therapies response genotypic test results The need for knowledge update propagation and consistency keep abreast the rapid pace knowledge discovery being witnessed the life sciences crucial pre requisite reduce the cost knowledge acquisition and maintenance There need and applicability semantic web based specifications and technologies address the above challenges will present semantics based approaches address the challenges enumerated above The role and applicability various semantic web standards such RDF and OWL the proposed solutions will also discussed 
1993 en Industry Deploying Enterprise Level Ontology Driven Faceted Search Currently one the most practical application spaces for Semantic Web technologies creating ontological layer over existing legacy databases Such layering allows flexible applications built without the cost restructuring large amounts data while maintaining the performance advantages relational database Whereas applications designed directly query database encode business logic specific queries ontological layer offers flexible framework whereby dynamically generated queries are resilient schema changes This same approach can used query multiple decentralized databases from seemingly centralized point view allowing access multiple database schemas via single interface ontology Semantic Web technologies such RDFS OWL and SWRL can used specify composition rules and abstractions making possible answer complex questions without developing complex queries TopQuadrant has applied this approach develop and deploy flexible faceted search system over network large decentralized legacy databases The system uses ontologies two distinct ways abstraction layer over underlying relational data model and search interface model driving the system itself This model based approach allows dynamic system configuration simply through changes the model The model controls what data can searched what facets can used for building queries and even how data should displayed The system combines the structured power ontologies with more conventional keyword based search over related unstructured document corpus The resulting hybrid system provides capabilities beyond what possible with either approach alone This talk will describe the process used for developing the ontological layer discuss challenges and technical solutions integrating the databases and bringing together structured and unstructured search will also show the benefits using ontology specify the search interface and interaction 
1994 en Industry Semantic Solutions Generating Business Value from Semantic Web Technologies Thanks the efforts many researchers over the past five years Semantic Web technologies have reached the point where they are now enabling new types business solutions this presentation will show how IBM Research using Semantic Web technologies and Semantic Super Computing generate new insight from the Web intranets and large document repositories includes introduction and overview the use Semantic Super Computing automatically identify index and augment semantic information covers relevant foundational technologies and concludes with case study one emerging application the technology that refer the Wikification Corporate Corpora
1995 en Industry Managing Richly Connected Information examine research issues that arise when most information items enterprise can linked each other via short paths implicit explicit such high recall settings the treatment metadata management indexing and ranking needs new attention Additional issues arise the best way handle updates the connections whether off the transaction path Even traditional techniques such classification and clustering documents which stand benefit from the extra information provided the called network meaning need reexamined for how best exploit the extra information The talk ends with examination some promising avenues for using high recall driver for the next wave business process automation
1996 en Research Survey the Web Ontology Landscape
1997 en Research Ranking Ontologies with AKTiveRank
1999 en Interview with Mark Greaves Mark Greaves currently Director Knowledge Systems Vulcan Inc Vulcan the private investment vehicle for Paul Allen founder Microsoft www vulcan com Vulcan sponsoring advanced research large knowledge bases and advanced web technologies including Project Halo www projecthalo com discussed with him the ISWC 2006 Athens the USA What Vulcan What the Halo Project What the main reason why this was not possible ten years ago How these technologies beyond what they now Will this tecnology openly available the future Has Europe any chances catch the this field 
2003 en Welcome and Introduction Introduction the Second Day Session Agenda Ihor Hurnjak Lviv Chamber Commerce and Industry Ukraine • Welcome words and Introduction Dmytro Aftanas President Lviv Chamber Commerce and Industry Ukraine • Welcome words from Host Organization Volodymyr Vorobey Specialist Knowledge Economy cognovís GmbH • Welcome words from the organizer cognovís GmbH and Partners • Introduction the First Day Session Session Moderator • Introduction the First Day Session Agenda • Introduction the Common rules for speeches and after speech discussions
2004 en  “five minute bridge” between the first day and the second day sessions
2005 en  projects for small and medium business problems solutions and challenges Ukraine
2006 en SME development environment needs and trends Role ICT SMEs Ukraine and our efforts promoting ICT tool for business development
2007 en Optimization the distribution systems with the use nowadays mobile technologies
2009 en Implementation commerce projects Ukraine Best Practices
2010 en Experience JSC “ENZYM” attraction information technologies Case Study
2012 en Welcome and Introduction Ihor Hurnjak Lviv Chamber Commerce and Industry Ukraine • Welcome words and Introduction Dmytro Aftanas President Lviv Chamber Commerce and Industry Ukraine • Welcome words from Host Organization Volodymyr Vorobey Specialist Knowledge Economy cognovís GmbH • Welcome words from the organizer cognovis GmbH and Partners • Introduction the First Day Session Session Moderator •Introduction the First Day Session Agenda •Introduction the Common rules for speeches and after speech discussions
2013 en Comarch ERP Case Study CDN – integrated system enterprise management
2014 en SMEs European research collaboration research institute perspective
2016 en  Case Study from SMEs Technological decisions the example OJSC “Lvivkholod”
2017 en ERP systems for SMEs Ukraine Best Practices
2018 en CRF presentation and its work European Research Programs Project Extended Enterprise management Enlarged Europe
2020 en Interview with Kamal Nigam Videolectures Net team spoke Kamal Nigam Pittsburgh CMU where asked him the following questions Can yoou describe your field work Where can your work applied What your topic research within the community What about the future your research within the community Your work Interdisciplinary How can you commnet the future general What are your personal goals 
2021 en Interview with Fei Fei After short stay the ECE Dept UIUC Fei Fei now back Princeton assistant professor the Computer Science Dept where she the the Vision Lab The Videolectures Net team spoke her Pittsburgh CMU where asked her the following questions What your field work What your topic research within the Machine Learning community Where you see your group years time What are your goals Why are you moving Princeton University you would have Machine Learning dream come true 
2022 en Generative Latent Space Models for Text and Image
2024 en Interview with Tom Mitchell Tom Mitchell the first Chair Department the first Machine Learning Department the World based Carnegie Mellon The Videolectures Net team spoke him Pittsburgh CMU where discussed about how started the department what was the response the broader community and its past present and future The university said you can only have department you have discipline that going here one hundred years otherwise you can not have department 
2025 en Joint Mining Biological Text and Images Case Studies
2026 en Generative Models for Visual Objects and Object Recognition via Bayesian Inference
2027 en Undirected Graphical Models for Text Image
2030 en Introduction the Machine Learning over Text Images Autumn School Eric Xing
2032 en Interview with Eric Xing Statistical machine learning theory and applications computational biology are the fields interest Eric Xing asked him this interview Carnegie Mellon University what actually statistical machine learning theory where can solutions this research applied and being the first Department the world does make his research any easier 
2034 en Interview with Christos Faloutsos met Christos Faloustos Pittsburgh CMU where discussed with him about his current work Here describes all his work the last ten years and the same time points out his groups progress projects goals achievements plus future plans 
2095 en Improving SVM Text Classification Performance through Threshold Adjustment
2096 en Application Inductive Logic Programming Structure Based Drug Design
2098 en Using Belief Networks and Fisher Kernels for Structured Document Classification
2099 en Majority Classification means Association Rules
2100 en Explaining Text Clustering Results using Semantic Structures
2101 en Efficient Statistical Pruning Association Rules
2102 en Minimal Free Representations Frequent Sets
2110 en Parametric Autentication How know who you are 
2112 en NGOSS Key Domains Fulfillment Assurance Billing
2115 en Optimizing Local Probability Models for Statistical Parsing Best Student Paper Runner 
2116 en Logistic Model Trees Best Student Paper
2119 en Taking causality seriously Propensity score methodology applied estimate the effects marketing interventions Best PKDD paper
2120 en Next Generation Data Mining Tools Power laws and self similarity for graphs streams and traditional data
2123 en Classification Approach Towards Ranking and Sorting
2124 en Color Image Segmentation Kernel the Feature Space
2125 en  Decomposition Classes Via Clustering Explain And Improve Naive Bayes
2126 en Two eyed algorithms and problems Best ECML paper
2137 en Introduction workpackages WP4 WP5 WP6
2139 en Metadata Extraction Human Language technology and the Semantic Web Part 
2140 en Metadata Extraction Human Language technology and the Semantic Web Part 
2142 en SDK API Towards European Semantic Interfaces
2146 en Metadata Extraction Human Language technology and the Semantic Web part 
2147 en Metadata Extraction Human Language technology and the Semantic Web Part 
2148 en Human Language Technology for the Semantic Web
2150 en Metadata Extraction Human Language technology and the Semantic Web Part 
2151 en Metadata Extraction Human Language technology and the Semantic Web Part 
2153 en Semantic Web Next Generation Web Services and Knowledge Management
2155 en Semantic Web and Ontology Management Technology
2157 en Ontology Learning Knowledge Discovery and the Semantic Web
2161 en Introduction workpackages WP13
2167 en Knowledge Discovery Part The basic idea Knowledge discovery let computer search for knowledge whereas the humans give just broad directions about where and how search Surprisingly often the case that already relatively simple techniques are able uncover useful hidden truth beneath the surface the known facts and relationships Knowledge discovery could defined research area with several subfields with the most representative Machine Learning and Data Mining Mitchell 1997 Fayyad 1996 Witten and Frank 1999 Hand 2001 and Data bases Different real life problems have been successfully addressed using Knowledge discovery methods including Data mining and Decision support Mladenic 2003 Mladenic and Lavrac 2003 Semantic Web Barnes Lee and Fischetti 1999 the other hand can seen mainly dealing with integration many already existing ideas and technologies with the specific focus upgrading the existing nature web based information systems more “semantic” oriented nature this context Semantic Web could viewed frontier Knowledge Management with some emphasis web based applications There are several dimensions along which Knowledge Discovery can bring important contributions Semantic Web Since techniques are mainly about discovering structure the data this can serve one the key mechanisms for structuring knowledge into ontological structure being further used Knowledge management process interesting aspect that data and corresponding semantic structures change time the consequence need able adapt ontologies that are modeling the data accordingly Sub field called “stream mining” deals with these kinds problems also important point out that scalability one the central issues especially the sub areas such Data mining where one needs able deal with real life datasets the terra byte sizes Semantic Web ultimately concerned with real life data the web which have exponential growth 
2168 en Knowledge Discovery Part The basic idea Knowledge discovery let computer search for knowledge whereas the humans give just broad directions about where and how search Surprisingly often the case that already relatively simple techniques are able uncover useful hidden truth beneath the surface the known facts and relationships Knowledge discovery could defined research area with several subfields with the most representative Machine Learning and Data Mining Mitchell 1997 Fayyad 1996 Witten and Frank 1999 Hand 2001 and Data bases Different real life problems have been successfully addressed using Knowledge discovery methods including Data mining and Decision support Mladenic 2003 Mladenic and Lavrac 2003 Semantic Web Barnes Lee and Fischetti 1999 the other hand can seen mainly dealing with integration many already existing ideas and technologies with the specific focus upgrading the existing nature web based information systems more “semantic” oriented nature this context Semantic Web could viewed frontier Knowledge Management with some emphasis web based applications There are several dimensions along which Knowledge Discovery can bring important contributions Semantic Web Since techniques are mainly about discovering structure the data this can serve one the key mechanisms for structuring knowledge into ontological structure being further used Knowledge management process interesting aspect that data and corresponding semantic structures change time the consequence need able adapt ontologies that are modeling the data accordingly Sub field called “stream mining” deals with these kinds problems also important point out that scalability one the central issues especially the sub areas such Data mining where one needs able deal with real life datasets the terra byte sizes Semantic Web ultimately concerned with real life data the web which have exponential growth 
2173 en Learning Semantic Sub graphs for Document Summarization
2177 en  short Tutorial Semantic Web
2180 en Semantic Web and Ontology Management Technology
2181 en Metadata Extraction Human Language technology and the Semantic Web
2183 en Human Language Technology for the Semantic Web
2185 en Introduction workpackages WP15
2200 en Onthology Based Information Extraction and Gate
2205 en Introduction SEKT partner University Sheffield 
2206 en Introduction SEKT partner Sirma Ltd Bulgaria
2207 en Introduction SEKT partner Vrije Universiteit Amsterdam Netherlands
2208 en Introduction SEKT partner Intelligent Software Components Spain
2209 en Introduction SEKT partner Autonomous University Barcelona Spain
2210 en Introduction workpackages WP1
2211 en Introduction workpackages WP2
2212 en Introduction workpackages WP3
2213 en Introduction workpackages WP4
2218 en Language Technologies This tutorial covers the use Human Language Technologies for the Semantic Web and Web Services includes sections HLT and Text Mining for the Semantic Web various forms Information Extraction Ontology Population and Semantic Metadata Creation and Evaluation The tutorial begins with introduction Human Language Technology looking both its background and development and then situating within the context text mining and other tasks involving knowledge discovery from large collections unstructured text which are necessary for the development the semantic web The second section concerns information extraction major component text mining Information extraction involves extracting facts and structured information from unstructured data contrast this with Information retrieval which concerns extracting documents from large text collections and with data mining which concerns discoveing patterns structured data introduce GATE and architecture for language engineering and its resources for information extraction and then expand the idea traditional information extraction focus semantic web enabled technology such ontology population and semantic metadata creation both which involve the use information extraction based ontologies look some current state the art semantic annotation systems such KIM Magpie MnM and OntoMat the third section discuss evaluation methods for such technology based the idea that traditional methods are insufficient when applied semantic web technology due the presence hierarchical ontological information rather than flat structures also take brief look usability issues annotation systems Finally the tutorial gives demonstrations two examples HLT use for the semantic web First present RichNews which aims automate the annotation news programs segmenting describing and classifying news broadcasts from transcripts Second present work ontology based and mixed initiative information extraction carried out the context SEKT 
2219 en Human Language technology for the Semantic Web this talk will present overview Human Language Technologyn HLT and its use Semantic Web development HLT concerned with automatic linguistic processing towards the semantic analysis and extraction information from textual data the context the Semantic Web the use HLT knowledge markup web documents for ontology population and text mining for ontology evolution extension and modification ontology models The talk will include examples both currently developed the context the SmartWeb project Mobile Broadband Access the Semantic Web http www smartweb projekt 
2223 en Introduction SEKT partner 
2227 en Introduction SEKT partner University Innsbruck Austria
2228 en Introduction SEKT partner JSI Slovenia
2229 en Introduction SEKT partner University Karlsruhe Institute AIFB Germany
2230 en Introduction SEKT partner Empolis GmbH Germany
2231 en Introduction SEKT partner Ontoprise GmbH Intelligente Lösungen für das Wissensmanagement Germany
2232 en Introduction SEKT partner Kea pro GmbH Switzerland
2266 en Ecopolitical debate and the politics Nature During the last thirty years philosophers the West have critiqued the underlying assumptions Modern philosophy relation the natural world This development has been part ongoing expansion philosophical work involving cross cultural studies world views ultimate philosophies Since philosophical studies the West have often ignored the natural world and since most studies ethics have focused human values those approaches which emphasize ecocentric values have been referred ecophilosophy Just the aim traditional philosophy sophia wisdom the aim ecophilosophy ecosophy ecological wisdom The Practice ecophilosophy ongoing comprehensive deep inquiry into values the nature the world and the self The mission ecophilosophy explore diversity perspectives human Nature contexts and interrelationships fosters deeper and more harmonious relationships between place self community and the natural world This aim furthered comparing the diversity ecosophies from which people support the platform principles the global long range deep ecology movement 
2311 en Force law and the prospects survival
2349 en Opentaps training Free yourself from expensive commercial ERP software difficult maintain legacy applications and messy integration projects opentaps complete open source solution for your enterprise Its sophisticated features and modern architecture will help bring together your entire organization automate business processes and improve efficiency 
2357 en Interview with Mario Orasche Gcp gamma capital partners independent Venture Capital investment firm focused financing dynamic technology companies Austria Germany Switzerland and CEE countries 
2361 en Spatial Data Mining Querie language GIS System The strength GIS providing rich data infrastructure for combining disparate data meaningful ways using spatial arrangement proximity toolbox GIS allows planners perform spatial analysis using geo processing functions such map overlay connectivity measurements thematic map coloring Although this makes effective the geographic visualization individual variables complex multi variate dependencies are easily overlooked The required step take GIS beyond tool for automating cartography incorporate the ability analyzing and condensing large number geo referenced variables into single forecast score This where data mining promises great potential benefits and the reason why there such hand glove fit between GIS and data mining INGENS INductive GEographic iNformation System prototype GIS which integrates data mining tools assist users their task topographic map interpretation The spatial data mining process aimed user who controls the parameters the process means query written mining query language this talk present SDMQL Spatial Data Mining Query Language spatial data mining query language used INGENS Currently SDMQL supports two data mining tasks inducing classification rules and discovering association rules For both tasks the language permits the specification the task relevant data the kind knowledge mined the background knowledge and the hierarchies the interestingness measures and the visualization for discovered patterns Some constraints the query language are identified the particular mining task describe the syntax the query language and finally briefly illustrate the application real repository maps 
2371 en Modeling real world networks using Kronecker multiplication Given large real graph how can generate syntheticn graph that matches its properties has similar degreen distribution similar small diameter similar spectrum etc First propose graph generator that mathematically tractablen and generates realistic graphs The main idea use non standardn matrix operation the Kronecker product generate graphs that wen refer Kronecker graphs show that Kronecker graphsn naturally obey all the above properties fact can rigorouslyn prove that they Once have the model fit real graph generate syntheticn graph that matches its properties has similar degree distribution similar small diameter similar spectrum etc present fast and scalable algorithm for fitting the Kronecker graphn generation model real networks naive approach fitting wouldn take super exponential time contrast our algorithm takes linear time exploiting the structure Kronecker matrix multiplication and byn using sampling Experiments large real and synthetic graphs show that our approachn recovers the true parameters and indeed mimics very well the patternsn found the target graphs Once fitted the model parameters and then resulting synthetic graphs can used for anonymization extrapolations and graph summarization The presentation starts Slovenian language and switches English few minutes into the lecture Another lecture the same topic can found icml07 leskovec smrg 
2373 en Data Mining Semantic Web This tutorial covers the field datamining general talks about its possible applications special case studies can added request and elaborates the issue hardware accelerators for datamining The introduction gives formal and informal definition through example plus points possible missunderstandings typical the topic The part methods and algorithms covers number different approaches each one presented thru animation using the examples that are both colourfull and unusual but excellent for pointing into the essence The part tools lists about dozen different tools and selects one for detailed case study The part applications includes examples from variety different fields engineering science medicine psychiatry etc The part hardware accelerators available special request This tutorial was presented far many times for industry and academia the USA and Europe and received the best tutorial award several conferences 
2377 en Biologically Inspired Flint Glass Flint glass optical glass that has relatively high refractive index and low Abbe number Flint glasses are arbitrarily defined having Abbe number less The currently known flint glasses have refractive indices ranging between and concave lens flint glass commonly combined with convex lens crown glass produce achromatic doublet lens because their compensating optical properties With respect glass the term flint derives from the flint nodules found the chalk deposits southeast England that were used source high purity silica George Ravenscroft circa 1662 produce potash lead glass that was the predecessor English lead crystal Traditionally flint glasses contain around — lead oxide however the manufacture and disposal these glasses are sources pollution many modern flint glasses the lead can replaced with other additives such titanium dioxide and zirconium dioxide without significantly altering the optical properties the glass Flint glass can fashioned into rhinestones which are used diamond simulants 
2384 en Funding the Semantic Web cross continental assessment and outlook the recent years semantic technologies have demonstrated their usefulness and applicability variety domains the Semantic Web being the most prominent one The Semantic Web has started move from academic research deployed business critical and scientific applications with support from recommendations standards developed under W3C governance and growing list commercial technologies and products being developed These developments seem early but firm steps establishing semantics core column computer science and application development The outreach this development can only assessed limited degree the moment but most likely will affect key aspects society and the way communicate This high potential was recognized early funding agencies all over the world However after the first strong funding DARPA subsequent research funding seems limited Europe seems have seem more substantial and sustained funding least during last few years Now may good time assess what has been achieved far and how funding agencies see future research directions funding opportunities and funding environments what are the planned strategies and instruments funding agencies maximize the impact future research semantics consider specifically interesting the research community hear the opinions and plans the major funding bodies around the world and learn about their view future issues requirements applications challenges related semantics and Semantic Web and extension their opinion the needs industry government and education for research the Semantic Web and related areas 
2385 en The Role Semantic Web Web Partner Follower Currently the web phenomenon that driving the best developers and captivating the best entrepreneurs Web Web encompasses some today most exciting web based applications mashups blogs wikis feeds interface remixes and social networking tagging systems Although most Web applications rely implicit lightweight shared semantics order deliver user value several metrics number startups funded number hype articles the trade press number conferences Web technologies are significantly outdistancing semweb technologies both implementation and mindshare Hackers are staying late building mashups with AJAX and REST and microformats and only rarely including RDF and OWL This panel will consider whether semantic web technology has role Web applications least the context the following areas Web and Semantics What unique value can semantic web technologies supply Web application areas How semantic web technologies match with the semantic demands Web applications Semantics and Web Ecosystems Web applications often strive build participatory ecosystems content that supplied and curated their users Can these users effectively create maintain map between and use RDF OWL content way that reinforces the ecosystem Semantic Web Practice Does semantic web technology enable the cost effective creation Web applications that are simple scalable and compelling for targeted user community Can semantic web technology genuinely strengthen Web applications will just footnote the Web wave 
2386 en Closing Cerimony Awards Next Year Presentation
2392 en Context Sensitivity Knowledge Rich Systems Part Defining context
2393 en Research the Semantics Linking and Importing Modular Ontologies
2394 en Research Block Matching for Ontologies
2395 en Research PowerMap Mapping the Real Semantic Web the Fly
2396 en Semantic Desktop and Social Semantic Collaboration Promiscuous Semantic Federation Semantic Desktops meet Web 
2397 en Semantic Desktop and Social Semantic Collaboration Case Study Engineering Knowledge Base for Intelligent Personal Assistant
2398 en Semantic Desktop and Social Semantic Collaboration Open Constitution Based Knowledge Communities the Semantic Web
2399 en Semantic Desktop and Social Semantic Collaboration Introduction
2400 en Semantic Desktop and Social Semantic Collaboration The Beagle Toolbox Towards Extendable Desktop Search Architecture
2401 en Semantic Desktop and Social Semantic Collaboration Method Retrieving Web Browsing Experience Using Semantic Periods
2402 en Semantic Desktop and Social Semantic Collaboration Semantic Clipboard Semantically Enriched Data Exchange Between Desktop Applications
2403 en Semantic Desktop and Social Semantic Collaboration SemDAV File Exchange Protocol for the Semantic Desktop
2404 en Semantic Desktop and Social Semantic Collaboration Supporting Mobile Service Interaction through Semantic Service Description Annotation and Automatic Interface Generation
2405 en Semantic Desktop and Social Semantic Collaboration Spontaneous Collaboration via Browsing Semantic Data Mobile Devices
2406 en Semantic Desktop and Social Semantic Collaboration Application Design and Interoperability for Managing Personal Information the Semantic Desktop
2407 en Semantic Desktop and Social Semantic Collaboration PIMO Population and Semantic Annotation for the Gnowsis Semantic Desktop
2408 en Semantic Desktop and Social Semantic Collaboration Overview Information Management and Knowledge Work Studies Lessons for the Semantic Desktop
2411 en Spatiotemporal Modelling Intracellular Signalling Bacterial Chemotaxis Whilst theoretical models have been used understand aspects bacterial chemotaxis systems for the past thirty years little work has focused the importance that spatial localisation proteins within the cytoplasm the cell has the overall functionality the intracellular network this talk will examine spatio temporal models signal transduction developed describe the phosphotransfer pathway within coli This model framework will then extended examine the importance protein localisation within sphaeroides species which contains considerably more phosphotransfer proteins than coli and the spatial localisation which plays particularly important role activating certain elements the phosphotransfer network The difficulties encountered obtaining robust parameter estimates for reaction rates within the sphaeroides will also detailed Joint work with Porter Maini and Armitage 
2412 en Conservation Laws and Identifiability Models for Cellular Metabolism New experimental techniques the biosciences provide with high quality data allowing quantitative mathematical modeling When fitting model parameters experimental data important know whether all parameters can uniquely estimated from available data this paper discuss class models for metabolism where the introduction conserved moieties may cause otherwise identifiable model unidentifiable general method for reparametrization identifiable rate expressions presented and the general results are exemplified three well cited models for yeast metabolism Joint work with Milena Anguelova Gunnar Cedersuna Carl Johan Franzen Mikael Johansson
2413 en Bayesian Inference for Systems Biological Models via Diffusion Approximation post genomic biology becomes more predictive the ability infer rate parameters known reverse engineering biochemical networks will become increasingly important One approach replace the underlying model diffusion approximation and the model identified using discrete time and often incomplete data that subject error Unfortunately likelihood based inference can problematic closed form transition densities nonlinear diffusions are rarely available widely used solution involves the introduction latent data points between every pair observations allow Euler Maruyama approximation the true transition densities become accurate Markov chain Monte Carlo MCMC methods can then used sample the posterior distribution latent data and model parameters however naive schemes suffer from mixing problem that worsens with the degree augmentation reparameterisation therefore implemented overcome this difficulty and the methodology applied simple prokaryotic auto regulatory gene network Joint work with Darren Wilkinson
2414 en Experimental Design for Efficient Identification Gene Regulatory Networks using Sparse Bayesian Models Identifying large gene regulatory networks important task while the acquisition data through perturbation experiments gene switches RNAi expensive thus desirable use identification method that effectively incorporates available prior knowledge such sparse connectivity and that allows design experiments such that maximal information gained from each one Our main contributions are twofold method for consistent inference network structure provided incorporating prior knowledge about sparse connectivity The algorithm time efficient and robust violations model assumptions Moreover show how use for optimal experimental design reducing the number required experiments substantially employ sparse linear models and show how perform full Bayesian inference for these not only estimate single maximum likelihood network but compute posterior distribution over networks using novel variant the expectation propagation method The representation uncertainty enables effective experimental design standard statistical setting experiments are selected such that average the experiments are maximally informative Few methods have addressed the design issue far Compared the most well known one our method more transparent and shown perform qualitatively superior the former hard and unrealistic constraints have placed the network structure for mere computational tractability while such are not required our method demonstrate reconstruction and optimal experimental design capabilities tasks generated from realistic non linear network simulators Joint work with Florian Steinke and Koji Tsuda 
2415 en Reconstructing Transcriptional Networks using Bayesian State Space Model major challenge systems biology the ability model complex regulatory interactions previous work have used Linear Gaussian state space models SSMs also known Linear Dynamical Systems LDS Kalman filter models reverse engineer regulatory networks from high throughput data sources such microarray gene expression profiling SSM models are subclass dynamic Bayesian networks used for modeling time series data and have been used extensively many areas control and signal processing The parameters SSM can learned using maximum likelihood methods However general the approach prone overfitting especially when fitting models with many variables with relatively small amounts data have instead turned fully Bayesian analysis which avoids overfitting and provides error bars all model parameters this paradigm the objective function simply the probability the data that which results from integrating out the parameters the model with respect their prior distribution Optimizing model with respect such objective function avoids overfitting the conventional sense practice Bayesian learning scheme infers distributions over all the parameters and makes modeling predictions taking into account all possible parameter settings doing penalize models with too many parameters embodying automatic Occam Razor effect describe results from simulation studies based synthetic mRNA time series data Receiver Operating Characteristic ROC analysis demonstrates overall accuracy transcriptional network reconstruction from the mRNA time series measurements alone approximately Area Under the Curve AUC for time points and better still for data sampled higher rate Incorporation prior information about known regulatory connections improves this accuracy fashion which appears linear with the number known connections included The implications these simulation studies for experimental design will discussed Joint work with Matthew Beal and Juan 
2416 en Reaction and Diffusion Fractal Sets Systems biologists are interested modelling chemical reactions the intracellular environment and date much what done based the use mass action kinetics construct models elementary reactions Mass action kinetic models are based number assumptions which are not obviously valid the intracellular environment The cytoplasm far from ideal isotropic wellmixed solution and often the concentrations important chemical species are very small Molecular crowding can have significant thermodynamic effects but also must play important dynamical role interesting approach that has been adopted this has its roots fractal geometry given molecule depending upon its size and shape and the sizes and shapes the molecules which surround will find itself able move environment restricted dimension see for example Simple ideas have been suggested which give spatially homogeneous rate like equations which attempt account for this has been suggested for example that rate laws which depend non integer powers the concentration species might used and alternatively that the rate constants for elementary reactions which involve the encounter different species opposed spontaneous decomposition individual molecules should time dependent this case the rates decay time the suggested form the Zipf Mandlebrot law which tends power law decay long times suggested that this power law characterises the dimension the restricted environment each chemical species Both these approaches suffer from shortcomings The use non integer powers concentrations can only justified very limited circumstances and has been shown inferior the time dependent rate parameter when describing certain lattice gas computer simulations chemical reactions However the latter clearly not invariant time translation the origin time has particular significance and not clear general principle what the correct choice time origin should Moreover experimental techniques are being refined the extent that spatio temporal resolution the species within single cell becoming possible might therefore aspire constructing theories which describe the dynamics for spatially non uniform distributions active species have recently been working class simple models this type These are spatio temporal dynamical systems which model reaction and diffusion certain class fractal sets has been known for some time now that possible define random walks and hence diffusion certain class fractals indeed was this observation that motivated the work described above simple example this class the Sierpinsky Gasket which has constrictions the diffusion process the sense that can disconnected the removal finite set points The talk will focus mainly this example but shall also suggest ways which could lead more general models Supported the Manchester Institute for Mathematical Science MIMS 
2417 en Modelling Transcriptional Regulation with Gaussian Processes Modelling the dynamics transcriptional processes the cell requires the knowledge number key biological quantities While some them are relatively easy measure such mRNA decay rates and mRNA abundance levels still very hard measure the active concentration levels the transcription factor proteins that drive the process and the sensitivity target genes these concentrations this paper show how these quantities for given transcription factor can inferred from gene expression levels set known target genes treat the protein concentration latent function with Gaussian process prior and include the sensitivities mRNA decay rates and baseline expression levels hyperparameters apply this procedure human leukemia dataset focusing the tumour repressor p53 and obtaining results good accordance with recent biological studies Joint work with Guido Sanguinetti and Magnus Rattray 
2418 en Parameter Estimation ODE with Regression Splines Application Biological Networks The construction and the estimation quantitative models gene regulatory networks and metabolic networks one the task Systems Biology Such models are useful because they provide tools for simulating and predicting biological systems Various approaches have been proposed such graphical models Bayesian dynamical models Ordinary Differential Equations ODE For the latter one can also expect derive parameters that often have meaningful biological sense focus the estimation parameter theta indexing vector ODE from observed time series concentration profiles which may nonlinear due the use Michaelis Menten dynamics mass action law Even when the likelihood simple the case Gaussian error noise the computation the Maximum Likelihood Estimator remains hard because the burden the optimization step Indeed the implicit definition the model necessitates the integration the ODE for each evaluation the likelihood Moreover the likelihood may have numerous local maxima need avoid hence the exploration the parameter space may computer intensive propose then alternative frequentist estimator theta based preliminary spline estimator the solution the ODE use simple characterization theta that enables derive learning algorithm avoiding the integration the ODE and that can split the estimation vector differential equation several estimations scalar differential equations illustrate this algorithm with different models used Systems Biology and sketch how can adapted various settings encountered the practitioner Joint work with Chris Klaassen and Florence Alché Buc 
2419 en Identifiability Delay Parameters for Nonlinear Time delay Systems with Applications Systems Biology The concept parameter identifiability will introduced briefly followed short description how this property can tested for ODE systems general rank calculations Then the extension this analysis delay systems recently developed Xia and Zhang will reviewed these works the authors use the framework modules over non commutative rings formulate analogous rank test for parameter identifiability delay systems with known time delays Our ongoing work will then motivated model cellular signal transduction Timmer where the sojourn time STAT the nucleus modelled unknown time delay which estimated numerically Timmer will show how the identifiability the time delay parameter determined the form the external input output representation the system Working the mathematical framework and formulate explicit criteria based rank calculations for the space spanned the gradients the output derivatives Finally several examples biological systems from the literature will discussed Joint work with Bernt Wennberg 
2420 en Dynamic Modelling Microarray Data recently released rHVDM Hidden Variable Dynamic Modelling Bioconductor package that predicts targets known transcription factor using time course microarray data The key feature behind the algorithm simple ODE model mRNA concentration the first stage rHVDM transcription factor activity the hidden variable deduced from the expression time profile small number known targets This information then used screen other genes for dependency that transcription factor The accuracy the technique has been demonstrated with Affymetrix microarray time course data and verified experimentally using siRNA knockdown targeted transcription factor p53 While implementing the rHVDM algorithm and refining for release encountered number problems These included parameter identifiability parameter count reduction algorithmic speed parameter domain restriction confidence interval estimation and measurement noise will discuss each these issues individually along with the techniques used address them 
2421 en Maximum Likelihood Estimation for Gene Regulatory Network Defined Differential Equations Gene regulation may described set deterministic differential equations describing the time rate evolution the gene product concentrations and containing parameters accounting for the regulatory relationships occurring the gene network will present maximum likelihood based estimators the parameters arising this formalism and will prove that they have desirable properties Our results may applied gene regulation model yielding the early Drosophila segments formation relying statistical modelling gene expression data obtained confocal laser scanning microscopy The proposed statistical model accounts for the uncertainty the measurement gene expression and the uncertainty the time which the measurements are performed 
2422 en Model Reduction for Parameter Estimation Estimating parameters biochemical network models central but often difficult problem general approach that may worth developing further first seek simplified reduced models with fewer dynamical degrees freedom estimate parameters for the reduced models and then use that information constrain the corresponding parameters the full model This approach can leverage appropriate human expertise and could principle applied recursively The choice variables eliminate during model reduction could also made clustering other machine learning methods Some relevant model reductions already exist for quasi equilibrium models transcriptional regulation networks which could provide starting point for this strategy 
2423 en System Identification Enzymatic Control Processes Using Population Monte Carlo Methods demonstrate the superiority Population Monte Carlo techniques over standard Metropolis Markov Chain Monte Carlo MCMC methods for inferring optimal parameters for particular mechanistic model biological process given noisy experimental data our understanding biological processes increases the proposed models describe them become more complex With such potentially large numbers equations and parameters longer feasible hand pick parameter values and sure that the most appropriate values have been chosen Monte Carlo methods are becoming more widely used for estimating parameter values however show that the standard Metropolis MCMC approach fails converge optimal values for even relatively simple models and that more sophisticated method the form non Markovian Population Monte Carlo may successfully employed produce consistent and accurate results illustrate the basic problem using the minimal model for the circadian genetic network Arabidopsis thaliana which consists linked differential equations containing total parameters with additional noise parameter incorporated estimate the variance noise the data Joint work with Mark Girolami 
2424 en Estimating Parameters and Hidden Variables Non linear State space Model Regulatory Networks Understanding and identifying biological complex systems work the cell requires develop models able capture the stochastic nature biological processes well their dynamics Focusing gene regulatory networks propose new quantitative model the form dynamical Bayesian network that allows represent both genes and proteins the same framework start from the nonlinear differential equations Michaelis Menten which are the gold standard represent biochemical interactions and develop discrete time and probabilistic model from these equations Compared previous works such Nachman our model takes into account the dependency between the regulatory proteins and the genes that code for them well protein protein interactions and protein degradations the resulting nonlinear dynamical system the proteins concentrations are hidden while gene expressions are observed order learn the model parameters first construct discrete time probabilistic model corresponding our continuous time state space model and then derive Kalman smoother algorithm based the unscented transformation recursively estimate the parameters and unobserved protein activities The generality the learning method opens the door various adaptations the model required the biology Numerical results parameter and state estimation for the repressilator and other several small networks are presented and show the relevance the model 
2425 en Benchmarking parameter estimation and reverse engineering strategies Parameter estimation has become central problem systems biology both the form calibration bottom models component reverse engineering algorithms With proliferation algorithms proposed for these purposes has become important compare them objective ways will argue that silico biochemical network models are extremely useful for this purpose Several networks will presented that are challenging tests for parameter estimation and network inference issue that arises from the use silico networks though whether they can provide realistic data The application this benchmarking methodology will illustrated with comparison four reverse engineering methods Joint work with Diogo Camacho Paola Vera Licona and Reinhard Laubenbacher 
2427 en Pipelined Vector Processing and Scientific Computation For almost two decades 1976 1993 technical scientific high performance computing has been dominated vector processing pioneered Seymour Cray and his Cray Research Incorporated This technology explained detail and the significant cost performance advantages are outlined While parallel processing more vogue today and fact dominating scientific computation since 1993 comeback vector processing may the horizon due the IBM Sony Toshiba Cell processor being parallel vector processor and being the highest performance single chip available today 
2428 en Social media blog tagging Metadata “just more content” The authoring tags unlike the authoring traditional metadata highly popular among users This harbours unprecedented opportunities for organizing content However tags are still poorly understood What they mean what senses are they similar different from metadata Different tags support different communities but how exactly they reflect the plurality opinions what the relation individual differences authoring and reading this paper offer definition and empirical evidence for the claim that tags are not metadata but just more content The analysis rests multi annotator classification blog corpus using the WordNet domain labels system WND the development system text classification methods using WordNet and WND and quantitative and qualitative comparative analysis these classifications argue that the notion gold standard may meaningless social media and outline possible consequences for labelling and search engine development 
2429 en Novel functional magnetic materials based magneto structural transitions zadnjih letih svetu intenzivirale raziskave podro materialov magnetokalori nimi lastnostmi Ena pomembnih aplikacij takih materialov izdelava ekolo neopore nih magnetnih hladilnih sistemov predavanju bodo predstavljeni materiali ejo gigantski magnetokalori efekt magnetni oblikovni spomin razpravi predstavljena teorija katere mere narava magneto strukturne sklopitve vpliva latentno toploto spremembo magnetne entropije Predstavljene bodo metode kako dose maksimalen magnetokalori efekt metode izdelave teh materialov njihove karakterizacije 
2431 en The 2006 ISL Rich Transcription Speech Text System
2434 en Anti Learning Signature Biological Classification
2435 en Generalization Unseen Cases Free Lunches and Good Turing estimation
2437 en The use machine translation tools for cross lingual text mining
2438 en  Support Vector Method for Multivariate Performance Measures examine the relationship between the predictions made different learning algorithms and true posterior probabilities show that maximum margin methods such boosted trees and boosted stumps push probability mass away from and yielding characteristic sigmoid shaped distortion the predicted probabilities Models such Naive Bayes which make unrealistic independence assumptions push probabilities toward and Other models such neural nets and bagged trees not have these biases and predict well calibrated probabilities experiment with two ways correcting the biased probabilities predicted some learning methods Platt Scaling and Isotonic Regression qualitatively examine what kinds distortions these calibration methods are suitable for and quantitatively examine how much data they need effective The empirical results show that after calibration boosted trees random forests and SVMs predict the best probabilities 
2444 en Identity difference and tolleration Prof Anna Elisabetta Galeotti Univerze Torinu Predavateljica profesorica politi filozofije med drugim tudirala Cambridgeu predavala Evropski univerzi Firencah Institute for Advanced Studies Princetonu harvardski univerzi svoje znanstvenoraziskovalno delo posebej posve omenjeni tematiki njej izdala tudi knjigo Una proposta pluralista Liguori 1994 
2449 en Chill Data for the Transcriptions 2006
2452 en Speech Activity Detection and Speaker Diarization for Lectures
2453 en Two Contrastive Systems Based HMM BIC and Based Solely HMM
2454 en IBM Speech Text Evaluation System
2456 en The Limsi Lecture Transcription System
2457 en UPC Speech Activity Detector Evaluation
2458 en The AMI Meeting STT System Release 
2459 en  Evaluation Data Transcribed LDC
2461 en  Speaker Diarization Results and Speech Activity Detection Results
2463 en AMI SAD and SPKR Submission
2464 en Toward Adaptive Information Fusion Multimodal Systems Techniques for information fusion are the heart multimodal system design this talk summarize recent work predictive modeling users multimodal integration patterns including that there are large individual differences users dominant speech and pen multimodal integration patterns these patterns can identified almost immediately and remain highly consistent for individual users over time they are highly resistant change even when users are given strong selective reinforcement explicit instructions switch patterns and these distinct patterns appear derive from enduring differences among users cognitive style also discuss findings systematic entrenchment users dominant multimodal integration pattern when under load including task difficulty increases and during error handling conclude highlighting work are now pursuing that combines predictive user modeling with machine learning techniques accelerate generalize and improve the reliability information fusion during multimodal system processing Implications this research will discussed for the design adaptive multimodal systems with substantially improved performance characteristics 
2465 en Completion biological networks the output kernel trees approach Elucidating biological networks appears nowadays one the most important challenge systems biology Due the availability various sources data machine learning has play major role regarding this issue given its large spectrum tools ranging from generative models concept learning methods this work the focus narrowed the completion biological interactions networks for which some the interactions between variables usually genes proteins are already known 
2467 en Part Novel Bayesian Approach for Uncovering Potential Spectroscopic Counterparts for Clinical Variables NMR Metabonomic Applications Metabonomic approaches based spectroscopic data are their infancy biomedicine key challenge clinical metabonomics uncovering and understanding the relations between the multidimensional spectroscopic data and the clinical measures currently used for disease risk assessment and diagnostics novel Bayesian approach for revealing clinically relevant signals presented here for real NMR metabonomics data set The results are not only mathematically superior but also biochemically fully coherent 
2470 en  Simpler Intuitive Approach Morpheme Induction
2472 en Exploration Exploitation Chalenge part 
2473 en Answer Validation Excercise AVE
2474 en Entailment Cases Intelligent Tutoring Systems
2479 en Learning Distance Metric for Structured Network Prediction Man made naturally formed networks typically exhibit high degree structural regularity this paper introduce the problem structured network prediction given set entities and desired distribution for connectivity return likely set edges connecting the entities together network having the specified degree distribution Prediction useful for initializing network augmenting existing network and for filtering existing networks when the structure the network known order capture the inter dependencies amongst pairwise predictions learn parameters our model build upon recent structured output models Novel our approach the use partially labeled training examples and network structure sensitive loss function present encouraging results the model predicting equivalence graphs and links social network 
2490 en Assesment food product time domain NMR and MRI predavanju bodo predstavljene napredne preiskave ivil neinvazivnimi metodami jedrske magnetne resonance slikanja magnetno resonanco Predavanje konkretnimi zgledi osredoto eno preu evanje vpliva postopkov jih razvija prehrambena tehnologija rok trajanja strukturo ivil sposobnost ivil hitreje ejo vodo 
2492 en Presentation the book »Free Culture« Lawrence Lessig About Free Culture Lawrence Lessig could called cultural environmentalist One America’ most original and influential public intellectuals his focus the social dimension creativity how creative work builds the past and how society encourages inhibits that building with laws and technologies his two previous books CODE and THE FUTURE IDEAS Lessig concentrated the destruction much the original promise the Internet Now FREE CULTURE widens his focus consider the diminishment the larger public domain ideas this powerful wake call shows how short sighted interests blind the long term damage they’ inflicting are poisoning the ecosystem that fosters innovation All creative works—books movies records software and —are compromise between what can imagined and what possible—technologically and legally For more than two hundred years laws America have sought balance between rewarding creativity and allowing the borrowing from which new creativity springs The original term copyright set the Constitution 1787 was seventeen years Now closer two hundred Thomas Jefferson considered protecting the public against overly long monopolies creative works essential government role What did know that ’ forgotten Lawrence Lessig shows that while new technologies always lead new laws never before have the big cultural monopolists used the fear created new technologies specifically the Internet shrink the public domain ideas even the same corporations use the same technologies control more and more what can and can’ with culture more and more culture becomes digitized more and more becomes controllable even laws are being toughened the behest the big media groups What’ stake our freedom—freedom create freedom build and ultimately freedom imagine LINKS AND DOWNLOADS http www free culture freecontent Free Culture Free Content http www lessig org Lessig org http www free culture freeculture pdf Free Culture pdf book FREE CULTURE available for free under Creative Commons license You may redistribute copy otherwise reuse remix this book provided that you for non commercial purposes and credit Professor Lessig 
2493 en Ethnomusicology the Nineties Perspectives the History Research Bruno Nettl rojen Pragi leta 1930 profesor emeritus glasbe antropologije University Illinois Urbana Champaign ZDA Doktorat pridobil Indiana University eprav njegov domicil desetletja University Illinois kot gostujo profesor deloval tevilnih univerzah ZDA drugje svetu Prejel vrhunske nagrade dose podro etnomuzikologije muzikologije antropologije folkloristike Med njegove najpogosteje citirane knjige sodijo North American Indian Musical Styles 1954 Introduction Folk Music the United States 1960 Theory and Method Ethnomusicology 1964 Folk and Traditional Music the Western Continents 1965 Eight Urban Musical Cultures 1978 The Study Ethnomusicology Issues and Concepts 1983 The Western Impact World Music 1985 The Radif Persian Music Studies Structure and Cultural Context 1987 Blackfoot Musical Thought Comparative Perspectives 1989 Comparative Musicology and Anthropology Music Essays the History Ethnomusicology 1991 Excursions World Music 1992 New Perspectives Improvisation 1992 Heartland Excursions Ethnomusicological Reflections Schools Music 1995 Encounters Ethnomusicology Memoir 2002 and The Study Ethnomusicology Issues and Concepts 2005 Marsikatera med njimi bila prevedena druge jezike 
2494 en Presentation Ljudmila Ljubljana digital media lab
2495 en General idea content the festival
2496 en Egoboobits More http www egoboobits net EGOBOO bits 
2497 en How licence your work under 
2500 en The Brazilian Experience the Creative Commons
2501 en Project Constructing Internet archive
2503 en Project minutes for our mother tongue
2504 en How came across Creative Commons
2506 en Open Source Enterprise Resource Planning and Order Management System for Eastern European Tool and Die Making Workshops
2516 en Modern Medical Implants Use Advanced Manufacturing Technologies LENS 
2518 en Topology structure and defects carbon nanosystems this talk will explore how the last twenty years carbon science has made the fundamental step from the flat world graphite into the three dimensional world fullerenes and nanotubes the building blocks the carbon nanotechnology revolution will look the history the discovery buckminsterfullerene and carbon nanotubes and explore analogies diverse fields biology architecture and sport The understanding defects nanocarbons essential order control their diverse properties For example irradiating bundles carbon nanotubes produces defects which increase their bending strength factor the same time such defects can store energy and were the cause the “Windscale” nuclear fire the 1950s Recent advances computational modelling and electron microscopy mean that now have much better understanding the structure formation and evolution intrinsic defects opening the intriguing possibility selective spatial creation defects – atomic level defect engineering 
2519 en Decision Support Multi Attribute Decission Modelling and DEXI
2521 en Overview Environmental applications Machine Learning
2531 en Bio entrepeneur Boot Camp for beginners Goal Understand the expectations their future financial partners Venture Capitalists come explain their ways working well what makes good business plan the past have worked with EVCA and EASD representatives addition independent VCs from European countries Goal Share experiences with entrepreneurs the country Biotech managers come describe their start experience explaining both the easy and more complex aspects business planning Goal Provide TOOLS Learn how use platform tools including the BioBootCamp™ software program specially developed the Excel and Microsoft Office environment that participants may generate their own business plans after the workshop Participants may use following the training create unlimited simulations assess the feasibility project cost and follow the economics and financials their new company during the first years They will learn how write convincing Executive Summary open the doors investors offices Plus The Bioentrepreneur Boot Camp for beginners Participants also get set Notes which includes information about Venture Capital and web sites relating Bio business These web sites allow bio entrepreneurs involved Bioentrepreneur Boot Camp continue networking and identify other areas need the end the training workshop each attendee takes away personal copy the BioBootCamp™ software and information package work their own project 
2560 en  set output point view FDR control multiple testing
2563 en Bounding the family wise error rate using resampling methods
2568 en Intrinsic bounds the multiple comparison procedure
2576 en Multiple hypotheses testing functional neuroimaging applications
2584 en Context Sensitivity Knowledge Rich Systems Contents parts 
2585 en Tags and Dependencies integrated View Document Annotation
2588 en SASA Semi Automatic Semantic Annotator for Personal Knowledge Management
2591 en Towards Trust for Semantic Web Annotations
2628 en Determining significance neuroimaging studies using covariate modulated false discovery rate
2636 en Systems and Techniques for Decision Support
2637 en  Science and Computational Scientific Discovery
2645 en Electricity Features Issues and Choices
2646 en CHP Electricity Regulation the for Facing the Liberalized Electricity Market
2648 en Cyc Representing Acquiring and Using Knowledge This lecture will given Michael Witbrock chief director Cycorp http www cyc com which involved the construction the largest knowledge database and system for assumptions the lecture will present how encode knowledge and how this knowledge being used computers with the intent perform new unknown facts will also show some demos which are pointing the capabilities Cyc which with its quality performs better results than any other known modern method which can found the web have mention also that Cycorp has opened its new branch office Slovenia the seminar will discuss the Cyc system which said one the most controversial experiments computer and artificial intelligence history The idea Cyc has its beginnings the 80s when the goal group scientists from the University Stanford was build base knowledge which would incorporate most the knowledge operate with everyday life top the knowledge base mechanism conclusion making would used and would enable the use encoded knowledge for the formulation unknown knowledge After years development the Cyc system contains great quantity common sense knowledge encoded formal logic The system was used for series difficult applications where deeper view into the stored information was needed the lecture will able see how Cyc works practice Cyc and Jozef Stefan Institut Slovenia have opened new branch Cyc continue the development the system Michael Witborck also the director the Slovene affiliation 
2649 en Resambling based confidence regions and multiple tests for correlated random vector
2650 en Conditions for validity sampling based
2651 en Gene based bin analysis genome wide association studied With the improvement genotyping technologies and the exponentially growing number available markers case control genome wide association studies promise key tool for investigation complex diseases However new analytical methods have developed face the problems induced this data scale such statistical multiple testing data quality control biological interpretation and computational tractability present novel method analyze genome wide association studies results The algorithm based Bayesian model that integrates genotyping errors and genomic structure dependencies Probability values are assigned genomic regions termed bins which are defined from gene biased partitioning the genome and the false discovery rate estimated have applied this algorithm data coming from three genome wide association studies Multiple Sclerosis The method practically overcomes the scale problems and permits identify new putative regions statistically associated with the disease 
2652 en Sea Levels and Climate Change Popular interest and scientific concerns have focussed the potential for sea level rise and increased risks coastal flooding future warmer world This talk will review the recent global evidence for changes including the 2007 IPCC Report and look detail changes observed the principal Tide Gauge site Newlyn from 1915 2005 Changes may include not only mean sea level rises but also increased meterorological effects surges and changes tidal regimes 
2653 en Research Causal link matrix and planning model for Web service composition Automated composition Web services the process forming new value added Web services one the most promising challenges the semantic Web service research area Semantics one the key elements for the automated composition Web services because such process requires rich machine understandable descriptions services that can shared Semantics enables Web service describe their capabilities and processes nevertheless there still some work done Indeed Web services described functional level need formal context perform the automated composition Web services The suggested model Causal link matrix necessary starting point apply problem solving techniques such regression based search for Web service composition The model supports semantic context order find correct complete consistent and optimal plan solution this paper innovative and formal model for planning oriented composition presented 
2654 en Research Web Service Composition via Generic Procedures Customizing User Preferences
2655 en Research Constraint based Approach Horizontal Web Service Composition
2658 en Scanning the brain and probing the mind Functional neuroimaging offers insight into the working human mind and brain used study how the brain function changes different neurological and psychiatric diseases But can also used explore the mysteries love determine what people like lie detector interface between the brain and the computer Are finally able read the human mind 
2661 en Abiding Issues the Study North American Indian Music
2664 en Interactions between antibodies and receptors imune responses from basic science medicine use
2665 en Nello Cristianini asking Gregory Chaitin about Pattern This ultra short interview where the posed question the one that even Gottfried Wilhelm Leibniz posed himself What the pattern and what research did Gregory Chaitin this subject 
2691 en Introduction the Workshop Multiple Simultaneous Hypothesis Testing
2692 en Regularization Kernel Methods Decreasing the Bandwidth the Gaussian Kernel
2704 en Kernel Tricks Means and Ends will present thoughts what made kernel machines popular and what may may not keep them going will also discuss applications different domains including computer graphics 
2706 en Practical Statistical Relational Learning The tutorial will composed three parts Foundational areas The first part will consist brief introduction each the four foundational areas SRL logical inference inductive logic programming probabilistic inference and statistical learning Obviously the short time available attempt will made comprehensively survey these areas rather the focus will providing the key concepts and techniques required for the subsequent parts For example the logical inference part will focus the basics satisfiability testing and the probabilistic statistical parts Markov networks The duration this part will approximately two hours half hour per subtopic Putting the pieces together The second part will introduce the key ideas SRL and survey major approaches using Markov logic the unifying framework will present state the art algorithms for statistical relational learning and inference and give overview the Alchemy open source software This part will essentially consist putting together the pieces introduced the first part Its duration will approximately hour Applications The third and final part will describe how efficiently develop state the art non applications various areas including hypertext classification link based information retrieval information extraction and integration natural language processing social network modeling computational biology and ubiquitous computing This part will also include practical tips using SRL Markov logic and Alchemy the kind information that seldom found research papers but key developing successful applications The duration this part will approximately hour 
2707 en Bayesian models human inductive learning everyday learning and reasoning people routinely draw successful generalizations from very limited evidence Even young children can infer the meanings words hidden properties objects the existence causal relations from just one few relevant observations far outstripping the capabilities conventional learning machines How they And how can bring machines closer these human like learning abilities will argue that people everyday inductive leaps can understood approximations Bayesian computations operating over structured representations the world what cognitive scientists have called intuitive theories schemas For each several everyday learning tasks will consider how appropriate knowledge representations are structured and used and how these representations could themselves learned via Bayesian methods The key challenge balance the need for strongly constrained inductive biases critical for generalization from very few examples with the flexibility learn about the structure new domains learn new inductive biases suitable for environments which could not have been pre programmed perform The models discuss will connect several directions contemporary machine learning such semi supervised learning structure learning graphical models hierarchical Bayesian modeling and nonparametric Bayes 
2708 en Graphical Models for HIV Vaccine Design will discuss two applications graphical models HIV vaccine design The first helps determine how strongly our immune system fights HIV The second helps identify which parts HIV can successfully attacked our immune system will also discuss how these applications have exposed weakness the process learning graphical models from data namely the inability quantify how many arcs learned graphical model are spurious will offer solution based the False Discovery Rate 
2709 en Welcome Although Bayesian methods for Reinforcement Learning can traced back the 1960s Howard work Operations Research Bayesian methods have only been used sporadically modern Reinforcement Learning This part because non Bayesian approaches tend much simpler work with However recent advances have shown that Bayesian approaches not need complex initially thought and offer several theoretical advantages For instance keeping track full distributions instead point estimates over the unknowns Bayesian approaches permit more comprehensive quantification the uncertainty regarding the transition probabilities the rewards the value function parameters and the policy parameters Such distributional information can used optimize principled way the classic exploration exploitation tradeoff which can speed the learning process Similarly active learning for reinforcement learning can naturally optimized The estimation gradient performance with respect value function and policy parameters can also done more accurately while using less data Bayesian approaches also facilitate the encoding prior knowledge and the explicit formulation domain assumptions The primary goal this tutorial raise the awareness the research community with regard Bayesian methods their properties and potential benefits for the advancement Reinforcement Learning introduction Bayesian learning will given followed historical account Bayesian Reinforcement Learning and description existing Bayesian methods for Reinforcement Learning The properties and benefits Bayesian techniques for Reinforcement Learning will discussed analyzed and illustrated with case studies 
2710 en Introduction Reinforcement Learning and Bayesian learning Although Bayesian methods for Reinforcement Learning can traced back the 1960s Howard work Operations Research Bayesian methods have only been used sporadically modern Reinforcement Learning This part because non Bayesian approaches tend much simpler work with However recent advances have shown that Bayesian approaches not need complex initially thought and offer several theoretical advantages For instance keeping track full distributions instead point estimates over the unknowns Bayesian approaches permit more comprehensive quantification the uncertainty regarding the transition probabilities the rewards the value function parameters and the policy parameters Such distributional information can used optimize principled way the classic exploration exploitation tradeoff which can speed the learning process Similarly active learning for reinforcement learning can naturally optimized The estimation gradient performance with respect value function and policy parameters can also done more accurately while using less data Bayesian approaches also facilitate the encoding prior knowledge and the explicit formulation domain assumptions The primary goal this tutorial raise the awareness the research community with regard Bayesian methods their properties and potential benefits for the advancement Reinforcement Learning introduction Bayesian learning will given followed historical account Bayesian Reinforcement Learning and description existing Bayesian methods for Reinforcement Learning The properties and benefits Bayesian techniques for Reinforcement Learning will discussed analyzed and illustrated with case studies 
2711 en Model based Bayesian Although Bayesian methods for Reinforcement Learning can traced back the 1960s Howard work Operations Research Bayesian methods have only been used sporadically modern Reinforcement Learning This part because non Bayesian approaches tend much simpler work with However recent advances have shown that Bayesian approaches not need complex initially thought and offer several theoretical advantages For instance keeping track full distributions instead point estimates over the unknowns Bayesian approaches permit more comprehensive quantification the uncertainty regarding the transition probabilities the rewards the value function parameters and the policy parameters Such distributional information can used optimize principled way the classic exploration exploitation tradeoff which can speed the learning process Similarly active learning for reinforcement learning can naturally optimized The estimation gradient performance with respect value function and policy parameters can also done more accurately while using less data Bayesian approaches also facilitate the encoding prior knowledge and the explicit formulation domain assumptions The primary goal this tutorial raise the awareness the research community with regard Bayesian methods their properties and potential benefits for the advancement Reinforcement Learning introduction Bayesian learning will given followed historical account Bayesian Reinforcement Learning and description existing Bayesian methods for Reinforcement Learning The properties and benefits Bayesian techniques for Reinforcement Learning will discussed analyzed and illustrated with case studies 
2712 en Gaussian Process Temporal Difference Although Bayesian methods for Reinforcement Learning can traced back the 1960s Howard work Operations Research Bayesian methods have only been used sporadically modern Reinforcement Learning This part because non Bayesian approaches tend much simpler work with However recent advances have shown that Bayesian approaches not need complex initially thought and offer several theoretical advantages For instance keeping track full distributions instead point estimates over the unknowns Bayesian approaches permit more comprehensive quantification the uncertainty regarding the transition probabilities the rewards the value function parameters and the policy parameters Such distributional information can used optimize principled way the classic exploration exploitation tradeoff which can speed the learning process Similarly active learning for reinforcement learning can naturally optimized The estimation gradient performance with respect value function and policy parameters can also done more accurately while using less data Bayesian approaches also facilitate the encoding prior knowledge and the explicit formulation domain assumptions The primary goal this tutorial raise the awareness the research community with regard Bayesian methods their properties and potential benefits for the advancement Reinforcement Learning introduction Bayesian learning will given followed historical account Bayesian Reinforcement Learning and description existing Bayesian methods for Reinforcement Learning The properties and benefits Bayesian techniques for Reinforcement Learning will discussed analyzed and illustrated with case studies 
2714 en Demo Control octopus arm using GPTD Although Bayesian methods for Reinforcement Learning can traced back the 1960s Howard work Operations Research Bayesian methods have only been used sporadically modern Reinforcement Learning This part because non Bayesian approaches tend much simpler work with However recent advances have shown that Bayesian approaches not need complex initially thought and offer several theoretical advantages For instance keeping track full distributions instead point estimates over the unknowns Bayesian approaches permit more comprehensive quantification the uncertainty regarding the transition probabilities the rewards the value function parameters and the policy parameters Such distributional information can used optimize principled way the classic exploration exploitation tradeoff which can speed the learning process Similarly active learning for reinforcement learning can naturally optimized The estimation gradient performance with respect value function and policy parameters can also done more accurately while using less data Bayesian approaches also facilitate the encoding prior knowledge and the explicit formulation domain assumptions The primary goal this tutorial raise the awareness the research community with regard Bayesian methods their properties and potential benefits for the advancement Reinforcement Learning introduction Bayesian learning will given followed historical account Bayesian Reinforcement Learning and description existing Bayesian methods for Reinforcement Learning The properties and benefits Bayesian techniques for Reinforcement Learning will discussed analyzed and illustrated with case studies 
2715 en ILP Invited Panel Structured Machine Learning The Next Years
2716 en Best Paper Information Theoretic Metric Learning this paper present information theoretic approach learning Mahalanobis distance function formulate the problem that minimizing the differential relative entropy between two multivariate Gaussians under constraints the distance function express this problem particular Bregman optimization problem that minimizing the LogDet divergence subject linear constraints Our resulting algorithm has several advantages over existing methods First our method can handle wide variety constraints and can optionally incorporate prior the distance function Second fast and scalable Unlike most existing methods eigenvalue computations semi definite programming are required also present online version and derive regret bounds for the resulting algorithm Finally evaluate our method recent error reporting system for software called Clarify the context metric learning for nearest neighbor classification well standard data sets 
2717 en Learning Distance Function Coding Similarity consider the problem learning similarity function from set positive equivalence constraints similar point pairs define the similarity information theoretic terms the gain coding length when shifting from independent encoding the pair joint encoding Under simple Gaussian assumptions this formulation leads non Mahalanobis similarity function which effcient and simple learn This function can viewed likelihood ratio test and show that the optimal similaritypreserving pro jection the data variant Fisher Linear Discriminant also show that under some naturally occurring sampling conditions equivalence constraints this function converges known Mahalanobis distance RCA The suggested similarity function exhibits superior performance over alternative Mahalanobis distances learnt from the same data Its superiority demonstrated the context image retrieval and graph based clustering using large number data sets 
2718 en  Transductive Framework Distance Metric Learning Spectral Dimensionality Reduction Distance metric learning and nonlinear dimensionality reduction are two interesting and active topics recent years However the connection between them not thoroughly studied yet this paper transductive framework distance metric learning proposed and its close connection with many nonlinear spectral dimensionality reduction methods elaborated Furthermore prove representer theorem for our framework linking with function estimation RKHS and making possible for generalization unseen test samples our framework suffices solve sparse eigenvalue problem thus datasets with 105 samples can handled Finally experiment results synthetic data several UCI databases and the MNIST handwritten digit database are shown 
2719 en Dirichlet Aggregation Unsupervised Learning towards Optimal Metric for Proportional Data Proportional data normalized histograms have been frequently occurring various areas and they could mathematically abstracted points residing geometric simplex proper distance metric this simplex importance many applications including classification and information retrieval this paper develop novel framework learn optimal metric the simplex jor features our approach include its flexibility handle correlations among bins dimensions widespread applicability without being limited hoc backgrounds and real global solution contrast existing traditional local approaches The technical essence our approach fit parametric distribution the observed empirical data the simplex The distribution parameterized affinities between simplex vertices which learned via maximizing likelihood observed data Then these affinities induce metric the simplex defined the earth mover distance equipped with ground distances derived from simplex vertex affinities 
2720 en Bias variance analysis relational domains
2721 en Learning Probabilistic Stochastic Models from Probabilistic Examples
2722 en Learning from Interpretations Rooted Kernel for Ordered Hypergraphs The paper presents kernel for learning from ordered hypergraphs formalization that captures relational data used Inductive Logic Programming ILP The kernel generalizes previous approaches graph kernels calculating similarity based walks the hypergraph Experiments challenging chemical datasets demonstrate that the kernel outperforms existing ILP methods and competitive with state the art graph kernels The experiments also demonstrate that the encoding graph data can affect performance dramatically fact that can useful beyond kernel methods 
2723 en Scalable Modeling Real Graphs using Kronecker Multiplication Given large real graph how can generate synthetic graph that matches its properties has similar degree distribution similar small diameter similar spectrum etc propose use Kronecker graphs which naturally obey all the above properties and present KronFit fast and scalable algorithm for fitting the Kronecker graph generation model real networks naive approach fitting would take super exponential time contrast KronFit takes linear time exploiting the structure Kronecker product and using sampling Experiments large real and synthetic graphs show that KronFit indeed mimics very well the patterns found the target graphs Once fitted the model parameters and the resulting synthetic graphs can used for anonymization extrapolations and graph summarization 
2724 en Recovering Temporally Rewiring Networks model based approach plausible representation relational information among entities dynamic systems such living cell social community stochastic network which topologically rewiring and semantically evolving over time While there rich literature modeling static temporally invariant networks much less has been done toward modeling the dynamic processes underlying rewiring networks and recovering such networks when they are not observable present class hidden temporal exponential random graph models htERGMs study the yet unexplored topic modeling and recovering temporally rewiring networks from time series node attributes such activities social actors expression levels genes show that one can reliably infer the latent timespecific topologies the evolving networks from the observation report empirical results both synthetic data and Drosophila lifecycle gene expression data set comparison with static counterpart htERGM 
2725 en Entire Regularization Paths for Graph Data Graph data such chemical compounds and XML documents are getting more common many application domains main difficulty graph data processing lies the intrinsic high dimensionality graphs namely when graph represented binary feature vector indicators all possible subgraph patterns the dimensionality gets too large for usual statistical methods propose efficient method select small number salient patterns regularization path tracking The generation useless patterns minimized progressive extension the search space experiments shown that our technique considerably more efficient than simpler approach based frequent substructure mining 
2726 en Learning Compress Images and Video present intuitive scheme for lossy color image compression Use the color information from few representative pixels learn model which predicts color the rest the pixels Now storing the representative pixels and the image grayscale suffice recover the original image similar scheme also applicable for compressing videos where single model can used predict color many consecutive frames leading better compression Existing algorithms for colorization the process adding color grayscale image video sequence are tedious and require intensive human intervention bypass these limitations using graph based inductive semi supervised learning module for colorization and simple active learning strategy choose the representative pixels Experiments wide variety images and video sequences demonstrate the efficacy our algorithm 
2727 en Adaptive Mesh Compression Computer Graphics using Multiscale Manifold Learning This paper investigates compression jects computer graphics using manifold learning Spectral compression uses the eigenvectors the graph Laplacian object topology adaptively compress objects compression challenging application domain ject models can have 105 vertices and reliably computing the basis functions large graphs numerically challenging this paper introduce novel multiscale manifold learning approach mesh compression using diffusion wavelets general extension wavelets graphs with arbitrary topology Unlike the global nature Laplacian bases diffusion wavelet bases are compact and multiscale nature decompose large graphs using fast graph partitioning method and combine local multiscale wavelet bases computed each subgraph present results showing that multiscale diffusion wavelets bases are superior the Laplacian bases for adaptive compression large jects 
2728 en Graph Clustering With Network Structure Indices Graph clustering has become ubiquitous the study relational data sets examine two simple algorithms new graphical adaptation the medoids algorithm and the Girvan Newman method based edge betweenness centrality show that they can effective discovering the latent groups communities that are defined the link structure graph However both approaches rely prohibitively expensive computations given the size modern relational data sets Network structure indices NSIs are proven technique for indexing network structure and efficiently finding short paths show how incorporating NSIs into these graph clustering algorithms can overcome these complexity limitations also present promising quantitative and qualitative evaluations the modified algorithms synthetic and real data sets 
2729 en Map Building without Localization Dimensionality Reduction Techniques This paper proposes new map building framework for mobile robot named Localization Free Mapping Dimensionality Reduction LFMDR this framework the robot map building interpreted problem reconstructing the coordinates jects that they maximally preserve the local proximity the jects the space robot observation history Not only traditional linear PCA but also recent manifold learning techniques can used for solving this problem contrast the SLAM framework LFMDR framework does not require localization procedures nor explicit measurement and motion models the latter part this paper will demonstrate visibility only and bearing only localization free mappings which are derived applying LFMDR framework the visibility and bearing measurements respectively 
2730 en Scalable Training regularized Log linear Models The bfgs limited memory quasi Newton method the algorithm choice for optimizing the parameters large scale log linear models with regularization but cannot used for regularized loss due its non differentiability whenever some parameter zero Eficient algorithms have been proposed for this task but they are impractical when the number parameters very large present algorithm OrthantWise Limited memory Quasi Newton owlqn based bfgs that can eficiently optimize the regularized log likelihood log linear models with millions parameters our experiments parse reranking task our algorithm was several orders magnitude faster than alternative algorithm and substantially faster than lbfgs the analogous regularized problem also present proof that owl guaranteed converge globally optimal parameter vector 
2731 en Support Cluster Machine For large scale classification problems the training samples can clustered beforehand downsampling pre process and then only the obtained clusters are used for training Motivated such assumption proposed classification algorithm Support Cluster Machine SCM within the learning framework introduced Vapnik For the SCM compatible kernel adopted such that similarity measure can handled not only between clusters the training phase but also between cluster and vector the testing phase also proved that the SCM general extension the SVM with the RBF kernel The experimental results confirm that the SCM very effective for largescale classification problems due significantly reduced computational costs for both training and testing and comparable classification accuracies product provides promising approach dealing with privacy preserving data mining problems 
2732 en Trust Region Newton Methods for Large Scale Logistic Regression Large scale logistic regression arises many applications such document classification and natural language processing this paper apply trust region Newton method maximize the log likelihood the logistic regression model The proposed method uses only approximate Newton steps the beginning but achieves fast convergence the end Experiments show that faster than the commonly used quasi Newton approach for logistic regression also compare with linear SVM implementations 
2733 en Large scale RLSC Learning Without Agony The advances kernel based learning necessitate the study solving large scale non sparse positive definite linear system provide deterministic approach recent researches focus designing fast matrixvector multiplication techniques coupled with conjugate gradient method Instead using the conjugate gradient method our paper proposes use domain decomposition approach solving such linear system Its convergence property and speed can understood within von Neumann alternating pro jection framework will report significant and consistent improvements convergence speed over the conjugate gradient method when the approach applied recent machine learning problems 
2734 en Unsupervised Prediction Citation Influences Publication repositories contain abundance information about the evolution scientific research areas address the problem creating visualization research area that describes the flow topics between papers quantifies the impact that papers have each other and helps identify key contributions this end devise probabilistic topic model that explains the generation documents the model incorporates the aspects topical innovation and topical inheritance via citations evaluate the model ability predict the strength influence citations against manually rated citations 
2735 en Three New Graphical Models for Statistical Language Modelling The supremacy gram models statistical language modelling has recently been challenged parametric models that use distributed representations counteract the difficulties caused data sparsity propose three new probabilistic language models that define the distribution the next word sequence given several preceding words using distributed representations those words show how real valued distributed representations for words can learned the same time learning large set stochastic binary hidden features that are used predict the distributed representation the next word from previous distributed representations Adding connections from the previous states the binary hidden features improves performance does adding direct connections between the real valued distributed representations One our models significantly outperforms the very best ngram models 
2736 en Mixtures Hierarchical Topics with Pachinko Allo cation The four level pachinko location model PAM McCallum 2006 represents correlations among topics using DAG structure does not however represent nested hierarchy topics with some topical word distributions representing the vocabulary that shared among several more specific topics This paper presents hierarchical PAM enhancement that explicitly represents topic hierarchy This model can seen combining the advantages hLD topical hierarchy representation with PAM ability mix multiple leaves the topic hierarchy Experimental results show improvements likelihood held out documents well mutual information between automatically discovered topics and humangenerated categories such journals 
2737 en Unsupervised Estimation for Noisy Channel Models Shannonâ€™ Noisy Channel model which describes how corrupted message might reconstructed has been the corner stone for much work statistical language and speech processing The model factors into two components language model characterize the original message and channel model describe the channelâ€™ corruptive process The standard approach for estimating the parameters the channel model unsupervised Maximum Likelihood the observation data usually approximated using the Expectation Maximization algorithm this paper show that better maximize the joint likelihood the data both ends the noisy channel derive corresponding directional algorithm and show that gives better performance than standard two tasks translation using probabilistic lexicon and adaptation part speech tagger between related languages 
2738 en Hierarchical Maximum Entropy Density Estimation study the problem simultaneously estimating several densities where the datasets are organized into overlapping groups such hierarchy For this problem propose maximum entropy formulation which systematically incorporates the groups and allows share the strength prediction across similar datasets derive general performance guarantees and show how some previous approaches such hierarchical shrinkage and hierarchical priors can derived special cases demonstrate the proposed technique synthetic data and realworld application modeling the geographic distributions species hierarchically grouped taxonomy Specifically model the geographic distributions species the Australian wet tropics and Northeast New South Wales these regions small numbers samples per species significantly hinder effective prediction Substantial benefits are obtained combining information across taxonomic groups 
2739 en Learning Combine Distances for Complex Representations The Nearest Neighbors algorithm can easily adapted classify complex objects sets graphs long proper dissimilarity function given over input space Both the representation the learning instances and the dissimilarity employed that representation should determined the basis domain knowledge However even the presence domain knowledge can far from obvious which complex representation should used which dissimilarity should applied the chosen representation this paper present framework that allows combine different complex representations given learning problem and different dissimilarities defined these representations build ideas developed previously metric learning for vectorial data demonstrate the utility our method domains which the learning instances are represented sets vectors learning how combine different set distance measures 
2740 en Non Isometric Manifold Learning Analysis and Algorithm this work take novel view nonlinear manifold learning Usually manifold learning formulated terms finding embedding unrolling manifold into lower dimensional space Instead treat the problem learning representation nonlinear possibly non isometric manifold that allows for the manipulation novel points Central this view manifold learning the concept generalization beyond the training data Drawing concepts from supervised learning establish framework for studying the problems model assessment model complexity and model selection for manifold learning present extension recent algorithm Locally Smooth Manifold Learning and show has good generalization properties learns representation manifold family related manifolds and can used for computing geodesic distances finding the projection point onto manifold recovering manifold from points corrupted noise generating novel points manifold and more 
2741 en Manifold adaptive dimension estimation Intuitively learning should easier when the data points lie low dimensional submanifold the input space Recently there has been growing interest algorithms that aim exploit such geometrical properties the data Oftentimes these algorithms require estimating the dimension the manifold first this paper propose algorithm for dimension estimation and study its finite sample behaviour The algorithm estimates the dimension locally around the data points using nearest neighbor techniques and then combines these local estimates show that the rate convergence the resulting estimate independent the dimension the input space and hence the algorithm manifold adaptive Thus when the manifold supporting the data low dimensional the algorithm can exponentially more efficient than its counterparts that are not exploiting this property Our computer experiments confirm the obtained theoretical results 
2744 en Salience Assignment for Multiple Instance Regression
2745 en Toward Learning Mixture Parts Pictorial Structures
2746 en Learning CRFs with Hierarchical Features Application 
2747 en Discriminative Graphical Models for Protein Quaternary Structure Motif Detection
2748 en Structural Prediction Statistical Alignment and Translation
2749 en Parameter Learning for Loopy Markov Random Fields with Structural Support Vector Machines
2750 en Learning Layered Graph with Maximal Number Distinct Paths Between Source and Sink
2751 en Sculpting Implants situ Light Adjustable Intraocular Lens esne leti starajo pogosto razvije esna mrena Vsako leto opravi preko milijonov operacij kjer esna mrena odstrani vsadijo umetne trenutno uveljavljenimi ami vedno tretjina pacientov esno mreno posegu potrebuje ala optimalen vid dosegli eljeni cilj brez dodatnih korekcij morale biti sposobne prilagoditve kon ani terapiji Novi materiali jih razvili Caltech titutu omogo ajo post operativne neinvazivne korekcije predavanju profesor Julia Kornfield predstavila skupne raziskave prof Bob Grubbsom Odseka kemijo esnim kirurgom prof Dan Schwartzem UCSF Skupaj razvili material omogo vivo prilagoditve Svetlobno prilagodljive izkazale uspe klini nih testih saj rezultati ponovljivi napovedljivi 
2753 en Patient Cooperative Rehabilitation Robotics Zurich
2755 en Assessment hand kinematics and its control dexterous manipulation
2756 en Grip force response graphical and haptic virtual environment
2757 en  Hierarchical SOM Identify and Recognize Objects Sequences Stereo Images
2758 en Can haptic interface used for evaluating upper limb prosthesis children and adults
2760 en Introduction and Welcome the workshop
2761 en Introduction Machine Learning This course covers feature selection fundamentals and applications The students will first reminded the basics machine learning algorithms and the problem overfitting avoidance the wrapper setting feature selection will introduced special case the model selection problem Methods derive principled feature selection algorithms will reviewed well heuristic method which work well practice One class will devoted feature construction techniques Finally lecture will devoted the connections between feature section and causal discovery The class will accompanied several lab sessions The course will attractive students who like playing with data and want learn practical data analysis techniques The instructor has ten years experience with consulting for startup companies the pattern recognition and machine learning Datasets from variety application domains will made available handwriting recognition medical diagnosis drug discovery text classification ecology marketing 
2762 en Basics algorithmics computation models formal languages Between the many theoretical computer science issues that one should ben aware when working Machine learning visit this series ofn lectures two The first corresponds strings and through the study strings then questions about more complex structures like trees and graphs describen the main algorithmic and combinatorial questions about substrings andn subsequences and concentrate our attention the topological questions ordering strings and computing distances and kernels The second complexity Not only should aware and have reasonable control the techniques involved the usual barriers butn should know something about classes for randomized algorithms alson show some examples concerning Las Vegas and Monte Carlo techniques 
2764 en Introduction CLOP Machine Learning Toolbox
2765 en Bipartite Graph Matching for Computing the Edit Distance Graphs the field structural pattern recognition graphs constitute very common and powerful way representing patterns contrast string representations graphs allow describe relational information the patterns under consideration One the main drawbacks graph representations that the computation standard graph similarity measures exponential the number involved nodes Hence such computations are feasible for rather small graphs only One the most flexible error tolerant graph similarity measures based graph edit distance this paper propose approach for the efficient compuation edit distance based bipartite graph matching means Munkres’ algorithm sometimes referred the Hungarian algorithm Our proposed algorithm runs polynomial time but provides only suboptimal edit distance results The reason for its suboptimality that implied edge operations are not considered during the process finding the optimal node assignment experiments semi artificial and real data demonstrate the speedup our proposed method over traditional tree search based algorithm for graph edit distance computation Also show that classification accuracy remains nearly unaffected 
2766 en Matching Tree Structures for Registration Medical Images Many medical applications require registration different images the same organ many cases such registration accomplished manually placing landmarks the images this paper propose method which able find reasonable landmarks automatically achieve this nodes the vessel systems which have been extracted from the images segmentation algorithm will assigned the called association graph method and the coordinates these matched nodes can used landmarks for non rigid registration algorithm 
2769 en Two two robot soccer short demo two two robotic soccer featuring the Cornell team legacy and current players robots 
2771 en Leonardo Goal assistance with divergent beliefs This demonstrates the robot Leonardo ability reason and act competently situations when the other this case human agents have different belief states 
2772 en Cosmo The lifelike pedagogical agent
2773 en Autonomous UAV capabilities This short demo summarizes the capabilities some autonomous unmanned air vehicles helos flying outdoors that not use GPS navigation techniques 
2774 en Autonomous UAV search and rescue This longer demo films the application some autonomous unmanned air vehicles helos flying outdoors for search and rescue operation 
2775 en iAQ Program that Discovers Rules This video presents entertaining program that discovers rules from data and outputs them the form English text and speech
2776 en BICA idea that can change the world This describes and demonstrates simulation the capabilities agent controlled biologically inspired cognitive architecture 
2777 en NERO Neuro Evolving Robotic Operatives This demonstrates the NERO real time strategy game and the capabilities its agents The technology involves neuroevolution 
2779 en Interactive derivation viewer This describes the IDV tool for graphically rendering derivations that are written the Thousands Problems for Theorem Provers TPTP language 
2780 en Artificial intelligence instance Aibo ingenuity This describes research related using for among other tasks learning behaviors for Aibo robot 
2781 en  nearest neighbor classification this short animated video the nearest neighbor classifier introduced with simple visuals real world application word pronunciation used exemplify how the classifier learns and classifies The video features synthesized voice over 
2782 en  service robot named Markovito This shows the Peoplebot Markovito delivers messages and objects between offices can perform speech communication face recognization global localization uses probablistic grid map and controlled Factored MDP 
2783 en Color based object recognition This demonstrates robodog that recognize objects fetch task The software runs world wide computing grid distributing the computational load over several beowolf clusters 
2784 en Power agents the Mars Desert Research Station comprehensive demonstration the agents being used the MDRS scripted with inspiration from the HAL 9000 Permission granted for additional video length although the main video ends 5min 
2786 en Motion planning multiple agents virtual environments Describes and demonstrates simulation the use coordination graphs avoid collisions multiple agents tasks requiring motion multiple agents 
2788 en Humanoids for autonomous operations The video describes Humanoid robotics project JPL claiming first practical application humanoid robotics 
2790 en Multimodal Interactive Robot Agent MIRA robot head short video demonstrating the speech communication reasoning abilities and humour MIRA 
2792 en MARQS Media album retrieval query sketch advertisement like short demo tool for retrieving photos from album sketching 
2793 en Robot Swarm localization using trilateration description and demonstration robust approach for ground robot formation movement behaviors 
2794 en Morphogenesis Shaping swarms intelligent robots Describes simulates and demonstrates hardware the utility rule based morphogenesis for shaping robot swarms For more videos pictures and information Morphogenesis and Morphology Control see the following site http iridia ulb supp IridiaSupp2007 003 index html Photos videos and information You can also download high quality version this video various formats from http iridia ulb 7Ealyhne aaai index html version the video You can check the following web sites you want know more about the robots swarm robotics and swarm intelligence http www swarmanoid com The Swarmanoid Project web page http www swarm bots org The Swarm bots Project web page Authors web pages http iridia ulb 7Ealyhne Anders Lyhne Christensen homepage http iridia ulb 7Erogrady Rehan Grady homepage http iridia ulb 7Emdorigo Marco Dorigo homepage 
2795 en Autonomous robot cleaning crew centralized collaborative planning and simulation demo for coordinating agent robot tasks 
2796 en Dance evolution The only submission from undergraduates this unique video challenges learn how dance demonstrating how neuroevolution can used interactively evolve dancing techniques 
2797 en Learning without overlearning This course covers feature selection fundamentals and applications The students will first reminded the basics machine learning algorithms and the problem overfitting avoidance the wrapper setting feature selection will introduced special case the model selection problem Methods derive principled feature selection algorithms will reviewed well heuristic method which work well practice One class will devoted feature construction techniques Finally lecture will devoted the connections between feature section and causal discovery The class will accompanied several lab sessions The course will attractive students who like playing with data and want learn practical data analysis techniques The instructor has ten years experience with consulting for startup companies the pattern recognition and machine learning Datasets from variety application domains will made available handwriting recognition medical diagnosis drug discovery text classification ecology marketing 
2798 en Introduction feature selection This course covers feature selection fundamentals and applications The students will first reminded the basics machine learning algorithms and the problem overfitting avoidance the wrapper setting feature selection will introduced special case the model selection problem Methods derive principled feature selection algorithms will reviewed well heuristic method which work well practice One class will devoted feature construction techniques Finally lecture will devoted the connections between feature section and causal discovery The class will accompanied several lab sessions The course will attractive students who like playing with data and want learn practical data analysis techniques The instructor has ten years experience with consulting for startup companies the pattern recognition and machine learning Datasets from variety application domains will made available handwriting recognition medical diagnosis drug discovery text classification ecology marketing 
2799 en Graph based Methods for Retinal Mosaicing and Vascular Characterization this paper propose highly robust point matching method Graph Transformation Matching GTM relying finding the consensus graph emerging from putative matches Such method two phased one the sense that after finding the consensus graph tries complete much possible successfully apply GTM image registration the context finding mosaics from retinal images Feature points are obtained after properly segmenting such images addition also introduce novel topological descriptor for quantifying disease characterizing the arterial venular trees Such descriptor relies diffusion kernels graphs Our experiments have showed only statistical signifficance for the case arterial trees which consistent with previous findings 
2800 en Stereo Vision for Obstacle Detection Graph Based Approach propose new approach stereo matching for obstacle detection the autonomous navigation framework accurate but slow reconstruction the scene not needed rather more important have fast localization the obstacles avoid them All the methods the literature based punctual stereo matching are ineffective realistic contexts because they are either computationally too expensive unable deal with the presence uniform patterns perturbations between the left and right images Our idea face the stereo matching problem matching between homologous regions The stereo images are represented graphs and graph matching computed find homologous regions Our method strongly robust realistic environment requires little parameter tuning and adequately fast experimentally demonstrated comparison with the best algorithms the literature 
2801 en  Continuous Based Approach for Partial Clique Enumeration many applications computer vision and pattern recog nition which use graph based knowledge representation great interest able extract the largest cliques graph but most methods are geared either towards extracting the single clique max imum size enumerating all cliques without following any particular order this paper present novel approach for partial clique enu meration that the extraction the largest cliques graph Our approach based continuous formulation the clique problem veloped Motzkin and Straus and able avoid extracting the same clique multiple times This done casting the problem into game theoretic framework and iteratively rendering unstable the solutions that have already been extracted 
2802 en  Bound for Non Subgraph Isomorphism this paper propose new lower bound subgraph isomorphism problem This bound can provide proof that subgraph isomorphism between two graphs can found The computation based the SDP relaxation – the best our knowledge – new combinatorial optimisation formulation for subgraph isomorphism consider problem instances where only the structures the two graph instances are given and therefore deal with simple graphs the first place The idea based the fact that subgraph isomorphism for such problem instances always leads lowest possible optimal objective value for our combinatorial optimisation problem formulation Therefore lower bound that larger than represents proof that subgraph isomorphism don’ exist the problem instance But note that conversely negative lower bound does not imply that subgraph isomorphism must present and only indicates that subgraph isomorphism still possible 
2803 en  Correspondence Measure for Graph Matching using the Discrete Quantum Walk this paper consider how coined quantum walks can applied graph matching problems The matching problem stracted using auxiliary graph that connects pairs vertices from the graphs matched way auxiliary vertices coined quantum walk simulated this auxiliary graph and the quantum interference the auxiliary vertices indicates possible matches When dealing with graphs for which there exact match the interference amplitudes gether with edge consistencies are used define consistency measure have tested the algorithm graphs derived from the NCI molecule database and found significantly reduce the space possible match ings thereby allowing the graphs matched directly analysis the quantum walk the presence structural errors between graphs used the basis the consistency measure test the performance this measure graphs derived from images the COIL 100 database 
2804 en Other software Weka Yale 
2805 en Feature construction This course covers feature selection fundamentals and applications The students will first reminded the basics machine learning algorithms and the problem overfitting avoidance the wrapper setting feature selection will introduced special case the model selection problem Methods derive principled feature selection algorithms will reviewed well heuristic method which work well practice One class will devoted feature construction techniques Finally lecture will devoted the connections between feature section and causal discovery The class will accompanied several lab sessions The course will attractive students who like playing with data and want learn practical data analysis techniques The instructor has ten years experience with consulting for startup companies the pattern recognition and machine learning Datasets from variety application domains will made available handwriting recognition medical diagnosis drug discovery text classification ecology marketing Play with the Gisette dataset the feature selection challenge See how with simple feature extraction methods performances can improved over the pure “agnostic” approach 
2807 en Probability Information Theory and Bayesian Inference
2808 en Embedded Methods This course covers feature selection fundamentals and applications The students will first reminded the basics machine learning algorithms and the problem overfitting avoidance the wrapper setting feature selection will introduced special case the model selection problem Methods derive principled feature selection algorithms will reviewed well heuristic method which work well practice One class will devoted feature construction techniques Finally lecture will devoted the connections between feature section and causal discovery The class will accompanied several lab sessions The course will attractive students who like playing with data and want learn practical data analysis techniques The instructor has ten years experience with consulting for startup companies the pattern recognition and machine learning Datasets from variety application domains will made available handwriting recognition medical diagnosis drug discovery text classification ecology marketing 
2809 en The algorithm and Mixtures Gaussians
2812 en PANEL Experiences research teaching and applications 
2813 en Lectures Clustering These lectures give introduction data clustering discuss few algorithms but also look theoretical questions related ton clustering The first two lectures are devoted spectral clustering graph Laplacians and their properties spectral clustering algorithms mathematical derivations the algorithms and some implementationn issues Moreover discuss the related modularity approach forn detecting communities networks The third lecture devoted ton the very general question what clustering try look atn clustering from different angles discuss different definitions ofn clustering and look into theoretical foundations clustering inn general the last lecture work the question how the numbern clusters should defined The focus two popular approaches the gap statistics and the stability approach 
2814 en Image Classification Using Marginalized Kernels for Graphs propose this article image classification technique based kernel methods and graphs Our work explores the possibility applying marginalized kernels image processing machine learning performant algorithms have been developed for data organized real valued arrays these algorithms are used for various purposes like classification regression However they are inappropriate for direct use complex data sets Our work consists two distinct parts the first one model the images graphs able represent their structural properties and inherent attributes the second one use kernel functions project the graphs mathematical space that allows the use performant classification algorithms Experiments are performed medical images acquired with various modalities and concerning erent parts the body 
2815 en Hierarchy Construction Schemes within the Scale Set Framework Segmentation algorithms based energy minimisation framework often depend scale parameter which balances fit data and regularising term Irregular pyramids are defined stack graphs successively reduced Within this framework the scale often defined implicitly the height the pyramid However each level irregular pyramid can not usually readily associated the global optimum energy global criterion the base level graph This last drawback addressed the scale set framework designed Guigues The methods designed this author allow build hierarchy and design cuts within this hierarchy which globally minimise energy This paper studies the influence the construction scheme the initial hierarchy the resulting optimal cuts propose one sequential and one parallel method with two variations within both Our sequential methods provide partitions near the global optima while parallel methods require less execution times than the sequential method Guigues even sequential machines 
2816 en Deducing Local Influence Neighbourhoods With Application Edge Preserving Image Denoising Traditional image models enforce global smoothness and more recently Markovian Field priors Unfortunately global models are inadequate represent the spatially varying nature most images which are much better modeled piecewise smooth This paper advocates the concept local influence neighbourhoods LINs The influence neighbourhood pixel defined the set neighbouring pixels which have causal influence LINs can therefore used part the prior model for Bayesian denoising deblurring and restoration Using LINs prior models can superior pixel based statistical models since they provide higher order information about the local image statistics LINs are also useful tool for higher level tasks like image segmentation propose fast graph cut based algorithm for obtaining optimal influence neighbourhoods and show how use them for local filtering operations Then present new expectation maximization algorithm perform locally optimal Bayesian denoising Our results compare favourably with existing denoising methods 
2817 en  Introduction Ensemble and Boosting
2818 en Graph Spectral Image Smoothing new method for smoothing both gray scale and color images presented that relies the heat diffusion equation graph represent the image pixel lattice using weighted undirected graph The edge weights the graph are determined the Gaussian weighted distances between local neighbouring windows then compute the associated Laplacian matrix the degree matrix minus the adjacency matrix Anisotropic diffusion across this weighted graph structure with time captured the heat equation and the solution the heat kernel found exponentiating the Laplacian eigen system with time Image smoothing accomplished convolving the heat kernel with the image and its numerical implementation realized using the Krylov subspace technique The method has the effect smoothing within regions but does not blur region boundaries also demonstrate the relationship between our method standard diffusion based PDEs Fourier domain signal processing and spectral clustering Experiments and comparisons standard images illustrate the effectiveness the method 
2819 en Probabilistic Relaxation Labeling Fokker Planck Diffusion Graph this paper develop new formulation probabilistic relaxation labeling for the task data classification using the theory diffusion processes graphs The state space our process the nodes support graph which represent potential object label assignments The edge weights the support graph encode data proximity and label consistency information The state vector the diffusion process represents the object label probabilities The state vector evolves with time according the Fokker Planck equation show how the solution state vector can estimated using the spectrum the Laplacian matrix for the weighted support graph Experiments various data clustering tasks show effectiveness our new algorithm 
2820 en  general purpose segmentation algorithm using analytically evaluated random walks ideal segmentation algorithm could applied equally the problem isolating organs medical volume editing digital photograph without modifying the algorithm changing parameters sacrificing segmentation quality However general purpose multiway segmentation objects image volume remains challenging problem this talk will describe recently developed approach this problem that inputs few training points from user from mouse clicks and produces segmentation computing the probabilities that random walker leaving unlabeled pixels voxels will first strike the training set exact mathematical equivalence with problem from potential theory these probabilities may computed analytically and deterministically The algorithm developed arbitrary weighted graph mesh order maximize the broadness application will illustrate the use this approach with examples from several segmentation problems without modifying the algorithm the single free parameter compare this algorithm other approaches and discuss the theoretical properties that describe its behavior 
2821 en Qualitative Spatial Relationships for Image Interpretation using Semantic Graph this paper new way express complex spatial relations proposed order integrate them Constraint Satisfaction Problem with bilevel constraints These constraints allow build semantic graphs which can describe more precisely the spatial relations between subparts composite object that look for image For example allows express complex spatial relations such “ surrounded ” This approach can applied image interpretation and some examples real images are presented 
2822 en Separation the Retinal Vascular Graph Arteries and Veins The vascular structure the retina consists two kinds vessels arteries and veins Together these vessels form the vascular graph this paper present approach separating arteries and veins based pre segmentation and few hand labelled vessel segments use rule based method propagate the vessel labels through the vascular graph embed this task double layered constrained search problem steered heuristical algorithm overcome the NPhard computational complexity Results are presented vascular graphs generated from hand made well automatical segmentation 
2823 en Theory and Applications Kernel Space Basics kernel definitions and theory are first given Then algorithms are described with explicit reference the representer theorem Support vector Mahcines Support Vector Regression andn Kernel Principal Components Analysis nnThe last course devoted examples kernel design Mahalanobis kernles and Fisher kernels 
2825 en Learning the topology data set
2826 en Graph Based Shapes Representation and Recognition this paper propose represent shapes graphs Based graphic primitives extracted from the binary images attributed relational graphs were generated Thus the nodes the graph represent shape primitives like vectors and quadrilaterals while arcs describing the mutual primitives relations invariant transformations such rotation and scaling relative geometric features extracted from primitives are associated nodes and edges attributes Concerning graph matching due the fact completeness graph subgraph isomorphism considerable attention given different strategies inexact graph matching also present new scoring function compute similarity score between two graphs using the numerical values associated the nodes and edges the graphs The adaptation greedy graph matching algorithm with the new scoring function demonstrates significant performance improvements over traditional exhaustive searches graph matching 
2827 en System for extracting data facts from large amount unstructured documents
2828 en Comparing Sets Digital Shapes through Topological Structures New technologies for shape acquisition and rendering digital shapes have simplified the process creating virtual scenes nonetheless shape annotation recognition and manipulation both the complete virtual scenes and even subparts them are still open problems Once the main components virtual scene are represented structural descriptions this paper deals with the problem comparing two more sets objects where each model represented attributed graph will define new distance estimate the possible similarities among the sets graphs and will validate our work using shape graph 
2829 en  Quadratic Programming Approach the Graph Edit Distance Problem this paper propose quadratic programming approach computing the edit distance graphs Whereas the standard edit distance defined with respect minimum cost edit path between graphs introduce the notion fuzzy edit paths between graphs and provide quadratic programming formulation for the minimization fuzzy edit costs Experiments real world graph data demonstrate that our proposed method able outperform the standard edit distance method terms recognition accuracy two out three data sets 
2830 en Graph Based Perceptual Segmentation Stereo Vision Images Multiple Abstraction Levels This paper presents new technique based perceptual information for the robust segmentation noisy scenes acquired stereo vision low pass geometric ¯lter ¯rst applied the given cloud points remove noise The tensor voting algorithm then applied order extract perceptual geometric information Finally graph based segmenter utilized for extracting the ®erent geometric structures present the scene through region growing procedure that applied hierarchically The proposed algorithm evaluated real scenes acquired with trinocular camera 
2831 en Morphological Operators for Flooding Leveling and Filtering Images Using Graphs define morphological operators weighted graphs order speed image transformations such floodings levelings and waterfall hierarchies The image represented its region adjacency graph which the nodes represent the catchment basins the image and the edges link neighboring regions The weights the nodes represent the level flooding each catchment basin the weights the edges represent the altitudes the pass points between adjacent regions 
2832 en Graph Based Multilevel Temporal Segmentation Scripted Content Videos This paper concentrates graph based multilevel temporal segmentation method for scripted content videos each level the segmentation similarity matrix frame strings which are series consecutive video frames constructed using temporal and spatial contents frame strings strength factor estimated for each frame string using priori information scripted content According the similarity matrix reevaluated from strength function derived the strength factors weighted undirected graph structure implemented The graph partitioned clusters which represent segments video The resulting structure defines hierarchically segmented video tree Comparative performance results different types scripted content videos are demonstrated 
2833 en Assessing the Performance Graph based Clustering Algorithm Graph based clustering algorithms are particularly suited for dealing with data that not come from Gaussian spherical distribution They can used for detecting clusters any size and shape without the need specifying the actual number clusters moreover they can profitably used cluster detection problems this paper propose detailed performance evaluation four different graph based clustering approaches Three the algorithms selected for comparison have been chosen from the literature While these algorithms not require the setting the number clusters they need however some parameters provided the user the fourth algorithm under comparison propose this paper approach that overcomes this limitation proving effective solution real applications where completely unsupervised method desirable 
2834 en  Fast Construction the Distance Graph Used for the Classification has been demonstrated that the diffcult problem classifying heterogeneous projection images similar those found electron microscopy macromolecules can successfully solved finding approximate Max Cut appropriately constructed weighted graph Despite the large size thousands nodes the graph and the theoretical computational complexity finding even approximate Max Cut algorithm has been proposed that finds good from the classification perspective approximate solution within several minutes running standard However the task constructing the complete weighted graph that represents instance the projection image classification problems computationally expensive Due the large number edges the computation edge weights can take tens hours for graphs containing several thousand nodes propose method which utilizes early termination technique significantly reduce the computational cost constructing such graphs compare synthetic data sets that resemble projection sets encountered the performance our method with that brute force approach and method based nearest neighbor search 
2835 en  the Relation Between the Median and the Maximum Common Subgraph Set Graphs Given set elements the median can useful concept get representative that captures the global information the set the domain structural pattern recognition the median set graphs has also been defined and some properties have been derived addition the maximum common subgraph set graphs well known concept that has various applications pattern recognition The computation both the median and the maximum common subgraph are highly complex tasks Therefore for practical reasons some strategies are used reduce the search space and obtain approximate solutions for the median graph The bounds the sum distances the median graph all the graphs the set turns out useful the definition such strategies this paper reduce the upper bound the sum distances the median graph and relate the maximum common subgraph 
2836 en Generalized Set Median String for Histogram Based Distances Algorithms and Classification Results the Image Domain compare different statistical characterizations set strings for three different histogram based distances Given distance set strings may characterized its generalized median the string —over the set all possible strings— that minimizes the sum distances every string the set its set median the string the set that minimizes the sum distances every other string the set For the first two histogram based distances show that the generalized median string can computed efficiently for the third one which biased histograms with individual substitution costs conjecture that this hard problem and introduce two different heuristic algorithms for approximating experimentally compare the relevance the three histogram based distances and the different statistical characterizations sets strings for classifying images that are represented strings 
2837 en Constellations and the Graph Embedding using Quantum Commute Times this paper explore analytically and experimentally the commute time the continuous time quantum walk For the classical random walk the commute time has been shown robust errors edge weight structure and lead spectral clustering algorithms with improved performance Our analysis shows that the commute time the continuous time quantum walk can determined via integrals the Laplacian spectrum calculated using Gauss Laguerre quadrature analyse the quantum commute times with reference their classical counterpart Experimentally show that the quantum commute times can used emphasise cluster structure 
2838 en Constellations and the Unsupervised Learning Graphs this paper propose novel method for the unsupervised clustering graphs the context the constellation approach object recognition Such method central clustering algorithm which builds prototypical graphs the basis fast matching with graph transformations Our experiments both with random graphs and realistic situations visual localization show that our prototypes improve the set median graphs and also the prototypes derived from our previous incremental method also discuss how the method scales with growing number images 
2839 en Graph Embedding Vector Spaces Means Prototype Selection The field statistical pattern recognition characterized the use feature vectors for pattern representation while strings more generally graphs are prevailing structural pattern recognition this paper aim bridging the gap between the domain feature based and graph based object representation propose general approach for transforming graphs into dimensional real vector spaces means prototype selection and graph edit distance computation This method establishes the access the wide range procedures based feature vectors without loosing the representational power graphs Through various experimental results show that the proposed method using graph embedding and classification vector space outperforms the tradional approach based nearest neighbor classification the graph domain 
2840 en Grouping Using Factor Graphs Approach for Finding Text with Camera Phone introduce new framework for feature grouping based factor graphs which are graphical models that encode interactions among arbitrary numbers random variables The ability factor graphs express interactions higher than pairwise order the highest order encountered most graphical models used computer vision useful for modeling variety pattern recognition problems particular show how this property makes factor graphs natural framework for performing grouping and segmentation which apply the problem finding text natural scenes demonstrate implementation our factor graph based algorithm for finding text Nokia camera phone which intended for eventual use camera phone system that finds and reads text such street signs natural environments for blind users 
2841 en Graph kernels and applications chemoinformatics Several problems chemistry can formulated classification regression problems over molecules which when represented their planar structure can seen labeled graphs Several approaches have been proposed recently define positive definite kernels over labeled graphs paving the way the use powerful kernel methods chemoinformatics this talk will review some these approaches and present relevant applications computational chemistry 
2842 en  Efficient Ontology Based Expert Peering System This paper proposes novel expert peering system for information exchange Our objective develop real time search engine for online community where users can query experts who are simply other participating users knowledgeable that area for help various topics consider graph based scheme consisting ontology tree where each node represents sub topic Consequently the fields expertise profiles the participating experts correspond subtrees this ontology Since user queries can also mapped similar tree structures assigning queries relevant experts becomes problem graph matching serialization the ontology tree allows use simple dot products the ontology vector space effectively address this problem demonstrative example conduct extensive experiments with different parameterizations observe that our approach efficient and yields promising results 
2843 en Computing Homology Group Generators Images Using Irregular Graph Pyramids introduce method for computing homology groups and their generators image using hierarchical structure irregular graph pyramid Starting from image hierarchy the image built two operations that preserve homology each region Instead computing homology generators the base where the number entities cells large first reduce the number cells graph pyramid Then homology generators are computed efficiently the top level the pyramid since the number cells small and top down process then used deduce homology generators any level the pyramid including the base level the initial image show that the new method produces valid homology generators and present some experimental results 
2844 en Approximating TSP Solution MST based Graph Pyramid The traveling salesperson problem TSP difficult solve for input instances with large number cities Instead finding the solution input with large number cities the problem approximated into simpler form containing smaller number cities which then solved optimally Graph pyramid solution strategies bottom manner using Boruvka’ minimum spanning tree convert Euclidean TSP problem with large number cities into successively smaller problems graphs with similar layout and solution until the number cities small enough seek the optimal solution Expanding this tour solution top down manner the lower levels the pyramid approximates the solution The new model has adaptive spatial structure and simulates visual acuity and visual attention The model solves the TSP problem sequentially moving attention from city city with the same quality humans Graph pyramid data structures and processing strategies are plausible model for finding near optimal solutions for computationally hard pattern recognition problems 
2845 en The Construction Bounded Irregular Pyramids with Union Find Decimation Process The Bounded Irregular Pyramid BIP mixture regular and irregular pyramids whose goal combine their advantages Thus its data structure combines regular decimation process with union find strategy build the successive levels the structure The irregular part the BIP allows solve the main problems regular structures their inability preserve connectivity represent elongated objects the other hand the BIP computationally efficient because its height constrained its regular part this paper the features the Bounded Irregular Pyramid are discussed presenting comparison with the main pyramids present the literature when applied colour segmentation task 
2846 en Extending the Notion Models for Integer Homology Computation When the ground ring field the notion algebraic topological model model useful tool for computing homology representative cycles homology generators and the cup product cohomology digital images well for controlling topological information when the image suffers local changes this paper formalize the notion lambda model lambda being integer which extends the one model and allows the computation homological information the integer domain without computing the Smith Normal Form the boundary matrices present algorithm for computing such model obtaining Betti numbers the prime numbers involved the invariant factors corresponding the torsion subgroup the homology the amount invariant factors that are power and set representative cycles the generators homology mod for such 
2847 en  Bioinformatics After brief introduction the use machine learning computational biology focus the problem biological networks inference define the problem problem kernel learning using prediction kernelized output spaces Methods based Output kernel Tree are presented solve the problem Results two benchmarks are shown 
2853 en Mining Frequent Closed Unordered Trees Through Natural Representations
2854 en Learning with spectral representations and use MDL principles
2855 en Characterizing Implications Injective Partial Orders
2856 en Genetic Approximate Matching Attributed Relational Graphs
2857 en Molecular Graph Kernels for Drug Discovery
2858 en Graphs Regularization for Data Sets and Images Filtering and Semi Supervised Classification
2859 en Graph Signature Simple Approach for Clustering Similar Graph
2860 en Szemerédi Regularity Lemma and PairwiseClustering
2861 en Web People Search Disambiguation using Random Walks
2864 en From Knowledge based Systems Skill based Systems Sailing Machine Learning Challenge
2865 en  Simple Algorithm for Topic Identification Data
2866 en Image Registration for Medical Diagnosis and Intervention
2867 en Information Technology Solutions for Diabetes Management and Prevention Current Challenges and Future Research directions
2868 en Ambulatory blood pressure monitoring highly sensitive for detection early cardiovascular rsk factors young adults
2869 en Development Implantable SAW Probe for Epilepsy Prediction
2870 en Evaluation non invasive blood pressure simulators
2871 en Wearable Wireless Biopotential Electrode for ECG Monitoring
2872 en The Education and Training the Medical Physicist Europe The European Federation Organisations for Medical Physics EFOMP Policy Statements and Efforts
2874 en Presentation Cochlear Implant Deaf People
2875 en Electrically Elicited Stapedius Muscle Reflex Cochlear Implant System fitting
2876 en Use rapid prototyping technology comprehensive rehabilitation patient with congenital facial deformity partial finger hand amputation
2877 en Experimental evaluation training device for upper extremities sensory motor ability augmentation
2878 en New Experimental Results Assessing and Rehabilitating the Upper Limb Function Means the Grip Force Tracking Method
2879 en Using computer vision rehabilitation method human hand
2880 en Assessment system developed for virtual teaching
2882 en From Academy Industry Translational Research Biophysics
2883 en Bases and rationale the electrochemotherapy
2886 en Standard versus optimized MRI based planning for uterine cervix cancer brachyradiotherapy – The Ljubljana experience
2887 en Problems faced after the transition from film DDR Radiology Department
2888 en Verification planned relative dose distribution for irradiation treatment technique using half beams the area field abutment
2889 en Scattered radiation spectrum analysis for the breast cancer diagnostics
2890 en EMITEL Encyclopedia for Medical Imaging Technology
2891 en Laminar Axially Directed Blood Flow Promotes Blood Clot Dissolution Mathematical Modeling Verified Microscopy
2892 en Ten problems for the next years
2893 en The next years ILP
2894 en SRL The next decade
2895 en Reunited the splinter groups into one big relevanr force
2897 en Statistical Predicate Invention propose statistical predicate invention key problem for statistical relational learning SPI the problem discovering new concepts properties and relations structured data and generalizes hidden variable discovery statistical models and predicate invention ILP propose initial model for SPI based second order Markov logic which predicates well arguments can variables and the domain discourse not fully known advance Our approach iteratively refines clusters symbols based the clusters symbols they appear atoms with clusters relations the clusters the jects they relate Since different clusterings are better for predicting different subsets the atoms allow multiple cross cutting clusterings show that this approach outperforms Markov logic structure learning and the recently introduced infinite relational model number relational datasets 
2898 en Adaptive Dimension Reduction Using Discriminant Analysis and means Clustering Regularized Kernel Discriminant Analysis RKDA performs linear discriminant analysis the feature space via the kernel trick The performance RKDA depends the selection kernels this paper consider the problem learning optimal kernel over convex set kernels show that the kernel learning problem can formulated semidefinite program SDP the binary class case further extend the SDP formulation the multi class case based key result established this paper that the multi class kernel learning problem can decomposed into set binary class kernel learning problems addition propose approximation scheme reduce the computational complexity the multi class SDP formulation The performance RKDA also depends the value the regularization parameter show that this value can learned automatically the framework Experimental results benchmark data sets demonstrate the efficacy the proposed SDP formulations 
2899 en Optimal Dimensionality Metric Space for Classification For large scale classification problems the training samples can clustered beforehand downsampling pre process and then only the obtained clusters are used for training Motivated such assumption proposed classification algorithm Support Cluster Machine SCM within the learning framework introduced Vapnik For the SCM compatible kernel adopted such that similarity measure can handled not only between clusters the training phase but also between cluster and vector the testing phase also proved that the SCM general extension the SVM with the RBF kernel The experimental results confirm that the SCM very effective for largescale classification problems due significantly reduced computational costs for both training and testing and comparable classification accuracies product provides promising approach dealing with privacy preserving data mining problems 
2900 en Learning for Efficient Retrieval Structured Data with Noisy Queries Increasingly large collections structured data necessitate the development efficient noise tolerant retrieval tools this work consider this issue and describe approach learn similarity function that not only accurate but that also increases the effectiveness retrieval data structures present algorithm that uses functional gradient boosting maximize both retrieval accuracy and the retrieval efficiency vantage point trees demonstrate the effectiveness our approach two datasets including moderately sized real world dataset folk music 
2903 en Robust Non linear Dimensionality Reduction using Successive Dimensional Laplacian Eigenmapse Non linear dimensionality reduction noisy data challenging problem encountered variety data analysis applications Recent results the literature show that spectral decomposition used for example the Laplacian Eigenmaps algorithm provides powerful tool for non linear dimensionality reduction and manifold learning this paper discuss significant shortcoming these approaches which refer the repeated eigendirections problem propose novel approach that combines successive 1dimensional spectral embeddings with data advection scheme that allows address this problem The proposed method does not depend non linear optimization scheme hence not prone local minima Experiments with artificial and real data illustrate the advantages the proposed method over existing approaches also demonstrate that the approach capable correctly learning manifolds corrupted significant amounts noise 
2905 en Stability for selecting the number clusters literature review questions and ideas
2907 en  formal analysis stability lessons and open questions
2909 en  statistical model cluster stability
2910 en Cluster Stability Analysis Based the Assessment Individual Clusters
2913 en Graph mincut transductive inference and spectral clustering some new elements
2925 en Druga Godba Festival performance the tango quintet Astorpia recent times Slovene musicians have been busy proving that they can successfully test themselves against virtually any style music traditional classical For several years now tango has been part everyday life here and its popularity keeps growing This new tight and well honed ensemble most whose members have classical music training can undoubtedly contribute greatly increasing the popularity tango Slovenia still further but they also offer much more than just reinterpretations the old Argentinian standards Since the name Astorpia itself alludes one the most important new tango artists Astor Piazzolla should come surprise that find five his compositions their first album MAR DEL PLATA among them Libertango and Invierno Porteno which have already become classics and make part cycle dedicated the four seasons addition these pieces which Astorpia manage imbue with renewed vigour and freshness their repertoire includes compositions number other artists They are not averse playing wittily with the established rhythms tango not even placing them Balkan context similar way composer Milos Simic one their songs the group take different direction entirely with fiery Czardas Viva Tango 
2930 en The Centibots 100 Robot Project The Centibots system was multi robotic system developed part SRI Its team 100 small robots were built from off the shelf components This video describes the distributed robot control software and subsequent demonstration 
2931 en How say robot This describes integrated robotic system for spatial understanding and situated interaction indoor environments Robot communication performed using only natural language but sometimes needs more than natural language understand 
2933 en Statistical Modeling Relational Data KDD has traditionally been concerned with mining data from single relation However most applications involve multiple interacting relations either explicitly relational databases implicitly semi structured and multimodal data Examples include link analysis social networks bioinformatics information extraction security ubiquitous computing etc Mining such data has become topic keen interest the KDD community recent years The key difficulty that data relational domains longer independent and identically distributed greatly complicating statistical modeling However research has now advanced the point where robust easy use general purpose techniques and languages for mining non data are available The goal this tutorial add sufficient subset these concepts and techniques the toolkits both researchers and practitioners 
2934 en Text Mining and Link Analysis for Web and Semantic Web The tutorial Text Mining and Link Analysis for Web Data will focus two main analytical approaches when analyzing web data text mining and link analysis for the purpose analyzing web documents and their linkage First the tutorial will cover some basic steps and problems when dealing with the textual and network graph data showing what possible achieve without very sophisticated technology The idea this first part present the nature structured and semi structured data Next the second part more sophisticated methods for solving more difficult and challenging problems will shown the last part some the current open research issues will presented and some practical pointers the available tolls for solving previously mentioned problems will provided 
2936 en Learning Bayesian Networks Bayesian networks are graphical structures for representing the probabilistic relationships among large number variables and doing probabilistic inference with those variables The 1990 saw the emergence excellent algorithms for learning Bayesian networks from passive data will discuss the constraint based learning method using intuitive approach that concentrates causal learning Then will discuss the Bayesian approach with some simple examples will show how using the Bayesian approach can even learning something about causal influences from passive data two variables Finally will show some applications finance and marketing 
2942 en Challenges Social Network Data Processes Privacy and Paradoxes The proliferation rich social media line communities and collectively produced knowledge resources has accelerated the convergence technological and social networks producing environments that reflect both the architecture the underlying information systems and the social structure their members studying the consequences these developments are faced with the opportunity analyze social network data unprecedented levels scale and temporal resolution this has led growing body research the intersection the computing and social sciences you have question for this lecturer 160 the KDD 2007 nbsp encourage you start debate comment each lecturers video send email and will ask them for you Disclamer Videolectures Net emphasises that the quality this video was notably improved because low light quality conditions provided the lecture auditorium 
2943 en From Mining the Web Inventing the New Sciences Underlying the Internet the Internet continues change the way live find information communicate and business has also been taking dramatically increasing role marketing and advertising Unlike any prior mass medium the Internet unique medium when comes interactivity and offers ability target and program messaging the individual level Coupled with its uniqueness the richness the data that available for measurability the variety ways utilize the data and the great dependence effective marketing applications that are heavily data driven makes data mining and statistical data analysis modeling and reporting essential mission critical part running the line business 
2944 en Calculating Latent Demand the Long Tail analytical framework for using powerlaw theory estimate market size for niche products and consumer groups the author New York Times bestselling book The Long Tail Why the Future Business Selling Less More which published 2006 and runs blog the subject longtail com 2007 was named one the “Time 100 ” the newsmagazine’ list the 100 men and women whose power talent moral example transforming the world http wikipedia org wiki Chris Anderson 28writer Chris Anderson Wikipedia article 
2945 en Information Genealogy Uncovering the Flow Ideas Non Hyperlinked Document Databases now have incrementally grown databases text documents ranging back for over decade areas ranging from personal email news articles and conference proceedings While accessing individual documents easy methods for overviewing and understanding these collections whole are lacking number and scope this paper address one such global analysis task namely the problem automatically uncovering how ideas spread through the collection over time refer this problem Information Genealogy contrast bibliometric methods that are limited collections with explicit citation structure investigate content based methods requiring only the text and timestamps the documents particular propose language modeling approach and likelihood ratio test detect influence between documents statistically well founded way Furthermore show how this method can used infer citation graphs and identify the most influential documents the collection Experiments the NIPS conference proceedings and the Physics ArXiv show that our method more effective than methods based document similarity 
2946 en Upping the Baseline for High Precision Text Classifiers Many important application areas text classifiers demand high precision and common compare prospective solutions the performance Naive Bayes This baseline usually easy improve upon but this work demonstrate that appropriate document representation can make outperforming this classifier much more challenging Most importantly provide link between Naive Bayes and the logarithmic opinion pooling the mixture experts framework which dictates particular type document length normalization Motivated document specific feature selection propose monotonic constraints document term weighting which shown effective method fine tuning document representation The discussion supported experiments using three large email corpora corresponding the problem spam detection where high precision particular importance 
2947 en From Trees Forests and Rule Sets Unified Overview Ensemble Methods Ensemble methods are one the most influential developments Machine Learning over the past decade They perform extremely well variety problem domains have desirable statistical properties and scale well computationally combining competing models into committee they can strengthen “weak” learning procedures This tutorial explains two recent developments with ensemble methods Importance Sampling reveals “classic” ensemble methods bagging random forests and boosting special cases single algorithm This unified view clarifies the properties these methods and suggests ways improve their accuracy and speed Rule Ensembles are linear rule models derived from decision tree ensembles While maintaining and often improving the accuracy the tree ensemble the rule based model much more interpretable nnThis tutorial aimed both novice and advanced data mining researchers and practitioners especially Engineering Statistics and Computer Science Users with little exposure ensemble methods will gain clear overview each method Advanced practitioners already employing ensembles will gain insight into this breakthrough way create next generation models John Elder lecture Nutshell Examples Timelinen Predictive Learning Decision Treesnn Giovanni Seni lecture Model Selection Bias Variance Tradeoff Regularization via shrinkage Ensemble Learning Importance Sampling ISLE Generic Ensemble Generationn Bagging Random Forest AdaBoost MARTn Rule Ensemblesn Interpretation
2948 en Fast Direction Aware Proximity for Graph Mining this paper study asymmetric proximity measures directed graphs which quantify the relationships between two nodes two groups nodes The measures are useful several graph mining tasks including clustering link prediction and connection subgraph discovery Our proximity measure based the concept escape probability This way strive summarize the multiple facets nodes proximity while avoiding some the pitfalls which alternative proximity measures are susceptible unique feature the measures accounting for the underlying directional information put special emphasis computational efficiency and develop fast solutions that are applicable several settings Our experimental study shows the usefulness our proposed direction aware proximity method for several applications and that our algorithms achieve significant speedup 000x over straightforward implementations 
2949 en Correlation Search Graph Databases Correlation mining has gained great success many application domains for its ability capture the underlying dependency between objects However the research correlation mining from graph databases still lacking despite the fact that graph data especially various scientific domains proliferate recent years this paper propose new problem correlation mining from graph databases called Correlated Graph Search CGS CGS adopts Pearson’ correlation coefficient correlation measure take into consideration the occurrence distributions graphs However the problem poses significant challenges since every subgraph graph the database candidate but the number subgraphs exponential derive two necessary conditions which set bounds the occurrence probability candidate the database With this result design efficient algorithm that operates much smaller projected database and thus are able obtain significantly smaller set candidates further improve the efficiency develop three heuristic rules and apply them the candidate set further reduce the search space Our extensive experiments demonstrate the effectiveness our method candidate reduction The results also justify the efficiency our algorithm mining correlations from large real and synthetic datasets 
2950 en  Framework For Community Identification Dynamic Social Networks propose frameworks and algorithms for identifying communities social networks that change over time Communities are intuitively characterized “unusually densely knit” subsets social network This notion becomes more problematic the social interactions change over time Aggregating social networks over time can radically misrepresent the existing and changing community structure Instead propose optimization based approach for modeling dynamic community structure prove that finding the most explanatory community structure hard and APX hard and propose algorithms based dynamic programming exhaustive search maximum matching and greedy heuristics demonstrate empirically that the heuristics trace developments community structure accurately for several synthetic and real world examples 
2951 en Fast Best Effort Pattern Matching Large Attributed Graphs focus large graphs where nodes have attributes such social network where the nodes are labelled with each person’ job title such setting want find subgraphs that match user query pattern For example ‘star’ query would “find CEO who has strong interactions with Manager Lawyer and Accountant another structure close that possible” Similarly ‘loop’ query could help spot money laundering ring Traditional SQL based methods well more recent graph indexing methods will return answer when exact match does not exist Our method can find exact well near matches and will present them the user our proposed ‘goodness’ order For example our method tolerates indirect paths between say the ‘CEO’ and the ‘Accountant’ the above sample query when direct paths not exist Its second feature scalability general the query has nodes and the data graph has nodes the problem needs polynomial time complexity nnq which prohibitive Our Ray “Graph Ray” method finds high quality subgraphs time linear the size the data graph Experimental results the DLBP author publication graph with 356K nodes and edges illustrate both the effectiveness and scalability our approach The results agree with our intuition and the speed excellent takes seconds average for node query the DBLP graph 
2952 en Support Feature Machine for Classification Abnormal Brain Activity this study novel multidimensional time series classification technique namely support feature machine SFM proposed SFM inspired the optimization model support vector machine and the nearest neighbor rule incorporate both spatial and temporal the multi dimensional time series data This paper also describes application SFM for detecting abnormal brain activity Epilepsy case point this study epilepsy studies electroencephalograms EEGs acquired multidimensional time series format have been traditionally used gold standard tool for capturing the electrical changes the brain From multi dimensional EEG time series data SFM was used identify seizure pre cursors and detect seizure susceptibility pre seizure periods The empirical results showed that SFM achieved over correct classification per seizure EEG average patients using fold cross validation The proposed optimization model SFM very compact and scalable and can implemented online algorithm The outcome this study suggests that possible construct computerized algorithm used detect seizure pre cursors and warn impending seizures through EEG classification 
2954 en Automatic Labeling Multinomial Topic Models Multinomial distributions over words are frequently used model topics text collections common major challenge applying all such topic models any text mining problem label multinomial topic model accurately that user can interpret the discovered topic far such labels have been generated manually subjective way this paper propose probabilistic approaches automatically labeling multinomial topic models objective way cast this labeling problem optimization problem involving minimizing Kullback Leibler divergence between word distributions and maximizing mutual information between label and topic model Experiments with user study have been done two text data sets with different genres The results show that the proposed labeling methods are quite effective generate labels that are meaningful and useful for interpreting the discovered topic models Our methods are general and can applied labeling topics learned through all kinds topic models such PLSA LDA and their variations 
2955 en Mining Statistically Important Equivalence Classes The support condence framework the most common measure used itemset mining algorithms for its antimonotonicity that efectively simplifies the search lattice This computational convenience brings both quality and statistical laws the results observed many previous studies this paper introduce novel algorithm that produces itemsets with ranked statistical merits under sophisticated test statistics such chi square risk ratio odds ratio etc Our algorithm based the concept equivalence classes equivalence class set frequent itemsets that always occur together the same set transactions Therefore itemsets within equivalence class all share the same level statistical signifiance regardless the variety test statistics equivalence class can uniquely determined and concisely represented closed pattern and set generators just mine closed patterns and generators taking simultaneous depth first search scheme This parallel approach has not been exploited any prior work evaluate our algorithm two aspects general compare LCM and FPclose which are the best algorithms tailored for mining only closed patterns particular compare epMiner which the most recent algorithm for mining type relative risk patterns known minimal emerging patterns Experimental results show that our algorithm faster than all them sometimes even multiple orders magnitude faster These statistically ranked patterns and the eficiency have high potential for real life applications especially biomedical and nancial fields where classical test statistics are dominant interest 
2956 en Local Decomposition for Rare Class Analysis Given its importance the problem predicting rare classes large scale multi labeled data sets has attracted great attentions the literature However the rare class problem remains critical challenge because there natural way developed for handling imbalanced class distributions This paper thus fills this crucial void developing method for Classification using lOcal clusterinG COG Specifically for data set with imbalanced class distribution perform clustering within each large class and produce sub classes with relatively balanced sizes Then apply traditional supervised learning algorithms such Support Vector Machines SVMs for classification Indeed our experimental results various real world data sets show that our method produces significantly higher prediction accuracies rare classes than state the art methods Furthermore show that COG can also improve the performance traditional supervised learning algorithms data sets with balanced class distributions 
2957 en Trajectory Pattern Mining The increasing pervasiveness location acquisition technologies GPS GSM networks etc leading the collection large spatio temporal datasets and the opportunity discovering usable knowledge about movement behaviour which fosters novel applications and services this paper move towards this direction and develop extension the sequential pattern mining paradigm that analyzes the trajectories moving objects introduce trajectory patterns concise descriptions frequent behaviours terms both space the regions space visited during movements and time the duration movements this setting provide general formal statement the novel mining problem and then study several different instantiations different complexity The various approaches are then empirically evaluated over real data and synthetic benchmarks comparing their strengths and weaknesses 
2960 en Interview with Gregory Piatetsky Shapiro Gregory Piatetsky Shapiro the President http www kdnuggets com KDnuggets which provides http www kdnuggets com consulting html research and consulting services the areas data mining knowledge discovery bioinformatics and business analytics Previously led data mining and consulting groups GTE Laboratories Knowledge Stream Partners and Xchange has extensive experience developing CRM customer attrition cross sell segmentation and other models for some the leading banks insurance companies and telcos also worked clinical trial microarray and proteomic data analysis for several leading biotech and pharmaceutical companies 
2963 en  Data Miner’ Story – Getting Know the Grand Challenges
2964 en Extracting Relevant Named Entities for Automated Expense Reimbursement Expense reimbursement time consuming and labor intensive process across organizations this talk present automated expense reimbursement system developed IBM Almaden Research Center Our complete solution involves electronic document management infrastructure that provides multi channel image capture transport and storage paper documents such receipts unconstrained data mining approach extracting relevant named entities from structured document images automation manual auditing procedures using extracted metadata The main focus this presentation our approach automatically extracting important metadata once aggregate documents through such scalable infrastructure Extracting relevant named entities robustly from document images with unconstrained layouts and diverse formatting fundamental technical challenge image based data mining question answering and other information retrieval tasks many applications that require such capability applying traditional language modeling techniques the stream OCR text does not give satisfactory result due the absence linguistic contexts such language constructs and punctuation present novel approach for extracting relevant named entities from document images learning the statistical dependencies between page layout and language features collectively from the sequence geometrically decomposed regions document using discriminative conditional random fields CRFs framework integrate this named entity extraction engine into our expense reimbursement solution and evaluate the system performance large collections real world receipt images provided IBM World Wide Reimbursement Center 
2965 en Cleaning Disguised Missing Data Heuristic Approach some applications such filling customer information form the web some missing values may not explicitly represented such but instead appear potentially valid data values Such missing values are known disguised missing data which may impair the quality data analysis severely such causing significant biases and misleading results hypothesis tests correlation analysis and regressions The very limited previous studies cleaning disguised missing data use outlier mining and distribution anomaly detection They highly rely domain background knowledge specific applications and may not work well for the cases where the disguise values are inliers tackle the problem cleaning disguised missing data this paper first model the distribution disguised missing data and propose the embedded unbiased sample heuristic Then develop effective and efficient method identify the frequently used disguise values which capture the major body the disguised missing data Our method does not require any domain background knowledge find the suspicious disguise values report empirical evaluation using real data sets which shows that our method effective – the frequently used disguise values found our method match the values identified the domain experts nicely Our method also efficient and scalable for processing large data sets 
2966 en Distributed Classification Peer Peer Networks This work studies the problem distributed classification peer peer P2P networks While there has been significant amount work distributed classification most existing algorithms are not designed for P2P networks Indeed server less and router less systems P2P networks impose several challenges for distributed classification not practical have global synchronization large scale P2P networks there are frequent topology changes caused frequent failure and recovery peers and there are frequent the fly data updates each peer this paper propose ensemble paradigm for distributed classification P2P networks Under this paradigm each peer builds its local classifiers the local data and the results from all local classifiers are then combined plurality voting build local classifiers adopt the learning algorithm pasting bites generate multiple local classifiers each peer based the local data combine local results propose general form Distributed Plurality Voting DPV protocol dynamic P2P networks This protocol keeps the single site validity for dynamic networks and supports the computing modes both one shot query and continuous monitoring theoretically prove that the condition for sending messages used DPV0 locally communication optimal achieve the above properties Finally experimental results real world P2P networks show that the proposed ensemble paradigm effective even there are thousands local classifiers most cases the DPV0 algorithm local the sense that voting processed using information gathered from very small vicinity whose size independent the network size DPV0 significantly more communication efficient than existing algorithms for distributed plurality voting 
2967 en Detecting Motifs Under Uniform Scaling Time series motifs are approximately repeated patterns found within the data Such motifs have utility for many data mining algorithms including rule discovery novelty detection summarization and clustering Since the formalization the problem and the introduction efficient linear time algorithms motif discovery has been successfully applied many domains including medicine motion capture robotics and meteorology this work show that most previous applications time series motifs have been severely limited the definition’ brittleness even slight changes uniform scaling the speed which the patterns develop introduce new algorithm that allows discovery time series motifs with invariance uniform scaling and show that produces objectively superior results several important domains Apart from being more general than all other motif discovery algorithms further contribution our work that simpler than previous approaches particular have drastically reduced the number parameters that need specified 
2969 en iLink Search and Routing Social Networks Part The growth Web and fundamental theoretical breakthroughs have led avalanche interest social networks This paper focuses the problem modeling how social networks accomplish tasks through peer production style collaboration propose general interaction model for the underlying social networks and then specific model iLink for social search and message routing key contribution here the development general learning framework for making such online peer production systems work scale The iLink model has been used develop system for FAQ generation social network FAQtory and experience with its application the context full scale learning driven workflow application CALO reported also discuss methods adapting iLink technology for use military knowledge sharing portals and other message routing systems Finally the paper shows the connection iLink SQM theoretical model for social search that generalization Markov Decision Processes and the popular Pagerank model 
2970 en Practical Guide Controlled Experiments the Web Listen Your Customers not the HiPPO The web provides unprecedented opportunity evaluate ideas quickly using controlled experiments also called randomized experiments single factor factorial designs tests and their generalizations split tests Control Treatment tests and parallel flights Controlled experiments embody the best scientific design for establishing causal relationship between changes and their influence user observable behavior provide practical guide conducting online experiments where end users can help guide the development features Our experience indicates that significant learning and return investment ROI are seen when development teams listen their customers not the Highest Paid Person’ Opinion HiPPO provide several examples controlled experiments with surprising results review the important ingredients running controlled experiments and discuss their limitations both technical and organizational focus several areas that are critical experimentation including statistical power sample size and techniques for variance reduction describe common architectures for experimentation systems and analyze their advantages and disadvantages evaluate randomization and hashing techniques which show are not simple practice often assumed Controlled experiments typically generate large amounts data which can analyzed using data mining techniques gain deeper understanding the factors influencing the outcome interest leading new hypotheses and creating virtuous cycle improvements Organizations that embrace controlled experiments with clear evaluation criteria can evolve their systems with automated optimizations and real time analyses Based our extensive practical experience with multiple systems and organizations share key lessons that will help practitioners running trustworthy controlled experiments 
2971 en Relational Data Pre Processing Techniques for Improved Securities Fraud Detection Commercial datasets are often large relational and dynamic They contain many records people places things events and their interactions over time Such datasets are rarely structured appropriately for knowledge discovery and they often contain variables whose meanings change across different subsets the data describe how these challenges were addressed collaborative analysis project undertaken the University Massachusetts Amherst and the National Association Securities Dealers NASD describe several methods for data preprocessing that applied transform large dynamic and relational dataset describing nearly the entirety the securities industry and show how these methods made the dataset suitable for learning statistical relational models better utilize social structure first applied known consolidation and link formation techniques associate individuals with branch office locations addition developed innovative technique infer professional associations exploiting dynamic employment histories Finally applied normalization techniques create suitable class label that adjusts for spatial temporal and other heterogeneity within the data show how these pre processing techniques combine provide the necessary foundation for learning high performing statistical models fraudulent activity 
2972 en  Event based Framework for Characterizing the Evolutionary Behavior Interaction Graphs Interaction graphs are ubiquitous many fields such bioinformatics sociology and physical sciences There have been many studies the literature targeted studying and mining these graphs However almost all them have studied these graphs from static point view The study the evolution these graphs over time can provide tremendous insight the behavior entities communities and the flow information among them this work present event based characterization critical behavioral patterns for temporally varying interaction graphs use non overlapping snapshots interaction graphs and develop framework for capturing and identifying interesting events from them use these events characterize complex behavioral patterns individuals and communities over time demonstrate the application behavioral patterns for the purposes modeling evolution link prediction and influence maximization Finally present diffusion model for evolving networks based our framework 
2977 en Domain Constrained Semi Supervised Mining Tracking Models Sensor Networks Accurate localization mobile objects major research problem sensor networks and important data mining application Specifically the localization problem determine the location client device accurately given the radio signal strength values received the client device from multiple beacon sensors access points Conventional data mining and machine learning methods can applied solve this problem However all them require large amounts labeled training data which can quite expensive this paper propose probabilistic semi supervised learning approach reduce the calibration effort and increase the tracking accuracy Our method based semi supervised conditional random fields which can enhance the learned model from small set training data with abundant unlabeled data effectively make our method more efficient exploit Generalized algorithm coupled with domain constraints validate our method through extensive experiments real sensor network using Crossbow MICA2 sensors The results demonstrate the advantages methods compared other state the art objecttracking algorithms 
2978 en Framework for Classification and Segmentation Massive Audio Data Streams recent years the proliferation VOIP data has created number applications which desirable perform quick online classification and recognition massive voice streams Typically such applications are encountered real time intelligence and surveillance many cases the data streams can compressed format and the rate data processing can often run the rate Gigabits per second All known techniques for speaker voice analysis require the use offline training phase which the system trained with known segments speech The state the art method for text independent speaker recognition known Gaussian Mixture Modeling GMM and requires iterative Expectation Maximization Procedure for training which cannot implemented real time this paper discuss the details such online voice recognition system For this purpose use our micro clustering algorithms design concise signatures the target speakers One the surprising and insightful observations from our experiences with such system that while was originally designed only for efficiency later discovered that was also more accurate than the widely used Gaussian Mixture Model GMM This was because the conciseness the micro cluster model which made less prone over training This evidence the fact that often possible get the best both worlds and better than complex models both from efficiency and accuracy perspective 
2979 en LungCAD Clinically Approved Machine Learning System for Lung Cancer Detection present LungCAD computer aided diagnosis CAD system that employs classification algorithm for detecting solid pulmonary nodules from thorax studies briefly describe some the machine learning techniques developed overcome the real world challenges this medical domain The most significant hurdle transitioning from machine learning research prototype that performs well house dataset into clinically deployable system the requirement that the CAD system tested clinical trial describe the clinical trial which LungCAD was tested large scale multi reader multi case MRMC retrospective observational study evaluate the effect CAD clinical practice for detecting solid pulmonary nodules from thorax studies The clinical trial demonstrates that every radiologist that participated the trial had significantly greater accuracy with LungCAD both for detecting nodules and identifying potentially actionable nodules this along with other findings from the trial has resulted FDA approval for LungCAD late 2006 
2980 en Truth Discovery with Multiple Conflicting Information Providers the Web The world wide web has become the most important information source for most Unfortunately there guarantee for the correctness information the web Moreover different web sites often provide conflicting information subject such different specifications for the same product this paper propose new problem called Veracity conformity truth which studies how find true facts from large amount conflicting information many subjects that provided various web sites design general framework for the Veracity problem and invent algorithm called TruthFinder which utilizes the relationships between web sites and their information web site trustworthy provides many pieces true information and piece information likely true provided many trustworthy web sites Our experiments show that TruthFinder successfully finds true facts among conflicting information and identifies trustworthy web sites better than the popular search engines 
2981 en Detecting Changes Large Data Sets Payments Cards Data Case Study important problem data mining detecting changes large data sets Although there are variety change detection algorithms that have been developed practice can problem scale these algorithms large data sets due the heterogeneity the data this paper describe case study involving payment card data which built and monitored separate change detection model for each cell multi dimensional data cube describe system that has been operation for the past two years that builds and monitors over 000 separate baseline models and the process that used for generating and investigating alerts using these baselines 
2982 en Event Summarization for System Management system management applications overwhelming amount data are generated and collected the form temporal events While mining temporal event data discover interesting and frequent patterns has obtained rapidly increasing research efforts users the applications are overwhelmed the mining results The extracted patterns are generally large volume and hard interpret they may emphasis intricate and meaningless non experts even domain experts While traditional research efforts focus finding interesting patterns this paper take novel approach called event summarization towards the understanding the seemingly chaotic temporal data Event summarization aims providing concise interpretation the seemingly chaotic data that domain experts may take actions upon the summarized models Event summarization decomposes the temporal information into many independent subsets and finds well fitted models describe each subset 
2983 en Machine Learning for Stock Selection this paper propose new method called Prototype Ranking designed for the stock selection problem takes into account the huge size real world stock data and applies modified competitive learning technique predict the ranks stocks The primary target select the top performing stocks among many ordinary stocks designed perform the learning and testing noisy stocks sample set where the top performing stocks are usually the minority The performance evaluated trading simulation the real stock data Each week the stocks with the highest predicted ranks are chosen construct portfolio the period 1978 2004 ’ portfolio earns much higher average return well higher risk adjusted return than Cooper’ method which shows that the method leads clear profit improvement 
2984 en IMDS Intelligent Malware Detection System The proliferation malware has presented serious threat the security computer systems Traditional signature based antivirus systems fail detect polymorphic and new previously unseen malicious executables this paper resting the analysis Windows API execution sequences called files develop the Intelligent Malware Detection System IMDS using Objective Oriented Association OOA mining based classification IMDS integrated system consisting three major modules parser OOA rule generator and rule based classifier OOA Fast FPGrowth algorithm adapted efficiently generate OOA rules for classification comprehensive experimental study large collection files obtained from the anti virus laboratory King Soft Corporation performed compare various malware detection approaches Promising experimental results demonstrate that the accuracy and efficiency our IMDS system outperform popular anti virus software such Norton AntiVirus and McAfee VirusScan well previous data mining based detection systems which employed Naive Bayes Support Vector Machine SVM and Decision Tree techniques 
2985 en iLink Search and Routing Social Networks Part The growth Web and fundamental theoretical breakthroughs have led avalanche interest social networks This paper focuses the problem modeling how social networks accomplish tasks through peer production style collaboration propose general interaction model for the underlying social networks and then specific model iLink for social search and message routing key contribution here the development general learning framework for making such online peer production systems work scale The iLink model has been used develop system for FAQ generation social network FAQtory and experience with its application the context fullscale learning driven workflow application CALO reported also discuss methods adapting iLink technology for use military knowledge sharing portals and other message routing systems Finally the paper shows the connection iLink SQM theoretical model for social search that generalization Markov Decision Processes and the popular Pagerank model 
2992 en Interview with Jon Kleinberg This interview was made the KDD 2007 Conference where cought with John Kleinber who was one the invited speakers discussed his popularity Cornell University and and how students affectionately call him Rebel King how published his recent text book algorithms with coauthor Eva Tardos and what are his future plans 
2993 en Interview with Pavel Berkhin What has Pavel Berkhin say about his beginings researcher his first and last algorithm the industry and general the KDD Conference since this years chairman the event 
3000 en Hierarchical Mixture Models Probabilistic Analysis Mixture models form one the most widely used classes generative models for describing structured and clustered data this paper develop new approach for the analysis hierarchical mixture models More specifically using text clustering problem motivation describe natural generative process that creates hierarchical mixture model for the data this process adversary starts with arbitrary base distribution and then builds topic hierarchy via some evolutionary process where controls the parameters the process prove that under our assumptions given subset topics that represent generalizations one another such baseball 160 sports nbsp base for any document which was produced via some topic this hierarchy can efficiently determine the most specialized topic this subset still belongs The quality the classification independent the total number topics the hierarchy and our algorithm does not need know the total number topics advance Our approach also yields algorithm for clustering and unsupervised topical tree reconstruction validate our model showing that properties predicted our theoretical results carry over real data then apply our clustering algorithm two different datasets “ newsgroups” and snapshot abstracts arXiv categories 240 000 abstracts both cases our algorithm performs extremely well 
3001 en Information distance from question answer provide three key missing pieces general theory information distance take bold steps formulating revised theory avoid some pitfalls practical applications The new theory then used construct question answering system Extensive experiments are conducted justify the new theory 
3002 en Statistical Change Detection for Multi Dimensional Data This paper deals with detecting change distribution multi dimensional data sets For given baseline data set and set newly observed data points define statistical test called the density test for deciding the observed data points are sampled from the underlying distribution that produced the baseline data set define test statistic that strictly distribution free under the null hypothesis Our experimental results show that the density test has substantially more power than the two existing methods for multi dimensional change detection 
3003 en Learning the Kernel Matrix Discriminant Analysis via Quadratically Constrained Quadratic Programming The kernel function plays central role kernel methods this paper consider the automated learning the kernel matrix over convex combination pre specified kernel matrices Regularized Kernel Discriminant Analysis RKDA which performs linear discriminant analysis the feature space via the kernel trick Previous studies have shown that this kernel learning problem can formulated semidefinite program SDP which however computationally expensive even with the recent advances interior point methods Based the equivalence relationship between RKDA and least square problems the binary class case propose Quadratically Constrained Quadratic Programming QCQP formulation for the kernel learning problem which can solved more efficiently than SDP While most existing work kernel learning deal with binary class problems only show that our QCQP formulation can extended naturally the multi class case Experimental results both binary class and multiclass benchmark data sets show the efficacy the proposed QCQP formulations 
3008 en Scalable Look Ahead Linear Regression Trees The motivation behind Look ahead Linear Regression Trees LLRT that out all the methods proposed date there has been scalable approach exhaustively evaluate all possible models the leaf nodes order obtain optimal split Using several optimizations LLRT able generate and evaluate thousands linear regression models per second This allows for near exhaustive evaluation all possible splits node based the quality fit linear regression models the resulting branches decompose the calculation the Residual Sum Squares such way that large part pre computed The resulting method highly scalable observe obtain high predictive accuracy for problems with strong mutual dependencies between attributes report experiments with two simulated and seven real data sets 
3009 en Estimating Rates Rare Events Multiple Resolutions consider the problem estimating occurrence rates rare events for extremely sparse data using pre existing hierarchies perform inference multiple resolutions particular focus the problem estimating click rates for webpage advertisement pairs called impressions where both the pages and the ads are classified into hierarchies that capture broad contextual information different levels granularity Typically the click rates are low and the coverage the hierarchies sparse overcome these difficulties devise sampling method whereby analyze specially chosen sample pages the training set and then estimate click rates using two stage model The first stage imputes the number webpage pairs all resolutions the hierarchy adjust for the sampling bias The second stage estimates click rates all resolutions after incorporating correlations among sibling nodes through tree structured Markov model Both models are scalable and suited large scale data mining applications real world dataset consisting billion impressions demonstrate that even with negative non clicked events the training set our method can effectively discriminate extremely rare events terms 160 heir click propensity 
3010 en Predictive Discrete Latent Factor Models for Large Scale Dyadic Data propose novel statistical method predict large scale dyadic response variables the presence covariate information Our approach simultaneously incorporates the effect covariates and estimates local structure that induced interactions among the dyads through discrete latent factor model The discovered latent factors provide predictive model that both accurate and interpretable illustrate our method working framework generalized linear models which include commonly used regression techniques like linear regression logistic regression and Poisson regression special cases also provide scalable generalized based algorithms for model fitting using both hard and soft cluster assignments demonstrate the generality and efficacy our approach through large scale simulation studies and analysis datasets obtained from certain real world movie recommendation and internet advertising applications 
3011 en  Scalable Modular Convex Solver for Regularized Risk Minimization wide variety machine learning problems can described minimizing regularized risk functional with different algorithms using different notions risk and different regularizers Examples include linear Support Vector Machines SVMs Logistic Regression Conditional Random Fields CRFs and Lasso amongst others This paper describes the theory and implementation highly scalable and modular convex solver which solves all these estimation problems can parallelized cluster workstations allows for data locality and can deal with regularizers such and penalties present our solver implements different estimation problems can easily extended scales millions observations and times faster than specialized solvers for many applications The open source code freely available part the ELEFANT toolbox 
3022 en Introduction the Panel Since the 1989 workshop knowledge discovery databases the field has seen sustained growth and interest and has attained significant maturity The main objectives this panel will reflect the successes and failures the field data mining over the last eighteen years and examine what insights can take with move forward 
3023 en Successes Failures and Learning From Them abstract level the theme the field concerned with extracting actionable and interpretable knowledge from data efficient manner possible The primary purpose this panel the context this underlying theme consider the following questions What have been the major successes and breakthroughs that field can point with pride What have been the critical mistakes mis steps that have been taken along the way And finally what can hope learn from both our successes and mistakes and how can this knowledge used determine how focus our efforts the future 
3024 en Successes Failures and Learning From Them Over the last eighteen years the field knowledge discovery and data mining has matured considerably Although the field has evolved result synergistic operation among researchers databases artificial intelligence statistics and systems has maintained its own identity From single workshop 1989 the field can now lay claim least major conferences and numerous symposium devoted its central theme 
3025 en Successes Failures and Learning From Them
3026 en Successes Failures and Learning From Them Another topic interest here highlight some the classic mistakes made the field Topics interest here could range from the use non representative training data the ignorance population drift when modeling time varying data from not accounting for errors data labels the model over reliance single technique for the task hand and from asking the wrong question the context the application driver sampling without care related topic here might think about the role benchmark datasets and algorithms and reflect the general importance and requirement for repeatable and reproducible results 
3027 en Successes Failures and Learning From Them Over the last eighteen years while there have clearly been successful deployment knowledge discovery and data mining solutions there have also undoubtedly been mistakes and failures This aspect the panel discussion will examine the low lights important mistakes and failures 160 with the end goal trying learn from them 
3028 en Debate The terms success and failure often convey fuzzy semantics that are open interpretation part the discussion expected that panelists will offer their thoughts the aforementioned questions while defining their interpretation these terms the context particular domains After initial round discussions the panelists the floor will then opened interactive session with the audience Finally panelists will asked conclude their presentations with their outlook how one can learn from the successes and failures the past years and what their opinion are the critical opportunities for the field the future 
3029 en San Jose jazz festival During the day the KDD 2007 attendees were the conference rooms but night everyone was outside the streets listen jazz the San Jose Jazz Festival which celebrates bringing jazz legends Silicon Valley bringing music schools supporting local musicians promoting emerging musicians and new jazz forms
3030 en Privacy Preserving DataMining The rapid growth the Internet over the last decade has been startling However efforts track its growth have often fallen afoul bad data for instance how much traffic does the Internet now carry The problem not that the data technically hard obtain that does not exist but rather that the data not shared Obtaining overall picture requires data from multiple sources few whom are open sharing such data either because violates privacy legislation exposes business secrets The approaches used far the Internet trusted third parties data anonymization have been only partially successful and are not widely adopted The paper presents method for performing computations shared data without any participants revealing their secret data For example one can compute the sum traffic over set service providers without any service provider learning the traffic another The method simple scalable and flexible enough perform wide range valuable operations Internet data 
3031 en Winning The DARPA Grand Challenge The DARPA grand challenge technical details enabling Sebastian Thrun 160 win and introduction the next phase called The Urban Grand Challenge 
3032 en Rules Race and Mel Gibson 2006 Slavoj Zizek talking about the explicit truth rules politics Mel Gibson society race racism antisemitism lecturing and developing psychoanalysis culture and societies Public open lecture for the students the European Graduate School EGS Media and Communication Studies department program Saas Fee Switzerland Europe 2006 
3033 en Learning and Recognizing Visual Object Categories Over the past few years there has been substantial progress the development techniques for recognizing generic categories objects images such automobiles bicycles airplanes and human faces Much this progress can traced two underlying technical advances detectors for locally invariant features image and the application techniques from machine learning Despite recent successes however there are some fundamental concerns about methods that rely heavily feature detection because the local image evidence used detection decisions often highly ambiguous due the absence contextual information are taking different approach learning and recognizing visual object categories which there separate feature detection stage our approach objects are modeled local image patches with spring like connections that constrain the spatial relations between patches Such models are intuitively natural and their use dates back over years Until recently such models were largely abandoned due computational challenges that are addressed our work Our approach can used learn models from weakly labeled training data without any specification the location objects their parts The recognition accuracy for such models better than when using techniques based feature detection that encode similar forms spatial constraint 
3035 en Everything Miscellaneous David Weinberger new book covers the breakdown the established order ordering explains how methods categorization designed for physical objects fail when can instead put things multiple categoreis once and search them many ways This dry book taxonomy but has the insight and wit you expect from the author The Cluetrain Manifesto Small Pieces Loosely Joined and former writer for Woody Allen 
3036 en Human Computation Tasks like image recognition are trivial for humans but continue challenge even the most sophisticated computer programs This talk introduces paradigm for utilizing human processing power solve problems that computers cannot yet solve Traditional approaches solving such problems focus improving software advocate novel approach constructively channel human brainpower using computer games For example the ESP Game described this talk enjoyable online game many people play over hours week and when people play they help label images the Web with descriptive keywords These keywords can used significantly improve the accuracy image search People play the game not because they want help but because they enjoy describe other examples games with purpose Peekaboom which helps determine the location objects images and Verbosity which collects common sense knowledge also explain general approach for constructing games with purpose 
3037 en Reverse engineering techniques find security bugs case study the ANI Alex Sotirov vulnerability engineer determina will discuss some latest techniques reverse engineering software find vulnerabilities Particularly discuss his technique that lead him find the ANI bug critical new bug WinXP and Vista Alex will describe the tools uses for reverse engineering and show how reverse engineered ANI Bug will continue discussed Windows security mechanisms ASLR and describe how ANI exploit bypasses them 
3038 en Statistical Aspects Data Mining Stats 202 This the Google campus version Stats 202 which being taught Stanford this summer will follow the material from the Stanford class very closely That material can found http www stats202 com www stats202 com The main topics are exploring and visualizing data association analysis classification and clustering The textbook Introduction Data Mining Tan Steinbach and Kumar Googlers are welcome attend any classes which they think might interest them 
3041 en Debunking third world myths with the best stats you ever seen You never seen data presented like this With the drama and urgency sportscaster http www ted com index php speakers view Hans Rosling debunks myths about the called developing world using extraordinary animation software developed his Gapminder Foundation The Trendalyzer software recently acquired Google turns complex global trends into lively animations making decades data pop Asian countries colorful bubbles float across the grid toward better national health and wealth Animated bell curves representing national income distribution squish and flatten Rosling hands global trends life expectancy child mortality poverty rates become clear intuitive and even playful Recorded February 2006 Monterey Duration More TEDTalks http www ted com Rosling believes that making information more accessible has the potential change the quality the information itself Business Week Online 
3042 en Aesthetic Science Understanding Preferences for Color and Spatial Composition
3043 en The Implications OpenID OpenID emerging standard that provides simple decentralised authentication for the Web OpenID follows the Unix philosophy solving one small problem rather than attempting tackle the many larger challenges posed online identity This talk will explore the implications OpenID and explore the best practices required take advantage this new technology while avoiding the potential pitfalls Speaker Simon Willison consultant OpenID and client and server side Web development and creator the Django Web framework Before going frelance Simon worked Yahoo Technology Development team and prior that the Lawrence Journal World award winning local newspaper Kansas Simon maintains popular Web development weblog http simonwillison net 
3044 en The Next Fifty Years Science The scientific method which provides with many technological goodies does not resemble the science 1600 Ever since Bacon science has undergone slow evolution Landmarks the history the scientific method are the invention libraries indexes citations controlled experiments peer review placebos double blind experiments randomization and search among others the core the scientific method the structuring information the next years the technologies information and knowledge accelerate the nature the scientific process will change even more than has the last 400 years can predict what specific inventions will arise the next years but based long term trends epistemic tools believe can speculate how the scientific method itself that how know will change the next five decades 
3045 en Faith Evolution and Programming Languages Faith and evolution provide complementary and sometimes conflicting models the world and they also can model the adoption programming languages Adherents competing paradigms such functional and object oriented programming often appear motivated faith Families related languages such Java and may arise from pressures evolution designers languages adoption rates provide with scientific data but the belief that elegant designs are better matter faith This talk traces one concept second order quantification from its inception the symbolic logic Frege through the generic features introduced Java touching features faith and evolution The remarkable correspondence between natural deduction and functional programming informed the design type classes Haskell Generics Java evolved directly from Haskell type classes and are designed support evolution from legacy code generic code Links successor Haskell aimed AJAX style three tier web applications aims reconcile some the conflict between dynamic and static approaches typing 
3047 en Introduction bioinformatics will start giving general introduction into Bioinformatics including basic biology typical data types sequences structures expression data and networks and established analysis tasks the second part will discuss the problem predictive sequence analysis with Support Vector Machines SVMs will introduce series kernels suitable for different analysis tasks Furthermore will discuss the basic data structures needed for large scale learning and how combine kernels for heterogeneous data the third part will focus Hidden Markov models and discriminative alternatives like Conditional Random Fields and Hidden Markov SVMs suitable for segmentation tasks frequently appearing Bioinformatics the last part will present three applications greater detail large margin alignment algorithm computational gene finding and the identification polymorphisms from resequencing arrays 
3048 en Introduction kernel methods This lecture given Smola combined with Bernhard Schoelkopf and will encopass Part Part Part the complete lecture Part and this lecture can found here mlss07 scholkopf intkmet Bernhard Schoelkopf title 
3049 en Introduction kernel methods This lecture given Bernhard Schölkop combined with Smola and will encompass Part Part Part the complete lecture Part this lecture can found here mlss07 smola intkmet Alex Smola title 
3051 en Interview with Usama Fayyad http videolectures net usama fayyad Usama Fayyad http yhoo client shareholder com press management cfm Yahoo Chief Data Officer and Executive Vice President Research Strategic Data Solutions Usama Fayyad responsible for Yahoo overall data strategy architecting Yahoo data policies and systems prioritizing data investments and managing the Company data analytics and data processing infrastructure Here discusses son contemporary topics such academy and industry cooperation privacy policy and his beginings young researcher and his first algorithms this interview the Videolectures Net team spoke him about his starts young researcher the distinction between researchers and engeneers data mining whether felt scientific businessman was very interesting her what was his opinion privacy policy does remember his first algorithm and his message the community fundamental belief that the most elegant theoretical problems are tipically embedded the most mundane real applications you really dont have think too fancy hard all you have you have embedd yourself real problem and try solve the real problem with real constraints 
3058 en Welcome from the Program Chairs This proceedings the published record the Thirteenth ACM SIGKDD International Conference Knowledge Discovery and Data Mining KDD held San Jose California August – 2007 The KDD conference provides forum for novel research results and important applications the area data mining and knowledge discovery The vibrancy excitement and breadth the field are reflected the strong lineup research papers invited talks tutorials and workshops the conference The conference and the proceedings represent the efforts large number people would like thank the Industrial and Government Applications Track Chairs the members the Organizing Committee the members the Program Committee including the Research Track Senior Program Committee the external reviewers and the student volunteers who helped out the conference These individuals contributed many hours their time serve their scientific community and help make the conference successful would also like thank the ACM staff and the conference sponsors for their support 
3059 en ACM SIGKDD Data Mining Practice Prize Winners
3060 en Temporal Causal Modeling with Graphical Granger Methods The need for mining causality beyond mere statistical correlations for real world problems has been recognized widely Many these applications naturally involve temporal data which raises the challenge how best leverage the temporal information for causal modeling Recently graphical modeling with the concept “Granger causality” based the intuition that cause helps predict its effects the future has gained attention many domains involving time series data analysis With the surge interest model selection methodologies for regression such the Lasso practical alternatives solving structural learning graphical models the question arises whether and how combine these two notions into practically viable approach for temporal causal modeling this paper examine host related algorithms that loosely speaking fall under the category graphical Granger methods and characterize their relative performance from multiple viewpoints Our experiments show for instance that the Lasso algorithm exhibits consistent gain over the canonical pairwise graphical Granger method also characterize conditions under which these variants graphical Granger methods perform well comparison other benchmark methods Finally apply these methods real world data set involving key performance indicators corporations and present some concrete results 
3061 en Graphical models introduction directed and undirected probabilistic graphical models including inference belief propagation and the junction tree algorithm parameter learning and structure learning variational approximations and approximate inference Introduction graphical models directed undirected and factor graphs conditional independence separation plate notation Inference and propagation algorithms belief propagation factor graph propagation forward backward and Kalman smoothing the junction tree algorithm Learning parameters and structure maximum likelihood and Bayesian parameter learning for complete and incomplete data Dirichlet distributions score based structure learning Bayesian structural brief comments causality and learning undirected models Approximate Inference Laplace approximation BIC variational Bayesian variational message passing for model selection Bayesian information retrieval using sets items Bayesian Sets Applications Foundations Bayesian inference Cox Theorem Dutch Book Theorem Asymptotic consensus and certainty choosing priors limitations 
3062 en Opening the 9th Machine Learning Summer School
3063 en Lost Translation Solving biological problems with machine learning demonstrate the application machine learning methods problems from biology chemistry and pharmacy nameley the prediction protein subcellular localization prediction chromatiographic separation oligo nucleotides and the prediction percutaneous drug absorption For these examples show how translating the primary data into problem specific features essential for solving classification and regression problems 
3064 en Learning Mental Associations means build Organizational Memories Office workspace reveals collections documents structured along directories bookmarks and email folders The respective taxonomies represent conceptual implicit knowledge generated the user about his her role tasks and interests Starting from that learning methods can applied generate electronic mental models allowing understand the user image events people documents appointments etc and the associative relationships among them result workspace transformed into vivid personal memory assistant which user supported her his perspective information categorization and retrieval Moreover users may publish parts the resulting profiles signal their competences their colleagues fostering peer peer collaboration 
3065 en Kernel Methods for Dependence and Causality
3066 en Convex Optimization The lectures will provide introduction the theory and applications convex optimization The emphasis will results useful for convex modeling recognizing and formulating convex optimization problems practice The first lecture will introduce some the fundamental theory convex sets and functions lecture will discuss general properties convex optimization problems and define important standard classes linear and quadratic programming second order cone programming semidefinite programming and their applications lecture the material will illustrated with various examples 
3067 en Statistical learning theory Learning Theory Foundations and Goals Learning Bounds Ingredients and Results Implications What conclude from bounds 
3068 en Dirichlet Processes Tutorial and Practical Course The Bayesian approach allows for coherent framework for dealing with uncertainty machine learning integrating out parameters Bayesian models not suffer from overfitting thus conceivable consider models with infinite numbers parameters aka Bayesian nonparametric models example such models the Gaussian process which distribution over functions used regression and classification problems Another example the Dirichlet process which distribution over distributions Dirichlet processes are used density estimation clustering and nonparametric relaxations parametric models has been gaining popularity both the statistics and machine learning communities due its computational tractability and modelling flexibility the tutorial shall introduce Dirichlet processes and describe different representations Dirichlet processes including the Blackwell MacQueen urn scheme Chinese restaurant processes and the stick breaking construction shall also through various extensions Dirichlet processes and applications machine learning natural language processing machine vision computational biology and beyond the practical course shall describe inference algorithms for Dirichlet processes based Markov chain Monte Carlo sampling and shall implement Dirichlet process mixture model hopefully applying discovering clusters NIPS papers and authors 
3069 en Topics image and video processing
3073 en Opening The 5th International Workshop Mining and Learning with Graphs There have been several workshops mining and learning from graphs recent years such last year MLG and its forerunner MGTS workshop series Mining Graphs Trees and Sequences These were successful but were tied the conference one research community Nowadays there seems surge interest mining and learning from structured data across several communities Most researchers however only have exposure one two communities and clear understanding the relative advantages and limitations different approaches has yet emerged believe this ideal time for workshop that allows active researchers this area discuss and debate the unique challenges mining and learning from structured data The MLG 2007 workshop will thus concentrate mining and learning with structured data general and its many appearances and facets such interpretations graphs trees sequences Specifically seek invite researchers Statistical Relational Learning Kernel Methods for Structured Inputs Outputs Graph Mining Multi Relational Data Mining Inductive Logic Programming among others 
3075 en Learning and Charting Chemical Space with Strings and Graphs Challenges and Opportunities for and Machine Learning Informatics methods and computers have not yet become pervasive chemistry they have physics and biology Drawing analogies from bioinformatics key ingredients for progress chemoinformatics are the availability large annotated databases compounds and reactions data structures and algorithms efficiently search these databases and computational methods predict the physical chemical and biological properties new compounds and reactions will describe how graph based methods play key role the development large public database compounds and reactions ChemDB and the underlying algorithms and representations machine learning kernel methods predict molecular properties and the applications these methods drug screening design problems and the identification new drug leads against major disease 
3076 en ProbLog and its Application Link Mining Biological Networks ProbLog recently introduced probabilistic extension Prolog Raedt Kimmig Toivonen IJCAI ProbLog program defines distribution over logic programs specifying for each clause the probability that belongs randomly sampled program and these probabilities are mutually independent The semantics ProbLog then defined the success probability query randomly sampled program has been applied link mining and discovery large biological network the talk will also discuss various learning settings for ProbLog and link mining particular shall present techniques for probabilistic local pattern mining probabilistic explanation based learning Kimmig Raedt Toivonen ECML and theory compression from examples Raedt ILP This joint work with Angelika Kimmig Hannu Toivonen Kate Revoredo and Kristian Kersting 
3077 en Graph Identification Within the machine learning community there has been growing interest learning structured models from input data that itself structured Graph identification refers methods that transform observed input graph into inferred output graph Examples include inferring organizational hierarchies from social network data and identifying gene regulatory networks from protein protein interactions The key processes graph identification are entity resolution link prediction and collective classification will overview algorithms for these tasks and discuss the need for integrating the results solve the overall problem collectively 
3078 en Learning Graph Matching fundamental problem pattern recognition graph matching has found variety applications the field computer vision graph matching patterns are modeled graphs and pattern recognition amounts finding correspondence between the nodes different graphs There are many ways which the problem has been formulated but most can cast general quadratic assignment problem where linear term the objective function encodes node compatibility functions and quadratic term encodes edge compatibility functions The main research focus this theme about designing efficient algorithms for solving approximately the quadratic assignment problem since hard this paper turn our attention the complementary problem how estimate compatibility functions such that the solution the resulting graph matching problem best matches the expected solution that human would manually provide present method for learning graph matching the training examples are pairs graphs and the “labels” are matchings between pairs graphs present experimental results with real image data which give evidence that learning can improve the performance standard graph matching algorithms particular turns out that linear assignment with such learning scheme may improve over state the art quadratic assignment relaxations This finding suggests that for range problems where quadratic assignment was thought essential for securing good results linear assignment which far more icient could just sufficient learning performed This enables speed ups graph matching orders magnitude while retaining state the art accuracy 
3085 en Department Knowledge Technologies Core business JSI Dep research technology development and deployment state the art analytic solutions large real life scenarios 
3087 en Department Communication Systems The Department Communication Systems concerned mainly with the research development and design next generation networks and wireless access systems and the development new algorithms for parallel and distributed computing and computer simulations Other research activities include the development software tools for testing modeling and simulation communication systems provision security services communication networks digital signal processing medicine etc With its research and development activities the department has been actively involved national and international projects including Framework Programme and Structural Funds projects 
3088 en Computer Systems Department Computer Systems Department Jozef Stefan Institute concerned primarily with the design automation computing structures and systems Within this broad area are concentrating particularly metaheuristic approach engineering design and logistics problems well system design and test 
3089 en Department Intelligent Systems Development methods and techniques intelligent computer systems with applications the areas event driven security and supervisory systems for near real time and mission critical operation and network communication systems 
3090 en Welcome and Presentation Center for Knowledge Transfer Information Technologies Centre for knowledge transfer information technologies performs educational promotional and infrastructural activities and provides direct exchange information and experience between researchers and the users their research results develop and prepare carefully designed educational events such seminars workshops conferences and summer schools Because our experiences European projects have decided offer the service the industries and organizations for consulting pre evaluating and helping prepare projects proposal well support the project implementation have prepared number training web portals with more than 2700 hours recorded tutorials from different domains knowledge available http videolectures net 
3091 en IRC IRENE AREA Science Park Assistance industry particular SMEs the definition technology needs Promotion through the IRC Network innovative ideas European level Identification potential technology partners Enhance Transnational Technology Transfer Agreements Support projects under the European Research Framework Programme
3092 en active media group com srl are specialized EDI electronic data interchange online solutions with our product DERWID® are present the Italian Austrian German and Lichtenstein’ markets Extensive know how cross platform software development system integratin EDI and growing Linux market are the basis our competence Solutions provided dedicated projects well standard tools for different requirements can offered 
3093 en  Level srl Level supplier Open Source software platforms and solutions the Devil Framework for collecting integrating correlating controlling and visualizing information produced and consumed hardware and software technologies involved modern working processes 
3094 en EIDON EIDON engineering and contract research company working partnership with enterprises provide cutting edge technological support for product and process innovation Established 1979 EIDON was one the first centers Italy provide technological support services this nature The company designs and develops ICT solutions for the global automated management and control production processes including those distributed throughout the country EIDON recognised MUR Italian Ministry University and Research excellence laboratory the fields computer science and electronics 
3095 en ELIMOS srl System integrator real time Software development Digital TVCC systems and centralization ANPR system domotic
3096 en Emaze Networks Emaze Networks innovative provider services and products the Information Security field Emaze customers are Financial and Insurance institutes Industry and Services companies amp departments Telecommunication and Utility companies 
3097 en GME general micro electronics srl Gme electronic engineers have been managing electronic product design and manufacturing for big European companies since 1993 are capable developing wide range electronic products home automation zigbee lonworks konnex wireless wifi rfid with all disciplines required 
3098 en Sicom test The mission the Company perform measurements and tests concerning telecommunication mobile terminal products Sicom services are including Functional tests Quality service QoS SAR measurements Network operator acceptance Global Certification Forum tests and railways GSM tests 
3099 en  CONNECT srl Connect engaged wireless applications devices integrated with Location Based Services for the Mobile Business The company works with mobile carrier for consulting services functional and inter operability IOT testing wireless systems mobile networks and DVB 
3100 en Testability Snc Development Deployement Installation and Startup Production Testing Lines for Electronic devices and equipment Automated Test Benches Mechanical Toolings for Electronics fixtures Replicas existing Production Testing lines Technology transfer
3101 en Wego Wego works the government sector Its activities consist consulting and software development for public administration entities and especially business process and administrative proceedings engineering front end solutions development electronic document management EDM 
3102 en IRC Slovenia Stefan Institute Helping local industry specify its new technological needs technological audits and with the help IRC network trying identify partners provide these new technologies Helping local industry identify which its technologies are suitable for transfer other regions industries and promoting these innovative ideas across Europe through the Innovation Relay Centres network Providing assistance the negotiation process between the provider and the receiver the technology Advising related aspects research exploitation such patenting and licensing Informing about relevant Community and national financial support schemes for innovation 
3103 en andEuros The andEuros company active electronics and software research and development provide complete solutions system architecture sensors sensor networks mixed signal hardware designs distributed software and hardware platforms embedded systems FPGA VHDL system chip design powerline communications and sensor protocols 
3104 en IGEA – GIS Development Consulting and Services GIS Development Consulting and Services GIS system implementation data services cartography educational and training services Projects software engineering programming system administration Research and Development Project management complex projects
3105 en IKS Implementing computer vision methods various fields video surveillance traffic control industrial quality inspection medical diagnostics Development database applications Algorithm development and testing
3106 en INDATA Research and development applied electronics Microprocessor applicaiton for building energy management Building management systems components based EN14908 ANSI 709 standard Hardware implementation SSGL protocol
3107 en ISKRA ITE Research production and implementation the products Surge protection devices Low Power Distribution Systems for Power suply Systems Telephone Exchanges and Terminals Base Stations Oile Gass and wather pipe lines Data transmission Systems External Lighting protection Base Stations Oile Gass and wather pipe line stations Medium Voltage Surge Arestors Integration and Enngenering for complete solutions Telecommunication Networks Surge and Over voltage protection solutions Reserch production and implementation Telecommunication Access and Sensor Systems
3109 en NOMEN CORE BUSINESS BIOMETRIC SECURITY Other Security Fields video amp audio surveliance close protection education Trainings for security personnel border security guards anti terror seminars…
3110 en SETCCE – Security Technology Competence Centre commerce products and services globally used and W3C compliant digital signature components products for electronic invoicing process management and outsourced services products and services for trusted electronic archiving ’ consulting services company wide business process materialization and optimization PKI related security policies application digital signatures ambiental intelligence pervasive systems etc 
3111 en Sequential Monte Carlo methods Parts and this lecture are presented mlss07 davy smcmc Manuel Davy title 
3112 en Stochastic Information Processing Sensor Networks Challenges Some Solutions and Open Problems
3113 en Students performing Easy the last day the MLSS
3115 en Interview about past present future MLSS this interview the Videolectures Net team spoke Bernhard Schölkopf the MLSS 2007 Tuebingen were interested how sees the social part the school still attends school with the same enthusiasm the talks were too narrow and specialised widely comprehensable and they should invite speakers from different fields such psychology 
3117 en Efficient Closed Pattern Mining Strongly Accessible Set Systems Many problems data mining can viewed special case the problem enumerating the closed elements independence system some specific closure operator consider generalization this problem strongly accessible set systems and arbitrary closure operators For this more general problem setting the closed sets can enumerated with polynomial delay deciding membership the set system and computing the closure operator can solved polynomial time discuss potential applications graph mining 
3118 en Support Vector Machines for Collective Inference Interdependent training instances violate the common assumption independently drawn examples and render classical learning algorithms inappropriate choice Collective inference approaches explicitly incorporate these dependencies translating the examples into graph where two training instances are connected their values depend each other present support vector approach for collective inference allowing for arbitrary dependencies the data and report empirical results Since exact inference for large graphs infeasible integrate approximate decoding technique based loopy belief propagation into the optimization problem empirically compare versions the procedure that are based exact using the Hugin algorithm and approximate decoding loopy belief propagation and others terms accuracy and execution time 
3120 en Opening the PMNP 2007 Sheffield
3121 en The Cost Learning Directed Cuts Classifying vertices digraphs important machine learning setting with many applications consider learning problems digraphs with three characteristic properties The target concept corresponds directed cut the total cost finding the cut has bounded priori and iii the target concept may change due hidden context For one motivating example consider classifying intermediate products some process for manufacturing cars the control flow software faulty correct The process can represented digraph and the concept monotone Typical faults that appear intermediate product will also present later stages the product The concept may depend hidden variable some pre assembled parts may vary and the fault may occur only for some charges and not for others order able trade off between the cost having faulty product and the costs needed find the cause the fault tight performance guarantees for finding the bug are needed 
3123 en Speeding Graph Edit Distance Computation with Bipartite Heuristic the present paper aim speeding the computation exact graph edit distance propose combine the standard tree search approach graph edit distance computation with the suboptimal procedure The idea use fast but suboptimal bipartite graph matching algorithm heuristic function that estimates the future costs The overhead for computing this heuristic function small and easily compensated the speed achieved tree traversal Since the heuristic function provides with lower bound the future costs guaranteed return the exact graph edit distance two given graphs 
3124 en Gene Regulatory Network Inference Silico Hypotheses and Experimental Validation The literature replete with various approaches extracting gene regulatory networks from microarray profiling data Although many these methods have produced networks which appear biologically plausible based circumstantial evidence from the literature very little work has been done validating the model networks experimentally this paper present new results from microarray time series study adaptation cold and successive adaptation optimal temperatures coli Model networks were inferred from the data using the variational Bayesian state space modelling approach Beal 2005 Analysis the biological implications these network models still going but preliminary analysis has already revealed some promising novel biological hypotheses relating the transcriptional response bacterial cells adapting the temperature shift Our model places number genes the higher level the hierarchy “hubs” the temperature shifted network including hns and hybC Encouragingly the model network reveal some the known regulatory interactions the literature The model also indicates that hns downregulates genes involved aerobic metabolism and upregulates genes involved anaerobic metabolism This immediately suggests the hypothesis that hns plays key role regulating switch between aerobic and anaerobic metabolism during the temperature adaptation The experimental verification this hypothesis extremely simple The hns mutant exhibits the phenotype growing 10oC but stops growing switched from 10oC 37oC Time series microarray data collected from this mutant strain should directly address the question whether the expression genes involved aerobic anaerobic metabolism during adaptation 37oC dependent the expression hns Regulatory interactions which are either confirmed not confirmed this experiment will used define Bayesian priors for iterative retraining the state space model including the time series data collected from the perturbed system present results from full cycle this iterative procedure 
3125 en Least squares estimation transcription regulation model The way transcription factors regulate the activity their target genes much interest Several authors have recently used model based computational approaches infer concentrations transcription factor proteins from high throughput gene expression data Here present approach explicitly formulated model periodic biological phenomena and least squares framework for parameter estimation such model Such computational strategy can used infer levels transcription factor activities the protein level using genes that are regulated single transcription factors and then decipher “transcriptional logic” genes under regulation the comboined actions multiple transcription factors 
3126 en Reverse engineering gene and protein regulatory networks using graphical models comparative evaluation study One the major goals systems biology infer the architecture biochemical pathways and regulatory networks from postgenomic data such microarray gene expression and cytometric protein expression data Various reverse engineering Machine Learning methods have been proposed the literature and important understand their relative merits and shortcomings the talk the learning performances three different graphical models machine learning methods namely Relevance networks Gaussian Graphical Models and Bayesian networks are cross compared real cytometric protein data and simulated data from the RAF signalling pathway Relevance networks are based pairwise association scores and straightforward implement But the inference not done the context the whole system and there possibility distinguished between direct and indirect associations Both shortcomings are addressed Gaussian graphical models where the partial correlation between two variables conditional all the other domain variables employed association score Bayesian networks are more flexible probabilistic graphical models for conditional dependence and independence relations Bayesian networks are based directed acyclic graphs and can exploited analyse interventional data for identifying putative causal interactions The empirical results were obtained applying the shrinkage estimator Schaefer and Strimmer 2005 compute the inverse covariance matrix for Gaussian Graphical Models and Bayesian network inference was done sampling BNs from the posterior distribution with order Markov chain Monte Carlo MCMC proposed Friedman and Koller 2003 The experimental results were obtained analysing data from the RAF protein signalling network reported Sachs 2005 which describes the interaction eleven phosphorylated proteins and phospholipids human immune system cells Thereby was distinguished between real cytometric protein activity measurements reported Sachs 2005 and synthetically generated data well between pure observational and interventional data Observational data are obtained passively monitoring the system without any interference while interventional data are obtained actively manipulating variables using gene knock out experiments Detailed results this empirical study have been published Werhli 2006 and Grzegorczyk 2007 The three main findings can summarized follows First exclusively Gaussian observational data Bayesian networks and Gaussian graphical models were found outperform Relevance networks Second for observational data significant difference between Bayesian networks and Gaussian Graphical models was observed Third only for interventional data Bayesian networks clearly performed superior the other two approaches 
3127 en Support Computation for Mining Frequent Subgraphs Single Graph Defining the support frequency subgraph trivial when database graphs given simply the number graphs the database that contain the subgraph However the input one large graph surprisingly difficult find appropriate support definition this paper study the core problem namely overlapping embeddings the subgraph detail and suggest definition that relies the non existence equivalent ancestor embeddings order guarantee that the resulting support anti monotone prove this property and describe method compute the support defined this way 
3128 en General Graph Refinement with Polynomial Delay many graph mining algorithms essential component its procedure for enumerating graphs such that two enumerated graphs are isomorphic All frequent subgraph miners require such component but also other data mining algorithms such for instance require such procedure which often called “refinement operator” “join operator” depending the enumeration can didate generation strategy Consequently the data min ing literature huge amount algorithms have been pre sented for enumerating graphs without isomorphisms None these algorithms however have been shown run with polynomial delay when enumerating the graphs even without accessing any data the worst case may take exponential time list the next graph From theoreti cal perspective this disappointing result Goldberg showed already the early nineties that enumerating all connected graphs without isomorphs can done with polynomial delay this paper address this prob lem show that there graph enumeration algorithm that can used graph mining algorithms and has polynomial delay Thus not only propose algorithm enumerate the interesting parts the class connected graphs but also improve the earlier bound graph enumer ation that was shown Goldberg the same time our algorithm general enough also applicable for other types graphs than connected graphs For instance can also used for enumerating unconnected graphs planar graphs outerplanar graphs and many other types graphs with polynomial delay The datastructure that produced the algorithm allows membership queries executed polynomial time for any given graph independent its representation can determine polynomial time part set enumerated subgraphs particular our algorithm not necessary compute canonical form However this desirable can use our algorithm enumerate graphs several canonical forms for instance the DFS and BFS canonical forms used gSpan and MoFA 
3129 en Improving frequent subgraph mining the presence symmetry The difficulty the frequent subgraph mining problem arises from the tasks enumerating the subgraphs and calculating their support the dataset the dataset graphs have additional information the form labels these problems can solved quite easily However the dataset graphs are unlabeled only have few labels then the complexity these problems greatly reduces the number and sizes the dataset graphs that can managed Thus far researchers working the frequent subgraph mining problem have given little attention such datasets and current algorithms tend poorly them Yet there are many applications which deal with this type data mainly the fields compute vision where the data structured meshes communication transportation networks where the information mostly topological 
3130 en DIGDAG first algorithm mine closed frequent embedded sub DAGs Although tree and graph mining have attracted lot attention there are nearly algorithms devoted DAGmining whereas many applications are dire need such algorithms present this paper DIGDAG the first algorithm capable mining closed frequent embedded sub DAGs This algorithm combines efficient closed frequent itemset algorithms with novel techniques order scale complex input data 
3131 en Abductive Stochastic Logic Programs for Metabolic Network Inhibition Learning revisit application developed originally using Induc tive Logic Programming ILP replacing the underlying Logic Pro gram description with Stochastic Logic Programs SLPs one the underlying Probabilistic ILP PILP frameworks both the ILP and PILP cases mixture abduction and induction are used The abductive ILP approach used variant ILP for modelling inhibition metabolic networks The example data was derived from studies the ®ects toxins rats using Nuclear Magnetic Resonance NMR time trace analysis their bio°uids together with background knowledge representing subset the Kyoto Encyclopedia Genes and Genomes KEGG The ILP approach learned logic models from non probabilistic examples The PILP approach applied this paper based gen eral approach introducing probability labels within standard sci enti¯ experimental setting involving control and treatment data Our results demonstrate that the PILP approach not only leads signi¯ cant decrease error accompanied improved insight from the learned result but also provides way learning probabilistic logic models from probabilistic examples 
3132 en  Efficient Sampling Scheme For Comparison Large Graphs new graph structured data being generated graph comparison has become important and challenging problem application areas such molecular biology telecommunications chemoinformatics and social networks Graph kernels have recently been proposed theoretically sound approach this problem and have been shown achieve high accuracies benchmark datasets Different graph kernels compare different types subgraphs the input graphs far the choice subgraphs compare rather hoc and often motivated runtime considerations There clear indication that certain types subgraphs are better than the others the other hand comparing all possible subgraphs has been shown hard thus making practically infeasible These difficulties seriously limit the practical applicability graph kernels this article attempt rectify the situation and make graph kernels applicable for data mining large graphs and large datasets Our starting point the matrix reconstruction theorem which states that any matrix size above can reconstructed given all its principal minors applying this the adjacency matrix graph recursively define graph kernel and show that can efficiently computed using the distribution all size subgraphs graph This distribution argue similar sufficient statistic the graph especially when the graph large Exhaustive enumeration these subgraphs prohibitively expensive scaling But bounding the deviation the empirical estimates the distribution from the true distribution suffices sample fixed number subgraphs Incidentally our bounds are stronger than those found the bio informatics literature for similar techniques our experimental evaluation our graph kernel outperforms state the art graph kernels both times time and classification accuracy 
3133 en Fast Inference Infinite Hidden Relational Models Relational learning area growing interest machine learning Dzeroski Lavrac 2001 Friedman 1999 Raedt Kersting 2003 2006 introduced the infinite hidden relational model IHRM which views relational learning context the entity relationship database model with entities attributes and relations compare also Kemp 2006 the IHRM for each entity latent variable introduced The latent variable the only parent the other entity attributes and parent relationship attributes The number states each latent variable entity class specific Therefore sensible work with Dirichlet process mixture models which each entity class can optimize its own representational complexity self organized way For our discussion sufficient say that integrate mixture model into the IHRM simply letting the number hidden states for each entity class approach infinity Thus natural outcome the IHRM clustering the entities providing interesting insight into the structure the domain 
3134 en Inferring vertex properties from topology large networks Network topology not only tells about tightly connected “communities ” but also gives cues more subtle properties the vertices introduce simple probabilistic latent variable model which finds either latent blocks more graded structures depending hyperparameters With collapsed Gibbs sampling can estimated for networks 106 vertices more and the number latent components adapts data through Dirichlet process prior Applied the social network music recommendation site Last reasonable combinations musical genres appear from the network topology revealed subsequent matching the latent structure with listening habits the participants The advantages the generative nature the model are explicit handling uncertainty the sparse data and easy interpretability extensibility and adaptation applications with incomplete data 
3135 en  Polynomial time Metric for Outerplanar Graphs Extended Abstract the chemoinformatics context graphs have become very popular for the representation molecules However lot algorithms handling graphs are computationally very expensive this paper focus outerplanar graphs class graphs that able represent the majority molecules define metric outerplanar graphs that based finding maximum common subgraph and present algorithm that runs polynomial time Having efficiently computable metric molecules can improve the virtual screening molecular databases significantly 
3136 en Weighted Substructure Mining for Image Analysis web related applications image categorization desirable derive interpretable classification rule with high accuracy Using the bag words representation and the linear support vector machine one can partly fulfill the goal but the accuracy linear classifiers not high and the obtained features are not informative for users propose combine item set mining and large margin classifiers select features from the power set all visual words Our resulting classification rule easier browse and simpler understand because each feature has richer information next step each image represented graph where nodes correspond local image features and edges encode geometric relations between features Combining graph mining and boosting can obtain classification rule based subgraph features that contain more information than the set features evaluate our algorithm web retrieval ranking task where the goal reject outliers from set images returned for keyword query Furthermore evaluated the supervised classification tasks with the challenging VOC2005 data set Our approach yields excellent accuracy the unsupervised ranking task and competitive results the supervised classification task 
3137 en  Universal Kernel for Learning Regular Languages give universal kernel that renders all the regular languages linearly separable are not able compute this kernel efficiently and conjecture that intractable but have efficient approximation
3138 en Mining Indexing and Searching Graphs Large Data Sets Recent research pattern discovery has progressed from mining frequent itemsets and sequences mining structured patterns including trees lattices and graphs general data structure graph can model complicated relations among data with wide applications Web social network analysis and bioinformatics However mining and searching large graphs graph databases challenging due the presence exponential number frequent subgraphs this talk present our recent progress developing efficient and scalable methods for mining and searching graphs large databases introduce gSpan and CloseGraph two efficient methods for mining frequent graph patterns graph databases Then introduce constraint based graph mining methods Further introduce graph indexing method gIndex and graph approximate searching method grafil both taking advantages frequent graph mining construct compact but highly effective graph index and perform similarity search with such indexing structures These methods not only facilitate mining and querying graph patterns massive datasets but also claim broad applications other fields including systems and software engineering 
3143 en Independence ratios nearly planar graphs With purposeful imprecision graph said nearly planar resembles some essential way planar graph Classic measures near planarity include the thickness the crossing number and the genus Modern versions nearly planar graphs include the graphs embedded surfaces with large width shortest noncontractible cycle Geometric graph theory has given different notion locally planar well two definitions quasi planar graphs This talk will begin with retrospective look independence ratios locally planar graphs consider contrasts between results about the independence ratio and those about the chromatic number will then proceed results and open questions about independence ratios various classes nearly planar graphs 
3144 en Honeycomb tori and Cayley graphs generalized dihedral groups investigate family graphs known some people honeycomb tori establish that they all are Cayley graphs generalized dihedral groups then look hamiltonicity properties for this family graphs 
3145 en Graphs with extremal energy tend have small number distinct eigenvalues The sum the absolute values the eigenvalues graph called the energy the graph study the problem finding graphs with extremal energy within specified sets graphs develop some tools for treating such problems and obtain some partial results particular show that many cases the expected extremal graphs with small number distinct eigenvalues not exist and that actual extremal graphs could have large number distinct eigenvalues Zigzag and central circuit structure
3146 en Chirality genera and simplicity orientably regular maps orientably regular map cellular embedding graph multigraph orientable surface with the property that the group orientation and incidencepreserving automorphisms has single orbit the arcs ordered edges the embedding will describe recent computer assisted determination all such maps surfaces genus 100 which revealed some interesting patterns leading new discoveries about gaps the genus spectrum examples that are chiral and have the property that the map its topological dual has simple underlying graph The last part joint work with Jozef Siran and Tom Tucker 
3147 en Zigzag and central circuit structure two faced plane graphs zigzag valent plane graph circuit edges such that any two but not three consecutive edges belong the same face railroad circuit evengonal faces such that any face adjacent its neighbors opposite edges Boundary circuits railroad are two ”parallel” zigzags valent graph two such central circuits consider the zigzag and railroad structure two faced and valent plane graphs generalizations Platonic polyhedra and their connections with other problems 
3148 en  automorphism groups vertex transitive graphs One the most fundamental questions one can ask about vertex transitive graph what the full automorphism group Aut This usually difficult question evidenced determining Aut should allow for the solution many other problems concerning For example edge transitive transitive normal Additionally one should able solve the isomorphism problem for this talk will report recent progress determining Aut for certain classes vertex transitive graphs especially Cayley graph certain abelian groups 
3149 en Geometry partial cube graphs Partial cubes are graphs defined geometric structure the graph vertices can placed the vertices hypercube such way that graph distance equals Hamming distance survey recent developments the theory these graphs that relate them other ways geometric structures lattice embeddings hyperplane arrangements systems translated quadrants the plane and flip graphs triangulations 
3150 en Erdös Rado theorems will show that this theorem has natural proof using linear algebra and that this approach also applies situations where sets are replaced objects such subspaces permutations partitions 
3151 en Small polyhedral models the torus the projective plane and the Klein bottle Models these manifolds have been studied least since the work Moebius with increasing depth and many results more recent times The models range from purely combinatorial various types geometric representations such topological complexes planar faced polyhedra convex nor necessarily convex smooth manifolds The talk will give survey available results and then concentrate what seems new direction – models that admit faces selfintersecting polygons One the unexpected results that some cases such models are simpler and more readily visualized than the more traditional ones and that other cases they are the only possible ones The understanding the role selfintersecting polygons faces sheds light among other things the relations between the Platonic solids and the Kepler Poinsot regular polyhedra Many open problems remain both the traditional framework and the new one 
3152 en Geometric intersection graphs Geometric intersection graphs are intensively studied both for their practical motivations and interesting theoretical properties Many classes allow elegant characterizations for many them optimization problems hard general can solved polynomial time will present survey recent results and old problems this area including questions related colorability maximum clique representations planar and planar graphs Computational complexity recognition many intersection defined classes graphs will one the main topics 
3153 en  Hurwitz theory enumerating branched surface coverings With chronological review Hurwitz theory survey some known results the enumeration the equivalence classes several types branched coverings surface particular relations with the enumeration the equivalence classes several types graph coverings and enumerating the isomorphism classes branched orientable surface coverings nonorientable surface will mentioned Also discuss similar problem for branched coverings having prescribed branched types 
3154 en Famous and lesser known problems “elementary” combinatorial geometry and number theory Which problems attain great notoriety and which are delegated collect dust shelf “Elementary” problems tend attract attention because they are very easy understand and look “solvable” mystery why some attract lot attention while others lie hibernating waiting for some new fresh ideas their recent interesting book Research Problems Discrete Geometry Springer New York 2005 Brass Moser Pach wrote “Although Discrete Geometry has rich history extending more than 150 years abounds open problems that even high school student can understand and appreciate Some these problems are notoriously difficult and are intimately related deep questions other fields mathematics But many problems even old ones can solved clever undergraduate high school student equipped with ingenious idea and the kinds skills used mathematical olympiad ”
3155 en Partial cubes and other graphs Partial cubes are isometric subgraphs the hypercube graphs while graphs are graphs embeddable hypercube scale These two classes graphs have been focus much study recent years the talk will discuss recent structure results and Euler type inequality for partial cubes which joint work with Klavˇzar will also review the classification embeddable fullerene graphs joint work with Marcusanu and related results 
3156 en Distance regular graphs and the quantum affine algebra bsl2 Combinatorial objects such graphs can often used construct representations abstract algebras this talk will consider graph possessing high degree regularity known distance regularity For this graph define algebra generated the adjacency matrix and certain diagonal matrix There exists set elements this algebra that under minor assumption satisfy some attractive relations Using these relations obtain representation the quantum affine sl2 algebra 
3157 en Infinite planar tessellations survey problems involving planar embeddings locally finite infinite graphs especially graphs that have only one infinite component when any finite subgraphs deleted Problems considered concern separating double rays geodetic double rays facial walks rate growth and vertex edge and face homogeneity 
3158 en Graph methods and geometry data recent years graph based methods have seen success different machine learning applications including clustering dimensionality reduction and semi supervised learning these methods graph associated data set after which certain aspects the graph are used for various machine learning tasks however important observe that such graphs are empirical objects corresponding randomly chosen set data points talk will discuss some our work using spectral graph methods for dimensionality reduction and semi supervised learning and certain theoretical aspects these methods particular when data sampled from low dimensional manifold 
3159 en Learning gene regulatory networks Arabidopsis Thaliana Gene regulatory networks govern the functional development and biological processes cells all organisms Genes regulate each other part complex system which vitally important gain understanding For example discovery the complete gene regulatory networks humans would allow the identification genes which cause disease and could used for drug discovery identify genes interacting with compounds interest Similarly plants knowledge the gene regulatory networks would allow the development stress drought salt temperature resistant crops Learning large gene regulatory networks with thousands genes with any certainty from microarray data extremely challenging This research aims build around known networks from the literature gene regulation and assesses which other genes are likely play regulatory role the same regulatory pathways The gene regulatory networks are modelled with Bayesian network The gene expThe use large scale public microarray data appears very useful starting point for informing future experiments order determine gene regulatory networks ression levels are quantised and greedy hill climbing search method used within network structure learning algorithm The inclusion extra genes with the best explanatory power into the model has been demonstrated robust Large sets microarray experiments are used this analysis specifically 2466 NASC Arabidopsis thaliana microarrays containing gene expression levels over twenty thousand genes number experimental conditions Initial investigation this data very promising have learned gene transcription sub networks see Figure regulated the plant’ circadian clock The network shown was generated from microarray data without the use any prior information and yet the method managed identify the strong causal relationships between clock components TOC1 LHY ELF3 ELF4 CCA1 and link these further key regulators important processes ZAT myb and GATA transcription factors 
3160 en  theory similarity functions for learning and clustering Kernel methods have proven very powerful tools machine learning addition there well developed theory sufficient conditions for kernel useful for given learning problem However while kernel function can thought just pairwise similarity function that satisfies additional mathematical properties this theory requires viewing kernels implicit and often difficult characterize maps into high dimensional spaces this talk will describe more general theory that applies more general similarity functions not just legal kernels and furthermore describes the usefulness given similarity function terms more intuitive direct properties the induced weighted graph interesting feature the proposed framework that can also applied learning from purely unlabeled data clustering particular one can ask how much stronger the properties similarity function should terms its relation the unknown desired clustering that can used cluster well Investigating this question leads number interesting graph theoretic properties and their analysis the inductive setting uses regularity lemma type results FK99 AFKK03 This work joint with Maria Florina Balcan and Santosh Vempala 
3161 en Convergence the graph Laplacian application dimensionality estimation and image segmentation Given sample from probability measure with support submanifold Euclidean space one can construct neighborhood graph which can seen approximation the submanifold The graph Laplacian such graph used several machine learning methods like semi supervised learning dimensionality reduction and clustering will present the pointwise limit three different graph Laplacians used the literature the sample size increases and the neighborhood size approaches zero show that for uniform measure the submanifold all graph Laplacians have the same limit constants However the case nonuniform measure the submanifold only the called random walk graph Laplacian converges the weighted Laplace Beltrami operator will give two applications these theoretical results 
3162 en ProBic identification overlapping biclusters usinf Probabilistic Relational Models applied simulated gene expression data Biclustering increasingly popular technique identify regulatory modules that are linked biological processes bicluster defined subset genes which have similar expression profile for subset conditions the context gene expression data describe novel method called ProBic simultaneously identify series overlapping biclusters gene expression data within the framework Probabilistic Relational Models PRMs PRMs are relational extension Bayesian Networks and allow for the integration relational data within unified probabilistic framework PRM model describes joint probability Bayesian networks but with additional constraints the conditional probability functions propose novel PRM based biclustering model which gene expression data can considered relational data The classes are Gene Condition and Expression Both the classes Gene and Condition have vector attribute Bicluster containing series bicluster ’ These vectors represent which biclusters exist for gene condition and are initially unknown Condition has extra attribute which unique number for each condition Expression has attribute Level containing the expression value and two reference slots which point the gene and condition for which the level was measured Expression Level conditionally dependent Gene Bicluster Condition Bicluster and Condition The conditional dependency modeled set Gaussian distributions with conjugate priors The ProBic model naturally deals with missing values fact there are ‘missing’ values this model and robust sets biclusters are obtained due explicit modeling noise The maximum likelihood solution approximated using Expectation Maximization strategy ProBic was applied simulated gene expression data sets and all the biclusters were successfully identified Various noise settings and different overlap models average sum product have been explored Our results show that PRM models can used identify overlapping biclusters efficient and robust manner naturally dealing with missing values and noise 
3163 en Probabilistic graph partitioning consider the problem Graph Partitioning for applications Web Mining and Collaborative Filtering Our approach based predicting the presence absence directed link based form probabilistic mixture model Being based generative model directed graphs are able apply approximate Bayesian treatment automatically select appropriate number partitions will discuss application Collaborative Filtering and comment relations mixed membership models Latent Dirichlet Allocation and Probabilistic Latent Semantic Analysis 
3164 en Estimating parameters and hidden states biological networks with particle filters Abstract Identifying biological networks requires develop models able capture their dynamics and statistical learning methods estimate their parameters from time series measurements particular Ordinary Differential Equations ODE are rich family quantitative models but their estimation remains bottleneck for reverse engineering especially when the biological processes are nonlinear and partially observed recent work have proposed state space model derived from ODE used Systems Biology that can encompass regulatory networks metabolic networks signaling pathways For this model have derived Bayesian estimation procedure for both parameters and hidden variables based nonlinear filtering and particular approximation scheme the Unscented Kalman Filter UKF Despite satisfactory results the UKF approximation possesses some limitations such few theoretical results and limited range applications propose then use Sequential Monte Carlo methods SMC also known particle filters which are now standard methods for filtering nonlinear and non Gaussian processes SMC methods provide nonparametric approximation the filtering probability discretely supported the called particles whose convergence properties have been intensively studied this work develop SMC approach for the Bayesian estimation the kinetic parameters and hidden states considering the parameters additional hidden states with evolution Despite the generality SMC methods the deterministic evolution the hidden variables implies fast degenerescence standard algorithms bootstrap filter overcome this problem use solution proposed Liu and West which relies adapted kernel smoothing the particle approximation The method illustrated the Repressilator ODE proposed for gene regulatory network and ODE for the JAK STAT signaling pathway Experimental results show that particle filters provide similar results UKF for the parameter estimation and lower Mean Square Error for the state estimation while offering greater versatility 
3165 en Evolution protein complexes and protein interaction networks There abundance data protein interactions and protein complexes both from conventional smallscale experiments collected over the decades including threedimensional structures and more recently largescale functional genomics experiments can now draw the information available about protein interactions order study the evolution interactions have shown that interactions just like individual proteins frequently emerge duplication and divergence The duplication protein that engages proteinprotein interactions raises issues about the stoichiometry and equilibrium protein complexes when the quantity one component increases Nevertheless our results indicate that most interactions and complexes have evolved stepwise duplications individual proteins engaged interactions show that duplicated complexes retain the same overall function but have different binding specificities and regulation revealing that duplication associated with functional specialization From analysis crystal structures proteins well the domain architectures multidomain proteins clear that physical interactions between identical homologous domainsand protein chains are extremely common How have this particular class interactions evolved and
3166 en Prediction graph will discuss the problem robust online learning over graph Consider the following game for predicting the labeling graph ”Nature” presents vertex the ”learner” predicts the label the vertex ˆy1 nature presents label nature presents vertex the learner predicts ˆy2 and forth The learner’ goal minimize the total number mistakes nature adversarial the learner will always mispredict but nature regular simple there hope that learner may make only few mispredictions Thus methodological goal give learners whose total mispredictions can bounded relative the ”complexity” nature’ labeling this talk consider the ”label cut size” measure the complexity graph’ labeling where the size the cut the number edges between disagreeing labels will give bounds which depend the cut size and the resistance diameter the graph 
3167 en Inferring ancestral states the bZIP transcription factor interaction network whole genome protein interaction network datasets become available for wide range species evolutionary biologists have the opportunity address some the unanswered questions surrounding the evolution these complex systems Protein interaction networks from divergent organisms may compared investigate how gene duplication deletion and ‘ wiring’ processes may have shaped the evolution their contemporary structures However current approaches aligning observed networks from multiple species are generally lacking the phylogenetic context necessary for meaningful conclusions drawn regarding network evolution Here show how probabilistic modeling can provide platform for the quantitative analysis multiple protein interaction networks apply this technique the reconstruction ancestral networks for the bZIP family transcription factors and find that excellent agreement obtained with alternative sequence based method for the prediction leucine zipper interactions Further analysis shows our probabilistic method significantly more robust the presence noise the observed network data than simple parsimony based approach addition the integration evidence over multiple species means that the same method may used improve the quality noisy interaction data for extant species This the first time that ancestral states protein interaction network have been reconstructed using explicit probabilistic model network evolution anticipate that will form the basis more general methods for probing the evolutionary history biochemical networks 
3168 en Mixture models graphs One the most fundamental challenges the analysis omics data sets clustering the relevant quantities gene transcripts protein levels etc into distinct groups One the simplest instances occurs when comparing data obtained from two different conditions where the basic task assess whether quantity upregulated downregulated unregulated This task has traditionally been addressed using statistics from probabilistic point view mixture models with one mixture representing one the three states regulation This approach tacitly assumes the various measurements independently drawn from the same mixture distribution However well known that biological quantities genes enzymes etc are not independent but they are linked often very complex network interactions various levels therefore reasonable use available network structure and weighting information order obtain more accurate inference the expression state This can also found useful finding suitable subnetworks that exhibit coherent behaviours giving rise testable biological predictions this contribution introduce probabilistic model that implements mixture models graph The graph structure encoded set conditional prior distributions over the latent class memberships This formulation leads naturally Gibbs sampling approach present preliminary results synthetic and real data where gene expression modelled mixture Gaussian and two exponential distributions 
3169 en Bayesian Inference transcription factor activity application the fission yeast cell cycle When modeling genetic regulatory interactions often assumed that the mRNA expression transcription factor reliable proxy for the regulatory activity that transcription factor There are many examples where this assumption does not hold due post transcriptional and translational modifications the transcription factor protein true transcription factor activity very difficult measure methods infer are becoming increasingly common and likely that will become increasingly important when building models regulatory interactions Previously have shown how Bayesian techniques particularly Markov Chain Monte Carlo based sampling can enable make inferences regarding the activity transcription factors based the transcript levels their targets However that work only looked simple regulatory interactions where one transcription factor acted individually set target genes this work investigate extending this model the more general and common case multiple transcription factors working together example application use data from small regulatory network from the fission yeast cell cycle which several transcription factors are known work together produce the desired response and for which plentiful experimental data are available 
3170 en Stochastic estimation fluxes metabolic networks The qualitative and quantitative information conveyed metabolic networks are important for regulating the metabolism organism achieve desired targets One approach quantification the 13C tracer experiment which aims provide information metabolic fluxes The flux estimation problem addressed steady state and dynamic conditions this presentation The problem formulation the steady state leads latent variable model structure which utilised applying the stochastic estimation framework solve the flux quantification problem natural algorithm solve this problem the expectationmaximisation algorithm which applied first This extended the Markov Chain Monte Carlo algorithm account for nonGaussian measurement noise Finally sequential Monte Carlo filter used determine the fluxes under dynamic conditions Results are presented for the central metabolism Cornybacterium Glutamicum the steady state and using simulated metabolic network for the dynamic case 
3171 en Stochastic Parameter Estimation Biochemical Signalling Pathways common when modelling biochemical networks use qualitative information such the general ODE model structure proceed parameter estimation while the same time retaining the basic model structure the best represents the biochemical process governing the cell This not the case however when the population the available molecules from each the participating species very small small copy number deeming necessary the introduction complex stochastic modelling techniques that make use chemical master equations simulate the trajectories the states species concentration the system Gene expression stochastic nature and consequence gene regulatory and signal transduction networks follow similar behaviour Most importantly large number gene expression data sets examined yeast mouse and human cells follow Pareto like distribution model skewed many low abundance transcripts covering large variety eukaryotic cells therefore apparent that stochastic modelling strategy should structure accommodate the specific needs the system 
3172 en  comparison hypothesis testing methods for ODE models biochemical systems this talk present comparison different methods testing alternative hypotheses expressed using ODE models biochemical systems investigated applicability limitations and stability range hypotheses testing methods including maximum likelihood based information criteria local deterministic approximations around maximum posteriori estimates Laplace approximations for computing marginal likelihoods importance sampling based marginal likelihood estimators and path sampling estimator built upon the principles thermodynamic integration demonstrate that the cases where models are linear the parameter space Laplace approximations provide fast and stable estimate the marginal likelihoods required for computing Bayes factors This estimate however fails when the models have non trivial parameter posteriors reject common importance sampling estimators they produce very unstable estimates practical cases relative errors the estimates vary from 600 depending the particular example used demonstrate that the annealed importance sampling estimator the marginal likelihoods and path sampling methods produce very good estimates even non trivial cases relative error within Maximum likelihood information criteria often produce the correct ordering the hypotheses These methods however not produce quantitative measure model preference odds and sometimes even fail preferring more complex model over the true one and there general method detect such failure The study performed over realistically sized ODE models biochemical systems using simulated data sets 
3174 en Frequent graph mining what the question The objective data mining find regularities interesting patterns large data sets such business transactions More recently there has been great interest extending this work structured data such graphs The domain could database molecular graphs the web graph and the question could find subgraphs which occur frequently the data Algorithms usually list frequent subgraphs other patterns There are many different formulations this problem this stage the development the field appears some interest put together general picture the different variants this talk present attempt towards this direction 
3175 en Transductive Rademacher complexities for learning over graph Recent investigations indicate the use probabilistic ”learning” perspective tasks defined single graph opposed the traditional algorithmical ”computational” point view This note discusses the use Rademacher complexities this setting and illustrates the use Kruskal’ algorithm for transductive inference based nearest neighbor rule 
3176 en Strings graphs invariants Strings play important role various sciences from computer science linguistics social sciences various natural sciences including bioinformatics Strings words finite sequences are mainly studied formal language theory and form the basis logic mathematics and theoretical computer science Although strings have simple linear structure may associate number invariants them particular via various graphs This non technical talk will explain some these features and survey some the recent work the present authors 123
3177 en  graphical representation proteins will review selection graphical representations proteins and explore their mathematical properties particular will consider highly condensed representations proteins ”magic circle” representation star like graphs and spectral like representations and will consider calculations some acompanying invariants Finally will outline graphical approaches protein alignment 
3178 en Graph complexity for structure and learning The talk will consider ways bounding the complexity graph measured the number partitions satisfying certain properties The approach adopted uses Vapnik Chervonenkis dimension techniques example such bound was given Kleinberg 2004 with application network failure detection describe new bound the same vein that depends the eigenvalues the graph Laplacian show application the result transductive learning graph labelling from examples 
3179 en Semidefinite ranking graphs consider the problem ranking the vertices undirected graph given some preference relation This ranking graphs problem has been tackled before using spectral relaxations Their approach strongly related the spectral relaxation made spectral clustering algorithms One problem with spectral relaxations that has been found clustering that even simple toy graphs the spectral solution can arbitrarily far from the optimal one has recently been shown that semidefinite relaxations offer many cases better solutions than spectral ones for clustering and transductive classification therefore investigate semidefinite relaxations ranking graphs 
3180 en Random walk graph kernels and rational kernels Random walk graph kernels Gartner 2003 Borgwardt 2005 count matching random walks and are defined using the tensor product graph Loosely speaking rational kernels Cortes 2004 2003 2002 use the weight assigned transducer define kernel The kernel shown positive semi definite when the transducer can written composition two identical transducers our talk will establish explicit connections between random walk graph kernels and rational kernels More concretely show that composition transducers analogous computing product graphs and that rational kernels weighted transducers may viewed generalizations random walk kernels weighted automata order make these connections explicit adapt slightly non standard notation for weighted transducers extensively using matrices and tensors wherever possible prove that under certain conditions rational kernels are positive semi definite Our proof only uses basic linear algebra and simpler than the one presented Cortes 2004 
3182 en Extracting Semantic Relations from Query Logs this paper study large query log more than twenty million queries with the goal extracting the semantic relations that are implicitly captured the actions users submitting queries and clicking answers Previous query log analyses were mostly done with just the queries and not the actions that followed after them first propose novel way represent queries vector space based graph derived from the query click bipartite graph then analyze the graph produced our query log showing that less sparse than previous results suggested and that almost all the measures these graphs follow power laws shedding some light the searching user behavior well the distribution topics that people want the Web The representation introduce allows infer interesting semantic relationships between queries Second provide experimental analysis the quality these relations showing that most them are relevant Finally sketch application that detects multitopical URLs 
3183 en Multiscale Topic Tomography Modeling the evolution topics with time great value automatic summarization and analysis large document collections this work propose new probabilistic graphical model address this issue The new model which call the Multiscale Topic Tomography Model MTTM employs non homogeneous Poisson processes model generation word counts The evolution topics modeled through multi scale analysis using Haar wavelets One the new features the model its modeling the evolution topics various time scales resolution allowing the user zoom and out the time scales Our experiments Science data using the new model uncovers some interesting patterns topics The new model also comparable LDA predicting unseen data demonstrated our perplexity experiments 
3184 en  Concept based Model for Enhancing Text Categorization Most text categorization techniques are based word and phrase analysis the text Statistical analysis term frequency captures the importance the term within document only However two terms can have the same frequency their documents but one term contributes more the meaning its sentences than the other term Thus the underlying model should indicate terms that capture the semantics text this case the model can capture terms that present the concepts the sentence which leads discover the topic the document new concept based model that analyzes terms the sentence and document levels rather than the traditional analysis document only introduced The concept based model can effectively discriminate between non important terms with respect sentence semantics and terms which hold the concepts that represent the sentence meaning The proposed model consists concept based statistical analyzer conceptual ontological graph representation and concept extractor The term which contributes the sentence semantics assigned two different weights the concept based statistical analyzer and the conceptual ontological graph representation These two weights are combined into new weight The concepts that have maximum combined weights are selected the concept extractor set experiments using the proposed concept based model different datasets text categorization conducted The experiments demonstrate the comparison between traditional weighting and the concept based weighting obtained the combined approach the concept based statistical analyzer and the conceptual ontological graph The evaluation results relied two quality measures the Macro averaged and the Error rate These quality measures are improved when the newly developed concept based model used enhance the quality the text categorization
3185 en Expertise modeling for matching papers with reviewers essential part expert finding task such matching reviewers submitted papers the ability model the expertise person based documents evaluate several measures the association between document reviewed and author represented their previous papers compare language model based approaches with novel topic model Author Persona Topic APT this model each author can write under one more personas which are represented independent distributions over hidden topics Examples previous papers written prospective reviewers are gathered from the Rexa database which extracts and disambiguates author mentions from documents gathered from the web evaluate the models using reviewer matching task based human relevance judgments determining how well the expertise proposed reviewers matches submission find that the APT topic model outperforms the other models 
3186 en SCAN Structural Clustering Algorithm for Networks Network clustering graph partitioning important task for the discovery underlying structures networks Many algorithms find clusters maximizing the number intra cluster edges While such algorithms find useful and interesting structures they tend fail identify and isolate two kinds vertices that play special roles 160 vertices that bridge clusters hubs and vertices that are marginally connected clusters outliers Identifying hubs useful for applications such viral marketing and epidemiology since hubs are responsible for spreading ideas disease contrast outliers have little influence and may isolated noise the data this paper proposed novel algorithm called SCAN Structural Clustering Algorithm for Networks which detects clusters hubs and outliers networks clusters vertices based structural similarity measure The algorithm fast and efficient visiting each vertex only once empirical evaluation the method using both synthetic and real datasets demonstrates superior performance over other methods such the modularity based algorithms 
3187 en Development NeuroElectroMagnetic Ontologies NEMO Framework for Mining Brain Wave Ontologies Event related potentials ERP are brain electrophysiological patterns created averaging electroencephalographic EEG data time locking events interest stimulus response onset this paper propose generic framework for mining and developing domain ontologies and apply mine brainwave ERP ontologies The concepts and relationships ERP ontologies can mined according the following steps pattern decomposition extraction summary metrics for concept candidates hierarchical clustering patterns for classes and class taxonomies and clustering based classification and association rules mining for relationships axioms concepts have applied this process several dense array 128 channel ERP datasets Results suggest good correspondence between mined concepts and rules the one hand and patterns and rules that were independently formulated domain experts the other Data mining results also suggest ways which expert defined rules might refined improve ontology representation and classification results The next goal our ERP ontology mining framework address some long standing challenges conducting large scale comparison and integration results across ERP paradigms and laboratories more general context this work illustrates the promise interdisciplinary research program which combines data mining neuroinformatics and ontology engineering address real world problems 
3188 en Exploiting Duality Summarization with Deterministic Guarantees Summarization important task data mining major challenge over the past years has been the efficient construction fixed space synopses that provide deterministic quality guarantee often expressed terms maximum error metric Histograms and several hierarchical techniques have been proposed for this problem However their time and space complexities remain impractically high and depend not only the data set size but also the space budget These handicaps stem from requirement tabulate all allocations synopsis space different regions the data this paper develop alternative methodology that dispels these deficiencies thanks fruitful application the solution the dual problem given maximum allowed error determine the minimum space synopsis that achieves 160 These complexity advantages offer both spaceefficiency and scalability that previous approaches lacked verify the benefits our approach practice experimentation 
3189 en Webpage Understanding Integrated Approach Recent work has shown the effectiveness leveraging layout and tag tree structure for segmenting webpages and labeling HTML elements However how effectively segment and label the text contents inside HTML elements still open problem Since many text contents webpage are often text fragments and not strictly grammatical traditional natural language processing techniques that typically expect grammatical sentences are longer directly applicable this paper examine how use layout and tag tree structure principled way help understand text contents webpages propose segment and label the page structure and the text content webpage joint discriminative probabilistic model this model semantic labels page structure can leveraged help text content understanding and semantic labels the text phrases can used page structure understanding tasks such data record detection Thus integration both page structure and text content understanding leads integrated solution webpage understanding Experimental results research homepage extraction show the feasibility and promise our approach 
3190 en Knowledge Discovery Multiple topic Document using Parametric Mixture Model with Dirichlet Prior Documents such those seen onWikipedia and Folksonomy have tended assigned with multiple topics meta data Therefore more and more important analyze relationship between document and topics assigned the document this paper proposed novel probabilistic generative model documents with multiple topics meta data focusing modeling the generation process document with multiple topics can extract specific properties documents with multiple topics Proposed model expansion existing probabilistic generative model Parametric Mixture Model PMM PMM models documents with multiple topics mixing model parameters each single topic Since however PMM assigns the same mixture ratio each single topic PMM cannot take into account the bias each topic within document deal with this problem propose model that considers Dirichlet distribution prior distribution the mixture ratio adopt Variational Bayes Method infer the bias each topic within document evaluate the proposed model and PMM using MEDLINE corpus The results measure Precision and Recall show that the proposed model more effective than PMM multiple topic classification Moreover indicate the potential the proposed model that extracts topics and document specific keywords using information about the assigned topics 
3191 en Tracking Multiple Topics for Finding Interesting Articles introduce multiple topic tracking MTT for iScore better recommend news articles for users with multiple interests and address changes user interests over time extension the basic Rocchio algorithm traditional topic detection and tracking and single pass clustering MTT maintains multiple interest profiles identify interesting articles for specific user given user feedback Focusing only interesting topics enables iScore discard useless profiles address changes user interests and achieve balance between resource consumption and classification accuracy Also relating topic’ interestingness article’ interestingness iScore able achieve higher quality results than traditional methods such the Rocchio algorithm identify several operating parameters that work well for MTT Using the same parameters show that MTT alone yields high quality results for recommending interesting articles from several corpora The inclusion MTT improves iScore’ performance recommending news articles from the Yahoo News RSS feeds and the TREC11 adaptive filter article collection And through small user study show that iScore can still perform well when only provided with little user feedback 
3192 en Content based Document Routing and Index Partitioning for Scalable Similarity based Searches Large Corpus present document routing and index partitioning scheme for scalable similarity based search documents large corpus consider the case when similarity based search performed finding documents that have features common with the query document While possible store all the features all the documents one index this suffers from obvious scalability problems Our approach partition the feature index into multiple smaller partitions that can hosted separate servers enabling scalable and parallel search execution When document ingested into the repository small number partitions are chosen store the features the document perform similarity based search also only small number partitions are queried Our approach stateless and incremental The decision which partitions the features the document should routed for storing ingestion time and for similarity based search query time solely based the features the document Our approach scales very well show that executing similarity based searches over such partitioned search space has minimal impact the precision and recall search results even though every search consults less than the total number partitions 
3193 en Mining Favorable Facets The importance dominance and skyline analysis has been well recognized multi criteria decision making applications Most previous studies assume fixed order the attributes practice different customers may have different preferences nominal attributes this paper identify interesting data mining problem finding favorable facets which has not been studied before Given set points multidimensional space for specific target point want discover with respect which combinations orders customer preferences the nominal attributes not dominated any other points Such combinations are called the favorable facets consider both the effectiveness and the efficiency the mining given point may have many favorable facets propose the notion minimal disqualifying condition MDC which effective summarizing favorable facets develop efficient algorithms for favorable facet mining for different application scenarios The first method computes favorable facets the The second method pre computes all minimal disqualifying conditions that the favorable facets can looked constant time extensive performance study using both synthetic and real data sets reported verify their effectiveness and efficiency 
3194 en Weighting versus Pruning Rule Validation for Detecting Network and Host Anomalies For intrusion detection the LERAD algorithm learns succinct set comprehensible rules for 160 detecting anomalies nbsp which could novel attacks LERAD validates the learned rules separate held out validation set and removes rules that cause false alarms However removing rules with possible high coverage can lead missed detections propose retain these rules and associate weights them present three weighting schemes and our empirical results indicate that for LERAD rule weighting can detect more attacks than pruning with minimal computational overhead 
3195 en Cost effective Outbreak Detection Networks Given water distribution network where should place sensors quickly detect contaminants which blogs should read avoid missing important stories These seemingly different problems share common structure Outbreak detection can modeled selecting nodes sensor locations blogs network order detect the spreading virus information quickly possible present general methodology for near optimal sensor placement these and related problems demonstrate that many realistic outbreak detection objectives detection likelihood population affected exhibit the property “submodularity” exploit submodularity develop efficient algorithm that scales large problems achieving near optimal placements while being 700 times faster than simple greedy algorithm also derive online bounds the quality the placements obtained any algorithm Our algorithms and bounds also handle cases where nodes sensor locations blogs have different costs evaluate our approach several large real world problems including model water distribution network from the EPA and real blog data The obtained sensor placements are provably near optimal providing constant fraction the optimal solution show that the approach scales achieving speedups and savings storage several orders magnitude also show how the approach leads deeper insights both applications answering multicriteria trade off cost sensitivity and generalization questions 
3196 en Joint Optimization Wrapper Generation and Template Detection Many websites have large collections pages generated dynamically from underlying structured source like database The data category are typically encoded into similar pages common script template recent years some value added services such comparison shopping and vertical search specific domain have motivated the research extraction technologies with high accuracy Almost all previous works assume that input pages wrapper induction system conform common template and they can easily identified terms common schema URL However observed that hard distinguish different templates using dynamic URLs today Moreover since extraction accuracy heavily depends how consistent input pages are argue that risky determine whether pages share common template solely based URLs Instead propose new approach that utilizes similarity between pages detect templates Our approach separates pages with notable inner differences and then generates wrappers respectively Experimental results show that our proposed approach feasible and effective for improving extraction accuracy 
3197 en Detecting Anomalous Records Categorical Datasets consider the problem detecting anomalies high arity categorical datasets most applications anomalies are defined data points that are ’abnormal’ Quite often have access data which consists mostly normal records along with small percentage unlabelled anomalous records are interested the problem unsupervised anomaly detection where use the unlabelled data for training and detect records that not follow the definition normality standard approach create model normal data and compare test records against probabilistic approach builds likelihood model from the training data Records are tested for anomalousness based the complete record likelihood given the probability model For categorical attributes bayes nets give standard representation the likelihood While this approach good finding outliers the dataset often tends detect records with attribute values that are rare Sometimes just detecting rare values attribute not desired and such outliers are not considered anomalies that context present alternative definition anomalies and propose approach comparing against marginal distributions attribute subsets show that this more meaningful way detecting anomalies and has better performance over semi synthetic well real world datasets 
3198 en Constraint Driven Clustering Clustering methods can either data driven need driven Data driven methods intend discover the true structure the underlying data while need driven methods aims organizing the true structure meet certain application requirements Thus need driven constrained clustering able find more useful and actionable clusters applications such energy aware sensor networks privacy preservation and market segmentation However the existing methods constrained clustering require users provide the number clusters which often unknown advance but has crucial impact the clustering result this paper argue that more natural way generate actionable clusters let the application specific constraints decide the number clusters For this purpose introduce novel cluster model Constraint Driven Clustering CDC which finds priori unspecified number compact clusters that satisfy all user provided constraints Two general types constraints are considered minimum significance constraints and minimum variance constraints well combinations these two types prove the hardness the CDC problem with different constraints propose novel dynamic data structure the Tree which organizes data points leaf nodes such that each leaf node approximately satisfies the CDC constraints and minimizes the objective function Based Trees develop efficient algorithm solve the new clustering problem Our experimental evaluation synthetic and real datasets demonstrates the quality the generated clusters and the scalability the algorithm 
3199 en  Spectral Clustering Approach Optimally Combining Numerical Vectors with Modular Network address the issue clustering numerical vectors with network The problem setting basically equivalent constrained clustering Wagstaff and Cardie and semisupervised clustering Basu but our focus more the optimal combination two heterogeneous data sources application this setting web pages which can numerically vectorized their contents term frequencies and which are hyperlinked each other showing network Another typical application genes whose behavior can numerically measured and gene network can given from another data source first define new graph clustering measure which call normalized network modularity balancing the cluster size the original modularity then propose new clustering method which integrates the cost clustering numerical vectors with the cost maximizing the normalized network modularity into spectral relaxation problem Our learning algorithm based spectral clustering which makes our issue eigenvalue problem and uses means for final cluster assignments significant advantage our method that can optimize the weight parameter for balancing the two costs from the given data choosing the minimum total cost evaluated the performance our proposed method using variety datasets including synthetic data well real world data from molecular biology Experimental results showed that our method effective enough have good results for clustering numerical vectors and network 
3200 en Dynamic hybrid clustering bioinformatics incorporating text mining and citation analysis unravel the concept structure and dynamics the bioinformatics field analyze set 7401 publications from the Web Science and MEDLINE databases publication years 1981–2004 For delineating this complex interdisciplinary field novel bibliometric retrieval strategy used Given that the performance unsupervised clustering and classification scientific publications significantly improved deeply merging textual contents with the structure the citation graph proceed with hybrid clustering method based Fisher’ inverse chi square The optimal number clusters determined compound semiautomatic strategy comprising combination 160 istancebased and stability based methods also investigate the relationship between number Latent Semantic Indexing factors number clusters and clustering performance The HITS and PageRank algorithms are used determine representative publications each cluster Next develop methodology for dynamic hybrid clustering evolving bibliographic data sets The same clustering methodology applied consecutive periods defined time windows the set and subsequent phase chains are formed matching and tracking clusters through time Term networks for the eleven resulting cluster chains present the cognitive structure the field Finally provide view how much attention the bioinformatics community has devoted the different subfields through time 
3201 en Enhancing Semi Supervised Clustering Feature Projection Perspective Semi supervised clustering employs limited supervision the form labeled instances pairwise instance constraints aid unsupervised clustering and often significantly improves the clustering performance Despite the vast amount expert knowledge spent this problem most existing work not designed for handling high dimensional sparse data This paper thus fills this crucial void developing Semi supervised Clustering method based spheRical KmEans via fEature projectioN SCREEN Specifically formulate the problem constraint guided feature projection which can nicely integrated with semi supervised clustering algorithms and has the ability effectively reduce data dimension Indeed our experimental results several real world data sets show that the SCREEN method can effectively deal with high dimensional data and provides appealing clustering performance 
3203 en BoostCluster Boosting Clustering Pairwise Constraints Data clustering important task many disciplines large number studies have attempted improve clustering using the side information that often encoded pairwise constraints However these studies focus designing special clustering algorithms that can effectively exploit the pairwise constraints present boosting framework for data clustering termed BoostCluster that able iteratively improve the accuracy any given clustering algorithm exploiting the pairwise constraints The key challenge designing boosting framework for data clustering how influence arbitrary clustering algorithm with the side information since clustering algorithms definition are unsupervised The proposed framework addresses this problem dynamically generating new data representations each iteration that are the one hand adapted the clustering results previous iterations the given algorithm and the other hand consistent with the given side information Our empirical study shows that the proposed boosting framework effective improving the performance number popular clustering 160 algorithms Kmeans partitional SingleLink spectral clustering and its performance comparable the state the art algorithms for data clustering with side information 
3204 en Assisting Translators Indirect Lexical Transfer present the design and evaluation translator’ amenuensis that uses comparable corpora propose and rank non literal solutions the translation expressions from the general lexicon Using distributional similarity and bilingual dictionaries the method outperforms established techniques for extracting translation equivalents from parallel corpora 
3205 en Nonlinear Adaptive Distance Metric Learning for Clustering good distance metric crucial for many data mining tasks learn metric the unsupervised setting most metric learning algorithms project observed data lowdimensional manifold where geometric relationships such pairwise distances are preserved can extended the nonlinear case applying the kernel trick which embeds the data into feature space specifying the kernel function that computes the dot products between data points the feature space this paper propose novel unsupervised Nonlinear AdaptiveMetric Learning algorithm called NAML which performs clustering and distance metric learning simultaneously NAML first maps the data high dimensional space through kernel function then applies linear projection find low dimensional manifold where the separability the data maximized and finally performs clustering the low dimensional space The performance NAML depends the selection the kernel function and the projection show that the joint kernel learning dimensionality reduction and clustering can formulated trace maximization problem which can solved via iterative procedure the framework Experimental results demonstrated the efficacy the proposed algorithm 
3206 en  Framework for Simultaneous clustering and Learning from Complex Data For difficult classification regression problems practitioners often segment the data into relatively homogenous groups and then build model for each group This two step procedure usually results simpler more interpretable and actionable models without any loss accuracy consider problems such predicting customer behavior across products where the independent variables can naturally partitioned into two groups pivoting operation can now result the dependent variable showing entries “customer product” data matrix present modelbased clustering meta algorithm that interleaves clustering and construction prediction models iteratively improve both cluster assignment and fit the models This algorithm provably converges local minimum suitable cost function The framework not only generalizes clustering and collaborative filtering model based coclustering but can also viewed simultaneous segmentation and classification regression which better than independently clustering the data first and then building models Moreover applies wide range modal multimodal data and can easily specialized address classification and regression problems demonstrate the effectiveness our approach both these problems through experimentation real and synthetic data 
3207 en Joint Cluster Analysis Attribute and Relationship Data Without Priori Specification the Number Clusters many applications attribute and relationship data are available carrying complementary information about real world entities such cases joint analysis both types data can yield more accurate results than classical clustering algorithms that either use only attribute data only relationship graph data The Connected Center CkC has been proposed the first joint cluster analysis model discover clusters which are cohesive both attribute and relationship data However well known that prior knowledge the number clusters often unavailable applications such community identification and hotspot analysis this paper introduce and formalize the problem discovering priori unspecified number clusters the context joint cluster analysis attribute and relationship data called Connected Clusters CXC problem True clusters are assumed compact and distinctive from their neighboring clusters terms attribute data and internally connected terms relationship data Different from classical attribute based clustering methods the neighborhood clusters not defined terms attribute data but terms relationship data efficiently solve the CXC problem present JointClust algorithm which adopts dynamic two phase approach the first phase find called cluster atoms provide probability analysis for this phase which gives probabilistic guarantee that each true cluster represented least one the initial cluster atoms the second phase these cluster atoms are merged bottom manner resulting dendrogram The final clustering determined our objective function Our experimental evaluation several real datasets demonstrates that JointClust indeed discovers meaningful and accurate clusterings without requiring the user specify the number clusters 
3210 en Foundations Statistical Learning Theory Empirical Infe rence high dimention spaces
3211 en Information Theo retic and Alge braic Methods for Network Anomaly Detection The tutorial will discuss two central issues Information Theoretic principles and algorithms for extracting predictive statistics distributed networks and algebraic and spectral methods for network anomaly detection The first part will deal with the concept predictive information the mutual information between the past and future process its sub extensive properties and algorithms for estimating from data will argue that the information theoretic predictability quantifies the complexity process and provides effective ways for detecting anomalies and surprises the process Using the Information Bottleneck algorithms one can extract approximate sufficient statistics from the past the future the process and use them anomaly detectors multiple time scales the second part will discuss ways for analyzing network activity using spectral methods distributed PCA and network Laplacian analysis for identifying regular temporal patterns connected network components combining the two approaches will suggest new techniques for network anomaly detectors for security 
3212 en Data stream management and mining The course provides introduction the data stream management and mining field The following points are treated applications which motivated these new developments telecommunications computer networks stock market security new concepts related data streams structure stream timestamps time windows main features data stream management systems adaptations data mining algorithms the case streams solutions summarize data streams 
3213 en Mining Massive Data Sets Today the amount data coming from all possible sources enormous and growing fast pace due large part the ubiquitous Web and its increasing presence our everyday life but also emails cell phones credit cards retail finance These data serve all sorts functions from query and search extracting information providing services well managing security Many fields are involved statistics data mining text mining data streams search social networks There lack sophisticated techniques produced academic activity where challenges mostly deal with novelty accuracy and scalability algorithms However real world applications challenges are quite different scalability usually one two orders magnitude more than academic publications ease use and capability integrate efficient techniques into working systems transparent way while always producing value for the customer Real world solutions are complex and usually need integrate many technical components from the various fields mentioned before thus becomes important assess how these fields can complement one another the first part the talk will present the challenges real world data mining applications will introduce the general Statistical Learning Theory framework and discuss some the technical issues involved large dimension data sets missing data outliers non structured data unlabelled data the second part will show taking examples from the implementation KXEN and applications developed how theoretical framework Structural Risk Minimization can used solve some the challenges met the real world will finally describe some open practical issues which will require further theoretical investigation 
3214 en User logs processing using machine learning techniques User modeling progressively becoming important and generic component many applications and services The mains reasons that explain this phenomenon are the tasks increasing complexity and the wide variety users nformation systems hypermedia websites and application software are becoming more and more complex hence difficult use efficiently Also the amount line information available user through Internet huge and still increasing everyday that recovering information becoming harder and harder Finally together with the huge development Internet more and more line commercial websites and services are proposed Internet users The aim and interest user modeling consists these situations helping the user efficiently use the systems offered and retrieve the information looking for filtering the information according his will and needs Furthermore while many software hypermedia websites and services are potentially used variety users these systems have been traditionally developed “one size fits all” manner Consequently they are often not adapted most the users with various knowledge preferences and needs this context user modeling allows personalizing such systems their content presentation order fit the individual 
3215 en Learning using Many Examples The statistical learning theory suggests choose large capacity models that barely avoid over fitting the training data that perspective all datasets are small Things become more complicated when one considers the computational cost processing large datasets Computationally challenging training sets appear when one want emulate intelligence biological brains learn quite efficiently from the continuous streams perceptual data generated our six senses using limited amounts sugar source power Computationally challenging training sets also appear when one want analyze the masses data that describe the life our computerized society The more data understand the more enjoy competitive advantages – The first part the tutorial clarifies the relation between the statistical efficiency the design learning algorithms and their computational cost – The second part makes detailed exploration specific learning algorithms and their implementation with both simple and complex examples – The third part considers algorithms that learn with single pass over the data Certain algorithms have optimal properties but are often too costly Workarounds are discussed – Finally the fourth part shows how active example selection provides greater speed and reduces the feedback pressure that constrain parallel implementations 
3216 en Large Scale Semi Supervised Learning Labeling data expensive whilst unlabeled data often abundant and cheap collect Semi supervised learning algorithms that can use both types data can perform significantly better than supervised algorithms that use labeled data alone However for such gains observed the amount unlabeled data trained should relatively large Therefore making semi supervised algorithms scalable paramount this work discuss several recent techniques for improving the scaling ability these algorithms 
3217 en Summarizing Data Stream History This article presents data mining algorithms whose goal build summaries designed summarize the whole history one several data streams that selected parts that history may studied later 
3218 en Emergent patterns large social systems Although they are composed hundreds thousands even millions heterogeneous individuals large scale social systems manifest consistent macroscopic patterns their network structure and interaction dynamics understanding these patterns can not only shed light certain aspects individual behavior but also provide insight into matters such identification key communities individuals the relation between social structure and group performance the dynamics information propagation the resilience networks attack and many others 
3219 en Evolving Networks Most real networks often evolve through time changes topology can occurnif some nodes and edges appear and disappear and even the topologynstays static the types weights node and edges can also change Mobilendevices with wireless capabilities mobile phones laptops etc are typicalnexample evolving networks where nodes users are spread around thenenvironment and connections between users can only occur they are near eachnothers This who near who network going evolve every time users movenand communication services such the spread any information will deeplynrely the mobility and the characteristics the underlying network nWe will present here some results focusing three key problems measuring ndescribing and modeling evolving networks using typical evolving networknwhere sensors had been distributed participants conference whichnwhere asked keep the sensor all time Each sensor was able detect andnrecord the presence others sensors within their radio range which gives someninformation the proximity participants
3220 en Diffusion and Cascading Behaviour Networks Diffusion process which information viruses ideas and new behaviorn spread over the network For example adoption new technology begins onn small scale with few “early adopters” then more and more people adopt itn they observe friends and neighbors using Eventually the adoption then technology may spread through the social network epidemic “infecting” most the network spreads over the network creates cascade Cascadesn have been studied for many years sociologists concerned with the diffusion ofn innovation more recently researchers have investigated cascades for selectingn trendsetters for viral marketing finding inoculation targets epidemiology andn explaining trends blogspace 
3221 en Mining Networks through Visual Analytics Analysts are faced with massive collections gathering documents events and actors from which they try make sense searching data locate patterns and discover evidence Visual and interactive exploration data has now established fruitful strategy tackle the problem posed this abundance information The Visual Analytics initiative promotes the use Information Visualization support analytical reasoning through sense making loop based which the analysis incrementally builds hypotheses 
3222 en Inference and Learning with Networked Data many applications would like draw inferences about entities that are interconnected complex networks For example calls emails and web pointers link people into huge social networks However traditional statistical and machine learning classification methods assume that entities are independent each other start discussing various applications classification scoring networked data from fraud detection counterterrorism network based marketing then discuss four characteristics networked data that allow improvements sometimes substantial over traditional classification models can take into account guilt association inference can performed collectively whereby inferences linked entities mutually reinforce each other iii characteristics linked entities can incorporated models and models can incorporate specific identifiers such the identities particular individuals improve inference present results demonstrating the effectiveness these techniques 
3223 en Ontologies and Machine Learning address the problem constructing light weight ontology from social network data example use social network mid size research institution obtained based mail communication The main contribution architecture consisting from five major steps that enable transformation the data from given mail transactions recordings ontology estimating the structure the organization Once having set sparse vectors apply approach semi automated ontology construction implemented the OntoGen tool The experiments and illustrative evaluation show that our approach useful and applicable real life situations where the goal model social structures based communication records 
3224 en Ontogen Software Demo address the problem constructing light weight ontology from social network data example use social network mid size research institution obtained based mail communication The main contribution architecture consisting from five major steps that enable transformation the data from given mail transactions recordings ontology estimating the structure the organization Once having set sparse vectors apply approach semi automated ontology construction implemented the OntoGen tool The experiments and illustrative evaluation show that our approach useful and applicable real life situations where the goal model social structures based communication records 
3226 en EEG fMRI correlation analysis data and model driven approach
3227 en  bursts and blobs How link EEG neuronal spikes and fMRI
3228 en From functional elements networks fMRI
3229 en Multimodal Imaging EEG fMRI integration
3230 en New BCI approaches Selective Attention Auditory and Tactile Stimulus Streams
3231 en The Machine Learning Approach Brain Computer Interfacing Part 
3233 en Attention improves object representations cortical activities
3234 en Matching pursuit and unification EEG analysis
3235 en Amplitude and phase patterns encephalographic signals multivariate approaches for movement related brain activity
3236 en EEG Coupling Granger Causality and Multivariate Autoregressive Models
3237 en Multimodal Imaging MEG NIRS integration
3238 en Exploiting temporal delays interpreting EEG MEG data terms brain connectivity
3239 en The Machine Learning Approach Brain Computer Interfacing Part 
3244 en Ontologies semantic web and 
3245 en The Long Road from Text Meaning Computers have given new way thinking about language Given large sample language corpus and computational tools process can approach language physicists approach forces and chemists approach chemicals This approach noteworthy for missing out what from language user point view important about piece language its meaning shall present this empiricist approach the study language and show how develop accurate tools for lemmatisation part speech tagging and parsing move from the raw input character stream analysis that stream increasingly rich terms words lemmas grammatical structures Fillmore style frames Each step the journey builds large corpus accurately analysed the previous levels distributional thesaurus provides generalisations about lexical behaviour which can then feed into analysis the ‘frames level The talk will illustrated with work done within the ‘Sketch Engine tool For much NLP and linguistic theory meaning given Thus formal semantics assumes meanings for words order address questions how they combine and WSD word sense disambiguation typically takes set meanings found dictionary starting point and sets itself the challenge identifying which meaning applies But since the birth philosophy meaning has been problematic our approach meaning eventual output the research programme not input 
3246 en Hidden Topic Markov Models Algorithms such Latent Dirichlet Allocation LDA have achieved significant progress modeling word document relationships These algorithms assume each word the document was generated hidden topic and explicitly model the word distribution each topic well the prior distribution over topics the document Given these parameters the topics all words the same document are assumed independent this work propose modeling the topics words the document Markov chain Specifically assume that all words the same sentence have the same topic and successive sentences are more likely have the same topics Since the topics are hidden this leads using the well known tools Hidden Markov Models for learning and inference show that incorporating this dependency allows learn better topics and disambiguate words that can belong different topics Quantitatively show that obtain better perplexity modeling documents with only modest increase learning and inference complexity Joint work with Michal Rosen Zvi and Yair Weiss 
3247 en Gears and the Mashup Problem Mashups are the most interesting innovation software development decades Unfortunately the browser security model did not anticipate this development mashups are not safe there any confidential information the page Since virtually every page has least some confidential information this big problem Google Gears may lead the solution Speaker Douglas Crockford Douglas Crockford the world foremost living authority JavaScript architect with Yahoo Ajax Strike Force the founder two startups and was Director Technology Lucasfilm Ltd Director New Media Paramount and researcher Atari and SRI 
3248 en The ‘Last Lecture’ Randy Pausch Almost all have childhood dreams for example being astronaut making movies video games for living Sadly most people don achieve theirs and think that shame had several specific childhood dreams and actually achieved most them More importantly have found ways particular the creation with Don Marinelli CMU http etc cmu edu Entertainment Technology Center helping many young people actually achieve their childhood dreams This talk will discuss how achieved childhood dreams being zero gravity designing theme park rides for Disney and few others and will contain realistic advice how you can live your life that you can make your childhood dreams come true too 
3249 en Three Beautiful Quicksorts This talk describes three the most beautiful pieces code that have ever written three different implementations Hoare classic Quicksort algorithm The first implementation bare bones function about dozen lines The second implementation starts instrumenting the first program measure its run time dozen systematic code transformations proceed make more and more powerful yet more and more simple until finally disappears puff mathematical smoke therefore becomes the most beautiful program never wrote The third program industrial strength library Qsort function that built with Doug McIlroy theme running through all three implementations the power elegance and simplicity This talk expands Chapter Beautiful Code edited Oram and Wilson and published Reilly July 2007 
3250 en Topics Biology Organismal Biology
3253 en Evolving Systems One the important research challenges today develop new theoretical methods algorithms and implementations systems with higher level flexibility and autonomy can say with higher level intelligence These systems have able evolve their structure and knowledge the environment and ultimately – evolve their intelligence address the problems modelling control prediction classification and data processing dynamically changing and evolving environment system must able fully adapt its structure and adjust its parameters rather than use pre trained and fixed structure That the system must able evolve self develop self organize self evaluate and self improve The talk will concentrate the problems and results the author encountered during last several years research this emerging area well the approach line identification particular type fuzzy models – called Takagi Sugeno fuzzy models including some applications particular mobile robots mobile communications process modelling and control line evolving classification intelligent inferential sensors 
3254 en Graphical Models the last decade probabilistic graphical models particular Bayes networks and Markov networks became very popular tools for structuring uncertain knowledge about domain interest and for building knowledge based systems that allow sound and efficient inferences about this domain The lecture gives brief introduction into the core ideas underlying graphical models starting from their relational counterparts and highlighting the relation between independence and decomposition Furthermore the basics model construction and evidence propagation are discussed with emphasis join junction tree propagation substantial part the lecture then devoted learning graphical models from data which quantitative learning parameter estimation well the more complex qualitative structural learning model selection are studied 
3255 en Data Quality industry the term „Quality“ used the context “Quality Control Assurance” products and later services has history about one hundred years used ISO norm “Suitability for use relative given objective usage” Looking “Products” and “Processes” one distinguishes between “Quality Design” and “Quality Performance” “Data Quality” term which used Statistical Offices and supranational Organizations OECD NAGroup etc for about the same time became popular computer science twenty years ago when data quality problems related data warehousing ETL data cleansing data mining and data integration were detected Data Quality mostly defined above fitness for use given objective data processing specific domain For example the objective may web mining where semi structured data integrated Evidently the term “data quality” has many various facets Stepwise refining the granularity starting from several data sources single value attribute variable one can differ between multi sources data bases single databases the schema data level records and values For instance the data level errors outliers null values missing values inconsistent incoherent values simply semantic misuse data are concern while the schema level integrity constraints may violated All these factors may lead low data quality 
3256 en Compact and Understandable Descriptions Mixtures Bernoulli Distributions Finite mixture models can used estimating complex unknown probability distributions and also clustering data The parameters the models form complex representation and are not suitable for interpretation purposes such this paper present methodology describe the finite mixture multivariate Bernoulli distributions with compact and understandable description First cluster the data with the mixture model and subsequently extract the maximal frequent itemsets from the cluster specific data sets The mixture model used model the data set globally and the frequent itemsets model the marginal distributions the partitioned data locally present the results understandable terms that reflect the domain properties the data our application analyzing DNA copy number amplifications the descriptions amplification patterns are represented nomenclature used literature report amplification patterns and generally used domain experts biology and medicine 
3257 en Multiplicative Updates for Regularized Linear and Logistic Regression Multiplicative update rules have proven useful many areas machine learning Simple implement guaranteed converge they account part for the widespread popularity algorithms such nonnegative matrix factorization and Expectation Maximization this paper show how derive multiplicative updates for problems regularized linear and logistic regression For –regularized linear regression the updates are derived reformulating the required optimization problem nonnegative quadratic programming NQP The dual this problem itself instance NQP can also solved using multiplicative updates moreover the observed duality gap can used bound the error intermediate solutions For –regularized logistic regression derive similar updates using iteratively reweighted least squares approach present illustrative experimental results and describe efficient implementations for large scale problems interest with tens thousands examples and over one million features 
3258 en Learning align statistical approach present new machine learning approach the inverse parametric sequence alignment problem given training examples set correct pairwise global alignments find the parameter values that make these alignments optimal consider the distribution the scores all incorrect alignments then search for those parameters for which the score the given alignments far possible from this mean measured number standard deviations This normalized distance called the ‘ score’ statistics show that the score function the parameters and can computed with efficient dynamic programs similar the Needleman Wunsch algorithm also show that maximizing the score boils down simple quadratic program Experimental results demonstrate the effectiveness the proposed approach 
3259 en Transductive Reliability Estimation for Kernel Based Classifiers Estimating the reliability individual classifications very important several applications such medical diagnosis Recently the transductive approach reliability estimation has been proved very efficient when used with several machine learning classifiers such Naive Bayes and decision trees However the efficiency the transductive approach for state the art kernel based classifiers was not considered this work deal with this problem and apply the transductive reliability methodology with sparse kernel classifiers specifically the Support Vector Machine and Relevance Vector Machine Experiments with medical and bioinformatics datasets demonstrate better performance the transductive approach for reliability estimation compared reliability measures obtained directly from the output the classifiers Furthermore apply the methodology the problem reliable diagnostics the coronary artery disease outperforming the expert physicians’ standard approach 
3260 en Fast Clustering based Kernel Density Estimation The Denclue algorithm employs cluster model based kernel density estimation cluster defined local maximum the estimated density function Data points are assigned clusters hill climbing points going the same local maximum are put into the same cluster disadvantage Denclue that the used hill climbing may make unnecessary small steps the beginning and never converges exactly the maximum just comes close introduce new hill climbing procedure for Gaussian kernels which adjusts the step size automatically extra costs prove that the procedure converges exactly towards local maximum reducing special case the expectation maximization algorithm show experimentally that the new procedure needs much less iterations and can accelerated sampling based methods with sacrificing only small amount accuracy 
3261 en Visualising the Cluster Structure Data Streams The increasing availability streaming data consequence the continuing advancement data acquisition technology Such data provides new challenges the various data analysis communities Clustering has long been fundamental procedure for acquiring knowledge from data and new tools are emerging that allow the clustering data streams However the dynamic temporal components streaming data provide extra challenges the development stream clustering and associated visualisation techniques this work combine streaming clustering framework with extension static cluster visualisation method order construct surface that graphically represents the clustering structure the data stream The proposed method OpticsStream provides intuitive representations the clustering structure well the manner which this structure changes through time 
3262 en Relational Topographic Maps introduce relational variants neural topographic maps including the self organizing map and neural gas which allow clustering and visualization data given pairwise similarities dissimilarities with continuous prototype updates assumed that the dis similarity matrix originates from Euclidean distances however the underlying embedding points unknown Batch optimization schemes for topographic map formations are formulated terms the given dis similarities and convergence guaranteed thus providing way transfer batch optimization relational data 
3263 en  Support Vector Machine Approach Dutch Part Speech Tagging Part Speech tagging the assignment Parts Speech the words given context use basic technique many systems that handle natural languages This paper describes method for supervised training Part Speech tagger using committee Support Vector Machines large corpus annotated transcriptions spoken Dutch Special attention paid the decomposition the large data set into parts for common uncommon and unknown words This does not only solve the space problems caused the amount data also improves the tagging time The performance the resulting tagger terms accuracy which quite good where the speed the tagger reasonably good 
3264 en Towards Adaptive Web Mining Histograms and Contexts Text Data Clustering present novel approach the growing neural gas GNG based clustering the high dimensional text data enhance our Contextual GNG models proposed previously shift the majority calculations context sensitive local sub graphs and local sub spaces and reduce computational complexity developing new histogram based method for incremental model adaptation and evaluation its stability 
3265 en Does SVM Really Scale Large Bag Words Feature Spaces are concerned with the problem learning classification rules text categorization where many authors presented Support Vector Machines SVM leading classification method Number studies however repeatedly pointed out that some situations SVM outperformed simpler methods such naive Bayes nearest neighbor rule this paper aim developing better understanding SVM behaviour typical text categorization problems represented sparse bag words feature spaces study details the performance and the number support vectors when varying the training set size the number features and unlike existing studies also SVM free parameter which the Lagrange multipliers upper bound SVM dual show that SVM solutions with small are high performers However most training documents are then bounded support vectors sharing same weight Thus SVM reduce nearest mean classifier this raises interesting question SVM merits sparse bag words feature spaces Additionally SVM suffer from performance deterioration for particular training set size number features combinations 
3266 en Incremental Learning with Multiple Classifier Systems Using Correction Filters for Classification Classification quite relevant task within data mining area This task not trivial and some difficulties can arise depending the nature the problem Multiple classifier systems have been used construct ensembles base classifiers order solve alleviate some those problems One the most current problems that being studied recent years how learn when the datasets are too large when new information can arrive any time that case incremental learning approach that can used Some works have used multiple classifier system learn incremental way and the results are very promising The aim this paper propose method for improving the classification prediction accuracy reached multiple classifier systems this context 
3267 en Combining Bagging and Random Subspaces Create Better Ensembles Random forests are one the best performing methods for constructing ensembles They derive their strength from two aspects using random subsamples the training data bagging and randomizing the algorithm for learning base level classifiers decision trees The base level algorithm randomly selects subset the features each step tree construction and chooses the best among these propose use combination concepts used bagging and random subspaces achieve similar effect The latter randomly select subset the features the start and use deterministic version the base level algorithm and thus somewhat similar the randomized version the algorithm The results our experiments show that the proposed approach has comparable performance that random forests with the added advantage being applicable any base level algorithm without the need randomize the latter 
3268 en Two Bagging Algorithms with Coupled Learners Encourage Diversity this paper present two ensemble learning algorithms which make use boostrapping and out bag estimation attempt inherit the robustness bagging overfitting against bagging with these algorithms learners have visibility the other learners and cooperate get diversity characteristic that has proved issue major concern ensemble models Experiments are provided using two regression problems obtained from UCI 
3269 en Relational Algebra for Ranked Tables with Similarities Properties and Implementation The paper presents new developments extension Codd’ relational model data The extension consists equipping domains attribute values with similarity relation and adding ranks rows database table This way the concept table over domains relation over relation scheme the classical Codd’ model extends the concept ranked table over domains with similarities When all similarities are ordinary identity relations and all ranks are set our extension becomes the ordinary Codd’ model The main contribution our paper twofold First present outline relational algebra for our extension Second deal with implementation issues our extension addition that also comment related approaches presented the literature 
3270 en  New Way Aggregate Preferences Application Eurovision Song Contests Voting systems have great impact the results contests elections Simple methods are actually used whereas they not provide most accurate results For example the Eurovision Song Contest the winner may not the most preferred candidate Condorcet criterion which consists preserving most the individual votes the final ranking seems intuitively the most relevant this paper propose new ranking method founded Condorcet voting count principle which minimizes the number pairwise inversions the individual preferences propose two step method computing the cycles among vote preferences and removing minimal set pairwise preferences erase all the cycles and turn the votes into partial order close possible total order Finally evaluate the impact our ranking procedure the last Eurovision Song Contests 
3271 en Noise Filtering and Microarray Image Reconstruction Via Chained Fouriers Microarrays allow biologists determine the gene expressions for tens thousands genes simultaneously however due biological processes the resulting microarray slides are permeated with noise During quantification the gene expressions there need remove gene’ noise background for purposes precision This paper presents novel technique for such background removal process The technique uses gene’ neighbour regions representative background pixels and reconstructs the gene region itself such that the region resembles the local background With use this new background image the gene expressions can calculated more accurately Experiments are carried out test the technique against mainstream and alternative microarray analysis method Our process shown reduce variability the final expression results 
3272 en Soft Topographic Map for Clustering and Classification Bacteria this work new method for clustering and building topographic representation bacteria taxonomy presented The method based the analysis stable parts the genome the called “housekeeping genes” The proposed method generates topographic maps the bacteria taxonomy where relations among different type strains can visually inspected and verified Two well known DNA alignement algorithms are applied the genomic sequences Topographic maps are optimized represent the similarity among the sequences according their evolutionary distances The experimental analysis carried out 147 type strains the Gammaprotebacteria class means the 16S rRNA housekeeping gene Complete sequences the gene have been retrieved from the NCBI public database the experimental tests the maps show clusters homologous type strains and presents some singular cases potentially due incorrect classification erroneous annotations the database 
3273 en Making Time Pseudo Time Series for the Temporal Analysis Cross Section Data The progression many biological and medical processes such disease and development are inherently temporal nature However many datasets associated with such processes are from cross section studies meaning they provide snapshot particular process across population but not actually contain any temporal information this paper address this constructing temporal orderings cross section data samples using minimum spanning tree methods for weighted graphs call these reconstructed orderings pseudo time series and incorporate them into temporal models such dynamic Bayesian networks Results from our preliminary study show that including pseudo temporal information improves classification performance conclude outlining future directions for this research including considering different methods for time series construction and other temporal modelling approaches 
3274 en Recurrent Predictive Models for Sequence Segmentation Many sequential data sets have segmental structure and similar types segments occur repeatedly consider sequences where the underlying phenomenon interest governed small set models that change over time Potential examples such data are environmental genomic and economic sequences Given target sequence and possibly multivariate sequence observation values consider the problem finding small collection models that can used explain the target phenomenon piecewise fashion using the observation values assume the same model will used for multiple segments give algorithm for this task based first segmenting the sequence using dynamic programming and then using median facility location techniques find the optimal set models report some experimental results 
3275 en Sequence Classification Using Statistical Pattern Recognition Sequence classification significant problem that arises many different real world applications The purpose sequence classifier assign class label given sequence Also obtain the pattern that characterizes the sequence usually very useful this paper technique discover pattern from given sequence presented followed general novel method classify the sequence This method considers mainly the dependencies among the neighbouring elements sequence order evaluate this method UNIX command environment presented but the method general enough applied other environments 
3276 en  Partial Correlation Based Algorithm for Causal Structure Discovery with Continuous Variables present algorithm for causal structure discovery suited the presence continuous variables test version based partial correlation that able recover the structure recursive linear equations model and compare the well known algorithm large networks generally outperformed run time and number structural errors 
3277 en Fuzzy Logic Based Gait Classification for Hemiplegic Patients this study fuzzy logic classification system was used first discriminate healthy subjects from patients rather than classifying those using Brunnstrom stages Decision making was performed two stages feature extraction gait signals and the fuzzy logic classification system which used Tsukamato type inference method According our signal feature extraction studies focused temporal events and symetrical features gait signal Developed system has six inputs while four them for temporal features evaluation rule block and two them symmetrical features evaluation rule block Our simulation test results showed that proposed system classify correctly 100 subjects patient and healthy elderly The correlation coefficient was found for classification subjects correct Brunnstrom stages The results show that classifying patients becomes increasingly difficult linearly according hemiplegia’ severity 
3278 en Traffic Sign Recognition Using Discriminative Local Features Real time road sign recognition has been great interest for many years This problem often addressed two stage procedure involving detection and classification this paper novel approach sign representation and classification proposed many previous studies focus was put deriving set discriminative features from large amount training data using global feature selection techniques Principal Component Analysis AdaBoost our method have chosen simple yet robust image representation built top the Colour Distance Transform CDT Based this representation introduce feature selection algorithm which captures variable size set local image regions ensuring maximum dissimilarity between each individual sign and all other signs Experiments have shown that the discriminative local features extracted from the template sign images enable simple minimum distance classification with error rate not exceeding 
3279 en Novelty Detection Patient Histories Experiments with Measures Based Text Compression Reviewing patient history can very time consuming partly because the large number consultation notes Often most the notes contain little new information Tools facilitating this and other tasks could constructed had the ability automatically detect the novel notes propose the use measures based text compression approximation Kolmogorov complexity for classifying note novelty define four compression based and eight other measures evaluate their ability predict the presence previously unseen diagnosis codes associated with the notes patient histories from general practice The best measures show promising classification ability which while not enough serve alone clinical tool might useful part system taking more data types into account The best individual measure was the normalized asymmetric compression distance between the concatenated prior notes and the current note 
3280 en Parameter Learning for Bayesian Networks with Strict Qualitative Influences propose new method for learning the parameters Bayesian network with qualitative influences The proposed method aims remove unwanted context specific independencies that are created the order constrained maximum likelihood OCML estimator This achieved averaging the OCML estimator with the fitted probabilities first order logistic regression model show experimentally that the new learning algorithm does not perform worse than OCML and resolves large part the independencies 
3281 en Tree Augmented Naive Bayes for Regression Using Mixtures Truncated Exponentials Application Higher Education Management this paper explore the use Tree Augmented Naive Bayes TAN regression problems where some the independent variables are continuous and some others are discrete The proposed solution based the approximation the joint distribution Mixture Truncated Exponentials MTE The construction the TAN structure requires the use the conditional mutual information which cannot analytically obtained for MTEs order solve this problem introduce unbiased estimator the conditional mutual information based Monte Carlo estimation test the performance the proposed model real life context related higher education management where regression problems with discrete and continuous variables are common This work has been supported the Spanish Ministry Education and Science project TIN2004 06204 C03 and Junta Andalucía project P05 TIC 00276 
3282 en Conditional Classification Trees Using Instrumental Variables The framework this paper supervised learning using classification trees Two types variables play role the definition the classification rule namely response variable and set predictors The tree classifier built recursive partitioning the prediction space such provide internally homogeneous groups objects with respect the response classes the following consider the role played instrumental variable stratify either the variables the objects This yields introduce tree based methodology for conditional classification Two special cases will discussed grow multiple discriminant trees and partial predictability trees These approaches use discriminant analysis and predictability measures respectively Empirical evidence their usefulness will shown real case studies 
3283 en Robust Tree Based Incremental Imputation Method for Data Fusion Data Fusion and Data Grafting are concerned with combining files and information coming from different sources The problem not extract data from single database but merge information collected from different sample surveys The typical data fusion situation formed two data samples the former made complete data matrix relative first survey and the latter which contains certain number missing variables The aim complete the matrix beginning from the knowledge acquired from the Thus the goal the definition the correlation structure which joins the two data matrices merged this paper provide innovative methodology for Data Fusion based incremental imputation algorithm tree based models addition consider robust tree validation boosting iterations relevant advantage the proposed method that works for mixed data structure including both numerical and categorical variables benchmarking methods consider explicit methods such standard trees and multiple regression well implicit method based principal component analysis widely extended simulation study proves that the proposed method more accurate than the other methods 
3284 en Visualizing Sets Partial Rankings Partial rankings are totally ordered subsets set items They arise different applications such clickstream analysis and collaborative filtering but can difficult analyze with traditional data analysis techniques they are combinatorial structures propose method for creating scatterplots sets partial rankings first representing them high dimensional space and then applying known dimensionality reduction methods compare different approaches using quantitative measures and demonstrate the methods real data sets from different application domains Despite their simplicity the proposed methods can produce useful visualizations that are easy interpret 
3285 en  Partially Supervised Metric Multidimensional Scaling Algorithm for Textual Data Visualization Multidimensional Scaling Algorithms MDS allow visualize high dimensional object relationships intuitive way interesting application the MDS algorithms the visualization the semantic relations among documents terms textual databases However the MDS algorithms proposed the literature exhibit low discriminant power The unsupervised nature the algorithms and the ’curse dimensionality’ favor the overlapping among different topics the map This problem can overcome considering that many textual collections provide frequently categorization for small subset documents this paper define new semi supervised measures that reflect better the semantic classes the textual collection considering the priori categorization subset documents Next the dissimilarities are incorporated into the Torgerson MDS algorithm improve the separation among topics the map The experimental results show that the model proposed outperforms well known unsupervised alternatives 
3286 en Landscape Multidimensional Scaling revisit the problem representing high dimensional data set distance preserving projection onto two dimensional plane This problem solved well known techniques such multidimensional scaling There the data projected onto flat plane and the Euclidean metric used for distance calculation real topographic maps however travel distance time not determined Euclidean distance alone but also influenced map features such mountains lakes investigate how utilize landscape features for distance preserving projection first approach with rectangular cylindrical mountains the MDS landscape presented 
3288 en Entropy Properties Decision Rule Class Connection with machine learning abilities Many methods Machine Learning are based the idea empirical risk minimisation find decision rule model from some set which most perfectly fits the data presented the training set This idea based the large number law empirical risk converges real risk the training set large enough But the class decision rules models too large some sense one meets the problem oferfitting the model perfectly corresponds the data presented the training set but shows large errors new data due the fact that only uniform convergence empirical risk the real risk guarantees closeness the optimal model behaviour the training set and the new data introduce the notion entropy decision rule class over fixed sample sequence log the number possible classifications the sequence the rules the class Maximum entropy over sequences fixed length determines sufficient condition the uniform convergence and corresponding estimates But only average entropy behaviour determine necessary and sufficient condition the uniform convergence The condition that average entropy per symbol should zero when the sequence length goes infinity the condition does not hold then there exists set objects with non zero probability measure such that almost all sequences arbitrary finite length from this set may divided all possible ways the rules the class One can easily see that this case overfitting inevitable Similar results are found for real dependencies instead decision rules 
3289 en Ground Facts Rules and Probabilistic Inference for Cyc One aspect Cyc very large logic based knowledge base that includes inter alia large amounts background knowledge over wide variety domains but more than that the Cyc project attempt move towards general artificial intelligence supporting automated reasoning about very wide variety real world concerns support that goal Cyc also encompasses obviously enough and inference engine able reason over large contextual knowledge base but also includes components for interpreting and producing natural language acquiring knowledge and responding user queries and for interfacing with other software Applying logic representation general knowledge scale and using the production intelligent behaviors has been difficult enough unfortunately becoming clear that doing using traditional logics probably not sufficient either for satisfying long term goal supporting general intelligence even for shorter term goals like recognizing interpreting and elaborating descriptions piracy events this talk briefly describe what Cyc and has been and how growing touch early approach abductive reasoning and classification traditional logical framework and some difficulties with that approach and then describe recent very initial work training the Markov Logic networks based ground facts and rules within the millions axioms the Cyc Finally sketch vision for system that truly integrates both sound deductive reasoning and the bounded unsoundness probabilistic classification induction abduction and deduction 
3290 en Really Achieving Your Childhood Dreams “The brick walls are there for reason they are not there keep out they let prove how badly want something ” 
3291 en CERN 27km Big Bang machine Presentation the http lhc web cern lhc Large Hadron Collider and the http atlasexperiment org Atlas Experiment happening under your feet here Geneva 
3293 en Outdoctrination Society Children Technology and Self Organisation Education
3294 en Distorted Morality Speech Harvard University about America war terror
3295 en PVC and cooperation from perspective
3298 en Text and web data mining Tutorial 
3299 en Text and web data mining Tutorial 
3304 en  practical experience CAVE laboratory
3307 en The Graphing Calculator Story midnight been working sixteen hours day seven days week not being paid fact project was canceled six months ago evading security sneaking into Apple Computer main offices the heart Silicon Valley doing clandestine volunteer work for eight billion dollar corporation http www pacifict com Story more www pacifict com Story 
3309 en Agent technologies for demonstrations MAS Tutorial
3310 en Knowledge technologies for network organisations This lecture presents the current research work JSI Knowledge technologies and potentials these technologies have solve problems Networked organisations Some real prototypes and solutions has been presented well some visionary plans 
3314 en The State the Oceans Jeremy Jackson marine ecologist and environmental advocate professor oceanography the Scripps Institution Oceanography describes how overfishing habitat destruction global warming and other human induced activities have contributed crisis the health the world oceans
3315 en How the Body Fights Infection Miniaturized battles are waged continuously heroic micro warriors that protect from viruses bacteria fungi and parasites Join Richard Locksley for look how these unseen victories and occasional defeats are played out and how vaccination stacks the deck our favor 
3322 en Nanowires and Nanocrystals for Nanotechnology Nanowires and nanocrystals represent important nanomaterials with one dimensional and zero dimensional morphology respectively Here will give overview the research about how these nanomaterials impact the critical applications faster transistors smaller nonvolatile memory devices efficient solar energy conversion high energy battery and nanobiotechnology
3325 en WTC Lecture collapse WTC Buildings BYU Physics professor and founder SCHOLARS FOR TRUTH Steven Jones presents his presentation the collapse WTC Buildings 160 and very informative and scientific presentation that raises serious questions about the official account the collapse the World Trade Center Towers and Building nbsp nbsp 
3326 en  Economic Response Unsolicited Communication
3327 en The Paradox Choice Why More Less
3328 en NASA Beyond Einstein Program Exploration the Limits Space Time Albert Einstein General Theory Relativity predicted results that were incredible that even did not accept them space expanding from Big Bang space itself contains energy that pulling the Universe apart from within and deep chasms gravity called black holes actually exist Astonishingly all these wild ideas are now known true But now need build Einstein work take the next step study the underlying physics the very phenomena that came out his theories NASA Beyond Einstein program consists series space missions large and small that push Einstein theories their limits using increasingly more sensitive probes The two flagship missions now development Constellation and LISA will explore extremes space measuring rays and gravitational waves The smaller missions the Einstein probes will target specific science questions such What Dark Energy and What powered the Big Bang 
3330 en Cost effective Outbreak Detection Networks Which blogs should read avoid missing important information Where should place sensors water distribution network quickly detect contaminants These seemingly different problems share common structure Outbreak detection can modeled problem selecting nodes blogs sensor locations network order detect the spreading virus information quickly possible present general methodology for near optimal sensor placement these and related problems demonstrate that many realistic outbreak detection objectives detection likelihood population affected exhibit the property “submodularity’’ exploit submodularity develop efficient algorithm that scales large problems provably achieving near optimal placements while being 700 times faster than simple greedy algorithm evaluate our approach several large real world problems including model water distribution network and real blog data also show how the approach leads deeper insights both applications answering multicriteria trade off cost sensitivity and generalization questions Joint work with Andreas Krause Carlos Guestrin Christos Faloutsos Jeanne VanBriesen and Natalie Glance Recepient best student paper award ACM SIGKDD ‘ conference 
3331 en Explanation SVM behaviour text classification are concerned with the problem learning classification rules text categorization where many authors presented Support Vector Machines SVM leading classification method Number studies however repeatedly pointed out that some situations SVM outperformed simpler methods such naive Bayes nearest neighbor rule this paper aim developing better understanding SVM behaviour typical text categorization problems represented sparse bag words feature spaces study details the performance and the number support vectors when varying the training set size the number features and unlike existing studies also SVM free parameter which the Lagrange multipliers upper bound SVM dual show that SVM solutions with small are high performers However most training documents are then bounded support vectors sharing same weight Thus SVM reduce nearest mean classifier this raises interesting question SVM merits sparse bag words feature spaces Additionally SVM suffer from performance deterioration for particular training set size number features combinations 
3332 en Energy Efficient Transistors Major technological shifts solid state device technology have typically been associated with improvements device energy efficiency This was true the transition from vacuum tubes bipolar transistors the 1950s and then again from bipolar transistors MOSFETs the 1970s The next technological revolution will similarly stem from improvement energy efficiency the device the circuit level This lecture will explore ways which new materials and transistors can extend the performance electronic systems 
3333 en Introduction Active Networks The goal active networking create communication networks that reposition static low level network operation into dynamic differentiated and adaptable behavior This allows communication hardware more fully used given that its operation can tailored specific application requirements This also enables more flexible and survivable communication network Active networking decouples the network protocol from its transport allowing easy insertion protocols top the transport layer Active networking also minimizes requirements for global agreement does not require years standards negotiation introduce new protocols Active networking enables the fly experimentation given easy insertion new protocols and network applications thus enabling the rapid deployment new services and applications The mechanism for implementing active network enable communication packets carry network code well data This code may installed the fly into low level network devices the packet flows throughout the network Ultimately the essence and fundamental uniqueness active networking the flexibility introduced tight integration code and data service the communication network Both code and data flow within and change the operation the network Legacy networks have focused improving the flow data based the fundamentals analyses such Shannon’ fundamental insights into entropy well analyses support moving bits such queuing theory With the tighter integration code and data active network broader view information encompassing both code and data the form Kolmogorov complexity required this form analysis there focus code and data combined entity Active packets the Kolmogorov complexity framework may vary from static data legacy networks pure executable code code the packets act small executable models information This presentation delves into some these issues 
3336 en Future Technology Google chairman and CEO Eric Schmidt
3337 en Interview with Santiago Calatrava Santiago Calatrava Architect Visuals Milwaukee Art Museum City Science and various buildings bridges
3338 en Stanford Experts Climate Change and Carbon Trading Schneider one the world leading scientific experts climate change his name cited all those climate change charts and graphs seen far Heller has extensive experience with policy and negotiations surrounding climate change and sustainable development Professor Heller also recently served Sergey host the recent Climate Change Conference meeting Montreal where Prof Heller proved his indepth knowledge thenuances legislative works such the Kyoto Protocol and the mechanisms that are currently being employed 
3343 en The International involvement the JSI Institute
3344 en The International involvement Jonneum Research and the JSI Institute
3346 en About the Cooperation Jonneum Research and the JSI Institute
3349 en Wireless Tech Regulatory Reality Policy and Fantasy the 21st Century Sascha Meinrath has been described http www savetheinternet com coalition community Internet pioneer and http infodev study oplan org the study background and introduction copy4 background and introduction entrepreneurial visionary and well known expert http wikipedia org wiki Wireless community network community wireless networks CWNs and http wikipedia org wiki Municipal broadband municipal broadband Leading news sources including http www economist com science displayStory cfm story 3535732 the Economist http www nytimes com 2006 technology circuits 27fon html 1160539200 53c38adbd350e304 5070 the New York Times http www thenation com blogs edcut pid 77928 the Nation and http www npr org templates story story php storyId 4834612 National Public Radio often cite Sascha work covering issues related CWNs Sascha the Research Director for the http www newamerica net New America Foundation http www spectrumpolicy org Wireless Future Program Additionally coordinates the http www oswc net Open Source Wireless Coalition global partnership open source wireless integrators researchers implementors and companies dedicated the development open source interoperable low cost wireless technologies regular contributor http www muniwireless com MuniWireless com the leading source for municipal wireless news and information and regular contributor http govtech net digitalcommunities Government Technology Digital Communities the online portal and comprehensive information resource for the public sector Sascha has also worked with http www freepress net Free Press the http www caida org the Cooperative Association for Internet Data Analysis CAIDA the http www acornactivemedia com Acorn Active Media Foundation the http www ethoswireless com Ethos Group and the http www cuwin net CUWiN Foundation Sascha holds Bachelor Degree from http www yale edu Yale University and Master Degree from the http www psych uiuc edu University Illinois Urbana Champaign both psychology Telecommunications Fellow the University Illinois the http www comm uiuc edu icr Institute for Communications Research where finishing his PhD community empowerment and the impacts and interactions participatory media wireless communications and emergent technologies more http www saschameinrath com saschameinrath com 
3353 en Sequential Monte Carlo methods continued Parts and this lecture are presented mlss07 doucet smcm Arnaud Doucet title 
3354 en  Turing Machine Yours The title this talk “Your Turing Machine Mine ” What alluding with this title the universality universal Turing machine and the same time the fact that there are many different universal Turing machines with somewhat different properties Universal Turing machines are both universal and individual different senses universal Turing machine one that can emulate imitate any other Turing machine and thus sense can undertake compute any very large class computable functions But there are indefinitely large number universal Turing machines that can defined 
3355 en Linguistically informed statistically driven induction morphology Problem induction morphology from unannotated text Main idea knowledge linguistic and statistical properties morphology allows for simple induction algorithm Develops ideas from previous work Goldsmith 2001 Schone amp Jurafsky 2000 Yarowsky amp Wicentowski 2000 2004 
3356 en Incrementally learning Incremental parser What the relation between the language surface statistics and its hidden syntactic structure explore this the author presents unsupervised parser Some the properties natural language that are used Tree structures are skewed Humans process language incrementally Words have the Zipfian distribution Bootstrapping learning 
3357 en Linguistic Relevance Unsupervised Data Oriented Parsing Empiricist Language Acquisition Possible Can acquire language constructing analogies with previous input 
3358 en  New Way look Networking Today research community congratulates itself for the success the internet and passionately argues whether circuits datagrams are the One True Way Meanwhile the list unsolved problems grows Security mobility ubiquitous computing wireless autonomous sensors content distribution digital divide third world infrastructure etc are all poorly served what available from either the research community the marketplace use various strained analogies and contrived examples argue that network research moribund because the only thing knows how fill the details conversation between two applications Today the 60s problems unsolved due our tunnel vision and not because their intrinsic difficulty And now like then simply changing our point view may make many hard things easy 
3359 en Unsupervised Learning Syntactic Structure Probabilistic models language Everybody knows that language variable Sapir 1921 Probabilistic models give precise descriptions variable uncertain world The choice for language isn’ dichotomy between rules and neural networks Probabilistic models can used over rich linguistic representations They support inference and learning There’ not much evidence poverty the stimulus preventing them being used 
3360 en Words puddles sound Words “sea sound” Saffran 2001 Discovering words from continuous speech with reliable cues word boundaries Jones 1918 Liberman 1967 where words are realised variably Pollack Pickett 1964 
3361 en Simulating Language Acquisition Many models Language Acquisition focus learnability problem Aim show that certain problematic constructions can learnt Often use artificial input toy grammars Output does not map onto child speech error output vector larger for ungrammatical items unclear how this relates actual error rates Implications outside the phenomenon under investigation can unclear 
3362 en Latent Semantic Grammar Induction Supervised Grammar Induction works great but expensive time consuming and area specific Unsupervised Grammar Induction more general solution can explore knowledge required hidden syntax projectivity prior distributions semantics 
3363 en Memory Based models inflectional morphology acquisition and processing Old and recent results using Memory Based Learning inflectional morphology Pinker fruit fly psycholinguistics Memory based learning with TiMBL learning storage Cases English and Dutch past tense more interesting German plural and Dutch plural Computational psycholinguistics methodology 
3364 en  Bayesian approach the Poverty the stimulus Shown that given reasonable domain general assumptions unbiased rational learner could realize that languages have hierarchical structure based typical child directed input Can use this paradigm explore the role recursive elements grammar the “winning” grammar contains additional non recursive counterparts for complex NPs perhaps language while fundamentally recursive contains duplicate non recursive elements that more precisely match the input 
3365 en Grammatical Inference Grammar Induction the Data the Method Why study the algorithms and not the grammars Learning the exact setting Learning probabilistic setting 
3366 en Using Minimum Description Length make Grammatical Generalizations What should Syntactic Theory Explain Which sentences are grammatical and which are not how transform observed sentences into grammar 
3367 en Learning Phonotactic Constraints from Continuous Speech Native listeners Dutch use knowledge legal and illegal sound sequences their language detect word boundaries continuous speech McQueen 1998 Such knowledge can modeled within the framework Optimality Theory set phonotactic constraints While many researchers within assume that constraints are innate this paper aims show that phonotactic constraints can learned from data 
3368 en From Unsegmented Speech Lexical Categories Using Phoneme Distributions Advantages Computational Modeling Language Mediates between theory and data evaluation exploration existence proofs Requires making underlying assumptions explicit can illuminate complex relationships between variables not easily grasped intuitively make behaviorally testable predictions human subjects approval required 
3369 en  Bayesian approach Word Segmentation Theoretical and Experimental results Word segmentation One the first problems infants must solve when learning language Infants make use many different cues phonotactics allophonic variation metrical stress patterns effects coarticulation and statistical regularities syllable sequences Statistics may provide initial bootstrapping used very early Thiessen Saffran 2003 language independent 
3370 en Bayesian models cross situational word learning
3371 en  annotated hierarchies model syntactic categories The role syntactic categories part speech tags linguistic description hierarchical organization categories factors syntactic categorization Presents computational model for induction hierarchical structure from relational and feature data Presents the results the application the model relational and feature data obtained from natural and artificial corpora 
3372 en Modeling semantic plausibility and the influence visual context during line sentence comprehension Area research the processes that underlie the human capacity understand language How does the human language processor work Architectures mechanisms How can model computationally Understanding Competence Behaviour Performance Interaction language with other cognitive systems and the environment 
3373 en Ecology bird populations the Pacific Flyways Hear straight from California experts about the threat global bird flu epidemic The following research scientists and public health experts from Davis and other Northern California organizations addressed the gamut common concerns Avian Influenza Symposium held Davis Calif April 2006 Organized the Yolo Audubon Society the program particularly emphasized the role that wild birds might play spreading avian influenza humans 
3374 en Biology Four Dimensions How early birds get time catch the worms clock our brains helps maintain daily circadian rhythms Joseph 160 Takahashi discusses the natural history biological rhythms and explains how and other scientists have unraveled the complex workings the body’ clocks Biological clocks are key understanding jet lag various sleep disorders and why teenagers have hard time rising early 
3376 en Science very high magnetic fields NMR investigations exotic quantum spin states After short introduction presenting Grenoble High Magnetic Field Laboratory and its high field NMR facility will illustrate possibilities high field NMR Solid State Physics several examples low dimensional quantum antiferromagnetic spin systems further focus two types dimer spin systems which give raise very different ground states under applied magnetic field One example the Shastry Sutherland compound SrCu2 BO3 which exhibits magnetization plateaus fractional values the saturation magnetization this compound plateaus appear because the kinetic energy the triplet excitations strongly reduced frustration that the triplets can crystallize into commensurate super lattice NMR signature such super lattice the magnetization plateau SrCu2 BO3 unique observation this type magnetization plateau created spontaneous breaking translational symmetry shall also discuss some new results the magnetic ground states fields above the plateau above which seemed candidate for supersolid phase Another type spin system represented the called Han purple compound BaCuSi2O6 for which there magnetic frustration and which Bose Einstein condensation triplet excitations occurs above shall present microscopic picture this complicated high field phase which NMR data reveal that the average boson density the condensate strongly modulated along the direction perpendicular the planes with density ratio for every second plane 
3379 en Bayesian Inference Mechanistic Systems Models Using Population MCMC demonstrate how Population Markov Chain Monte Carlo techniques may used sample from the complex posterior distributions which arise when estimating parameters over nonlinear mechanistic mathematical models biological processes given noisy data Further show how the samples obtained may employed using Power Posteriors method accurately calculate the marginal likelihoods and Bayes factors over such models 
3380 en Parameter estimation ODE using Support Vector Regression and Qualitative Constraints Dynamical systems used for the modeling biological networks such gene regulatory networks metabolic networks are generally based Ordinary Differential Equations ODE Although nonlinear ODE are commonly used Systems Biology their identification and estimation from real data remain difficult task because the high number parameters estimate compared with the relatively few number observations 
3381 en Reconstructing hidden protein activity nonparameteric methods Most the cellular processes are not accessible direct measurements For example the level protein activities can often only assessed indirectly their effects gene expression the modification other proteins The exact form the functional relationships describing such interactions are unknown well Nevertheless some progress can made combining factor analysis dynamical models with nonparametric regression methods which don impose any form reconstructed functions the other hand identifiability becomes are major problem and needs balanced against flexibility will report our experience with simulated and experimental data exploring the limits reconstructing hidden protein activities and interaction networks 
3382 en  study MCMC and deterministic approximations for hypothesis testing using ODE models this talk present comparison different methods testing alternative hypotheses expressed using ODE models biological systems investigated applicability limitations and stability range hypotheses testing methods including maximum likelihood based information criteria local deterministic approximations around maximum posteriori estimates Laplace approximations for computing marginal likelihoods importance sampling based marginal likelihood estimators and path sampling estimator built upon the principles thermodynamic integration 
3383 en From Physiologically Based Pharmacokinetic Modelling toward System Biology Pharmacokinetic modelling has had since the beginning systemic approach the description chemicals absorption distribution metabolism and excretion from the body The earliest models were physiological and mechanistic the sense that they started from mathematical description the body organs given composition and properties linked blood flow For while the lack fast methods for solving differential equation systems led the formulation and use empirical and much simpler compartmental models Interest physiologically based PBPK modelling has persisted however toxicology where data are sparse and where transpositions from animals humans are best grounded physiology and biochemistry Advances Bayesian numerical analysis now allow rigorous inferences for PBPK models including the context complex data structures hierarchical population models 
3384 en Gene regulatory network reconstruction Bayesian integration prior knowledge and different experimental conditions There have been various attempts improve the reconstruction gene regulatory networks from microarray data the systematic integration biological prior knowledge Our approach follows the Bayesian paradigm where the prior knowledge expressed terms energy functions from which prior distribution over network structures obtained the form Gibbs distribution The hyperparameters this distribution represent the weights associated with the prior knowledge relative the data have derived and tested MCMC scheme for sampling networks and hyperparameters simultaneously from the posterior distribution thereby automatically learning how trade off information from the prior and the data have extended this approach Bayesian coupling scheme for learning gene regulatory networks from combination related data sets that were obtained under different experimental conditions and are therefore potentially associated with different active subpathways 
3385 en Weak noise approximate inference for diffusion models The modelling the Stochastic Kinetics biochemical networks stochastic differential equations SDE has been successfully used basis for statistical inference for such models Since Monte Carlo based inference can time consuming for SDEs suggest different approximate approach The idea that diffusion model applies well chemical kinetics when the number molecules each type large this limit also the number uctuations are small leading small diffusion term compared the drift This suggests the application weak noise expansion 
3386 en Variational Inference for Markov Jump Processes Markov jump processes MJPs underpin our understanding many important systems science and technology They provide rigorous probabilistic framework model the joint dynamics groups species interacting individuals with applications ranging from information packets telecommunications network epidemiology and population levels the environment These processes are usually non linear and highly coupled giving rise non trivial steady states often referred emerging properties Unfortunately this also means that exact statistical inference unfeasible and approximations must made the analysis these systems traditional approach which has been very successful throughout the past century ignore the discrete nature the processes and approximate the stochastic process with deterministic process whose behaviour described system non linear coupled ODEs This approximation relies the stochastic fluctuations being negligible compared the average population counts There are many important situations where this assumption untenable for example stochastic fluctuations are reputed responsible for number important biological phenomena from cell differentiation pathogen virulence Researchers are now able obtain accurate estimates the number macromolecules certain species within cell prompting need for practical statistical tools handle discrete data 
3387 en Mathematical Modeling Cell Signalling Pathways recent years the analysis cell signalling systems through data based models ordinary differential equations ODE other paradigms stochastic models has emerged invaluable tool understand the underlying complexity the protein interactions happening cellular signal transduction Compared with other biochemical systems the modelling cell signalling systems faces additional difficulties related the challenges quantifying protein protein processes but also the lack complete information about the topology the considered network interactions Since most the metabolic systems the complete network interactions virtually perfectly established cell signalling systems the real structure the pathways open question elucidated either parallel through mathematical modelling based analysis this talk discuss the use power law models advantages and challenges biochemical systems also show how pre existent biological knowledge and quantitative data can integrated through mathematical modelling validate hypothesis about the structure signalling pathways 
3388 en Towards Polymer Model Genetic Recombination Homologous recombination refers the shuffling genetic material during cellular division meiosis and mitosis and response environmentally induced genetic damage occurs preferentially over certain regions and notably influenced physical compartmentalization due chromosome packing Although number experimental techniques exist for identifying such effect they are generally costly and time consuming Here suggest Bayesian approach recom bination with mechanistic prior such that may infer posterior distributions for recombination frequencies and efficiencies between regions where experimental data may absent 
3389 en  software tool for Bayesian inference ODE Biochemical Models extendable software platform was developed enable model parameter inference and model comparison ODE models biochemical systems The software accepts ODE models defined using either SBML language experimental data from plain files spreadsheets and performs model parameter inference using Markov Chain Monte Carlo methods The software also implements several methods for computing marginal likelihoods which are required for model comparison 
3391 en Introduction Basic Notions Graph Theory the beginning examples and applications configurations are shown nBasic definitions graph theory follow 
3392 en Isomorphism Matrices and Graph Invariants Subgraphs and Connectivity Graphs
3394 en Basic and Advanced Operations Graphs
3396 en Money Debt Paul Grignon minute animated presentation Money Debt tells very simple and effective graphic terms what money and how being created entertaining way get the message out The Cowichan Citizens Coalition and its Duncan Initiative received high praise from those who previewed recommend painless but hard hitting educational tool and encourage the widest distribution and use all groups concerned with the present unsustainable monetary system Canada and the United States More http www moneyasdebt net moneyasdebt net 
3399 en Semi supervised Learning for Text Classification
3401 en  Graphical Model the Local Structure Proteins
3403 en  Kernel based Nonlinear Approach for Time Series Forecast
3404 en Catching Faster Bayesian Model Selection and Model Averaging
3405 en Probabilistic Counting Algorithms for Massive Data Streams
3407 en Transductive Rademacher Complexity and its Applications
3408 en Ensemble Systems for Incremental and Nonstationary Learning
3409 en Supervised Learning Matrices with the Dual Spectral Regularization
3410 en Discovering the Truth Conducting Experiments
3414 en Automatic Techniques for Extracting Semantic Data from text and media Using the results number large European projects Fabio will outline the main issues for acquiring ontological knowledge from text and media large scale lot the work described here based collaborations with the jet engine company Rolls Royce This session will give attendees insights into how information extraction techniques can support the population ontologies with data 
3417 en Polynitrogen Chemistry Podan pregled dela podro kemije polidu ikovih spojin spojin visoko vsebnostjo ika Prikazana sinteza karakterizacija novih polidu ikovih ionov N3NOF N7O Opisani bodo napori kombinacijo kationa visoko energijskimi anioni kot NO3 ClO4 
3418 en Potential and limitations minimally supervised botstrapping The detection relation instances central functionality for the extraction structured information from unstructured textual data and for gradually turning texts into semi structured information With respect the acquisition the classifiers detection grammars the existing approaches fall three large categories detection classifiers grammars acquired through intellectual human labor detection classifiers grammars acquired through supervised learning detection classifiers grammars acquired through unsupervised minimally supervised learning the talk will provide examples for the classes approaches and summarize their respective advantages and disad¬vantages will argue that different relation detection tasks require different methods even different combinations methods One empirically promising and theoretically attractive line research the learning extraction rules from seeds Several minimally supervised approaches have been investigated that accomplished rather decent results with minimum effort The learning algorithms are not domain dependent The seed based bootstrapping approaches are theoretically pleasing because the learned patterns and rules are modular and transparent They can reused new applications and they can valuable resource for computational linguistic investigation will explain several bootstrapping methods most them starting with patterns seeds and some with event seeds will also describe our own approach bootstrapping 2007 radical extension 2006 this approach learning starts from small set ary relation instances seeds order auto ¬ ¬cally learn pattern rules from parsed data which then can extract new instances the ary relation and its projections After fruitful period skillful trial and error there seems the right time now for more systematic investigation the alternative approaches relation detection addition tables recall and precision values for competing methods urgently need explanations causal theories explaining the virtues and shortcomings alternative techniques with respect properties domains and text data describe one theory this kind based experimental evidence and explanatory insight The advocated scientific methodology will enable optimal choices for specific tasks effectively reduce the number promising combinations methods for future investigation and guide the search for completely new approaches 
3419 en Supervised reconstruction biological networks The inference reconstruction various biological networks including regulatory signalling metabolic pathways from large scale heterogeneous data currently active research subject with several important applications systems biology While several approaches proposed far cast this problem inferring graph novo from genomic data will argue this talk that the network interest often partially known and that the reconstruction process should use this partial knowledge guide the inference the missing edges will then review how this paradigm leads naturally various supervised machine learning algorithms for graph inference and illustrate the relevance the approach through several examples successful prediction missing enzymes metabolic networks 
3421 en Identification functional modules based transcriptional regulation structure
3423 en About the previous Chairs EURANDOM
3424 en How Roberto Fernandez came EURANDOM
3425 en Random processes partially ordered fields gibbs fields These probabilistic objects are all defined terms families probability kernels satisfying appropriate consistency relations This common feature can exploited develop parallel theories which concepts and techniques can shared imported The talk will present the main lines this parallel treatment discuss the resulting body comparable properties extremality and mixing limit states Dobrushin uniqueness criteria iii review instances interplay between the theories phase transitions uniqueness criteria and present some remaining questions and open problems
3427 en How was right even when was wrong For the past several years have warned people not ask predict the future because predictions are usually wrong Undaunted failure this talk will try predict the future the semantic web based very personal view its history the history the internet web semantic web and and the mistakes made predicting where and how they would valuable 
3428 en POWERSET Natural Language and the Semantic Web The Semantic Web promises revolutionize access information adding machine readable semantic information content which normally interpretable only people addition will also revolutionize access services adding semantic information create machine readable service descriptions This ambitious vision has been slow take off because chicken and egg problem Markup required before people will build applications applications are required before worth the hard work doing markup Natural language processing NLP has advanced the point where can break the impasse and open the possibilities the Semantic Web First NLP systems can now automatically create annotations from unstructured text This provides the data that semantic web applications require Second NLP systems are themselves consumers semantic web information and thus provide economic motivation for people create and maintain such information For example new generation natural language search systems illustrated Powerset can take advantage semantic web markup and ontologies augment their interpretation underlying textual content They can also expose semantic web services directly response natural language queries 
3440 en Utilizing ISP P2P collaboration enhance trust P2P systems
3441 en  Collaborative Web search via adaptive peer network
3444 en Emergent Networks Distributed Reputation System
3445 en Efficient and Decentralized Page Rank Approximation P2P Networks with Malicious Agents
3446 en Globalization and Changes Life Courses Modern Societies Research Goals which extent has globalization influenced life courses modern societies How different domestic institutions filter these transformations How actors respond globalization How does globalization affect social inequality What mean globalization 
3449 en Social Dynamics Age the Web People have moved the web For many their social and commercial interactions satisfy their information and entertainment needs generate content massive scale follows The emergence online collective intelligence that can tapped What these trends portend And how can benefit from them 
3450 en Computer Modeling Genome Evolution during Sympatric Speciation the natural even large and panmictic populations the inbreeding coefficient could relatively high because individuals are looking for sexual partners the relatively short distances have simulated the evolution such population the square lattice Results simulations were compared the human population and its genetic pool particular have analyzed distribution recombination spots along the human chromosomes using the method cumulative detrended walks Frequency recombination all human chromosomes excluding chromosome which has partner for recombination higher the subtelomeric regions both ends chromosomes and relatively lower the middle part chromosomes This resembles the distribution accepted recombination events the bitstring representing haplotypes the computer simulated populations our simulations individuals before reproduction have produce gametes connected with some probability recombination between haplotypes bitstrings consider that recombination event accepted gamete produced this recombination succeeded forming the surviving zygote Under high inbreeding and low frequency intragenomic recombinations the middle parts bitstrings one genome complemented each other while the ends the defective alleles are eliminated purifying Darwinian selection Such conditions are characteristic for populations after sympatric speciation conclusion the middle part chromosomes more conserved and its structure seems responsible for belonging higher taxons while the ends chromosomes genes responsible for the intra species biodiversity are located 
3451 en Publish Perish Publish Perish Phenomenon Evaluations scientists depend number papers positions lists authors and journals’ impact factors Japan Spain and elsewhere such assessments have reached formulaic precision But bureaucrats are not only wholly responsible for these changes scientists have enthusiastically colluded What began someone else’ measure has become our own goal… Lawrence The politics publication Nature 422 259 2003 
3452 en Log periodic Oscillations due Discrete Effects Complex Networks Authors show how discretization affects two major characteristics complex networks internode distances measured the shortest number edges between network sites and average path length and result there are log periodic oscillations the above quantities The effect occurs both numerical network models well such real systems coauthorship language food and public transport networks Analytical description these oscillations fits well numerical simulations They consider simple case the network optimization problem arguing that discrete effects can lead nontrivial solution 
3453 en Workshop Introduction “Critical Infrastructure” large scale infrastructure which degraded disrupted destroyed would have serious impact health safety security well beings citizens the effective functioning governments and economy Schmitz 2006 
3454 en Integrated Risk Reduction Information based Infrastructure Systems Goal Mitigate the danger blackouts communication and power supply networks Support the “strategic assessment” the current situation taking into account the dependency interdependency structure “Identified risks can accepted not with regard the goal ” Support the “strategic decision making” based the assessment the current situation Critical infrastructures CIs have undergone drastic changes the last decades The ubiquitous use ICT has pervaded all traditional infrastructures rendering them more intelligent increasingly interconnected complex interdependent and therefore more vulnerable Critical infrastructures are vital backbones modern societies and are increasingly depending and communication networks Due the increasing penetration CIs are more and more connected with each other with advantages and disadvantages Due this interconnection critical infrastructures can provide their services more cost efficiently the other side case disturbances their behaviour can not ever mastered the large blackouts USA and Europe have shown Increasing complexity and manifold conventional and emerging threats jeopardise the system mutual dependent critical infrastructures CIP gains high importance and has understood holistic process considering technologies and persons acting within this system systems 
3457 en  Lies Damn Lies and Statistics Critical Assessment Preferential Attachment type Network Models the Internet Basic Question the available Internet related connectivity measurements and their analysis support the sort claims that can found the existing complex networks literature Key Issues What about data hygiene What about statistical rigor What about model validation Author discusses some the main problems and challenges associated with measuring inferring and modeling various types Internet related connectivity structures this end uses some known examples illustrate the need understand the process which Internet connectivity measurements are obtained explore the sensitivity inferred graph properties known ambiguities the data more critical with respect the dominant preferential attachmenttype network modeling paradigm and more serious ambitious when comes model validation Ignoring any these issues bound produce results that are best described the well known aphorism lies damned lies and statistics 
3460 en Modelling Interdependencies Critical Infrastructures under Natural Disasters Case Supply Communication and Transportation Infrastructures This paper introduces the methodological challenge identifying and quantifying the interdependencies among several critical infrastructures First interdependency structures during natural disaster are modeled based past events considering supply electricity water and gas communication internet and telephone and transportation infrastructures road networks Interdependencies are defined with respect physical functional and socio economic interrelationships quantification strategy then introduced based empirical surveys and economic models case study the developed model applied the 2004 Mid Niigata earthquake which severely damaged infrastructure systems the northern mountainous region Japan 
3463 en  Configurable Hardware Framework for Trusted Computing Base Application the Power Grid Objectives Develop enabling technology provide customizable level trust significant critical infrastructure exemplified the Power Grid computing and communication systems The focus design methods and runtime techniques achieve application specific level reliability and security while delivering optimal and timely performance 
3464 en Simulation Experiments Emerging Instruments for CIP Critical infrastructures CIs have undergone drastic changes the last decades The ubiquitous use ICT has pervaded all traditional infrastructures rendering them more intelligent increasingly interconnected complex interdependent and therefore more vulnerable Critical infrastructures are vital backbones modern societies and our society fully dependent them Besides the traditional threats like natural disasters man made disasters and terrorist attacks the complexity the system interdependent infrastructures has considered additional threat The increasing penetration leads interdependencies and feedbacks which make more and more difficult distinguish cause and effect That means critical infrastructures have designed fault tolerant systems Redundancy and selfhealing are approved design principles But such design principles cause increasing costs and the private sector complying with the rules shareholder value has prevent costs the other hand security critical infrastructures has high societal importance That means new business models and security technologies have introduced that fulfil the interests the private enterprises and the state addition novel security technologies like Modelling and Simulation have developed and used order protect critical infrastructures well train people responsible for safety and security 
3466 en Candidate gene prioritization genomic data fusion The overwhelming amount biological data makes the assignment candidate genes diseases and biological pathways formidable challenge present ENDEAVOUR generally applicable computational methodology prioritize candidate genes based their similarity case specific reference gene sets Unlike previous methods ENDEAVOUR capable flexibly utilizing multiple data sets from diverse sources allows the modular incorporation novo generated data sets and integrates distinct prioritizations into global ranking applying order statistics first validate the overallperformance statistical cross validation diseases and biological pathways validate novel candidate for DiGeorge syndrome zebrafish model and present several new candidates for congenital heart disease extend the basic ENDEAVOUR methodology using data from multiple species human mouse rat drosophila and elegans also present alternative machine learning methodology for gene prioritization using kernel methods for novelty detection that outperforms our previous results 
3467 en Towards semi automatic functional annotation tool based decision tree techniques
3468 en Machine Learning Techniques Identify Putative Genes Involved Nitrogen Catabolite Repression the Yeast Saccharomyces cerevisiae
3469 en Interview with Bernardo Huberman Bernardo Huberman Senior Fellow and Director the Information Dynamics Lab Hewlett Packard Laboratories received his Physics from the University Pennsylvania and currently Consulting Professor the Department Applied Physics Stanford University originally worked condensed matter physics ranging from superionic conductors two dimensional superfluids and made contributions the theory critical phenomena low dimensional systems was one the discoverers chaos number physical systems and also established number universal properties nonlinear dynamical systems His research into the dynamics complex structures led his discovery ultradiffusion hierarchical systems 
3470 en Interview with Denis Noble the interview can find out that Denis Noble professor Cardio Vascular Phisiology built one the first models the heart and recently wrote very provocative book called Music Life about systems biology The Videolectures Net team spoke him Dresden the European Conference Complex Systems asked him about his lecture the conference DNA molecules meaning life and how does the organism works When asked moved from applications philosophy answers positively Use book get rid some mistakes you may have made using metaphores other people use metaphores contrast the ladder but then throw these away too Leave yourself think yourself what you really think biology about 
3471 en Welcome Since June 1st 2007 Dirk Helbing Professor Sociology particular Modeling and Simulation ETH Zurich Before worked Managing Director the Institute for Transport Economics Dresden University Technology where was appointed full professor 2000 Having studied Physics and Mathematics Göttingen his master thesis dealt with the nonlinear modelling and multi agent simulation observed self organization phenomena pedestrian crowds Two years later finished his Stuttgart University modelling social interaction processes means game theoretical approaches stochastic methods and complex systems theory which was awarded two research prizes After having completed his habilitation traffic dynamics and optimization 1996 received Heisenberg scholarship Both theses were printed international publishers Apart from this Helbing has organized several international conferences and edited proceedings special issues material flows networks and cooperative dynamics socio economic and traffic systems has given 250 talks and published more than 200 papers including several contributions journals like Nature Science PNAS which were discussed the public media newspapers radio and more than 200 times collaborates closely with international scientists For example worked the Weizmann Institute Israel Xerox PARC Silicon Valley INRETS Paris and the Collegium Budapest Institute for Advanced Study Hungary where now member the external faculty 
3472 en  Framework Program Wolfgang Boch working with the European Commission for more than years Information and Communication Technologies ICT within the Framework Programmes for Research January 2007 has been appointed Head Unit for Future and Emerging Technologies – Proactive Initiatives the context Framework Programme VII 2007–2013 FET Proactive aims nurture the roots innovation Europe supports long term and foundational research ICT particular radical interdisciplinary and multi disciplinary explorations such bio nano info cogno new and alternative approaches towards the development new scientific foundations and technological breakthroughs The FET proactive Initiatives are granted the European Union total funding 120 € for the years 2007–2008 The FET scheme acts the pathfinder and incubator for new ideas and themes for long term research the area information and communication technologies His background Electrical Engineering and Informatics with focus feedback and control Systems holds Master Degree Electrical Engineering from the University Karlsruhe Germany Prior joining the European Commission worked for years the German aerospace and avionics industry the European Commission has held previous positions Head Unit ICT research related Grid Technologies and Telematics Applications for the Environment 
3473 en Universal Access Human Knowledge Public Access Digital Materials The goal universal access our cultural heritage within our grasp With current digital technology can build comprehensive collections and with digital networks can make these available students and scholars all over the world The current challenge establishing the roles rights and responsibilities our libraries and archives providing public access this information With these roles defined our institutions will help fulfill this epic opportunity our digital age 
3474 en Towards Structured Output Prediction Enzyme Function
3475 en Integration genome wide data infer genetic networks comprehend biology system one needs analyze the structure and dynamics cell components modules rather than isolated part Progress technological devices analytical methods and biological models are required decipher molecular networks and eventually analyze the cell system Clustering analysis gene expression profiles allows the analysis “ correlation” between genes and biological conditions However yet restrictive does not reveal the causality regulatory relationships Besides very difficult infer molecular networks from expression profiling only the only accessible information the steady state concentration mRNA This information necessary but not sufficient characterize the structure transcriptional network and analyze its dynamic and functional properties Modeling transcriptional networks should take into account information such RNA concentrations cis acting sequences transcriptional activity and forth since each variable carries unique biological information However due limitation accurate and highly parallel measuring technologies these data are not routinely accessible have developed innovative bioarrays measure with sufficient accuracy parallelism and throughput relevant data infer transcriptional networks For instance are manufacturing DNA array containing promoter regions human perform ChIP chip analysis order localize for given transcription factor all putative binding sites onto the genome One can then return DNA arrays confirm hypothesis generated from ChIP chip data are also developing cell microarrays characterize genome wide upstream regulators for given gene one hand and transcriptional activity the other hand Technological breakthroughs micro and nanotechnologies generate comprehensive and relevant data are thus critical innovation analytical methods for deciphering transcriptional regulatory networks and developing system biology 
3476 en Mixture model regressions for ChIP chip experiment analysis
3477 en  Marginalized Variational Bayesian Approach the Analysis Array Data
3478 en Identification overlapping biclusters using probabilistic relational models
3479 en Discovering Common Sequence Variation Arabidopsis thaliana order characterize natural sequence variation strains the model plant Arabidopsis thaliana whole genome resequencing with high density oligonucleotide arrays was performed collaboration with Perlegen Sciences Inc Array data were analyzed with combination existing model based Hinds Science 2005 and novel machine learning methods For the identification single nucleotide polymorphisms SNPs developed algorithm based support vector machines Training and evaluation was done published alignments Nordborg PLoS Biology 2005 the same false discovery rates FDR the algorithm identifies significantly more true SNPs especially regions high polymorphism density and low hybridization quality The union SNP predictions from both methods contains average 143 572 SNPs per strain FDR 648 570 non redundant SNPs Furthermore machine learning algorithm was developed detect polymorphic regions containing insertions deletions and variational hotspots where SNP detection algorithms typically fail identify individual SNPs discovers the approximate location substantial additional proportion polymorphisms deleted nucleotides and insertion sites With combination all three methods SNPs can directly called are contained polymorphic region prediction Zeller preparation examined the patterns and forces shaping sequence variation Arabidopsis Clark Science 2007 significant differences were observed between gene families and genes mediating interaction with the biotic environment harbor exceptional polymorphism levels 
3480 en Gene based bin analysis genome wide association studies
3481 en Supervised Attribute Relevance Determination for Protein Identification Stress Experiments
3482 en Need Systems Approach for Biological Explanation Anti Learnable Signatures
3487 en The Mathematics Emergence and Flocking Stephen Smale professor emeritus mathematics the University California Berkeley who has contributed broad range mathematical fields has been named recipient the 2007 Wolf Foundation Prize Mathematics one array prestigious prizes awarded yearly the Israeli foundation Though retired from Berkeley since 1994 Smale continues explore new fields such learning theory the mathematical description nerve connections the brain that give rise intelligence and learning flocking the tendency group behavior look coordinated with flock birds school fish and the mathematics data mining Newsroom University Califonia 2007 
3488 en Principle Systems Biology illustrated using the Virtual Heart Highest systems property “The living organism does not really exist the milieu extérieur but the liquid milieu intérieur … complex organism should looked upon assemblage simple organisms … that live the liquid milieu intérieur ”
3489 en The Origin Rhythmic Behavior Regulated Biological Systems
3490 en Science mapping with asymmetric occurence analisys propose new innovative methods order reconstruct paradigmatic fields thanks simple statistics over scientific content database first define asymmetric paradigmatic proximity between concepts which provides hierarchical structure over the set concepts propose implement overlapping categorization describe paradigmatic fields sets concepts that may have several different usage and introduce embedding represent these sets structured way This enables have micro meso and macro scale approach our set concepts Concepts can also dynamically clustered providing high level description the evolution the paradigmatic fields apply our set methods case study from the Complex Systems Community through the mapping the dynamics more than 400 Complex Systems Science concepts indexed database several millions journal papers 
3491 en Slower faster Reduction consensus times through social inertia the Voter Model this paper investigate the role heterogeneity added the Voter Model our model voters are equipped with individual inertia change opinion which depends the persistence time voter’ current opinion the simplest case inertia values are linearly increasing with persistence time slope but our findings are qualitatively valid for other monotonously increasing functions too Here contrast the Voter Model voters change their individual behavior over time and the system builds heterogeneity The unexpected outcome this dynamics non monotonous development average consensus times the slope value decreases systematically with increasing systems with higher average inertia reach the final attractor state faster For slopes larger than consensus times increase and can exceed the reference time the Voter Model These results are obtained only considering heterogeneity voters that evolves through the described ageing the voters find monotonously increasing consensus times control setting homogeneous inertia values the paper present the dynamical equations for simplified mean field model that give insight into the complex dynamics leading the observed slower faster effect 
3492 en  the Relevance Extremes Means Organization Science Scalability key element complexity science Many complex systems tend selfsimilar across levels—the same dynamics work multiple levels They are explained scaling laws Scalability results from what Mandelbrot calls fractal geometry cauliflower obvious example Fractals often show Pareto distributions and are signified power laws Researchers find organization related power laws intrafirm decisions consumer sales salaries size firms movie profits director interlocks biotech networks and industrial districts for example Power laws signify Pareto distributions which show “fat tails ” nearly infinite variance unstable means and unstable confidence intervals Pareto distributions are alien most quantitative organizational researchers who are trained Gaussian statistics and are trained great lengths configure their data fit the requirements linear regression normal distributions and related statistical methods While normal distributions and related current quantitative methods are still relevant for significant portion organizational research power laws signify that Pareto distributions fractals and underlying scale free theories are increasingly pervasive and valid characterizations organizational dynamics Where true researchers ignoring power law effects risk drawing false conclusions and promulgating useless advice practitioners This because what important most managers are the extremes they face not the averages The implications for organization science however beyond extreme events Tools not exist theoretical vacuum The adoption normal distribution statistics carries heavy baggage assumptions Reliance linearity randomness gradualism and equilibrium influences how theories are built how legitimacy conferred and how research questions are formulated begin with findings about kinds power laws Then present sixteen scale free theories that apply organizations Next discuss research implications Then discuss implications terms the basic predictor function How does basic thinking about prediction data statistics and the error term have change 
3493 en Visual Analysis Controversy User generated Encyclopedias Wikipedia large and rapidly growing Web based collaborative authoring environment where anyone the Internet can create modify and delete pages about encyclopedic topics remarkable property some Wikipedia pages that they are written thousands authors who may have contradicting opinions define network authors revising other authors and present methods for its visual analysis that yield interesting insight into the structures controversy highlighting the dominant authors page the roles they play and the alters they confront 
3494 en Network Structure Folksonomies Folksonomies can viewed three mode graphs graphs made nodes tags users resources connected hyper edges shall report some network statistical properties folksonomy graph based data collected for the del icio system Moreover introducing suitable distance between resources based tag occurrence shall show that folksonomies embed meaningful semantic clusterization resources 
3495 en Social Web Search This talk will present two research projects under way the Network and agents Network NaN which study ways leveraging online social behavior for better Web search GiveALink org social bookmarking site where users donate their personal bookmarks search and recommendation engine built from similarity network derived from the hierarchical structure bookmarks aggregated across users distributed Web search engine based adaptive peer network learning about each other peers can route queries through the network efficiently reach knowledgeable nodes The resulting peer network structures itself small world that uncovers semantic communities and outperforms centralized search engines 
3496 en Linked But how The growing interest social sites scientific research well business has led sharp increase the analysis such sites The tools and methods technically analyze such sites are developed and are being enhanced One major question though seems left mostly unattended one takes the relationship data site like MySpace what the ‘real’ interpretation the social network analysis There clear definition the meaning link frienship acquaintance awareness When analyzing the dynamics such site the question time dependent relevance links added this problem this talk these points will adressed with the goal bringing into the focus the discussion the content driven interpretation the analysis social sites 
3497 en Cloasing Discussion Discussion and wrap led Bettina Hoser with the presenting participants the Social Websites Complex Dynamics and Structure Satellite Conference 
3498 en Complexity Human Activity Conflicts Currencies and Crimes
3501 en Chorus Plans and Progress Meeting Objectives Part 
3502 en Chorus Plans and Progress Meeting Objectives Part 
3503 en Quaero French governmental initiative Quaero … Ergo Sum Presentation industrial research program Multimedia Search and Navigation Part 
3504 en Quaero French governmental initiative Quaero … Ergo Sum Presentation industrial research program Multimedia Search and Navigation Part 
3505 en THESEUS Project Structure and Activitiesof Core Technology Cluster CTC 
3507 en iAd Norwegian Initiative Part 
3508 en iAd Norwegian Initiative Part 
3509 en MultimediaN Dutch Initiative Part 
3510 en MultimediaN Dutch Initiative Part 
3512 en Mundo Spanish Initiative Part 
3513 en Mundo Spanish Initiative Part 
3514 en Mundo Spanish Initiative Part 
3515 en Open Session European National Initiatives Challenges communalities difficulties targeted expected impact success criteria What could done together 
3516 en  Introduction OWL Starting with overview the requirements for defining and using ontologies the Web Sean will then outline the main concepts and issues associated with the Web ontology languaages RDF RDFS and OWL the end this presentation attendees will have gained basic understanding the principles underlying OWL 
3517 en Ontology Engineering Methodologies Using the insights gained decade research Asun will describe the main principles and phases underlying the construction ontologies including acquisition conceptualization evaluation and integration the end this presentation attendees will have overview the main steps involved creating industrial strength ontology 
3518 en Ontology Engineering Design Patterns Building upon Asun presentation here Aldo will focus Ontology Design particular Aldo will apply the software engineering notion design patterns the design ontologies This session will give attendees number insights into the differences between good and bad ontology design 
3519 en Semantic Web Services this session John and David will first give overview the problem and vision for applying Semantic Web technologies Web Services then they will describe number the most important approaches and finally Semantic Web Service applications the end this session attendees will gained understanding the main issues Semantic Web Services and overview OWL SAWSDL and WSMO 
3520 en Web Service Modelling Ontology this session John and David will first give overview the problem and vision for applying Semantic Web technologies Web Services then they will describe number the most important approaches and finally Semantic Web Service applications the end this session attendees will gained understanding the main issues Semantic Web Services and overview OWL SAWSDL and WSMO 
3523 en Semantic Web Applications the final session Enrico will first describe the Semantic Web exists today and then outline the main requirements and issues surrounding the creation Semantic Web applications 
3525 en Dynamics Real world Networks our recent work found interesting and unintuitive patterns for time evolving networks which change some the basic assumptions that were made the past The main objective observing the evolution patterns develop models that explain processes which govern the network evolution Such models can then fitted real networks and used generate realistic graphs give formal explanations about their properties addition our work has wide range applications can spot anomalous graphs and outliers design better graph sampling algorithms forecast future graph structure and run simulations network evolution Another important aspect this research the study local patterns and structures propagation networks aim identify building blocks the networks and find the patterns influence that these block have information virus propagation over the network Our recent work included the study the spread influence large person person product recommendation network and its effect purchases also model the propagation information the blogosphere and propose algorithms efficiently find influential nodes the network Further work will include three areas research will continue investigating models for graph generation and evolution Second will analyze large online communication networks and devise models how user characteristics and geography relate communication and network patterns Third will extend the work the propagation influence recommendation networks blogs the Web studying how information spreads over the Web finding influential blogs and analyzing their patterns influence http www cmu edu jure thesis Thesis Committee Christos Faloutsos Chair Avrim Blum John Kleinberg Cornell University John Lafferty
3532 en Structural adaptive smoothing Images fMRI and DWI The talk presents class structural adaptive smoothing methods developed WIAS The main focus will the Propagation Separation approach proposed Polzehl and Spokoiny 2006 The method allows simultaneously identify regions homogeneity with respect prescribed model structural assumption and use this information improve local estimates This achieved iterative procedure The name Propagation Separation synonym for the two main properties the algorithms case homogeneity that the prescribed model holds with the same parameters within large region the algorithm essentially delivers series nonadaptive estimates with decreasing variance and propagates the best estimate from this series Separation means that soon two design points and significant differences are detected between estimates observations will not used estimate the parameter establish some theoretical nonasymptotic results properties the new algorithm present how this approach can adjusted different imaging modalities ranging from denoising greyvalue and color images the analysis data from functional Magnetic Resonance Imaging fMRI and Diffusion Weigted Imaging DWI experiments 
3534 en Computation the MLE for bivariate interval censored data will discuss the new package MLEcens which computes the nonparametric maximum likelihood estimator MLE for the distribution function bivariate interval censored data The computation the MLE consists two steps parameter reduction step and optimization step will discuss algorithms for both steps will also illustrate the package using several examples 
3536 en Stochastic chains with variable length memory and the algorithm Context Stochastic chains with variable length memory define interesting family stochastic chains infinite order finite alphabet The idea that for each past only finite suffix the past called context enough predict the next symbol The set contexts can represented rooted tree with finite labeled branches The law the chain characterized its tree contexts and associated family transition probabilities indexed the tree These models were first introduced the information theory literature Rissanen 1983 universal tool perform data compression Recently they have been used model scientific data areas different biology linguistics and music Originally called finite memory source tree machines these models became quite popular the statistics literature under the name Variable Length Markov Chains coined Buhlmann and Wyner 1999 talk will present some the basic ideas problems and examples application the field will focus the algorithm Context which estimates the tree contexts and the associated family transition probabilities defining the chain 
3541 en Denoising and Dimension Reduction Feature Space The talk presents recent work that interestingly complements our understanding the picture kernel based learning Our finding that the relevant information supervised learning problem contained negligible error finite number leading kernel PCA components the kernel matches the underlying learning problem Thus kernels not only transform data sets such that good generalization can achieved using only linear discriminant functions but this transformation also performed manner which makes economic use feature space dimensions the best case kernels provide efficient implicit representations the data for supervised learning problems Practically propose algorithm which enables recover the subspace and dimensionality relevant for good classification Our algorithm can therefore applied analyze the interplay data set and kernel geometric fashion aid model selection and denoise feature space order yield better classification results complement our theoretical findings reporting applications our method data from gene finding and brain computer interfacing This joint work with Claudia Sannelli and Joachim Buhmann
3542 en Wedgelet Partitions and Image Processing many applications Image Processing crucial dispose efficient tools for extraction analysis and representation geometrical contents natural images These latter can modelled classes bivariate functions regular finite number regions separated smooth boundaries now well established fact that the usual two dimensional tensor product wavelet bases are not optimal for approximating such classes the last ten years several methods have been suggested remedy Among them wedgelets representations over quadtree structures represent contour based approach which allows efficient digital implementation while capturing mainly geometric features natural images discuss some algorithmic aspects due the discrete nature the method leading fast computation optimal solutions possible application present new scheme for digital image compression based these methods The main ingredient for the design efficient coding scheme consider spatial redundancies between neighbouring atoms the representation relatively the properties the target regularity class Joint work with Mattia Fedrigo Felix Friedrich and Hartmut Führ 
3543 en Complex Systems Art Performance The tasks the artist between this self organizing process firstly the preparation the used objects which are mostly liquids The objects are put into physical relation certain amounts and certain configurations This equivalent the initial state the self organizing Proceeding from this initial state develops the process creating form while the artist can influence the self organization regulations like for example adding new objects physical reconfigurations existing objects 
3544 en The Foundations the Economics Innovation During the last forty years economics innovation has emerged distinct area enquiry the crossing the economics growth industrial organization regional economics and the theory the firm becoming well identified area competence economics specializing not only the analysis the effects the introduction new technologies but also and mainly understanding technological change endogenous process the result the interpretation elaboration and evolution different fields analysis economic theory innovation viewed complex path dependent process characterized the interdependence and interaction variety heterogeneous agents able learn and react creatively with subjective and procedural rationality 
3545 en Landscape Dynamics Farol Attendies Arthur’ paradigm the Farol bar for modeling bounded rationality and inductive behavior undertaken The memory horizon available the agents and the selection criteria they utilize for the prediction algorithm are the two essential variables identified represent the heterogeneity agent strategies The latter enriched including various rewarding schemes during decision making Though the external input comfort level not explicitly coded the algorithm pool contributes each agent’ decision process Playing with the essential variables one can maneuver the overall outcome between the comfort level and the endogenously identified limiting state The distribution algorithm clusters significantly varies for shorter agent memories This turn affects the long term aggregated dynamics attendances observe that transition occurs the attendance distribution the critical memory horizon where the correlations the attendance deviations take longer time decay zero larger part the crowd becomes more comfortable while the rest the bar goers still feel the congestion for long memories Agents’ confidence their algorithms and the delayed feedback attendance data increase the overall collectivity the system behavior 
3546 en Interview with Mark Newman Professor Physics the University Michigan Holds joint appointment the Department Physics and the Center for the Study Complex Systems Also member the External Faculty the Santa Institute Research interests Networks and graph theory Phase transitions and critical phenomena Monte Carlo methods Glassy spin systems Prehistoric evolution and extinction 
3547 en Interview with Stephan Mertens Assistant professor Privatdozent for theoretical physics Otto von Guericke University Also external professor the Santa Institute Current active fields research Random Number Generation Computational Complexity and Statistical Mechanics Low autocorrelated binary sequences 
3548 en Interview with Armando Bazzani Professor Mathematical Physics from the Department Physics the University Bologna Interested application physical method social system especially mobility problem new cities 
3549 en Web Spam Detection Web spam can significantly deteriorate the quality search engine results Thus there large incentive for commercial search engines detect spam pages efficiently and accurately This talk presents spam detection systems that combine link based and content based features and use the topology the Web graph exploiting the link dependencies among the Web pages 
3550 en Machine Learning for Intrusion Detection Intrusion detection one core technologies computer security The goal intrusion detection goal identi cation malicious activity stream monitored data which can network tra operating system events log entries majority current intrusion detection systems IDS follows signature based approach which similar virus scanners events are detected that match speci pre ned patterns known signatures The main limitation signature based IDS their failure identify novel attacks and sometimes even minor variations known patterns Besides signi cant administrative overhead incurred the need maintain signature databases Machine learning ers major opportunity improve quality and facilitate administration IDS Supervised learning can used for automatic generation detectors without need manually and update signatures Anomaly detection and other unsupervised learning techniques can detect new kinds attacks provided they exhibit unusual character some feature space our contribution kernel and distance based learning algorithms for network intrusion detection will presented The two essential parts our approach are online learning algorithms and feature extraction The major requirements the algorithmic part are linear run time online learning and data type abstraction Simple but ective anomaly detection algorithms will presented that satisfy these requirements Feature extraction algorithms can reduced computation similarity measures between sequential objects order access the feature from the application layer network protocols which most modern remote exploits operate similarity measures are computed directly over byte streams TCP connections Algorithms and data structures will presented that allow  cient computation similarity measures linear time with very low run time constants and memory consumption 
3551 en Learning with structured data structured outputs focus the prediction structured outputs classical example sequence labeling with applications speech vision natural language biology Beyond sequences the prediction structured data like trees lattices graphs also occurs many domains Structured prediction usually considered extension multi class classification considered challenging problem since the size the output space increases drastically with the number potential dependencies between output variables Several methods have been recently proposed the community order overcome this complexity and the domain still largely open will provide review these methods and discuss there potential and limitations These different ideas will illustrated with Natural language processing and text mining applications 
3552 en Automatic detection and aggregation name variants from large multi lingual document collections Most the Named Entity Recognition software will recognize Vladimir Putin Wladimir Putin and Vladimir Poutine being named entities But for some application necessary mark them being all variants the same person the Joint Research Centre try handle this problem merging name variants that gathered News corpus part the Europe Media Monitor EMM system Such highly multi lingual system 000 news article per day more than languages quite likely use various spellings refer the same person example during hours EMM found variants referring Abdullah Gul Turkish foreign minister Abdullah Gül Abdullah Gul Abdulá Gül Abdullah Guel Abdullah Gulas Our approach consists extracting names from multilingual corpus and then merge very similar names our repository The various steps are guessing new names using language specific light resources storing names repository lookup for known names Including some variants for languages that decline proper names For example Polish can face the following sentence containing declension the proper name Tony Blair Brown tymczasem wybra skromne wakacje ojczy nie chc wyra nie odró Tony’ego Blaira compute similarity names including names written different alphabets order merge two variants belonging the same person NewsExplorer the system automatically add 450 new names per day are automatically recognized being variant existing person names are possible variants validated expert Those figures highlight the importance such system when dealing with multi lingual information Various collected variants person names gathered are available our public website http press jrc NewsExplorer
3553 en Predicting the Outcome Game Optimization many complex systems often viewed black box optimization problem Such problems are often difficult solve using conventional techniques for variety reasons such the absence derivatives mixed data types and Techniques such Genetic Algorithms Estimation Distribution Algorithms such MIMIC and the method and more recently mathematically rigorous approaches such Probability Collectives have been used for black box optimization turns out that many these techniques fall under the category Monte Carlo Optimization this technique present brief statistical analysis Monte Carlo Optimization MCO and show that identical Parametric Machine Learning Owing this identity can use techniques improve the performance MCO Then present new version the black box optimization technique Probability Collectives and demonstrate the use techniques improve its optimization performance 
3554 en Repair Strategies for Minimizing the Risk Cascading Failures Electricity Networks industrialized countries reliable supply electrical energy taken for granted order guarantee stable energy supply also case non serious failures electrical equipment the underlying electric power network has been designed with redundancies Nevertheless major blackouts the transmission grid occur all over the world They are typically caused sequence cascading failures and may evidence critically loaded transmission system Furthermore the increasing trade electricity consequence the liberalization the energy markets has led additional load the existing infrastructure consequence the reliable operation and maintenance the electric power grid minimum cost increasingly demanding task The goal our work develop repair strategies that minimize the risk cascading failures power operator has generally not enough time repair failed lines once cascade has started because cascading failures typically evolve time scales seconds and minutes Consequently focus repair strategies during normal operation Even during normal operation there are typically some lines that are not operating due random failures maintenance work While the system may still have enough capacity transmit the power demand the average loading and therefore the blackout risk increases with every failed line 
3555 en Evolution the Topology High voltage Electricity Network The electricity network represents example evolving complex system The first local network consisted only few components but within several decades they have evolved into highly connected continental system The growth the network influenced various factors such economy demography politics and technological developments this paper follow the growth the French electricity transmission network from its establishment 1960 until the year 2000 The data set contains maps for different years the 400KV power lines used this data extract information related the network growth rate such the number lines number lines intersections nodes and line length each map Firstly compare the results data sets with several economic and demographic indicators order indentify factors which correlate with the growth rate the electricity networks further eveluate topological properties such node connectivity degree information centrality betweenness centrality and robustness and observe their respective change the course time Our result might helpful for more efficient and fault tolerant network design 
3556 en Chromodynamics Cooperation Finite Populations tag based models for cooperation individuals recognize each other via arbitrary signals called tags Cooperators use tag until they are discovered defectors who then destroy cooperation based this tag exploiting cooperators many tags are available then cooperators can always establish new signals recognition This leads constant chase Cooperators establish new signals for cooperation while defectors constantly try find out about these signals Tag based cooperation intimately related the green beard effect While conventional wisdom leads the breakdown cooperation based such green beards can shown that green beards can lead cooperation they are worn red queens 
3557 en Equilibrium Transitions Stochastic Evolutionary Games analyze the long run behaviour stochastic dynamics well mixed populations and spatial games with local interactions review results concerning the effect the number players and the noise level the stochastic stability Nash equilibria address the problem equilibrium selection spatial games with many players introduce concept ensemble stability The standard stochastic stability describes long run behaviour systems with fixed number players the zero noise limit the contrary the ensemble stability concerned with fixed but nevertheless low noise level the limit the infinite number players present examples games which when the number players increases the noise level decreases population undergoes transition between its equilibria particular may happen that risk dominant and Pareto efficient strategy which stochastically stable the long run played with arbitrarily small probability the noise level low and the number players big enough 
3558 en Mobility Promotes and Jeopardizes Biodiversity Rock Paper Scissors Games Counterintuitive naive understanding Darwinian evolution where among two interacting species one expected fitter than the other and therefore outcompetes surprising biodiversity exists within the earth ecosystems Rock paper scissors games where three strategies cyclically dominate each other have emerged fruitful metaphor for the explanation biodiversity this talk discuss populations spatially coevolving with local cyclic dominance and show that they are capable preserving coexistence all subpopulations and this way ensuring biodiversity find that the individuals mobility competes with the locality interactions cyclic dominance such that biodiversity gets lost above certain mobility threshold Below this critical value all subpopulations coexist forming fascinating moving patterns composed entangled spirals which describe analytically 
3559 en Filtering Multi Lingual Terrorist Content with Graph Theoretic Classifi cation Tools Since the web increasingly used terrorist organizations the ability automatically detect multi lingual terrorist related content extremely important this talk present efficient detection methodology based the recently developed graph based web document representation models Evaluation performed corpora English and Arabic languages 
3560 en Recognition and Disambiguation geographical references text present approach recognise geographical references multilingual documents and disambiguate homographic place names The purpose this work provide users with meta information about documents whole collections and present their geographical coverage visually The approach has been implemented for sixteen languages and fully operational part the online news analysis system NewsExplorer http press jrc NewsExplorer and further JRC applications 
3561 en Cooperation Diffusive Spatial Games Random diffusion shown important mechanism fostering cooperative behavior among simple agents memoryless unconditional cooperators defectors living spatially structured environment particular under the Prisoner Dilemma framework when allowing the agents move with the simple always move rule find that cooperative behavior not only possible but may even enhanced addition for broad range densities mobile cooperators can more easily invade population mobile defectors when compared with the fully viscous immobile case Thus such simple mobility pattern may have played fundamental role both the onset and development cooperative behavior paving the way more complex individual and group motility rules 
3562 en Using linguistic information features for text categorization report some experiences using linguistic information additional features classical Vector Space Model Extracted information every word like the Part Speech and stem lexical root have been combined different ways for experimenting possible improvement the classification performance and several algorithms like SVM BBR and PLAUM Automatic Text Classification Automatic Text Categorization also known tries related documents predefined set classes Extensive research has been carried out this subject and wide range techniques are appliable solve this task feature extraction feature weighting dimensionality reduction machine learning algorithms and more Besides the classification task can either binary one out two possible classes select multi class one out set possible classes multi label set classes from larger set potential candidates most cases the latter two can reduced binary decisions the used algorithm does our experiments order verify the contribution the new features have combined them included into the vector space model preprocessing the Reuters 215781 collection well known set data the research community devoted text categorization problems 
3563 en Hierarchical Meanfield Theory Evolutionary Games Structured Populations Evolutionary games played out populations structured spatial embedding more general networks interaction have been shown have fundamentally different dynamics and outcomes compared those taking place well mixed ones Recent experimental and theoretical work published largely interdisciplinary journals such Nature and PNAS has demonstrated that longstanding open problems biology sociology and the economic sciences ranging from the maintenance diversity the evolution altruism and reciprocity can only understood look beyond well mixed populations and take into account the effects spatial structure The question how one goes about choosing the relevant model describe population structures however stands unanswered Models where individuals are confined the sites some lattice the nodes some random graph have proved highly sensitive seemingly minor changes the implementation the dynamics and the details the underlying topology interactions our paper introduce minimal model population structure that described two distinct hierarchical levels interaction derive the dynamics governing the evolution such system starting from fundamental individual level stochastic processes and find that the simple and straightforward hierarchical application the mean field approximation the assumption being well mixed both levels surprisingly unveils new level dynamical complexity believe that such minimal structure more relevant wide range natural systems than more subtle setups with delicate dependence the details and symmetries the model show that such minimal structure sufficient for the emergence effects previously only observed for explicit spatial embedding and demonstrate the potential our model identify robust effects population structure the dynamics and outcome evolutionary games 
3569 en The Evolution Cooperation Simple Games and Complex Societies
3570 en Social Networks from the Perspective Physics the history public speaking there have been many famous denials One sunny day 1880 Karl Marx declared not Marxist less auspicious occasion 1973 Richard Nixon insisted not crook Neither Marx’ nor Nixon’ audience gave much credence their denials and you too may respond with disbelief when tell you that not networker Marc Granovetter Connections 1990 Instead the slogan the day will are all networkers now 
3571 en Efficiency and Stability Evolving Innovation Networks present model network evolution which the formation deletion links coupled with the dynamics the state variable the nodes the network The model originally intended describe economic network agents engaged knowledge production through knowledge exchange although the framework can generalized other evolving networks With respect previous works improve investigating how rich structures can emerge collapse depending the individual rule link formation deletion used selfish and boundedly rational agents characterize the emerging network topologies terms their efficiency and stability The model reproduces qualitatively the main stylized facts innovation networks namely that they are sparse locally dense and heterogeneous degree 
3572 en Academic Employment Networks and Departmental Rank Academic prestige rankings are stagnant over time despite departmental changes Departments might maintain their prestige through hiring and training patterns This paper uses data from professors employment histories January 2007 define retrospective employment network and uses that network describe the relationship between departments centrality the hiringnetwork and academic prestige This paper tests whether that relationship depends whether not consider PhD training part the network and department size addition the analysis shows that the relationship robust variations graph definitions and measurement techniques 
3573 en Socioeconomic Networks with Long range Interactions well networked communities information often shared informally among individual direct and indirect acquaintances Here study model previously proposed Jackson and Wolinsky account for communicating information and allocating goods socioeconomic networks The model defines utility function node which weighted sum contributions from all nodes accessible from First show that scale free networks are more efficient than Poisson networks for the range average degree typically found real world networks then study evolving network mechanism where new nodes attach existing ones preferentially utility found the presence three regimes scale free rich get richer fit get rich and Poisson degree distribution The fit get rich regime characterized decrease average path length 
3574 en Efficient Simulation Complex Reaction Networks Complex reaction networks commonly appear natural systems Some examples are chemical ecological metabolic and gene expression networks These networks can described graphs which the nodesrepresent reactive species and the edges represent reactions Computer simulations these networks are commonly done using rate equations which provide the time dependent concentrations thereactive species well the reaction rates These equations are easy construct and efficient integrate numerically However they are applicable only whenthe populations reactive species are large andfluctuations are negligible case that the reactive species appear low copy numbers stochastic methods based the master equation are needed However the master equation not feasible for complex networks because the number equations proliferatesexponentially with the number reactive species Here present new computational method based moment equations which dramatically reduces the number equations enables efficiently simulate fluctuating reactionnetworks any level complexity The method requires only one equation for each reactive speciesand one equation for each reaction thus reducing the number equtaions the absolute minimum for stochastic simulation The reduction achieved with compromise the accuracy the results 
3575 en Hierarchical Analysis Piecewise Affine Models Gene Regulatory Networks propose this paper method hierarchically organize certain type piecewise affine differential system This specific class dynamical systems has been extensively studied for the past few years provides good framework model gene regulatory networks Using the hierarchical organization piecewise affine system present technique qualitatively analyze the asymptotic behavior the whole system thanks the analysis several smaller subsystems Specifically adapted these networks algorithm threshold elimination presented that refines certain cases the hierarchical decomposition and therefore improves the analysis 
3578 en Information Transfer Moving Animal Groups The movement animal flocks give one the clearest examples the concept complexity Simple interactions between animals lead patterns that are somehow regular but the same time difficult characterise this paper discuss first these models and their predictions about the movement flocks provide novel results about how information transfered these systems look recent experiments locusts and pigeons which show that least some the patterns seen these groups can explained the phase transitions and bifurcations that arise from these models particular look phase transition the marching locusts and symmetry breaking the decision making pigeons 
3580 en Honeybees Moving Home The Effect Swarm Size Decision making Honeybee swarms are faced with challenging task how decide new home The way which such decision made prime example decentralised decision making only small subset bees the swarm are involved the process each acting upon local information Previous work has used individual based simulations unravel how the behaviour the bees engaged decision making results the swarm collectively choosing the best possible nest site Here explore how the size the swarm affects the accuracy the decision making process when the presence certain number bees one nest site quorum used end the deliberations soon quorum reached bees involved the decision making process indicate the other bees the swarm that decision has been made and the swarm will prepare for lift off Assuming fixed quorum size show that the larger the swarm the less likely will able select the best nest site the quorum will reached early the process also show that the speed the decision making process reduced small swarms especially when only sites mediocre quality have been discovered Our results therefore indicate that large swarms will often make sub optimal decisions while small swarms will require more time select nest site but that small swarms select average better quality sites 
3581 en Individual based Model Bacterial Mobility Biofilms propose new individual based model mobile bacteria producing biofilm The model based the assumption that bacteria have brownian motion and produce polymeric substance that reduce their mobility increasing local viscosity define the biofilm the polymeric substance together with the bacteria contains Our simulation results show that bacteria mobility increases the heterogeneity and the complexity the biofilm that evaluate with entropy measure The obtained biofilm patterns show good qualitative agreement with experimental observation biofilm micrographs 
3582 en Firewalls Atrial Myocytes Atrial myocoytes play prominent role the generation heart beats Their contraction controlled Calcium signals that emerge the cellular periphery and then proceed centripetally engage the force generating myofilaments Experiments have demonstrated that these initial signals need overcome barrier just below the cell membrane before they move inward Since atrial myoctes lack transverse tubules that transmit external signals the cell interior ventricular myocytes such firewall represents crucial determinant atrial dynamics For instances allows atrial myocytes fine tune their responses wide range vital stimuli Here present computationally advantageous model investigate the mechanisms that give rise these graded centripetal signals Our framework takes into account the three dimensional organisation atrial myocytes especially the spatially restricted release Calcium from internal storage compartments employ fire diffuse fire FDF model examine the spatio temporal patterns and probe the dependence wave propagation physiologically relevant parameters Mimicking excitable medium the FDF approach reflects the significance noise intracellullar Calcium dynamics The explicit construction the corresponding Green function allows for detailed analysis 
3583 en Endocytosis and Signaling Competition Rab Proteins Endocytosis and signaling are tightly linked dynamic network subcellular compartments termed endosomes actively controls signal propagation amplitude and timing uptake and transport membrane associated signaling molecules The small GTPase Rab5 the central organizer the protein machinery that assembles early endosomes providing unique identity the compartment that controls cargo sorting transport and signaling potential interlink experimental and computational approaches unravel the design principles underlying the function and regulation the endocytic pathway and understand the molecular links that govern endosomal control signaling events Our approach takes into account both newly identified Rab5 effectors well the perspective going genome wide RNAi screening for novel endocytic transport regulators develop and analyze mathematical core model the kinetic interactions between the endosomal organizers Rab4 Rab5 and Rab7 The values the model parameters are estimated from literature and FRAP experiments Simulations and bifurcation analysis the model reveal bistable behavior Rab5 versus Rab7 dominance that reproduces the controled and robust transition from early late endosomal compartments observed means computational motion tracking individual endosomes fluorescence live cell imaging data The modeled Rab5 module serves blueprint for the sequential assembly the endocytic pathway therewith contributing important spatial aspect systems biology Our kinetic model explains the experimentally observed transitions between endosomal compartments the result cargo regulated competition between Rab proteins 
3584 en Ventricular Fibrillation the Human Heart Why different from Fibrillation the Dog and Pig Heart Sudden cardiac death one the major health problems the industrialised world leading over 300 000 mortalities the alone annually most cases caused cardiac arrhythmia called ventricular fibrillation Under normal conditions the coordinated contraction the heart leads effective pumping blood through the body contrast during fibrillation coordination contraction completely lost rendering the heart incapable pumping around blood Despite the huge socio economical costs and decades research its causes and mechanisms still remainpoorly understood experimental studies into the mechanisms pig and dog hearts are considered the best model systems for the human heart given their comparable size such studies found that fibrillation caused highly disorganised electrical wave patterns consisting more rotating spiral waves has been assumed that similar organisation underlieshuman However recent clinical studies suggest that fibrillation inthe human heart may have far more simple organisation Modelling studies have played important role and are playing increasingly important role cardiac arrhythmia research from the single ion channel the whole heart level However the whole heart level most modelling studies thus far have used phenomenological models small heart animal models obtain qualitative insights mechanisms and patterns Instead use detailed model the human ventricles quantitatively study human and why might different from the pig and dog heart indeed find that human has significantly simpler organisation than the pig and dog heart with wave patterns consisting around spiral waves only then study the dependence wave pattern complexity various major parameters our model excitability anisotropy action potential duration APD restitution slope minimum APD find that wave pattern complexity most strongly dependent minimum APD factor that found differ between human and pig and dog hearts thus propose that differences minimum action potential duration cause the differences wave pattern complexity during the human and pig and dog hearts Both the simpler spatial organisation human and suggested cause may have important implications for treating and preventing this dangerous arrhythmia humans 
3585 en Information Transfer Calcium Signal Transduction Calcium ions act second messenger many cell types They transfer extracellular signals from hormones targets within the cell like Ca2 dependent enzymes transcription factors Since number different effectors and cellular targets exist has been suggested that specific information encoded the amplitude frequency and waveform the signal and decoded again later cellular targets After stimulation the calcium concentration the cytosol hepatocytes for example can display complex dynamic behavior including spiking and bursting oscillations Using the information theoretic measure Transfer Entropy Schreiber 2000 studied the properties this signal transduction under different conditions Therefore coupled simple Ca2 dependent enzyme activation process model calcium oscillations Kummer 2000 and experimentally measured calcium time series simulated the system stochastically account for random fluctuations the case low particle numbers approximate the rate information transfer analyzed the resulting time series for different levels activation and different numbers particles using kernel density estimation 
3586 en Population based adaptive Systems Implementation NEW TIES this paper introduce the notion Population based Adaptive Systems PAS with tier adaptation evolutionary individual and social learning discuss some important aspects using combinations these adaptivemechanisms general pay special attention using natural reproductionin and the consequences this for combinations also presentdetails the NEW TIES system partly running example partly forits own sake concrete realisation tier PAS that available asa research platfrom for experimental studies 
3587 en Evolutionary Classification Toxin Mediated Interactions The rock scissors paper game gives atemplate for the structural dynamics toxin induced oscillations withinbacteria The first player the sensitive which toxified thesecond the producer bearing the metabolic costs for resistance and toxinproduction The producer turn again out competed the Resistant who has metabolic costs for toxin production least the Sensitivewins again because has expenses for resistance This leads acoexistive cyclic dynamics the population density these threespecies derive here scenario for the evolutionary dynamics three speciesinvolved this RSP game Starting from basic biologicalprinciples determine evolutionary stable states pathways the traitspace bacteria For the bacteriocin producing bacteria sample mechanisms aredemonstrated derive functional relations between the parameters ofour model necessary for evolutionary dynamics The process usesadaptive dynamics and analyze the stability type the obtained singular point investigate this behaviorwith respect the toxicity the producer and the yield intrinsic growthspeed relation each species The result can generalizedto all kinds toxin disease interactions three species targetdynamics get Zeeman class which permanent and guarantees stablecoexistence three species population dynamics and also with respect toadaptive evolution This implies that all toxin mediated interactions tend toa stable coexistive fixed point given reasonable biological relations betweenthe parameters 
3588 en Cooperation Social Dilemmas The emergence and maintenance cooperative behavior that beneficial others but costly the individual represents major conundrum evolutionary biology Punishment represents efficient mechanism stabilize and maintain cooperation social dilemmas and ubiquitous animal and human societies ranging from toxin producing microorganisms law enforcement institutions but remains unresolved how initially rare and costly punishment behavior can gain foothold and spread through the population nature animals and humans often carefully select their interaction partners adjust their behavioral patterns response them the simplest case they simply refuse participate risky enterprises Such voluntary participation social dilemmas efficient mechanism prevent deadlocks states mutual defection and thus represents potent promoter cooperation but fails stabilize However the combined efforts punishment and volunteering may change the odds favor cooperation Interestingly even though the combined efforts fail infinite populations they nevertheless provide efficient mechanism stabilize cooperation and punishment under the stochastic dynamics finite populations with mutation and selection Thus the freedom withdraw leads prosocial coercion This implements Hardin principle mutual coercion mutually and voluntarily agreed upon 
3589 en Evolutionary Dynamics Finite Populations Oscillations Diffusion and Drift Reversal Coevolutionary dynamics arises wide range from biological social dynamical systems For infinite populations standard approach analyze the dynamics are deterministic replicator equations however lacking systematic derivation finite populations modelling finite size stochasticity Gaussian noise not general warranted show that for the evolutionary Moran process and Local update process the explicit limit infinite populations leads the adjusted the standard replicator dynamics respectively addition the first order corrections the population size are given the finite size update stochasticity and can derived generalized diffusion term Fokker Planck equation This framework can readily transferred other microscopic processes the local Fermi process the inclusion mutations the process explicitely discuss the differences for the Prisoner Dilemma and Dawkin Battle the Sexes where show that the stochastic update fluctuations the Moran process lead finite size dependent drift reversal Claussen and Traulsen Phys Rev 025101 2005 Traulsen Claussen Hauert Phys Rev Lett 238701 Traulsen Nowak Pacheco Phys Rev 011909 2006 Traulsen Claussen Hauert Phys Rev 011901 2006 
3590 en Combined Problems Cooperation and Coordination game theory much attention has been paid symmetrical players games with binary decisions the players Within this frame questions social cooperation and social dilemmas have mostly been attached investigations the Prisoner Dilemma with and this context the readiness individuals resist the temptation defect studied various settings These investigations aim explaining the origin and stability cooperation among selfish individuals But what the readiness resist temptation not enough reach desired outcome Maybe there are more than one desired solutions and the individuals additionally have coordinate their actions realize one them this work focus game theoretical conflicts that exhibit combination cooperation and coordination problems the same game Examples are the Turn Taking Dilemma Neill 2003 and the Route Choice Game Helbing 2005 Stark 2007 The first one similar the above described but the second inequality reversed The Pareto inefficient equilibrium and thereby the cooperation dilemma remains the same but the system optimal solution maximal cumulative payoff shifted the off diagonal the bimatrix When considering iterated game this leads non trivial temporal coordination problem flipping between the upper right and the lower left solutions the bimatrix would lead the only Pareto efficient solution the supergame The latter point also holds for the Route Choice Game with and that represents the problem efficient usage networks with capacity restricted links traffic networks data communication networks course investigations regarding the performance systems with this underlying conflict yield completely different results than those with game underlying However currently there very little work done this direction this contribution will present current research this topic well empirical results previous work Helbing Schönhof Stark Holyst 2005 How individuals learn take turns Emergence alternating cooperation congestion game and the prisoner dilemma Adv Complex Syst 116 Neill 2003 Cooperation and coordination the turn taking dilemma TARK 231 244 Stark Helbing Schönhof Holyst 2007 Alternating cooperation strategies route choice game Theory experiments and effects learning scenario Innocenti Sbriglia eds Games Rationality and Behaviour Palgrave MacMillan 
3591 en Chaos and Stability Learning Random Two person Games Game theory often assumes perfect rationality All agents know all payoff structures They assume their opponents play fully rationally Outcomes Nash equilibria player has incentive deviate unilaterally 
3592 en Competing Associations study six species Lotka Volterra type system different two dimensional lattices when each species has two superior and two inferior partners The invasion rates from predator sites randomly chosen neighboring prey site depend the predator prey pair whereby cyclic symmetries within the two three species defensive alliances are conserved Monte Carlo simulations reveal unexpected non monotonous dependence alliance survival the difference alliance specific invasion rates The invasion probabilities are supplemented Gaussian noise and conditions are identified that warrant the largest impact noise the evolutionary process Our findings are conceptually related the coherence resonance phenomenon dynamical systems via the mechanism threshold duality that not limited predator prey cyclical interactions but may apply models evolutionary game theory well thus indicating its applicability several different fields research 
3593 en Structure and Dynamics Complex Networks
3594 en The Real World Web Search Problem There are numerous papers which present methods address web search related challenges such relevance and ranking query processing and classi cation Unfortunately many these methods are ine ective large scale commer cial setting despite statistically signi cant experimental results help bridge this gap between academic and commercial settings this lecture examines the components large scale commercial search engines then proposes classes problems encountered researchers this area biases bad erent assumptions about statistics users queries web contents insucient miss ing data inconsistencies related evaluations and objectives and policies external factors including resource limitations Using real stories and personal experiences the lecture illustrates examples these problems along with few proposed approaches deal with reduce their consequences ects addition the classes problems there are several fundamental prop erties the web that are often not considered ciently when performing experiments ning problems resulting unrealistic experiments jectives Even within search engine overlooking key properties such the non stationarity the users and the web can result ine ective evaluations and may even lead failed subsystems Fortunately very simple approaches can often highly ective This lec ture helps put context how commercial search engines work what problems they face what ective solutions require and how evaluations and problem nitions could changed more ectively predict success commercial setting while still retaining interest researchers 
3596 en Detecting Money Laundering Actions Using Data Mining and Expert Systems Nowadays terrorism one the biggest troubles that almost every country faces mainly influences the economy and the well being the citizens and this effect relatively larger the developed countries Since the financial sources terrorist groups can regarded black money the solutions against the money laundering actions can expected identify the transactions the terrorists Then blocking their accounts could slow down their actions cannot stop many countries the financial institutions are expected inform compliance regulation bodies about any persons transactions that they think suspicious cope with this necessity various software packages for anti money laundering AML have been developed and are commercially available 
3598 en Approximation algorithms for anonymity and privacy preservation query logs The talk reviews number topics related the concept kanonymity discusses two information theoretic measures for capturing the amount information that lost during the anonymization process iii presents approximation algorithms for the anonymization problem and discusses topics privacy preservation query logs 
3599 en  Systems Perspective Influenza Virus Replication Cell Cultures
3600 en Website Privacy Preservation for Query Log Publishing this work study privacy preservation for the publi cation search engine query logs particular introduce new privacy concern which that website privacy business privacy define the possible adversaries that could interested disclosing website information and the vulnerabilities found the query log from which they could benefit also detail anonymization techniques protect website information and explore the different types attacks that adversary could use then present graph based heuristic validate the effectiveness our anonymization method and perform experimental evaluation this approach Our experimental results show that the query log can appropriately anonymized against specific attack for website exposure only removing approximately the total volume queries and clicked URLs 
3601 en Link Analysis and Text Mining Current State the Art and Applications for Counter Terrorism The information age has made easy store large amounts data The proliferation documents available the Web corporate intranets news wires and elsewhere overwhelming However while the amount data available constantly increasing our ability absorb and process this information remains constant Search engines only exacerbate the problem making more and more documents available matter few key strokes Link Analysis new and exciting research area that tries solve the information overload problem using techniques from data mining machine learning Information Extraction Text Categorization Visualization and Knowledge Management 
3602 en Fitting mixtures regression lines with the forward search application clustering and outlier detection The forward search method for detecting unidentified subsets and masked outliers and for determining their effect models fitted the data This talk describes semi automatic approach outlier detection and clustering through the forward search address challenging issues including selection the number groups The performance the algorithm shown several trade data sets relevant for fraud detection problems 
3603 en Feature selection fundamentals and applications Variable and feature selection have become the focus much research areas application for which datasets with tens hundreds thousands variables are available These areas include text processing internet documents gene expression array analysis and combinatorial chemistry The objective variable selection three fold improving the prediction performance the predictors providing faster and more cost effective predictors and providing better understanding the underlying process that generated the data This presentation will cover wide range aspects such problems providing better definition the objective function feature construction feature ranking multivariate feature selection efficient search methods and feature validity assessment methods Most feature selection methods not attempt uncover causal relationships between feature and target and focus instead making best predictions will examine situations which the knowledge causal relationships benefits feature selection Such benefits may include explaining relevance terms causal mechanisms distinguishing between actual features and experimental artifacts predicting the consequences actions performed external agents and making predictions non stationary environments 
3604 en Geolocalisation Cellular Telephone Networks Cellular telephone operators are currently required provide caller localisation information for use emergency services Localisation fields appended Call Detail Records can now also exploited for commercial purposes such new network services subscription fraud detection customer behaviour monitoring health care monitoring law enforcement and forensics and national and international security The talk reviews cellphone localisation technology via survey location based services and applications overview localisation techniques with example GSM trace mobile demonstration types information available
3606 en Consistency Principle Biological Dynamical Systems propose consistency principle between different levels understand biological system Three topics are discussed First result consistency between molecule replication and cell reproduction universal statistical laws chemical abundances over cells are derived also confirmed experimentally They include power law distribution gene expressions log normal distribution chemical abundances over cells and embedding the power law into the network connectivity Second result consistency between gene and phenotype general relationship between phenotype fluctuations genetic variation and isogenic phenotypic fluctuation developmental noise derived Third touch upon the chaos mechanism for stem cell differentiation with autonomous regulation result consistency cell reproduction and growth cell ensemble 
3607 en Interacting Random Boolean Networks Random Boolean networks RBN have been extensively studied asmodels genetic regulatory networks While many studies have been devoted tothe dynamics isolated random Boolean networks which may considered asmodels isolated cells this paper consider set interacting RBNs which may regarded simplified model tissue monoclonal colony order introduce cellular automata model where each cellsite occupied RBN The mutual influence among cells modelled byletting the activation some genes RBN affected that some genes inneighbouring RBNs shown that the dynamics the far from trivial Different measures are introduced provide indications about the overallbehaviour sense which made precise the text shown that the degreeof order the affected the interaction strength and that markedlydifferent behaviours are observed propose classification these behavioursinto four classes based upon the way which the various measures order areaffected the interaction strength shown that the dynamical properties ofisolated RBNs affect the probability that composed those RBNs belongsto one the four classes and therefore also affects the probability that higherinteraction strength leads greater smaller degree order 
3608 en Evaluating Deterministic Policies Two player Iterated Games construct statistical ensemble games where each independent subensemble have two players playing the same game derive the mean payoffs per move the representative players the game and evaluate all the deterministic policies with finite memory particular show that one the players has generalized tit for tat policy the mean payoff per move both players the same forcing the equalization the mean payoffs per move both players the case symmetric non cooperative and dilemmatic games show that generalized tit for tat imitation policies together with the condition not being the first defect leads the highest mean payoffs per move for the players Within this approach can decided which policies perform better than others The Prisoner Dilemma and the Hawk Dove games have been analyzed and the equilibrium states the infinitely iterated games have been determined The infinitely iterated Prisoner Dilemma game can have Nash solutions only players have deterministic policies 
3610 en Anticipative Control Switched Queueing Systems The relevant dynamics queueing process can anticipated taking future arrivals into account the transport from one queue another associated with transportation delays typical for traffic productions networks future arrivals queue are known over some time horizon and thus can used for anticipative control the corresponding flows queue controlled switching its outflow between and off similar green and red traffic lights where switching requires non zero setup time Due the presence both continuous and discrete state variables the queueing process described hybrid dynamical system From this formulation derive one observable fundamental importance the green time required clear the queue This quantity allows detect switching time points for serving platoons without delay green wave manner Moreover quantify the cost delaying the start service period its termination terms additional waiting time Our findings may serve basis for strategic control decisions 
3611 en Folding Funnels Energy Landscapes Local minima and the saddle points separating them the energy landscapeare known dominate the dynamics biopolymer folding Here weintroduce notion folding funnel that concisely defined interms energy minima and saddle points while the same time conformingto notion folding funnel discussed the protein foldingliterature 
3612 en  the Quantum Complexity Classical Words show that classical and quantum Kolmogorov complexity binary words agree additive constant Both complexities are defined the minimal length any classical resp quantum computer program that outputsthe corresponding word follows that quantum complexity extension classical complexity the domain quantum states This true even allow small probabilistic error the quantum computer output outline mathematical proof this statement based some analytical estimates and classical programfor the simulation universal quantum computer 
3613 en Simulating Dynamic ATM Network Effects using Cellular Automata The dynamical behaviors groups airspace sectors are not trivial analyzed withoutappropriate theoretical tools this paper suggest discrete model based cellular automata express the air traffic dynamics and complexity the controlled airspace Discrete time simulations have been performed with random selected scenarios traffic and with independent sector parameters investigate the impact availability local sectors the whole state the airspace Obtained results show the existence traffic threshhold that leads experimental saturation airspace the test scenario 900 sectors with fly overtime ranging from minutes and sector capacity ranging from aircraft per time unit the resulting traffic threshold was 18000 flights 
3614 en Science Technology and Applications Swarm Robotics
3615 en Distributive Adaptive Control Real world Cognitive Architecture applied Robots Spaces and Avatares
3617 en Flocking Synchronization Phenomenon with Logistic Agents this paper intend show that the flocking phenomenon observed many animal species behaviors may modeled synchronization process occurring within entity states Although flocking has been widely studied and simulated Swarm Intelligence few works mention synchronization key aspect the problem and model properly This paper proposes modeling terms reactive multi agent system composed interacting logistic agents moving environment This specific MAS called Logistic MAS LMAS takes actually inspiration from the coupled map lattice field which provides also many tools toanalyse convergence and stability the system develop our approach boththeoretical and applied way demonstrate its relevance 
3618 en Optimising the Topology Complex Neural Networks this paper study instances complex neural networks neural networks with complex topologies use Self Organizing Map neural networks whose neighbourhood relationships are defined complex network classify handwritten digits show that topology has small impact performance and robustness neuron failures least long learning times Performance may however increased artificial evolution the network topology our experimental conditions the evolved networks are more random than their parents but display more heterogeneous degree distribution 
3619 en Statistical techniques for fraud detection prevention and evaluation The talk begins setting the context fraud defined and its breadth outlined figures are given showing how significant fraud and different areas fraud are examined including health care fraud banking fraud and scientific fraud The particular data analytic challenges banking fraud are described and illustrated detail These include the fact that the classes are highly unbalanced with typically more than 1000 transactions being fraudulent that class labels may often incorrect that there will typically delays discovering the true labels that the transaction arrival times are random that the data are dynamic and perhaps most challenging all that the distributions are reactive changing response the implementation fraud detection systems The role mechanistic and empirical models tackling these problems described Both have been widely used and both have contribution make Banking data and particular banking fraud data are examined detail Raw credit card transaction data have variables per transaction and this can multiplied many fold for behavioural data fraud detection problems Questions arise how aggregate the data should one try classify individual transactions should activity records constructed fundamental aspect any predictive problem data analysis the choice appropriate criterion for estimation and performance assessment the case fraud one needs particular combine both classification accuracy and timeliness classification This means that standard measures classification performance such error rate AUC statistic information value etc are not sufficient Suitable measures and performance curves are described which combine these aspects and which are now being adopted the industry Various statistical used here John Chambers’ sense ‘greater statistics’ approaches have been developed for fraud detection problems and some are described and illustrated using data from some the banks which have been collaborating with particular look supervised classification and anomaly detection methods Finally the context banking fraud some the deeper but very important conceptual issues are outlined including the economic imperative whether fraud now becoming ‘acceptable’ and what exactly learn from empirical comparisons Scientific fraud contrasted with banking fraud They have rather different drivers particular financial gain generally irrelevant scientific fraud which makes unusual kind fraud although course the impact can even more serious Several examples are given from range disciplines The role data analytic tools detecting scientific fraud and the nature such tools described
3620 en Plastic Card Fraud Detection using Peer Group Analysis Fraud detection describesmethods that attempt identify fraudulent activity quickly possible From statistical methods perspective there are broadly two approaches fraud detection These relate whether intend detect known examples fraudulent activity whether intend detect novel forms fraudulent behaviour the former case pattern matching techniques are used the latter case anomaly detection techniques are deployed Peer group analysis unsupervised method for monitoring behaviour over time and can used for anomaly detection the context plastic card fraud detection peer groups are built for each account where peer group collection other accounts that behave similarly The subsequent behaviour each account measured relation its peer group Should account’ behaviour deviate strongly from its peer group then the account flagged anomalous and its recent transactions are flagged potential frauds This approach differs from the usual anomaly detection methods where each account’ current behaviour measured relation its own past behaviour show how apply peer group analysis times series that consist timealigned multivariate continuous data The initial analysis comprises method determine the peer group members for each time series For this need compare time series describe one method that useful for plastic card transaction data Once have the peer groups the analysis then comprises method for tracking time series with respect its peer group anomaly said have occurred should the separation between the time series and its peer group exceed some externally set threshold Account histories plastic card transaction data are neither time aligned nor they consist purely continuous data transaction can occur any time and each transaction has associated with record containing large amount information This enables the card issuer distinguish between the large number possible transaction types that can occur For example account holder who checks their balance ATM example transaction where money transferred account holder who purchases rental car but was not present the point sale describe one way time align different account transaction histories and transform some pertinent information into continuous variables summarise experiments performed using peer group analysis real credit card transaction data particular examine the effect that missed fraudulent transactions have the performance the peer groups describe method for robustifying against fraudulent transactions contaminating peer groups present our results using new measure performance that has been designed specifically for plastic card fraud Not all accounts can tracked well enough their respective peer groups usefully identify anomalous behaviour describe measure peer group quality which use identify accounts that are more likely successfully analysed using peer groups 
3621 en Modeling rare events online advertisement targeting using machine learning and data mining The Turn automatic targeting network provides advertisers revolutionary option for online advertising campaigns online advertising billion industry 2006 according the Interactive Advertising Bureau advertiser simply inputs its into self serve console and Turn does the rest Unlike many networks operating today Turn incorporates extensive industry expertise and innovative technology from the fields machine learning information science and statistics truly make online advertising risk free relevant simple effective and most importantly profitable Unlike traditional networks where advertisers need teams employees manage manual targeting including selecting sites selecting and optimizing hundreds thousands keywords the Turn network automatically analyzes and targets ads Turn’ technology dynamically selects and blends hundreds variables such past performance brand strength user profiles action type and site categories determine the best targets for each thus eliminating guesswork time and complexity The Turn network based statistical technology that intelligently targets both text and graphical ads dynamically and automatically selecting and blending targeting variables Turn can determine the best group ads for any situation Turn offers true pay forperformance with its unique bidded CPA model Because advertisers pay for actions that they define Turn eliminates the risk worthless fraudulent clicks Whether advertiser paying for product purchases site visits leads email signups the advertiser control what they pay for and when they pay for the context this problem setting with billions impressions this poster will address some key issues modeling rare events using machine learning and data mining such uncertainty the regression versus classification dilemma and feature engineering 
3622 en Open Source Intelligence Open Source Intelligence can defined the retrieval extraction and analysis information from publicly available sources Each these three processes the subject ongoing research resulting specialised techniques Today the largest source open source information the Internet Most newspapers and news agencies have web sites with live updates unfolding events opinions and perspectives world events are published Most governments monitor news reports feel the pulse public opinion and for early warning and current awareness emerging crises The phenomenal growth knowledge data and opinions published the Internet requires advanced software tools which allow analysts cope with the overflow information Malicious use the Internet has also grown rapidly particularly line fraud illegal content virtual stalking and various scams These are all creating major challenges security and law enforcement agencies The alarming increase the use the Internet extremist and Terrorist groups has emerged The number terrorist linked websites has grown from about 1998 some 4500 today These sites use slick multimedia distil propaganda whose main purpose enthuse and stir rebellion embedded communities instill fear the “enemy” and fight psychological warfare Anonymous communication between terrorist cells via bulletin boards chat rooms and email also prevalent The Joint Research Centre has developed significant experience Internet content monitoring through its work media monitoring EMM for the European Commission EMM forms the core the Commissions daily press monitoring service and has also been adopted the European Council Situation Centre for their ODIN system new research topic the JRC Web mining and open source intelligence This applies EMM technology the wider Internet and not just news sites This applies advanced multi lingual search techniques identify potential web resources and the extraction and download all the textual content This then followed automatic change detection the recognition places names and relationships and further analysis the resultant large bodies text These tools help analysts process large amounts documents and derive structured data easier analyse This talk will review main topics • Internet trends and the rapid rise Web user generated content • Information retrieval Live content monitoring multilingual news reports Web scraping RSS feed generation Web Mining and content monitoring • Information Extraction Topic filtering Topic Clustering multilingual named entity extraction geocoding and geolocating text event extraction opinion mining • Information Analysis Social Network derivation geospatial indexing and analysis incident tracking databases statistical trend analysis threat monitoring and assessment 
3623 en The Digital Territory Complex System Interacting Agents Emergent Properties and Technologies this paper attempt contribute the integration themathematics and the technological developments and demonstratetheir interplay realizing the concept Digital Territory describe the main mathematical tools that can exploited inthe study properties that emerge soon population sizereaches certain threshold point Our aim show thatnowadays have reached level mathematical and technologicalmaturity sufficient model and simulate any possible worldmodel 
3624 en Combining Information Retrieval and Information Extraction for Medical Intelligence Global epidemic and medical surveillance essential function Public Health agencies whose primary aim protect the public from major health threats perform this function effectively one requires timely and accurate medical information from wide range sources this work present system designed monitor the disease epidemics analyzing textual reports mostly the form news available the Web The system rests two major components—MedISys based Information Retrieval technology and PULS Information Extraction system The Medical Information System MedISys automatic tool that gathers reports concerning Public Health from thousands Internet sources world wide languages classifies them according hundreds categories detects trends across categories and languages and notifies users MedISys compiles quantitative summaries latest reports variety diseases bioterrorism toxins bacteria hemorrhagic fevers viruses medicines water contaminations animal diseases Public Health organisations etc The system categorises all documents according about 200 classes health threats using pre defined weighted boolean queries alerts uses statistical procedures detect sudden increase the volume articles any the classes MedISys part the EuropeMediaMonitor EMM product family developed the ’ Joint Research Centre JRC which also includes NewsBrief live news aggregation system and NewsExplorer news summary and analysis system MedISys has already proved useful and effective tool which attracts thousands users daily technology natural direction for further enhancing the functionality that MedISys offers One reason for this that able deliver information about specific incidents the diseases whereas returns entire matched documents with indication which alerts fired Another reason that could boost precision since keyword based queries may trigger documents which are off topic but happen mention the alerts unrelated contexts while pattern matching assures that the keywords appear relevant contexts only 
3625 en Learning Extract Security related Event Information from Large News Collections Automatic Event Extraction from texts emerges portant and complex text mining task Its goal detect description events speci¯ type described the text For each event the Event Extraction system expected ¯ the time the location the participants this event and their roles well other related circum stances this talk present Machine Learning approach for learning information extraction patterns method for semi automatic lexical acquisition and information aggregation strategy implemented working prototype nexus which detects automatically security related events clusters news articles 
3626 en Chaotic Saddles Spatiotemporal Complex Systems Chaotic transients such chaotic saddles strange repellers semi attractors and super transients have been observed many deterministic systems Kantz and Grassberger 1985 Rempel and Chian 2005 Chian Rempel and Rogers 2006 Rempel and Chian 2007 Formulas can derived relate the average life time the transient dimensions the chaotic transient and Lyapunov exponents the flow this paper show that chaotic saddles are responsible for chaotic transients and intermittency extended complex systems exemplified nonlinear regularized long wave equation relevant fluid and plasma studies Rempel and Chian 2007 Following transition spatiotemporal chaos via quasiperiodicity and temporal chaos the intermittent time series displays random switching between regimes temporal and spatiotemporal chaos Before the transition spatiotemporal chaos identify spatiotemporal chaotic saddle responsible for chaotic transients that mimic the dynamics the post transition attractor and can used predict its behavior After the transition spatiotemporal chaos describe method identify temporal and spatiotemporal chaotic saddles responsible for the two intermittent regimes similar scenario has been observed the Kuramoto Sivashinsky equation suggest that this scenario can readily found extended dissipative dynamical systems that exhibit transient spatiotemporal chaos prior the transition sustained spatiotemporal chaos which evolve from temporal chaos spatiotemporal chaos via crisis like chaotic transition pipe flows and nonlinear optical systems fact this scenario has been observed model ring cardiac cells and plasma laboratory experiments drift waves 
3627 en Testing Complexity Measures Symbolic Dynamics Coupled Tent Maps evaluate new complexity measures the symbolic dynamics coupled tent maps These measures embody the idea quantify complexity terms order statistical dependencies that cannot explained interactions between units demonstrate that these measures are able identify complex dynamical regimes 
3629 en CiteSeerX ChemXSeer Lessons for Cyber infrastructure and Web science cyberinfrastructure have become crucial for scientific progress and open source systems have greatly facilitated design and implementation CiteSeer search engine and digital library for academic documents computer and information science was one the first cyberinfrastructure projects show the promise improved search and access for scientific information For chemistry propose the ChemXSeer funded NSF Chemistry architecture portal for academic researchers environmental chemistry which integrates the scientific literature and search with experimental analytical and simulation datasets 
3630 en Interview with Françoise Fogelman Soulié Françoise Soulie Fogelman has over years experience data mining and CRM both from academic and business perspective talked with her the MMDSS event Italy Gazzada asked her the following questions How academia and industry together with young researchers Privacy policy issues Datamining dream come true Advice young researchers
3633 en Web Click Network analyze the traffic weighted Web host graph obtained from large sample real Web users over about seven months number interesting structural properties are revealed this complex dynamic network some line with the well studied boolean link host graph and others pointing important differences find that while search directly involved surprisingly small fraction user clicks leads much larger fraction all sites visited The temporal traffic patterns display strong regularities with large portion future requests being statistically predictable past ones Given the importance topological measures such PageRank modeling user navigation well their role ranking sites for Web search use the traffic data validate the PageRank random surfing model The ranking obtained the actual frequency with which site visited users differs significantly from that approximated the uniform surfing teleportation behavior modeled PageRank especially for the most important sites interpret this finding consider each the fundamental assumptions underlying PageRank and show that each violated actual user behavior Joint work with Mark Meiss Santo Fortunato Alessandro Flammini and Alessandro Vespignani 
3634 en Dynamic Visualization Internet Topology Evolution
3635 en State topology Interplay Epidemic Dynamics Adaptive Network
3636 en New Insights the Traceroute Process Network Exploration Dynamical processes taking place real networks define them evolving subnetworks whose topology not necessarily the same the underlying one investigate the problem determining the emerging degree distribution focusing class tree like processes such those used explore the Internet topology general theory based mean field arguments proposed both for single source and multiple source cases and applied the specific example the traceroute exploration networks Our results provide qualitative improvement the understanding dynamical sampling and the interplay between dynamics and topology large networks like the Internet 
3637 en Emergent Opinion Dynamics Endogenous Networks recent years networks have gained unprecedented attention studying broad range topics among them complex systems research particular multi agent systems have seen increased recognition the importance the interaction topology now widely recognized that emergent phenomena can highly sensitive the structure the interaction network connecting the system components and there growing body abstract network classes whose contributions emergent dynamics are well understood However much less understanding have yet been gained about the effects network dynamics especially cases when the emergent phenomena feeds back and changes the underlying network topology Our work starts with the application the network approach discrete choice analysis standard method econometric estimation where the classic approach grounded individual choice and lacks social network influences this paper extend our earlier results considering the endogenous dynamics social networks particular study model where the behavior adopted the agents feeds back the underlying network structure and report results obtained computational multi agent based simulations 
3639 en Battling Networks Rival Social Movements
3641 en Targeted Reinnervation for Improved Myoelectric Prosthesis Control Don miss the moment from Pop Tech 2005 the world first non fictional bionic man maneuvers his prosthetic arm using only his 160 mind Jesse Sullivan and his doctor Todd Kuiken move every heart the room with indomitable spirit and astonishing bionics 
3642 en Gene Organism and Environment Bad Metaphors and Good Biology The standard metaphors used describe DNA and development are examined including the claim that DNA makes protein that DNA 160 self replicating and the organisms adapt their environments this lecture distinguished evolutionary geneticist Richard Lewontin explains that DNA manufactured the cell machinery that proteins are folded rules that are not related DNA sequence and that organisms rather than adapting their environment are actively engaging constructing their own environments that organisms and environments evolve 
3643 en Our Lives Our Facebooks Students large number American colleges and universities have come rely The Facebook http facebook com vital supplement their social lives social connector website Facebook serves the information needs students who have perpetually flux social networks result frequency and penetration student use remarkable this presentation longitudinal analysis Facebook use freshmen the University North Carolina Chapel Hill will presented Use patterns will analyzed with special concentration factors that contributed the product success 
3644 en Where Mind and Matter Meet Recent advances cellular science are heralding important evolutionary turning point For almost fifty years have held the illusion that our health and fate were preprogrammed our genes concept referred genetic determinacy Though mass consciousness currently imbued with the belief that the character one life genetically predetermined radically new understanding unfolding the leading edge science Cellular biologists now recognize that the environment the external universe and our internal physiology and more importantly our perception the environment directly controls the activity our genes This video will broadly review the molecular mechanisms which environmental awareness interfaces genetic regulation and guides organismal evolution 
3645 en Scaling Laws Biology and Other Complex Systems Life very likely the most complex phenomenon the Universe manifesting 160 extraordinary diversity form and function over enormous range Yet many its most fundamental and complex attributes scale with size surprisingly simple fashion For example metabolic rate the power required sustain the system scales approximately the power mass over orders magnitude from molecular levels the largest multicellular organisms Similarly time scales such lifespans and growth rates increase with exponents which are typically simple powers will shown how these universal quarter power scaling laws follow from fundamental generic principles embedded the dynamics and geometry underlying networks leading general quantitative theory that captures essential features many diverse biological systems Examples will include animal and plant vascular systems growth cancer aging and mortality sleep DNA nucleotide substitution rates These ideas will extended discuss social organisations such cities and firms what extent all can think these very large organisms and therefore extension biology Analogues metabolic rate and behavioral times cities scale counter their behaviour biology Driven innovation and the creation wealth this has dramatic implications for their growth development sustainability and pace life which left unchecked potentially sow the seeds for their collapse 
3646 en Return the RNAi World Rethinking Gene Expression and Evolution While investigating the genetic workings the microscopic worm elegans Mello and 160 colleague Andrew Fire PhD the Carnegie Institution Washington discovered RNAi natural but previously unrecognized process which certain form RNA can manipulated silence— interfere with—the expression selected gene The discovery published the journal Nature 1998 has had two extraordinary impacts biological science One research tool RNAi now the state the art method which scientists can knock out the expression specific genes cells thus define the biological functions those genes But just important has been the finding that RNA interference normal process genetic regulation that takes place during development Thus RNAi has provided not only powerful research tool for experimentally knocking out the expression specific genes but has opened completely new and totally unanticipated window developmental gene regulation RNAi now showing promising the clinic new class gene specific therapeutics 
3647 en Mysteries the Human Genome The human genome the hereditary material pass our progeny can cast billion letter string over DNA alphabet four currently understand this mass mostly the form genes DNA substrings that code for proteins the quintessential constituents every living cell The remainder our genome was often deemed junk This picture changed when the genome related species became available comparison are suddenly able pinpoint the locations staggering one million additional human subsequences that must important the human cell The functions these regions remain largely unknown while their sheer volume overwhelms any comprehensive experimental approach Guided experimental results for handfuls these subsequences computational approaches can employed tackle the tremendous challenge understanding this data and providing key biological observations this talk will describe ultraconserved elements some the most perplexing regions within the human genome and track down phenomenon turning genomic junk into gold The talk will assume prior knowledge Molecular Biology 
3648 en How Bacteria Cause Disease Join Warren Levinson learn about the various agents that cause infectious diseases bacteria viruses fungi protozoa and worms with focus how bacteria are transmitted and cause disease and how exotoxins and endotoxins cause symptoms disease 
3649 en BacGrid Simulations Bacteria using the GRID Bacterial biofilms provide systems the complexity needed 160 exemplify many the generic features multi cellular behaviour without such complexity once becoming overwhelming They are addition enormous environmental industrial and medical importance Many processes biofilms operate the macroscopic scale and are thus susceptible continuum modelling approaches essential however that models incorporate appropriate way information about the micro scale behaviour and their results must turn coupled back into the rules adopted the cell scale modelling motivating the use agent based modelling The simulation such complex systems typically requires huge computing resources The Grid provides unrivalled technology for large scale distributed simulation and exceptionally well suited addressing the challenges raised integrative biology this paper present BacGrid system for performing distributed simulation bacteria using the High Level Architecture HLA and the Grid present the bacterial model and show results from initial experiments investigating the role quorum sensing molecule QSM the development the bacterial colony sketch out the design for the distribution bacterial simulation components across the grid and indicate how this technology can used create large scale simulations conclude with discussion the current status the system and our plans for future work and experiments 
3650 en The Origin the Human Mind Insights from Brain Imaging and Evolution UCSD cognitive scientist Martin Sereno takes you captivating exploration the brain structure and function revealed through 160 investigations with new advanced imaging techniques and understandings evolution 
3651 en Evolution the Human Species Eminent evolutionary biologist Christopher Wills takes you exploration human evolutionary history and how derived from both 160 the genetic and fossil records 
3652 en ISP aided Biased Query Search for P2P Systems Testlab More than half Internet traffic today contributed peer peer P2P systems P2P systems build their overlay topology largely agnostic the Internet underlay which often leads traffic management challenges for Internet Service Providers ISP and potentially inefficient neighborhood selection for P2P nodes overcome this propose use oracle hosted the ISPs that ISPs and P2P users can cooperate for improved performance The oracle can queried P2P nodes while choosing neighbors for content search and will rank the possible neighbors the querying node according locality indication like the hop distance The ISP would gain keeping traffic within its Autonomous System network and the P2P node would experience improved performance like lesser delay and better bandwidth this paper evaluate the benefits our scheme performing experiments real Testlab consisting routers switches and computers running actual instances P2P applications showhow configure representative topologies for P2P networks using VLANs and trunking ports andpresent experimental results with content search phase P2P network using different file sharing and search query distributions 
3654 en Uncovering Latent Structure Valued Graphs Variational Approach more and more network structured datasets are available the statistical analysis valued graphs has become common place Looking for latent structure one the many strategies used better understand the behavior network Several methods already exist for the binary case present model based strategy uncover groups nodes valued graphs This framework can used for wide span parametric random graphs models Variational tools allow achieve approximate maximum likelihood estimation the parameters these models provide simulation study showing that our estimation method performs well over broad range situations 
3656 en Eigenmode Decision Majority Process Complex Networks The nature opinion formation dynamics complex networks investigated using eigenmode analysis Opinion formation dynamics modeled decision majority process spin like variables located vertices complex networks Hamiltonian the system defined and estimated the eigenvalue and eigenvector the adjacency matrix constructed from several network models Then the eigenmodes initial and final state the dynamics are analyzed numerical studies shown that the magnitude the largest eigenvector the initial states are key determinant for the resulting dynamics proved that the final state the dynamics can estimated the eigenmodes the initial state 
3657 en Generating Graphs with Predefined Core Structure The modeling realistic networks great importance for complex systemsresearch Previous procedures typically model the natural growth networks byiteratively adding nodes use geometric positioning information define linkconnectivity with preference for nearest neighbors already highly connectednodes combine several these approaches Our novel model based the well know concept cores originally introduced social network analysis Recent studies exposed the significant core structure several real world systems the network theInternet present two algorithms for generating networks which strictlyadhere the sizes given core structure but also exhibit adaptationto various use cases showcase this comparative evaluation with twowell known network generators 
3658 en Randomness and Complexity Networks Recently showed that simple model network rewiring could besolved exactly for any time and any parameter value also showed that this model can recast terms several well known models statistical physics such urn model and the voter model also noted that has been applied wide range problems Here consider various generalisations this model and includesome new exact results 
3659 en Spectral Plot Properties Qualitative Classification Networks introduce tentative classification scheme for empirical networks based global qualitative properties detected through the spectrum the Laplacian the graph underlying the network Our method identifies several distinct types networks across different domains applications indicates hidden regularity properties and provides evidence for processes like node duplication behind the evolution construction given class networks 
3660 en Connections between Random Boolean Networks and their Annealed Model Random Boolean Networks RBN with bias are considered show that the behaviour the called annealed modelis completely determined the expectation the average sensitivity proof that the annealed model its ordered phase and only the corresponding quenched modelis its ordered phase side product get annealed analysis forRBNs with fixed bias 
3662 en Directed Overlapping Clusters Social Networks Recently efficient search technique locating communities networkmodules densely connected groups nodes was introduced fordirected networks Palla New Journal Physics 186 2007 Here investigate the centrality properties directed module membersin social networks obtained from mail exchanges and fromsociometric questionnaires Our results indicate that nodes the overlaps betweenmodules play central role the studied systems Furthermore the two different types networks show interesting differencesin the relation between the centrality measures and therole the nodes the directed modules 
3663 en Dynamics and Biological Networks Case Studies the Machinery Life Gene regulation networks and other molecular networks that regulate the processes life the living cell are prototypes for dynamical networks that combine the aspects both transferring dynamical signaling the one hand and being structurally dynamical themselves the other hand Both phenomena while living vastly different timescales that molecular interactions versus the timescale macroevolution are closely interwoven and depend each other will take closer look this interesting type complex networks and will review few approaches and views from different angles 
3664 en Topographic Analysis Empirical Human Sexual Network Spreading electronic viruses among computers and mobile phones typically depends address phone number lists The network formed these lists not symmetric the fact that has ’ address does not ensure that has ’ address Thus the underlying network which such spreading takes place directed the links are general one way present extension our analysis for spreading undirected graphs the case directed graphs find that some ideas from Web link analysis lead concrete prediction that the epidemic coverage changes qualitatively when the rate infections from ”outside” the network exceeds threshold rate Specifically for low rate infections from outside with high probability only the giant component and its out components are infected while for above threshold infection rate from outside the whole graph likely infected 
3665 en Evolution Cooperation Dynamical Graphs Population structure has been proposed one the mechanism promoting cooperation Until recently most studies assumed that the interaction network can described regular graph Recently Ohtsuki have shown for number other interaction topologies that selection favours cooperation the fixation probability single cooperator higher than the fixation probability neutral mutant the prisoners dilemma game the benefit the altruistic act divided its cost exceeds the average number neighbours that They found this relation approximately valid populations different structure which interaction topology described variously regular random regular random scale free graphs Similarly Santos have shown that the heterogeneous degree distribution these other types graphs generally facilitate the dominance cooperative behaviour Previous studies have assumed that the graph static during evolution This assumption implies that newborn individual accepted strategy imitation given position interacts with exactly the same individuals that were connected every preceding individual this position Some recent papers studied the evolution cooperation dynamical networks They either studied the fixation probability single cooperator among defectors the case when graph dynamics much faster than dynamics evolution the relative speed graph and evolutionary dynamics were waried systematically they assumed that cooperators and defectors were the same fraction initially the population Here investigate how sensitive the fixation probability single cooperator the network dynamics dynamics slow relative the evolution 
3666 en From Protein Protein Domain Domain Interactions and Back With the advent domain interaction networks derived from structures and experimentally determined large scale protein interaction networks number interesting questions arise Are interaction interfaces more conserved than the rest the surfaces Can the structure protein interaction networks linked underlying domain interactions Can motifs derived from domain interactions predict protein interactions Can viral domains mimick native human protein interaction interfaces There intricate relationship between domain domain and protein protein interactions whose understanding helps answer the above questions the talk will review how construct networks derived from structural domains and how complement large experimental protein interaction networks with interactions extracted from literature will shed light onto the structure these networks how identify functional modules and how predict interactions The discussed techniques will used identify candidate targets pancreas cancer and will show how viruses interfere with the apoptotic programme their hosts 
3667 en  Social Network Approach Unsupervised Induction Syntactic Clusters for Bengali this paper describe some experiments fully unsupervised induction parts speech tags for Bengali words from raw text corpus For this purpose construct the network 5000 most frequent Bengali words where nodes are the types and the weight the edge between two types indicative their distributional similarity and cluster the network using the Chinese Whispers algorithm also propose the concept tag entropy that measures the cohesiveness the word clusters terms the lexical categories the constituent words 
3668 en Rearrangement Spirals into Target Patterns the Course Dictyostelium discoideum Aggregation The amoebae Dictyostelium discoideum has been frequently investigated suitable model system the framework biological pattern formation signal transduction cell differentiation and morgenesis see for review Under conditions starvation populations these amoebae aggregate due chemical waves cAMP cAMP wave passes cell moves the opposite direction consequently towards the origin the signal long the cAMP concentration increasing over time Formally this system regarded complex self organizing network cells communicating through chemical medium The spatio temporal patterns cAMP waves are manifestation the intrinsic properties this active medium Depending the experimental conditions either spiral circular shaped waves cAMP arise Sometimes pattern one type transformed into the other one the course time experiments two different examples for transitions from one the other type spatio temporal patterns were reported the first case continuous transition from the spiral type pattern target waves was observed the later stages aggregation the second case the transition was induced spatially homogeneous cAMP pulse when after resetting oscillating spots bearing target patterns emerged instead the originally present spirals Similar results were reported Lee The biological significance different types cAMP waves for Dictyostelium discoideum morphogenesis and the mechanisms transitions between them are still unclear Thus the question arises what are the internal cellular properties and the external experimental conditions which lead such transition attempt find the answer this question applying mathematical modelling approach 
3669 en Examining Higher Order Transformations for Scale free Small World Graphs The degree distribution scale free Small World networks follows power law For random graph generators its exponent constrained the construction mechanism whereas real world data different slopes can observed However the degree distribution alone does not reveal much the local structure these graphs Therefore propose graph transformation call ”higher order” transformation which encodes the number common neighbours two vertices share its edge weights Studying the degree distribution secondand third order graphs and comparing natural language cooccurrence data find that the higher order transformation reveals differences that cannot detected only looking traditional measures the original graph 
3671 en Statistical Dynamics Religions and Adherents argue that religion another degree freedom describe population evolving network present comprehensive analysis called religion evolutions measured through their number adherents The Avrami Kolmogorov differential equation which usually describes solid state transformations used each case order obtain the preferential attachment parameter introduced previously often found close unity indicating smooth evolution However large values suggest the occurrence extreme cases which conjecture are controlled called external fields few cases indicate the likeliness detachment process Various cases are illustrated seems that religion exciting and even more physically interesting statistical physics subject than language due the presence external fields and various time scales Hamiltonian and Langevinian like description will suggested Ausloos and Petroni Statistical Dynamics Religions and Adherents Europhys Lett 2007 38002 Abrams Strogatz Modelling the dynamics language death Nature 424 2003 900 col 
3672 en Social Networks and Ideological Movements History Burning and the Rise English Protestantism There historical consensus that the beginning the reign the Catholic Queen Mary 1553 the Protestant reforms instituted Henry VIII the 1530s and continued under Edward 1547 had engaged the support only tiny minority the population The restoration Catholicism met with widespread approval But mere six years later the introduction Protestantism the Edwardian model Elizabeth 1559 met with virtually protest good historical case can made that the persecution and burning high profile Protestants Mary was important factor reversing public opinion network approach which society envisaged scale free network with each individual influenced their religious beliefs small number others whom they pay attention yields the result that the burnings may well have been the decisive factor The highly connected individuals here are course the Protestant martyrs England 1559 had not become nation Protestant zealots but sufficient people were impressed the martyrs’ demeanour acquiesce the new faith This analysis supported contemporary evidence that Protestant leaders under Mary stressed that executions were opportunities display public fortitude and piety influence people 
3673 en  Language Change Rates Depend Population Size earlier study Nettle 1999b concluded based computer simulations and some inferences from empirical data that languages will change the more slowly the larger the population gets replicate this study using more complete language model for simulations the Schulze model combined with Barab´asi Albert network and richer empirical dataset the World Atlas Language Structures edited Haspelmath 2005 Our simulations show either weak stronger dependence language change population sizes depending the parameter settings and empirical data like some the simulations show weak dependence 
3674 en Global and Local Dynamics Correlated Systems this talk will show results concerning the characterization and visualization correlations financial systems means network analysis will discuss results from the application new method which able construct complex graphs from cross correlation matrices Dynamical changes the local topology and hierarchy these graphs are detected and related markets fluctuations Aste Matteo Hyde Physica 346 2005 Tumminello Aste Matteo Mantegna PNAS 102 2005 10421 10426 Aste and Matteo Physica 370 2006 156 161 Tumminello Aste Matteo and Mantegna EPJB 2007 209 217 Pozzi Matteo Aste preparation 2007 
3677 en PAC Bayes Analysis Classification The lecture will introduce the PAC Bayes approach the statistical analysis learning After some historical introduction the key theorems will covered will then consider some applications including for Support Vector Machines and novelty detection discussion the status the prior the approach will lead investigation how learning the prior can used practical applications Discussions further extensions the approach will conclude the presentation 
3679 en Similarity and differences finite automata
3680 en  line learning algorithms theory and practice
3682 en Probabilistic Graphical Models and Structured Prediction
3683 en Magic Moments Moment based Approaches Structured Output Prediction
3685 en Support Vector Machines and Kernel Methods
3687 en  The History Ugliness “History Beauty ” Umberto Eco explored the ways which notions attractiveness shift from culture culture and era era With UGLINESS collection images and written excerpts from ancient times the present asks repulsiveness too the eye the beholder And what learn about that beholder when delve into his aversions Selecting stark visual images gore deformity moral turpitude and malice and quotations from sources ranging from Plato radical feminists Eco unfurls taxonomy ugliness gross out contests ’ both absorbing and highbrow 
3688 en Interview with Neil Johnson
3690 en Interview with Adobe Chief Software Architect Kevin Lynch speaks about his begennings Macintosh how startet the business years ago and how named the Adobe breakthrough application Dreamweaver The Videolectures Net team encountered him the W3C Video the Web Workshop where among other things asked him about his personal and professional dream come true his vision the video the general 
3691 en Interview with the W3C Chief Executive Officer Steve Bratt the CEO the Consortium Videolectures Net sent paper the W3C Video the Web Workshop which was held December 2007 San Jose California There met Bratt and asked him few questions after the workshop finished How W3C handling video this moment What will happen after this workshop Who standardising the video the web big repositories W3C What the closest domain video the web the semantic web How you see research and video the web The first thing you will when you leave the building 
3692 en Interview with W3C Compound Document Specialist Doug Schepers has been programming since his early teens has focused SVG for the past years developing SVG applications founding member Vectoreal association SVG professionals You can reach him svg http schepers schepers you want read more about Doug you can read his personal Web site Schepers Videolectures Net sent paper the W3C Video the Web Workshop which was held December 2007 San Jose California There met Doug and asked him few questions after the workshop finished Any comments your presentation What W3C doing for the standardisation the video the web What did you miss the workshop The current hot topic about the video the web Personal and professional dream come true First thing you will after you leave this building 
3693 en  alternative modeling for biological signaling networks Biological signaling networks transmit and process extra cellular information triggering complex transformations that lead different cellular responses The overall cellular behavior well grasped differential equations the challenge produce mathematically affordable microscopic models leading these equations The usual modeling approach based chemical kinetics hampered the large number assumptions needed alternative propose spin flip dynamics defined asymmetric mean field interactions This dynamics yield density profile processes whose trajectories converge almost surely the solutions dynamical systems with possibly complex behavior 
3694 en Singular Diffusion Equations Minimally Stochastic Solution Schemes Total variation and balanced forward backward BFB diffusion are popular examples singular diffusion processes Finite extinction time the experimentally observed tendency create piecewise constant regions and the absence parameters makes them very interesting image processing tools However their appropriate numerical treatment still challenge this contribution minimally stochastic approach the underlying singular equations presented relies analytical solutions two pixel signals and stochastic rounding This introduces regularisation via integer arithmetic and does not require any limits the diffusivity Experiments demonstrate the favourable performance the proposed probabilistic method 
3695 en Locally Analytic Schemes for Diffusion Filtering Images Nonlinear diffusion filtering has proven its value versatile tool for structure preserving image denoising Among the most interesting methods this class are tensor driven anisotropic diffusion well singular isotropic diffusion filters like total variation flow For different reasons devising good numerical algorithms for these filters challenging spatial discretisation transforms nonlinear diffusion partial differential equations into systems ordinary differential equations Their investigation yields insights into the properties diffusion based algorithms but leads also the design new algorithms with favourable stability properties which are the same time simple implement Moreover interesting links wavelet based denoising methods are established this way The talk focusses the construction and properties locally semi analytic schemes for nonlinear isotropic and anisotropic diffusion images with extensions the case 
3696 en Adaptive procedures for FDR control multiple testing Multiple testing classical statistical topic that has enjoyed tremendous surge interest the past ten years due the growing domain applications that are demand for powerful and reliable procedures this regard For example bioinformatics often the case that multiple testing procedures are needed process data very high dimension where only small number sample points are available their 1995 seminal work Benjamini and Hochberg first introduced the false discovery rate FDR notion type error control that particularly well suited screening processes where very high number hypotheses has tested has since then been recognized facto standard first review existing called step testing procedures with FDR control valid under several types dependency assumptions the joint test statistics and show that can recover and extend them considering very simple set output point view along with with what call self consistency condition which sufficient ensure FDR control then proceed consider adaptive procedures where the estimation the total proportion true null hypotheses can lead improved power this regard introduce algorithm that almost always more powerful than adaptive procedure proposed Benjamini Yekutieli and Krieger 2006 
3697 en Homeomorphic smoothing splines monotonizing unconstrained estimator nonparametric regression
3698 en MCMC SMC What next The Monte Carlo method was initially developed for scientific computing statistical physics during the early days the computers Due the rapid progress computer technology and the need for handling large datasets and complex systems the past two decades have witnessed strong surge interest Monte Carlo methods from the scientific community Researchers ranging from computational biologist signal image processing engineers and financial econometricians now view Monte Carlo techniques essential tools for inference Besides using the popular Markov chain Monte Carlo strategies and adaptive variants various sequential Monte Carlo strategies have recently appeared the scene resulting wealth novel and effective inferential and optimization tools this talk will present what believe the state the art Monte Carlo simulations for inference and will try identify the next challenges 
3699 en Contour Enhancement and Completion via Left Invariant Evolution Equations 
3700 en Shape constraints and algorithms consider several problems the areas nonparametric regression and image analysis under shape constraints The task always produce simple functions with small number local extreme values while multiresolution criteria ensure good approximation the fitted functions These strategies easily lead minimisation problems that can very difficult solve hence the design efficient algorithms crucial One the problems that study concerned with online data where fast processing particularly important 
3712 en STM Manipulation Atoms and Molecules Novel quantum structures can realized manipulating surface single atoms andn molecules Recent efforts manipulating these basic construction species meansn low temperature ultra high vacuum scanning tunneling microscope combined withn variety tunneling spectroscopic methods will presented The performedn experiments are important for both fundamental understanding and construction ofn novel nano devices Described will measurements lateral forces requiredn move individual atoms realization multi step single molecule switch and ann hybrid device composed atoms and molecules 
3714 en Graphite new twist Carbon element that unique the variety utility and individuality its allotropes Diamond and graphite each have several uniquely extreme properties that have been exploited twentieth century science and technology Against the curious landscape the periodic table the discoveries fullerenes 1985 and nanotubes 1991 stand out substantial landmarks Their beauty lies creating isolatable molecular forms the somewhat messier world crystal defects similar topological concepts can applied leading sheets which are buckled folded welded together unified into one sheet The description these defects comes from the science dislocations and their structures can deduced from first principles methods such density functional theory DFT connector between sheets similar the ramp connecting the floors multistorey car park prismatic screw dislocation dipole fold pile basal dislocation dipoles The identification and characterization dislocations graphite gives insight into structures which have been overlooked the science graphite especially radiation damage which occurs reactor graphite subjected energetic neutrons 
3717 en Wetting and Contact Lines Micrometer sized Ellipsoids experimentally and theoretically investigated the wetting fluid interface solid micrometer sized ellipsoidal particles The latter were obtained from uniaxial stretching monodisperse polystyrene spheres radius and the aspect ratio was varied from about have demonstrated that such ellipsoids oil water interfaces manifest long range capillary interactions considerable energies about 105 times the thermal energy The contact line exhibits saddle like deformations and has quadrupolar symmetry the interface pulled down near the tips the ellipsoid and pulled near the middle the particle Two ellipsoids attract each other tip tip side side but repel one another when side tip configuration These trends are indeed line with the general rule according which the interaction between capillary charges the same sign attractive while repulsive between charges opposite signs interpret our experimental data numerically solved the partial wetting problem single ellipsoid and found that the contact line indeed saddle shaped curve with quadrupolar symmetry Furthermore comparisons experimental and simulated data allowed determine contact angles and rather unexpectedly the latter were found decrease significantly with increasing ellipsoid aspect ratio 
3725 en  Ventures you will soon discover Ventures not just another venture capital fund are entrepreneurs just like you having exited our last startup immediately prior launching this fund have proven track record entrepreneurs having founded three successfully exited technology startups All our exits have been relatively quick and medium size – just like the strategy Ventures are technologists like you who know your industry and can get deep understanding your business within hours not weeks are young like you and understand your needs and what motivates you and our stated purpose not just generate significant returns for the fund but also look after you and make sure that the end the day you get what you wanted After all want you come back and also refer your friends 
3726 en Interview with Yoav Andrew Leitersdorf Venture Capital
3728 en Online Learning Music Preference consider the problem online learning changing environment under sparse user feedback Specifically address the classification music types according user’ preferences for hearing aid application The classifier operating under limited computational resources must capable adjusting types data not represented the training set and changing user demands The user provides feedback only occasionally prompting the classifier change its state propose online learning algorithm capable incorporating information from unlabeled data semi supervised strategy and demonstrate that the use unlabeled examples significantly improves classification performance the ratio labeled points small 
3729 en Linear Programming Boosting for Classiﬁcation Musical Genre Classification musical genre from raw audio files fairly well researched area music research and such provides good starting point for testing new algorithm The Music Information Retrieval Evaluation eXchange MIREX yearly competition wide range machine learning applications music MIREX 2005 included genre classification task the winner which was application the multiclass boosting algorithm AdaBoost believed that Linear Programming Boosting LPBoost more appropriate algorithm for this application due the higher degree sparsity the solutions The present study aims improve the result using similar feature set and the multiclass boosting algorithm LPBoost References Bergstra Casagrande Erhan Eck and Bal´azs Aggregate features and ADABOOST for music classification Machine Learning 473–484 2006 Schapire and Singer Improved boosting algorithms using confidence rated predictions Machine Learning 297–336 1999 Ayhan Demiriz Kristin Bennett and John Shawe Taylor Linear programming boosting via column generation Machine Learning – 225–254 2002 
3730 en The Conditionally Independent Voice Model will talk about two related topics First will introduce the conditionally independent voice model which expresses music collection voices that evolve independently from one another when conditioned process that describes some shared evolving attribute such harmony will show application pitch spelling from MIDI though believe the model may find use variety musical applications Attempts train this model automatically using traditional Baum Welch type methods were not particularly successful due perhaps the inappropriateness the marginal likelihood criterion introduce method for directly minimizing the error rate test set using computational ideas from POMDPs 
3731 en Information Dynamics and the Perception Temporal Structure Music has often been observed that one the more salient effects listening music create expectations within the listener and that part the art making music create dynamic interplay uncertainty expectation fulfilment and surprise was not until the publication Shannon work information theory however that the tools became available quantify some these concepts Since then there has been sporadic interest the relationship between information theory and music and aesthetic perception general this talk will examine how small number emph time varying information measures such entropies and mutual informations computed the context dynamically evolving probabilistic model can used characterise the temporal structue stimulus sequence considered random process from the point view Bayesian observer One such measure novel emph predictive information rate which conjecture may provide explanation for the inverted relationship often found between simple measures randomness entropy rate and judgements aesthetic value Berlyne 1971 explore these ideas the context Markov chains using both artificially generated sequences and two pieces minimalist music Philip Glass showing that even overly simple model the Markov chain when interpreted according information dynamic principles produces structural analysis which largely agrees with that expert human listener will also discuss how the same principles can applied models more complex than the fully observed Markov chain particular hidden Markov models using online variational Bayesian methods track the observer probabilistic beliefs about unobserved variables 
3732 en Time Frequency and Synchrony Analysis Responses Steady State Auditory and Musical Stimuli from Multichannel EEG Brain responses audio stimuli are analysed using data driven time frequency analysis This achieved based the electroencephalogram EEG recordings and with auditory chirps music the audio stimulus The empirical mode decomposition EMD applied multichannel EEG recordings and the insight into the brain responses provided the analysis the dynamics auditory steady state responses ASSR The proposed approach further illustrated the analysis EEG responses classical music comprehensive synchrony analysis provided based the visualization EMD and spectrogrammatching techniques Simulation results illustrate the potential the proposed approach future brain computer machine interfaces 
3733 en The Mental Representation Music Neural Darwinist Perspective this presentation review the perceptual research related auditory representation for music The research suggests that multiple representations exist concurrently the auditory system and that the dominant representation shaped the specific auditory environment note that the research consistent with theories competitive representations such Edelman neural Darwinist approach propose that the difference predictive accuracy for different representations provides the feedback mechanism which competing representations are selected Repercussions for cognitive modeling music are discussed 
3734 en Measuring and Modeling Musical Expression Expressive timing and dynamics are important part musical meaning For those skeptical this claim will play some examples music with and without expressive timing and dynamics will then provide overview previous approaches measuring and modeling musical expression different contexts One relatively unexplored task that analyzing music for which musical score available will describe why this different problem than score following and will argue for the importance score free models working with improvisation and related tasks will provide some preliminary results employing correlation based model Autocorrelation Phase Matrix APM infer metrical trees unscored music Expressive timing and dynamics can then measured with respect these trees note for the audience The spirit NIPS workshops bring new and perhaps even half baked ideas the table that spirit hope that talk derailed into discussion about measuring and modeling expressive timing and dynamics unscored streams MIDI audio 
3735 en Project Presentation Closing the Loop Sound Evaluation and Design CLOSED Objectives Despite being promising and lively playground sound design not solid discipline yet believe that the reason found the lack design oriented measurement and evaluation tools The CLOSED project aims providing functional aesthetic sound measurement tool that can profitably used designers one end this tool will linked with physical attributes sound enhanced everyday objects the other end will relate user emotional response The measurement tool will made set easy interpret indicators which will related use natural context and will integrated the product design process facilitate the control sonic aspects objects functionalities and services encountered everyday settings The aim the CLOSED project provide such concepts and tools toward closing the loop sound evaluation and design more http closed ircam 
3736 en Project Presentation Emergent Cognition through Active Perception EmCAP EmCAP Emergent Cognition through Active Perception research project the field Music Cognition funded the European Commission FP6 IST started October 2005 and will finish September 2008 Our goal investigate how complex cognitive behaviour artificial systems can emerge through interacting with environment and how becoming sensitive the properties the environment such systems can autonomously develop effective representations 
3737 en Hierarchical Bayesian Models for Audio and Music Processing recent years there has been increasing interest statistical approaches and tools from machine learning for the analysis audio and music signals driven partially applications music information retrieval computer aided music education and interactive music performance systems The application statistical techniques quite natural acoustical time series can conveniently modelled using hierarchical signal models incorporating prior knowledge from various sources from physics studies human cognition and perception Once realistic hierarchical model constructed many audio processing tasks such coding restoration transcription separation identification resynthesis can formulated consistently Bayesian posterior inference problems this talk will review recent advances various signal models for audio and music signal analysis particular factorial switching state space models Gamma Markov random fields will discussed Some models admit exact inference otherwise efficient algorithms based variational stochastic approximation methods can developed will illustrate applications music transcription tempo tracking restoration and source separation applications 
3738 en Hallucinations Auditory Perception this talk want review the need for richer architectures for auditory processing Many experiments point the tangled web connections the perceptual system yet our engineering solutions remain almost exclusively bottom How that can provide context that our systems can solve musical analysis and auditory scene analysis problems talk about notable systems that are successful hallucinators 
3739 en  Auditory Model for the Detection Perceptual Onsets and Beat Tracking Singing describe biophysically motivated model auditory salience and present results which show that the derived measure salience can used successfully identify the position perceptual onsets musical stimulus evaluate the method using corpus unaccompanied freely sung stimuli briefly show that perceptual onsets detected the model are good agreement with those identified combination state the art algorithms and manual correction show that this continuousmeasure salience can used track and predict rhythmic structure the basis its periodicity thus avoiding the necessity for hoc decisions when event has occurred 
3741 en Model Compression Bagging your Cake and Eating too part 
3742 en Model Compression Bagging your Cake and Eating too part 
3743 en Architecture Conscious Data Analysis Progress and Future Outlook Over the past several years architectural innovation processor design has led new capabilities single chip commodity processing and high end compute clusters Examples include hardware prefetching simultaneous multithreading SMT and more recently true chip multiprocessing the very high end systems area networking technologies like InfiniBand have spurred the development affordable cluster based supercomputers capable storing and managing peta bytes data contend that data mining and machine learning algorithms which often require significant computational and communication resources stand benefit from such innovations appropriately leveraged The challenges are daunting First large number state the art data mining algorithms grossly under utilize modern processors the building blocks current generation commodity clusters This due the widening gap between processor and memory performance and the memory and intensive nature these applications Second the emergence multi core architectures the commodity market bring with them further complications Key challenges brought the fore include the need enhance available fine grained parallelism and alleviate memory bandwidth pressure Third parallelizing data mining algorithms multi level cluster environment challenge given the need share and communicate large sets data and balance the workload the presence data skew this talk will discuss progress made the context these challenges and attempt demonstrate that architecture conscious solutions are both viable and necessary will attempt separate general methodologies and techniques from specific instantiations whenever makes sense will conclude with discussion future outlook both the context systems support for next generation algorithms well terms educational objectives brought the fore this context This joint work with graduate students Gregory Buehrer Amol Ghoting and Shirish Tatikonda 
3744 en Who Afraid Non Convex Loss Functions The NIPS community has suffered acute convexivitis epidemic applications seem have trouble moving beyond logistic regression SVMs and exponential family graphical models For new model convexity viewed virtue Convexity sometimes virtue But often limitation theory has essentially never moved beyond convex models the same way control theory has not really moved beyond linear systems 
3745 en Large Scale Learning with String Kernels applications bioinformatics and text processing such splice site recognition and spam detection large amounts training sequences are available and needed achieve sufficiently high prediction performance classification regression tasks Although kernel based methods such SVMs often achieve state the art results training and evaluation times may prohibitively large When single kernel computation time already linear the input sequences seems difficult achieve further speed ups this work describe efficient technique for computing linear combinations string kernels using sparse data structures such explicit maps sorted arrays and suffix tries trees arrays computing linear combinations kernels make the dominant part SVM training and evaluation speeding their computation essential Considering the recently proposed and successfully used linear time string kernels like the Spectrum kernel and the Weighted Spectrum kernel show that one can accelerate SVM training factors and times respectively while requiring considerably less memory Our method allows train string kernel SVMs sets large million sequences Moreover using these techniques the evaluation new sequences often several thousand times faster allowing apply the classifiers genome sized data sets with seven billion test examples The presented algorithms are implemented our Machine Learning toolbox SHOGUN for which the source code publicly available http www shogun toolbox org References Gusfield Algorithms strings trees and sequences Cambridge University Press 1997 Leslie Eskin and Noble The spectrum kernel string kernel for SVM protein classification Altman Dunker Hunter Lauderdale and Klein editors Proceedings the Pacific Symposium Biocomputing pages 564–575 Kaua’ Hawaii 2002 ¨atsch and Sonnenburg Accurate Splice Site Prediction for Caenorhabditis Elegans pages 277–298 MIT Press series Computational Molecular Biology MIT Press 2004 Sonnenburg Philips Schweikert and ¨atsch Accurate splice site prediction using support vector machines BMC Bioinformatics 2007 Sonnenburg ¨atsch and Rieck Large scale learning with string kernels Bottou Chapelle DeCoste and Weston editors Large Scale Kernel Machines Neural Information Processing Series pages –104 MIT Press Cambridge 2007 Sonnenburg Zien and ¨atsch ARTS Accurate Recognition Transcription Starts Human Bioinformatics e472–480 2006 
3746 en Speeding Stochastic Gradient Descent order tackle large scale learning problems whose solution necessarily involves large model with many tunable parameters difficult non convex optimization has performed efficiently Computational complexity arguments strongly suggest that deep architectures will necessary represent the kind complex functions that involves Unfortunately this involves difficult optimization problems and efficient approximate iterative optimization becomes key obtain good generalization and not much the regularization techniques that have been well studied the last two decades Furthermore because the size the data sets involved such tasks imperative that computation scale more than linearly with respect the number training examples many cases the algorithm beat stochastic gradient descent and the comparisons have made looking the curve test error versus computation time Following recent interest online versions second order optimization methods present computational tricks that yield linear time variant natural gradient optimization Another issue that particularly difficult address the optimization multi layer neural networks how parallelize efficiently SMP machines becoming cheaper and easier use compare and discuss different strategies for exploiting parallelization training for multi layer neural networks showing that naive approaches fail but those taking into account the communication bottleneck yield impressive speed ups 
3747 en Stationary Features and Folded Hierarchies for Efficient Object Detection Most discriminative techniques for detecting instances from object categories still images consist looping over partition pose space with dedicated binary classifiers This strategy inefficient for complex pose for fine grained descriptions fragmenting the training data which inevitable dealing with high class variation severely reduces accuracy the computational cost high pose resolution prohibitive due visiting massive pose partition overcome data fragmentation will discuss novel framework centered pose indexed stationary features which allows for efficient one shot learning pose specific classifiers Such features assign response pair consisting image and pose and are designed that the probability distribution the response constant object actually present avoid expensive scene processing the classifiers are arranged hierarchy based nested partitions the pose which allows for efficient search The hierarchy then folded for training all the classifiers each level are derived from one base predictor learned from all the data The hierarchy unfolded for testing parsing scene amounts examining increasingly finer object descriptions only when there sufficient evidence for coarser ones will illustrate these ideas detecting and localizing cats highly cluttered greyscale scenes This joint work with Francois Fleuret 
3748 en Efficient Machine Learning using Random Projections alternative cumbersome nonlinear schemes for dimensionality reduction the technique random linear projection has recently emerged viable alternative for storage and rudimentary processing high dimensional data invoke new theory motivate the following claim the random projection method may used conjunction with standard algorithms for multitude machine learning tasks with virtually degradation performance Thus random projections can been shown result both significant computational savings and provably good performance 
3749 en New Quasi Newton Methods for Efficient Large Scale Machine Learning The BFGS quasi Newton method and its limited memory variant LBFGS revolutionized nonlinear optimization and dominate this day Their application large scale machine learning however has been hindered the fact that they assume smooth strictly convex and deterministic objective function finite dimensional vector space Here relax these assumptions one one and present BFGS variants newly developed our group that perform well non convex smooth quasi convex non smooth and non deterministic objectives Paradigmatic applications include parameter estimation MLPs non convex smooth and SVMs convex non smooth and stochastic approximation gradients non deterministic for efficient online learning large data sets are also able lift LBFGS RKHS for online SVM training all these cases our BFGS variants outperform previous methods wide variety models and data sets from toy problems large scale data mining tasks 
3750 en Large Scale Euclidean MST and Hierarchical Clustering present new fast algorithms for performing the single linkage hierarchical clustering method classical data mining method used heavily bioinformatics and astronomy given similarities which are metrics present experimental results that demonstrate significant speedup over previous algorithms both synthetic and real data including dataset million astronomical observations and dataset protein folding trajectories Additionally our algorithms use considerably less storage than previous methods More generally our algorithm appears the fastest practical solution the well known Euclidean Minimum Spanning Tree problem 
3751 en Large Scale Sequence Labelling The general sequence labelling problem consists processing input sequence and producing output sequence discrete labels Since the space the possible output sequences discrete this can viewed massive classification problem The notion structured output prediction arises when one makes strong modelling assumption order learn the association with reasonable number examples The conditional independence assumption states that label can modelled function the inputs and the labels for suitable choice the sets and The invariance assumption states that this function does not depend The choice sets and has non trivial impact the generalization performance and the training and testing times 
3753 en Introduction the Workshop this workshop aim highlight important problems and gather ideas how address them The target audience are practitioners providing insight into and analysis problems with certain methods comparative studies several methods well theoreticians interested characterizing the hardness continuous distributions proving relevant properties established method 
3754 en Infer NET Practical Implementation Issues and Comparison Approximation Techniques Infer NET efficient general purpose inference engine developed Microsoft Cambridge Tom Minka John Winn and others aims highly efficient general purpose and extensible three normally contradictory goals have largely managed achieve these goals using compiler like architecture that code generated perform the desired inference task Infer NET can apply one range inference algorithms given probabilistic model and provides useful framework for comparing the performance different algorithms this talk will describe the capabilities and infrastructure Infer NET and give examples applying both expectation propagation and variational message passing the same model will also describe some failure cases that have encountered for each algorithm 
3755 en Approximating the Partition Function Deleting and then Correcting for Model Edges
3758 en Large scale Bayesian Inference for Collaborative Filtering The Netflix prize problem provides excellent testing ground for machine learning The problem large scale and the data complex and noisy therefore likely that relatively complex models with careful regularization are needed order get reasonable predictions Bayesian modeling approach seems ideal for the task possible scale the size the Netflix data set where extremely high dimensional Bayesian expectations will possibly have approximated this talk ordinal regression low rank matrix decomposition model presented use variational Bayes inference algorithm demonstrate that possible make large scale Bayesian algorithm This model also highlight some the general limitations The more accurate expectation propagation expectation consistent inference cannot applied this linear model without further approximations therefore propose hybrid approach with inspired modifications the algorithm compare the different variational approximations with Laplace approximation MAP approximation and Hamiltonian MCMC the latter one sample takes around hours computing time 1GHz processor with fast code there very clear case made for deterministic approximate inference Another good feature the Netflix data the magnitude the the test set which makes even small differences the performance significant 
3759 en Perturbative Corrections Expectation Consistent Approximate Inference Algorithms for approximate inference usually come without any guarantee for the quality the approximation Nevertheless often find cases where such algorithms perform extremely well the computation posterior moments when compared time consuming and the limit exact simulations exact enumerations prominent example the Expectation Propagation algorithm when applied Gaussian process classification Can understand when and why can trust the approximate results not how could obtain systematic improvements this talk rederive the fixed point conditions using the ideas expectation consistency and explicitly consider the terms neglected the approximation will show how one can derive formal asymptotic power series expansion for this correction and compute its leading terms will illustrate the approach for the case classification and for networks Ising variables Expectation Consistent Approximate Inference Manfred Opper and Ole Winther JMLR 2177 2204 2005 
3760 en  Completed Information Projection Interpretation Expectation Propagation This talk presents interpretation expectation propagation hybrid between two different iterated Bregman projections algorithms from the convex analysis and programming literature whose convergence behavior well studied suggested that convergence results for may developed through this interpretation adapting relevant convergence proofs for the related projections algorithms Example convergence results for special cases are derived through this connection well through connection between and the Gauss Seidel iterative solution method 
3762 en Learning Information Extraction and the Web
3763 en The Security Mobile Agent Systems model for mobility called Petri hypernets was presented Hypernets offer visual formalism describe hierarchically structured dynamic agents The agents take the form Petri nets which manipulate other agents resources logic was proposed which one can describe the temporal and the structural properties agents hypernet One can also analyse some properties hypernets expressible Petri net invariants thanks the translation hypernets safe Petri net systems given Recently see have addressed the problem modelling complex hybrid discrete agent systems modular way The idea here obtain the view the complete system from number simpler views each devoted specific perspective One view for instance could describe how some mobile agents can evolve time — this view could captured hypernet Another could address other issues for instance the rights agent read some messages The purpose the talk describe how the approach can used model specify and verify some security aspects mobile agent systems 
3764 en Subgroup Discovery Recent Biomedical Applications This talk presents recent advances data mining focusing subgroup discovery and the ways use subgroup discovery generate actionable knowledge for decision support Actionable knowledge explicit symbolic knowledge typically presented the form rules that allow the decision maker recognize some important relations needed perform appropriate action such planning population screening campaign aimed detecting individuals with high disease risk Different subgroup discovery approaches are outlined illustrated with case studies from medicine and functional genomics 
3765 en Neutrinos Discovering New Physics World The discovery neutrino mass and mixing one the major discoveries particle physics the recent years Non zero neutrino masses and mixing are considered the first direct evidence new physics beyond the Standard model Phenomenological consequences this discovery well possible implications for fundamental theory will discussed Future programs research and possible developments the neutrino technologies will outlined 
3767 en  compact high brilliance SAXS SWAXS GISAXS instrument for laboratory use compact modular laboratory unit for SAXS SWAXS and GISAXS with high brilliance presented that facilitates nanostructure analysis bulk materials liquid crystals bio polymer nanoparticle solutions and thin solid films The system MICRO based upon combination point focus microbeam delivery system GeniX from Xenocs Grenoble France working maximum power Watt with the Hecus camera architecture with and detectors With monochromatized radiation SAXS resolution Qmin 003 Å corresponding values 2000 Å can easily achieved Due the point cross section the primary beam desmearing the scattering data not required The beam brilliance exceeds that high power rotating anode SAXS systems factor and that conventional line focussing systems two orders magnitude This allows reduce measuring times down seconds for many problems nanostructure research facilitating high throughput structural proteomics and line process analytical applications Due the low electrical power Watt and the consequently minimal cooling requirements the system design extremely compact and economical and therefore optimally suited for installation multi facility analytical laboratories mobile test stations The software package includes modules for system control SWAXView Labview ® based and for line data analysis EASYSWAX supporting automatic multi sample analysis and routine analytical applications amp and 
3776 en The rule law and the role the courts The perception law from within proper understanding the role the courts safeguarding the rule law independent branch government prerequisite for any viable public appreciation the law general and the judicial system particular This notably and quite obviously the case with the perception the role the courts from the viewpoint the two “political” branches government well the general public which will presumably the focus other talks the conference but also partly dependent upon the self positioning the judiciary which will the main focus the originating point this talk This task may addressed several ways principled level the challenge reconciling the internal need for independent – autonomous – judiciary with the external drive for its accountability more concrete level translated into individual choices that fall somewhere between the lines judicial restraint and judicial activism epitomized the now slightly démodé “political question” doctrine While the doctrine itself has somewhat disappeared from the legal debate the recent years the questions posed remain just valid today Should judges making policy Where the line made between what the proper realm adjudication and what goes beyond into improper interference with the other branches government Can judicial activism ever defended proper and what extent and under what circumstances May certain increased level judicial activism justified transitional societies and inasmuch used further the cause judicial independence The talk will address these questions with reference recent examples from across the globe their actuality and practical volatility ranging from the relatively harmless academic questioning Justice Ginsburg’ dissent the recent Ledbetter Goodyear Tire amp Rubber case calling upon Congress “correct” the Supreme Court’ “parsimonious reading” certain legislation and trying “propel legislative change” the critical case the unfortunate illegitimate ousting absurdly vast numbers judges Pakistan attempt stifling judicial autonomy anticipation judicial decisions unfavorable the government 
3777 en Measuring Public Confidence European Courts This paper considers indicators public confidence the courts nine continental European Union countries considering ways this may evaluated factors contributing detracting from public confidence and ways some European countries have addressed public interests and concerns draw European study that set out explore ways measuring the quality justice nnThe study developed framework within which participating nations reported their efforts measure and improve the performance their judicial systems including the institutional framework recruitment and training means evaluation and measures satisfaction and quality The European research aimed understand the quality measurement systems that had been used the jurisdictions involved the study assess their impact and the possibility generalising any them other jurisdictions nnIt was means assumed that quality was measured quantitatively will seen more detail shortly vast range indicators was available from financial data and information appeals and their outcomes public campaigns the media and the streets While noting tendency for judges and managers value different types information and appeal diverse sets values the researchers remained equally interested all approaches return below some further observations the tensions between legal and managerial approaches and the possibility their reconciliation the present paper explore variety ways which courts and other public institutions may able gather evidence public confidence the lack order make judgments their standing the community nnThroughout the study have been particularly interested measures that may lead courts some action improve reform their performance and here report those measures that appeared enhance the capacity the courts earn public confidence Let consider what information might able gain better understand its quality which may more interest than its quantity 
3781 en ECHR Caselaw Media and Judiciary
3786 en The first inorganic nanopods and nanobuds The discovery WS2 and MoS2 nanotubes and inorganic fullerene like nanoparticles shortly proceeded the discovery carbon fullerenes C60 nanotubes and onions The WS2 and MoS2 nanomaterials have shown important applications solid lubricants electron devices catalysts super shock absorbers etc tribology contrary plate like crystals exhibit ultra low friction and wear even humidity The mass production non agglomerated important challenge report new production approaches new forms macroscopic quantities The synthesis based sulphurization MoOx WOx and MoxSyIz quasi one dimensional precursors which transform MoS2 WS2 based nanomaterials The results various characterisation methods reveal the possible mechanism the formation these new complex nanomaterials W5O14 nanowires are synthesized chemical transport reaction using NiI2 growth promoter The light blue crystals metallic conductivity with specific resistivity have grown typically several millimetres length and 200 wideness This rarely synthesized phase was reported homogeneous phase only 1978 McColm and meantime declared the compound which may hardly exist The W18O49 nanowires several millimetres length are synthesized chemical transport reaction using iodine transport agent The morphology the wires can controlled the ratio between starting materials and the growth conditions optimisation can gain pure purple W18O49 phase with crystals several hundred nanometers wide blue nanowire W18O49 phase with wideness bellow 200 The first inorganic nanobuds – WS2 nanotubes decorated outer surface with fullerene like particles are synthesized sulphurization the W5O14 nanowires The sulphurization takes place gas mixture H2S and with flow rate min 1050 for hours The fullerene like particles nucleate surface corrugations the nanowires and grow diffusion process simultaneously with the transformation nanowires hollow multi wall nanotubes slightly lower sulphurization temperature the material was transformed WS2 nanotubes The diameter the tubes nanobuds smaller than the wideness precursor nanowires revealing exfoliation the precursors The sulphurized W18O49 nanowires transform nanotubes decorated with flakes WS2 but not forming the fullerenes like particles Nanowires based Mo6S2I8 were also used precursor crystals for sulphurization synthesized the Mo6S2I8 nanowires directly from elements 1320 The prolonged reaction time hours resulted several millimetre long needles having diameter from several tens few hundred nanometers The result the sulphurization are the first MoS2 nanopods “mama tubes” spherical MoS2 nanoparticles grown the confined geometry MoS2 nanotube reactors 
3787 en Nanostructuring polycristalline gold thin films deposited glass means ion beam Thin solid films appear most commonly polycrystalline form which means that they have higly constrained single crystalline grains Polycrystalline films are used large variety devices such magnetic storage media catalytic and thermal elements protective coatings thus desirable extend polycrystalline films the approaches which have been developed for the self organised formation nanostructures single crystalline metal substrates Ion beam sputtering can used modify surfaces nanoscale level most cases the result formation ripples the surface Substrates with well defined vertical roughness controlled orientation and periodicity can achieved varying macroscopic parameters that influence ripple formation such ion beam energy and ion beam dose Thin films 150 thick were deposited glass microscope slides two different deposition techniques thermal and sputter deposition thus resulting different initial grain sizes and grain size distributions The films were then ion beam sputtered sequence different times determine the evolution the morphology and the role grain size plays the morphological characteristics ion beam sputtered thin films Resulting morphology was then characaterised SEM imaging and AFM giving data roughness wavelength and underlaying grain size evolution For comparison commercially obtained gold films grown mica which had grain sizes the order few hundred were also included the experiment 
3788 en Structural and electronic properties molybdenum chalcohalide nanowires combine initio density functional and quantum transport calculations based the nonequilibrium Green’ function formalism compare structural electronic and transport properties Mo6S6 xIx nanowires with carbon nanotubes find systems with particularly stable and rigid with their electronic structure and conductance close that metallic single wall carbon nanotubes Mo6S6 xIx nanowires are conductive irrespective their structure more easily separable than carbon nanotubes and capable forming ideal contact leads through thio groups 
3789 en Some topics theoretical nanofriction natural for all properties determined surfaces and interfaces rather than bulk adhesion and friction increase importance when the objects that come into contact  and move relative one another are nanosized this talk propose review some theory and simulation work recently done our group topics and models that are inspired nanofriction nnAmong them are Some strange phenomena determined the sliding periodic but incommensurate systems The effect high temperatures and surface melting the friction felt AFM tip The negative differential friction predicted for high speed sliding coaxial nanotubes The diffusive ballistic crossover predicted for the frictional slip time gold nanoclusters graphite 
3790 en Zero bias conductance through coupled quantum dots Using three supplementary numerical methods quantum Monte Carlo algorithm based the constrained path method variational approach and numerical renormalization group technique compute zero temperature conductance through different interacting regions Comparison our results with those obtained with the essentially exact Bethe ansatz method reveals excellent agreement then extend our calculations three quantum dots coupled series well multiple quantum dot systems coupled parallel study the effect various strengths inter dot overlap the shape Kondo plateaus that appear function the gate voltage Our results for conductance are further supplemented with calculations various correlation functions terms the gate voltage the limit when the overlap between quantum dots small the system behaves two channel Kondo model investigate possibility for detecting Non Fermi liquid behavior the system weakly coupled quantum dots and discuss its experimental relevance also present the phase diagram containing different Kondo regimes 
3791 en Magnetic impurity formation quantum point contacts quantum point contact QPC narrow region separating two wider electron reservoirs the standard building block sub micron devices such quantum dots small boxes electrons and qubits the proposed basic elements quantum computers function its width the conductance through QPC changes integer steps 2e2 signalling the quantization its transverse modes Such measurements also reveal additional shoulder value around which has become known the anomaly Recently has been suggested that this phenomenon can explained one invokes the existence magnetic impurity the QPC low densities Here report our extensive density functional calculations that reveal the formation electronic state with spin magnetic moment the channel the density increases above pinch off under very general conditions 
3792 en  efficient mixed semiclassical quantum mechanical model simulate planar and wire nano transistors The design miniaturized planar and nanowire field effect devices for CMOS compatible nano electronics poses new challenges the field nanostructure modelling Pros and cons innovative devices incorporating different channel materials strained III and crystal orientations need assessed Transistors with body thickness TSi and channel length few nanometres have been demonstrated Uch02 Wak03 where strong quantization effects the vertical direction coexist with quasi ballistic far from equilibrium carrier transport the lateral direction the field engineering applications full quantum–mechanical modelling realistic nano transistors has been far mainly restricted ballistic transport Lau04 However scattering the channel still remarkably important predict the drain current even for nano devices with ≈ Pal04 Moreover unclear the complex full quantum treatment the scattering would lead manageable numerical models and the expected huge computation times will paid off improved accuracy this contribution report recent advances the development efficient modelling framework capable combine the accuracy quantum mechanical simulations with semiclassical treatment carrier transport aimed the accurate calculation the main performance metrics planar and wire like devices for nano electronic applications 
3793 en Optical Properties and Excitonic Effects Nanowires this contribution discuss the role excitons the dielectric function and the optical properties nanowires make use the “EXCITING” package developed Graz The package based the solution the two particle Bethe Salpeter equation BSE for the electron hole pairs and includes the electron hole corre lations focus the Mo6S6 nanowires despite the fact that far only its close relative Mo6Se6 has been synthesized Mo6S6 has bridging anions and the dressing anions are all atoms has very promising strongly anisotropic mechanical well electronic properties 
3794 en Can particles the nanoscale result better drug delivery systems Due the advances molecular biotechnology and bioinformatics there strong increase new candidate drug molecules However their transport the actual site action and bioavailability are decisive issue order enable adequate delivery small larg drug molecules some special formulation will required Current advances material science and nanotechnology promise the development new generations drug carriers for these active substances for diagnostic and therapeutic purposes Today are mostly investigated liposomes nanoparticles dendrimers nanotubes etc where size geometry porosity dispersity surface chemistry are highly defined Carrier composition and structure promises control over biological fate the talk three examples studied our lab will used illustrate these points preparation drug loaded solid lipid nanoparticles interactions nanoparticles with the cells and surfactant selection for adequate nanoparticles production that causes minimal toxicity HEK 293 cells while preventing nanoparticles aggregation These observations indicate that the design and development novel nanoparticles for drug delivery combination factors such composition size and surface properties influence bioavailability uptake into the cells and toxicity Current work focuses systematic variation these parameters develop carrier system with designed function 
3795 en Formulation PLGA nanoparticles for intracellular delivery protein drug Design and formulation advanced drug delivery systems DDS such nanoscale carriers presents attractive research area the field drug formulation vast contribution expected delivery biopharmaceuticals clearly recognized that inadequate delivery the single most important factor delaying their application clinical practise spite some successful guidelines formulation protein drugs DDS requires step step strategy and methods differing from those used for classical pharmaceutical drugs since proteins are the most delicate ones term retaining their biological function model protein drug cystatin was selected our work having high potential for inactivating cysteine proteases enzymes involved processes tumour invasion and metastasis Nanoparticles was used carrier system with the aim increase the bioavailability the protein drug protecting from premature degradation biological environment and faciliting its intracellular delivery Cystatin was incorporated poly lactide glycolide PLGA nanoparticles the water oil water emulsion solvent diffusion method preserve its biological activity optimized technique was developed adjusting physical and chemical parameters processes during nanoparticle production Cystatin loaded NPs had size 300 350 diameter and contained cystatin retaining its starting activity follow cellular uptake nanoparticles cystatin was labelled with fluorescent dye Alexa Fluor 488 prior its encapsulation into NPs Image analysis showed rapid internalization NPs into MCF 10A neoT cells the fluorescence spots were detected after treatment with NPs the other hand labelled free cystatin was internalised very slowly suggesting that NPs facilitate the delivery its cargo into the cells Cystatin delivered NPs also exerted its inhibitory activity intracellular target cathepsin suggesting that its integrity was preserved throughout the processes formulation and delivery the other hand free cystatin did not impart proteolityic activity cathepsin when tested under the same conditions using the substate specific for intracellular cathepsin Our results show that protein drug can formulated the active form into PLGA NPs when suitably selecting the process parameters production NPs are also able facilitate delivery protein drug into the cells enabling its activity the intracellular target
3796 en Nanoscale functionalities for biopharmaceutical drug delivery One our recent research challenges has been exploitation the active principle protein aggregation involving metal coordination specifically designed protein analogues Specifically designed analogues tumour necrosis factor alpha TNF alpha rich histidines served model proteins LK801 TNF alpha analogue with double histidine mutation Glu107HisGly108HisTNF alpha the tip region the bell shaped molecule Due the symmetrical trimeric structure histidine residues the tip region form almost planar cluster six well accessible histidines resulting strong binding Immobilized Metal Affinity Chromatography IMAC which was used for efficient single step purification IMAC was also used for preparation His10 TNF TNF alpha analogue with His10 tag and amino acid sequence responsible for enterokinase cleavage added the native terminus and H7dN6TNF analogue which has tag comprised seven histidines terminus Two types inorganic nanoparticles containing metal ions were prepared zinc phosphate nanoparticles precipitation and zinc modified silica adsorption zinc ions commercially available silica nanoparticles For the proof concept preliminary experiments bovine serum albumin BSA was used for binding BSA contains naturally surface exposed histidines and was also expected coordinatively bind nanoparticles with metal ions When such particles were exposed low buffers buffers containing imidazole release BSA was confirmed SDS PAGE analysis thus proving the reversibility metal specific binding the next steps histidine rich TNF analogues were used for binding phosphate nanoparticles and release studies were performed under different conditions also measured biological activity TNF alpha analogues prior binding and later after the release from inorganic nanoparticles The controlled formation TNF alpha analogues nanoparticles was tried protein self assembly using metal ions Zn2 First experiments were performed with only the addition zinc ions and later performed experiments using Zn2 and different biocompatible chelates phytic acid and Tetraazacyclotetradecane tetraacetic acid Upon administration above mentioned protein aggregates the testing animals increased immune response anticipated the case TNF alpha analogues enhanced formation antibodies against TNF alpha would advantageous serving basis for developing new drugs for chronic diseases associated with pathogenically elevated TNF alpha levels rheumatoid arthritis Crohn disease psoriasis etc His10 TNF analogue appears especially interesting since exhibits very low vitro cytotoxic activity Upon formation nanostructures significantly diminished number accessible receptor binding sites and consequently even more reduced cytotoxicity expected leading safe formation anti TNF alpha antibodies 
3797 en Novel routes nano materials for ion batteries Advanced ion batteries providing enhanced storage capacities and improved power performances are currently required not only the fast growing market portable electronics but also emerging electric hybrid electric vehicles are investigating two novel techniques for this purpose Spark Discharge Generation SDG and Electrostatic Spray Reductive Precipitation ESRP SDG uses physical “top down” approach that relies the atomization two metal rods via sudden spark Two cylindrical rods are connected high voltage and parallel variable capacitance The capacitors are periodically charged the break down voltage the system determined the gap between the rods Through the high temperature the generated spark electrode material rapidly evaporated and the vapour condenses form nano sized metallic particles addition unconventional densification technique called Magnetic Pulse Compaction MPC being used for self manufacturing metal alloy rods atomized ESRP physical chemical technique relying combined “top down” and “bottom ” approach which bridges aerosol generation with chemical precipitation order form nanoparticles Electro Spraying liquids consists the creation charged aerosols applying high voltage between nozzle through which the liquid sprayed fed and counter electrode Interesting properties this phenomenon are the narrow size distribution the emitted droplets well tuning the droplet size controlling experimental parameters Moreover high net surface charge the generated droplets causes repulsive interaction preventing droplet coalescence These beneficial aspects have been exploited combination with well known technique for the synthesis metallic and alloyed particles namely Reductive Precipitation metal chlorides NaBH4 Dissolved metal chlorides precursors are forced flow syringe pump which provides constant supply the nozzle with controlled flow rate Under the influence the high electric field small charged droplets are formed and attracted towards ring shaped counter electrode which placed the reductive solution this way the droplets containing precursor metal ions are driven into the reductive bath where they are immediately reduced their zero valent state Primary particles with size the range can obtained proper selection the experimental parameters 
3798 en Manipulation Nanoscale Charged Polar States Manganites The complicated interplay among charge spin and lattice degrees freedom manganites believed induce the unexpected magnetic and transport phenomena such the colossal magnetoresistance CMR Manganites display also variety useful multiferroic properties such colossal magnetocapacitance effect and high dielectric constant multiferroics ferromagnetic order can controlled electric field ferroelectric order can controlled magnetic field Among them La1 xSrxMnO3 the most attractive candidate for multiferroic applications because combination desirable properties this work report the observation the high contrast electric field induced charged polar states after the local application the electric field the surface samples via several Scanning Probe Microscopy SPM techniques La0 9Sr0 1MnO3 and La0 89Sr0 11MnO3 single crystals The electric field induced contrast observed Kelvin mode KFM confirming local modification the surface properties manganites Piezoelectric effect the induced states assessed using Piezoresponse Force Microscopy PFM These results are complemented the measurements piezoresponse hysteresis and surface potential hysteresis loops some area standard pulse mode The induced polar charged states relax with characteristic time constant about hours room temperature which exceeds Maxwell relaxation time many orders magnitude The mechanisms the observed phenomena are discussed along with the possible instrumentation effects The origin the effect can related the nanoscale charge and spin dynamic inhomogeneities appearing manganites due delicate balance charge lattice and magnetic order The injection the additional charge carriers the induced area promotes the appearance the polar charged states The long relaxation time for the induced charged state may explained the existence the intrinsic inhomogeneous states All these results show that the existence the stable areas with the increased charge concentration possible and thus confirms the tendency towards charge segregation manganites 
3799 en Self catalysed growth GaAs nanowires MBE Semiconductor nanowires NWs growth typically assisted metal particle called the catalyst The use the catalyst material different from the components the wire may change the semiconductor properties due the diffusion the catalyst the nanowire body during the growth Moreover the most commonly used catalyst metal that incompatible with the technology For the above mentioned reasons therefore importance develop technology leading catalyst free growth semiconductor nanowires Here report preliminary results catalyst free growth GaAs NWs molecular beam epitaxy The GaAs NWs have been grown cleaved edges wafers with catalyst pre deposition The growth lasted minutes and has been performed 580 620 ° Two kinds nanowires have been obtained The NWs the first type are long with section diameter the range tens and have spherical particle their end tip Energy dispersive ray spectroscopy EDS demonstrates that the spherical particle composed and that the body GaAs The NWs density depends the crystallographic orientation the facets that compose the cleaved edges the wafers The second type NWs are generally characterised smaller aspect ratio clearly faceted lateral and tip surfaces and metallic particle their tip EDS curves reveal that they are completely made GaAs The EDS results suggest that induced self catalysed growth occurred specific surface locations where droplets formed and were trapped during the first stages the GaAs deposition Work progress understand the growth process and particular understand whether the droplet less NWs grow through different process the absence droplet due its lost during growth 
3800 en Carbon nanotubes added hexagonal WO3 films world wide concern for enviromental safety that demands monitoring the emission hazardous gases into the atmosphere combined with recent advances wireless senzor networks increasing the need low power gas sensors and low cost Among metal oxides between theirselves the tungsten oxides are among the most used materials electro photo and gasochromic applications this work soft chemical nanocrystalline processing route has been demonstrated for the preparation hexagonal tungsten oxides the acidic precipitation Na2WO4 2H2O solution temperatures low 120 ° and 330 ° The structural properties films were investigated TEM Philips The sensing properties films were measured gaseous ammonia various temperatures founded the correlation between structure and gas sensing properties WO3 films The average size WO3 H2O crystallites ÷ 100 After the head treatment films the average size WO3 crystallites decreased ÷ The electron diffraction the film confirmed the phase change from orthorhombic hexagonal one The gas measurements were performed direct injection using gas serynge and the arrows the graphics indicate the total amount gas present the measurement chamber after successive injections 
3801 en Preparation the Bi12SiO20 thin films the sol gel method Bismuth silicon oxide Bi12SiO20 BSO which has sillenite structure piezoelectric electro optic photo refractive and optically active material Recently the sillenites have begun considered for use dielectric the field electronics They are used new material LTCC Low temperature fired ceramic technology Because the low sintering temperature good chemical and dielectric properties the “bulk” BSO1 decided prepare thin films this material this paper will report the preparation BSO thin films using sol gel method various substrates The aim work was achieve pure BSO thin films with good control over their microstructure and thickness 
3802 en Photosensitive titanium oxide sols and gels for solar energy conversion and storage Due the potential applications the field environmental protection the photochemistry TiO fast growing area both terms research and commercial activity Beside the white pigment properties rutile and anatase paints and cosmetic products titanium dioxide used heterogeneous catalysis and photocatalysis water purification air cleaning photoelectrochemical solar cells for the production hydrogen and electricity active layer the design electrochromic devices gas sensor corrosion protective coating ceramics and electric devices such varistors name few such applications the performance titanium oxide could optimized with specific nanostructural control over the morphology the material Under irradiation electron hole pair generated TiO then technological devices are based chemical reactions induced electron transfers Due the large band gap TiO 2eV only the solar spectrum used major objective for future work the development semiconductor photocatalyst film which able utilize visible well light Nanoscience has the potential provide entirely new classes materials with capabilities that transcend these limitations and generate the performance breakthroughs required for viable economy based sustainable energy Recent investigations this area allowed synthesize novel photo sensitive titanium oxide sols and gels controlling the condensation titanium species non aqueous solvents Depending different parameters such concentration ageing thermal treatment emphasise few the structuration the inorganic framework leads various layered structure The adsorbed organic species control the growth the nano objects present the sol gel Due the enhanced surface area volume ratio these nanostructured sols and gels produce singular photo electrochemical properties that are drastically different from their bulk counterparts When irradiated these materials can absorb photons with lower energy than the bandgap energy the original semiconductor and thus significant increase the limiting efficiency conventional solar cells expected These new materials are principally characterized partially occupied intermediate band isolated from the valence and conduction bands Our purpose use these intermediate band materials sensitizers both third generation photoelectrochemical solar cells and photo batteries ultracapacitors 
3803 en HAADF STEM imaging from qualitative quantitative interpretation atomic resolution HAADF STEM images our presentation overview qualitative and quantitative HAADF STEM technique will given and illustrated examples characterization various inorganic ceramic materials such CaTiO3 solid solution GaN blue laser diode bulk CaTiO3 and doped SrTiO3 The specimens for the HAADF STEM observations were prepared high energy and low energy ion milling and were observed FEG JEOL 2010F The probe semi angle was mrad The inner and outer annular angles the HAADF detector were 100 and 220 mrad respectively The HAADF STEM image simulations were carried out using calculation scheme developed Watanabe Our results showed that differences small the average atomic number can readily detected HAADF STEM imaging qualitative interpretation atomic resolution HAADF STEM images compared intensity ratios between different atom columns used intensity profiles show the difference the chemical composition between individual atom columns this way could qualitatively interpret the ordering and partial ordering solute atoms bulk materials evaluate the occupancy atom columns special structures and study the segregation impurities along grain boundaries Quantitative interpretation required image simulations and matching the processed experimental images with the calculated ones However order calculate HAADF STEM images the exact structure the observed structural phenomena should known the positions the atoms order create proper supercells for calculations The realistic values the Debye Waller factor should also used calculations After image calculations appropriate matching algorithms with the experimental images were applied order determine the best fit between calculated and experimental image 
3804 en Structural properties magnetic nanoparticles The basic magnetic properties nanoparticles have been intensively studied and the influence the small nano size the magnetic properties generally well understood However the magnetic properties mixed oxide nanoparticles depend the size particles not only directly but also indirectly through the influence the small size the structure nanoparticles known that the structure nanoparticles more flexible compared the “bulk” structure Usually adapts the small size and the large surface volume ratio resulting distribution atoms over different lattice sites that significantly different that the bulk material Additionally defects are usually present the structure the nanoparticles Different aspects the deviations the structure nanoparticles from the ideal “bulk” state will discussed the cases two structural types magnetic nanoparticles spinel ferrites ZnFe2O4 Mn0 5Zn0 5Fe2O4 CoFe2O4 and hexagonal ferrite hexaferrite BaFe12O19 the spinels the deviation the nanoparticles crystal structure from the bulk situation expresses itself mainly with different distribution the constituting cations over two different lattice sites existing the structure tetrahedrally coordinated sites and octahedrally coordinated sites the case hexaferrites the exchange two cations and over different lattice positions not likely hexaferrites crystal structure can described stacking sequence two basic blocks spinel block containing cations and the block containing and cations Here the adaptation the crystal structure the small nanoparticle size the change the stacking the two structural blocks expected The flexibility the nanoparticles crystal structure results flexibility the nanoparticles’ chemical composition allowing large compositional deviations from the bulk stoichiometry without losing the single phase structure Depending the method used for their synthesis the nanoparticles also differ the state their crystallinity The small spinel ferrite nanoparticles controlled sizes could relatively simply prepared already low temperatures this work two methods were used precipitation reversed microemulsions and thermal decomposition the corresponding oleates contrary spinel ferrites relatively high temperatures are needed for the formation hexaferrites making their controlled synthesis the form the small nanoparticles relatively difficult Special hydrothermal methods were used for their synthesis this work The structure the nanoparticles has been studied using ray diffractometry XRD high resolution electron microscopy HREM coupled with energy dispersive ray spectroscopy EDX and ray absorption spectroscopy EXAFS XANES measured beamline synchrotron radiation laboratory HASYLAB DESY Hamburg project 065 under Contract RII3 2004 506008 SFS 
3805 en The nanostructure silicon thin films for solar cells typical thin film silicon solar cell deposited glass substrate covered with conductive transparent metal oxide The active part solar cell consists three six silicon layers each with thickness ten several hundred nanometers deposited layer layer fashion these structures layers with different individual optical gaps stacked together order cover much the solar spectrum possible changing the structure the material going from pure anorphous monocrystalline possible obtain the variation optical gap using the same material Silicon the form nanocrystals drags that sense particular attention last decade For any practical use important know size and size distribution nano particles this kind structure series multilayered silicon thin films was prepared the decomposition silane gas diluted with hydrogen radio frequency glow discharge Films with nanocrystallites different sizes were processed varying the silane hydrogen ratio The nanostructures the silicon thin films were studied Raman spectroscopy and high resolution transmission electron microscopy HRTEM Raman spectrum the microcrystalline shows one intensive sharp band 521 For crystallites smaller than this band transversal optical mode broadened and its position shifted lower frequencies The shift dependent the average crystallite sizes The size the nanocrystallites the investigated samples was estimated from the shift the mode the Raman spectra the after the deconvolution the spectra The volume fraction the crystalline phase can estimated from the ratio the integrated intensities the crystalline and the amorphous modes after the deconvolution the Raman spectra Since the deconvolution procedure influences the accuracy obtained result various methods deconvolution were applied Therefore for the calculation the Raman shifts and the integrated intensities the spectra are frequently fitted the sum amorphous Gaussian contributions and crystalline contribution Voight further deconvoluted the spectra but using somewhat different procedure than that one usually described the literature Since the spectra the multilayered thin films can deconvoluted the modes belonging the and the mode the crystalline fraction first removed the amorphous contribution directly subtracting the experimental spectra completely from the spectra our multilayered samples The band the appears asymmetric and broad which suggests the coexistence smaller and larger crystals deconvoluted the mode the into two components The two components can assigned one belonging the small crystallites and the other the larger crystallites 
3806 en Characterization and Properties Novel Oxygen Contained Hollandite VO1 Nanorods Synthesized Nonaqueous Sol Gel Route Using the nonaqueous sol gel route based benzyl alcohol pathway new compound VO1 the form nanorods has been synthesized Comprehensive structural investigations have been carried out using complementary neutron and synchrotron powder ray diffraction well different electron microscopy techniques SEM TEM EDX SAED EELS for determination material morphology crystallinity and oxidation state vanadium The data show that the structure can described hollandite type containing only oxygen the channels along the axis with hydrogen attached the one octahedral coordinating oxygen forming thus group The nanorods are single crystalline 500 long and 105 diameter with the growth direction along the axis The shape edge and white line ratio confirmed that the vanadium oxidation state between and which also deduced from the charge neutrality analysis being Temperature dependent conductivity measurement evidenced Arrhenius behavior and semiconducting ground state with band gap cooling mode initio density functional calculations with local spin density approximation including orbital potential LSDA predicts direct band gap and high degree hybridization between and orbitals The temperature dependence magnetic susceptibility follows the Curie Weiss law above 150 The extracted effective magnetic moment per vanadium consistent with the mixture and oxidation states with predominant fraction 
3807 en  microspectroscopy powerful tool for spatially resolved studies supports for solid phase organic synthesis Solid Phase Organic Synthesis SPOS efficient technique for the synthesis fine chemicals and for the development compounds libraries through combinatorial approaches SOPS performances can optimized carefully tuning the chemo physical properties polymeric supports usually porous beads with particular reference the distribution the reaction products into the beads which gives information the pore accessibility the efficiency the reactant’ diffusion process into pores and the load capacity the bead Differently from optical transparent polymers for which all parameters interest can quantified two photon microscopy opaque supports are difficult characterize conventional analytical techniques propose new method systematically study parameters affecting performance opaque supports for SPOS based microspectroscopy thin bead slides transmission mode All data collected with Bruker VERTEX interferometer coupled with Hyperion 3000 microscope Opaque amino methacrylate beads with different pore diameters Synbeads Resindion Mitsubishi Chem Corp Milan Italy are acylated via chemical coupling with nitropropionic acid different reactions times Functionalized and non functionalized beads cut microns slices are chemically imaged with Focal Plane Array detector FPA 64X64 pixel coupled with conventional source allowing fast chemical imaging the nitro functional group presence and distribution within the bead order achieve better ratio and then more accurate details nitro group distribution selected bead sections are also mapped microns spatial resolution along their diameter using Mercury Cadmium Telluride MCT single point detector operated with Synchrotron Radiation The combined approached proposed has the main advantage useful for each type SPOS support material and allows imaging easy and fast access data bead functionalization and functional group distribution More accurate quantitative relations between bead polymer type its degree polymerization bead pore dimension and mean porosity supported reaction and synthesis condition can achieved exploiting the high brightness source and the major sensitivity MCT detector 
3808 en Can high superconductivity explained with the BCS model optical approach
3810 en The roles Rule Law and Judiciary the German society The roots reach the European tradition the English Magna Charta 1215 the Act Settlement 1701 the enlightenment the 18th century and the liberty movements The independence judges said one the achievements the Prussian kingdom Frederick 2nd When building his castle Sanssouci was annoyed the rattling mill that spoilt the silence the park front his residence tried buy from the miller When the man refused sell because did not want lose the basis his living the king angrily threatened him with expropriation nnBut the brave man said have replied were not for the Kammergericht Court Appeal Your Majesty The story has always made good public relation for the Rule Law Prussia and the the mill still seen Unfortunately only legend The king was entitled give the judges orders make decision their place Frederick did times Only his political testament recommended his successors not that any more Even the judges really were independent Prussia another question was what kind cases belonged their jurisdiction Maybe their jurisdiction applied all civil and all criminal matters nAs far the state was concerned however judges were entitled decide only its civil fiscal matters the business the monarch had with his subjects civil contracts etc But not the legality the administrative procedure the results Very late the 19th century they established court that could deal with these matters which turned out forerunner our modern administrative judiciary Much later than that were born the constitutional courts nnThe people the 19th century were preoccupied with getting constitutions from their monarchs they did not bother much yet about having judged independent judiciary matter fact constitutional matters were not tried earlier than after the foundation the first German Republic 1919 special court for constitutional matters was first established after the 2nd world war Western Germany with the Federal Constitutional Court Karlsruhe 
3815 en Introduction data modelling This first presentation introduces the basic principles data modelling together with linear the parameters models 
3816 en The Multi layer Perceptron This presentation describes the multilayer perceptron and practical issues data modelling 
3817 en Functional Analysis Data Modelling This second presentation describes the basic theory functional analysis used kernel methods 
3818 en Introduction Support Vector Machines This first presentation introduces support vector machines 
3819 en Kernel Based Methods This second presentation covers more general kernel methods including training model selection and practical aspects 
3820 en Dimensionality Reduction This presentation discusses methods for dimensionality reduction 
3821 en Semi supervised learning This presentation introduction semi supervised learning 
3822 en Hierarchical Clustering This presentation describes approaches hierarchical clustering 
3823 en Bayesian methods for data Modelling His presentation introduces the basic ideas Bayesian methods for data modelling 
3824 en Graphical models This presentations provide introduction graphical models together with more advanced topics inference propagation and learning structure 
3825 en Factorial Switching Kalman Filters for Condition Monitoring Neonatal Intensive Care This presentation describes the application data modelling using Kalman filters premature baby monitoring 
3826 en Learning with Gaussian Processes This presentation describes the basic foundations and advanced theory Gaussian processes 
3827 en Application Data Modelling Fault Detection Internal Combustion Engine This presentation describes the application data modelling fault detection internal combustion engine 
3828 en Applications Machine Learning the Game This presentation based his PhD from the University Cambridge describes number applications machine learning the game 
3829 en Modelling Genomic Data This presentation describes work the modelling genomic data 
3830 en Panel discussion – Future Challenges Data Modelling
3831 en Applications Machine Vision This presentation describes novel approaches spatial inference problems vision and image processing Markov random field models are described for image restoration foreground segmentation graph cutting and stereo matching 
3833 en Efficient Computation Recursive Principal Component Analysis
3841 en Transparent Courts Responsible Media Society Served Finding Workable Way
3842 en Putting Things Order the Fundamental Role Ranking Classification and Probability Estimation
3843 en Classification Web Documents Using Graph Based Model
3844 en The uneasy relationship between media and justice towards theoretical explanation this paper examine how political and social theory could used make sense the uneasy relationship between media news media particular and the justice system speak ‘uneasy’ relationship this context raises two fundamental questions namely whether this relationship always and inevitably going difficult and what kind harm may ultimately result from persistently distorted and negative media portrayals justice Liberal theory sees the media watchdog ‘Fourth Estate’ democracy which aims for the truth order expose malpractice abuse power nnHowever the liberal narrative also allows for the fact that this ideal seldom attained often because news media are thrown off course commercial imperatives which result sensationalist superficial and distorted reporting its worst this seen something which could lead serious erosion the rule law However contrasting the liberal ideal and its discontents with Niklas Luhmann’ theory autopoiesis also examine different argument namely that law and the media are closed and self referential systems they both produce accounts the social which are inevitably distorted nnFurthermore precisely because law closed and autonomously working system autopoietic theory allows reach the conclusion that law exceptionally well equipped deal with extraneous pressures such those generated very inquisitive sensation driven press 
3846 en Joint Inclusion Memorandum Macedonia
3852 en Learning Classify Documents with Only Small Positive Training Set
3856 en Structured Prediction Maximum Margin Techniques Traditionally there has been mismatch between the requirements nontrivial applications and the prediction tools offered machine learning Applications such natural language processing optical character recognition and path planning are often implemented terms combinatorial inference algorithms such parsing algorithms Viterbi decoding and planning These inference algorithms necessarily utilize the inherent structure the problem efficiently navigate exponential number target elements such the set all parse trees for sentence the set possible words particular length the set all paths between two points graph the other hand research into supervised learning techniques machine learning and statistics has focused primarily regression and classification algorithms which best handle only handful classes These techniques cannot applied directly most applications Typically engineers are required meticulously define learnable subproblems inducing independence assumptions which are often strongly violated practice recent years however the advent conditional random fields and then maximum margin structured classification has changed the way the machine learning community views these problems Researchers have found ways which the inherent structure the problems can used directly train these combinatorial inference procedures Dubbed structured prediction this class algorithms utilizes the same implicit structural properties that make the inference algorithms efficient this presentation after introducing structured prediction high level will cover detail one the two most cited formalisms structured prediction maximum margin structured classification With particular emphasis placed functional gradient techniques will present number algorithms for solving these problems along with their results various applications and discussion relative trade offs 
3857 en Using the Web Reduce Data Sparseness Pattern based Information
3859 en Introduction Graph Labelling Workshop and Web spam Challenge
3860 en  Fast Method Predict the Labeling Tree Given vertex weighted tree with structural diameter and set vertices give method compute the corresponding Gram matrix the pseudoinverse the graph Laplacian 2SG time discuss the application this method predicting the labeling graph Preliminary experimental results digit classification task are given 
3862 en Beyond String Search Fast and Accurate Retrieval Entities and Dependencies
3863 en Fighting Spam under Attack Some Notes from the Field
3865 en Nonparametric Relational Learning with Applications Decision Support and Bioinformatics and with Perspective for the Semantic Web
3867 en Semi Supervised Learning Comparative Study for Web Spam and Telephone User Churn compare wide range semi supervised learning techniques both for Web spam filtering and for telephone user churn classification Semisupervised learning has the assumption that the label node graph similar those its neighbors this paper measure this phenomenon both for Web spam and telco churn conclude that spam often linked spam while honest pages are linked honest ones similarly churn occurs bursts groups social network 
3868 en Web Spam Challenge 2007 Track Secure Computing Corporation Research discriminate spam Web hosts pages from normal ones text based and link based data are provided forWeb Spam Challenge Track Given small part labeled nodes about aWeb linkage graph the challenge predict other nodes’ class spam normal extract features from link based data and then combine them with text based features After feature scaling Support Vector Machines SVM and Random Forests are modeled the extremely high dimensional space with about million features Stratified fold cross validation for SVM and out bag estimation for are used tune the modeling parameters and estimate the generalization capability the small corpus for Web host classification the best Measure value and the best AUC value the large corpus for Web page classification the best Measure value and the best AUC value 
3872 en Polyp Detection Endoscopic Video using SVMs
3873 en  Density Biased Sampling Technique Improve Cluster Representativeness
3874 en Expectation Propagation for Rating Players Sports Competitions
3875 en Efficient Closed Pattern Mining Strongly Accessible Set Systems
3876 en Discovering Emerging Patterns Spatial Databases Multi Relational Approach
3877 en Mining Large Graphs Laws and Tools
3880 en Approximation and Inference using Latent Variable Sparse Linear Models variety Bayesian methods have recently been introduced for performing approximate inference using linear models with sparse priors focus four methods that capitalize latent structure inherent sparse distributions perform standard MAP estimation hyperparameter MAP estimation evidence maximization iii variational Bayes using factorial posterior and local variational approximation using convex lower bounding All these approaches can used compute Gaussian posterior approximations the underlying full distribution however the exact nature these approximations frequently unclear and challenging task determine which algorithm and sparse prior are appropriate Rather than justifying prior selections and modeling assumptions based the credibility the full Bayesian model sometimes done base evaluations the actual cost functions that emerge from each method this end discuss common objective function that encompasses all the above and then briefly assess its properties with respect three representative applications finding maximally sparse signal representations predictive modeling RVMs and iii active learning experimental design The requirements these problems can quite different and can lead very restricted choices for the sparse prior and final approximation adopted general find that the best approximate model often does not correspond with the most plausible full model Finally consider several extensions the sparse linear model including classification covariance component estimation and the incorporation non negativity constraints While closed form expressions for the moments needed for dealing with these problems may intractable show alternative implementation that involves transforming dual space using simple auxiliary functions Preliminary results show that substantial improvement possible over existing methods 
3881 en Message Passing Algorithms for GMRFs and Non Linear Optimization review variety iterative methods for inference and estimation Gaussian graphical models also known Gauss Markov random fields GMRFs and consider how adapt these methods non linear optimization problems involving graph structured objective functions Specifically review the walk sum interpretation Gaussian belief propagation GaBP and consider novel stable form GaBP which always converges the optimal estimate another direction discuss iterative Lagrangian relaxation method applicable for GMRFs which decompose sum convex quadratic potential functions defined cliques the graph then consider how such methods can adapted solve more general classes MRFs with smooth potential functions For instance the potential functions are convex straight forward use Gaussian inference efficiently implement Newton method leading the optimal solution non convex MRFs still possible obtain approximate solutions using the method Levenberg Marquardt time permits may also consider the half quadratic optimization approach for MRFs having non smooth potential functions all these approaches the problem approximated sequence convex quadratic problems each which can solved distributed fashion using Gaussian inference techniques 
3882 en Bounds the Bethe Free Energy for Gaussian Networks consider approximate inference Gaussian probabilistic models with approximate free energy methods define the fractional Bethe free energy and directly minimize lower bound for the free energies derived and give necessary conditions for the fractional Bethe free energy bounded Our results are line with the earlier work the analysis standard message passing done Malioutov 2006 and Weiss and Freeman 2001 and improve them showing that pairwise normalizability does not hold standard message passing guaranteed converge global minimum only special cases Joint work with Tom Heskes 
3883 en Learning with Millions Examples and Dimensions Competition proposal Over the years many different classification methods have been proposed machine learning However currently very difficult judge which method the most efficient with respect training time and memory requirements and classification performance which are the practically relevant criteria possible explanation for this difficulty that methods are often evaluated under different conditions For instance different datasets evaluation criteria model parameters and stopping conditions are used would therefore like organize competition that designed fair and enables direct comparison current large scale classifiers this end plan provide generic evaluation framework tailored the specifics the competing methods for example for Support Vector Machine classifiers one would addition test error record the objective value the primal problem Providing wide range datasets each which having specific properties like extremely sparse dense high low dimensional propose evaluate the methods based the following figures training time test error dataset size test error and dataset size training time seek help from the community gather relevant large scale real world data sets and critically review and discuss fair evaluation criteria and finally invite researchers organize and participate this challenge 
3884 en Interview with Yann LeCun His lab has projects computer vision object detection object recognition mobile robotics bio informatics biological image analysis medical signal processing signal processing and financial prediction The Videolectures Net team talked him NIPS 2007 asked him stuff like What your current topic research How can you comment your humoristic approach giving lectures Humor and content What happend your research between Summer school 2006 Chicago and today How can you explain your work year old child Machine Learning dream come true What your philosophy 
3885 en Introduction the Workshop Until recently the issue musical representation had focused primarily symbolic notation musical information and structure and the representation musical performance Research how represent musical experience the brain emerging rich area investigation thanks ongoing advances brain scanning technology such EEG and fMRI This day the workshop addresses the problem representation musical experience the brain from computational modelling approach chiefly based machine learning and signal processing The overarching question addressed this workshop whether can devise efficient methods study and model the representation musical experience the brain combining traditional forms musical representation musical notation audio performance etc with brain scanning technology This problem particular relevance for the successful modelling cognitive music behaviour design interactive music systems informing techniques contemporary composition providing methods enhance music performance and even helping music analysis suggesting ways listening music 
3886 en Psychoacoustic Influences the Neural Correlates music Syntactic Processing Music consists perceptually discrete elements that are organized according syntactic regularities Violations these regularities typically elicit two ERP components the ERAN and the several studies tried disentangle music syntactic and psychoacoustic influences the underlying cognitive processes first study compared the electrophysiological response chord sequences that differed the music syntactic regularity but were similar with regard sensory factors such pitch commonality pitch repetition and roughness showed that ERAN and were elicited irrespective these similarities indicating that these ERP components are index music syntactic processing second study evaluated effects long term exposure the processing music syntactic irregularities The ERAN amplitude declined over the course experimental session about 120 min suggesting that cognitive representations musical regularities can change implicitly response the repeated presentation unexpected irregular harmonies third study explored whether the ERAN actually elicited irregular chords containing several voices deviance the most prominent upper voice demonstrated two different patterns neurophysiological responses these two irregularities strengthening the assumption that two different cognitive mechanisms are involved the processing irregularities chord sequences and melodies respectively Finally tried follow the development the neural correlates music syntactic processing found increase between the second and the fifth followed decline between the fifth and the eleventh year age for the ERAN Almost the same course development was observed for the which was however not present the two year olds However the observed differences between the age groups were not significant indicating quite high stability the brain responses music syntactic violations 
3888 en Learning novel concepts beyond one class OLINDDA OnLIne Novelty and Drift Detection Algorithm addresses the problem novelty detection online continuous learning scenario extension single class classification problem This paper presents its current version that evolved toward the discovery new concepts initially emerging clusters and further cohesive sets clusters New strategies for validation and merging clusters well for dynamically adapting the number clusters are discussed and experimentally evaluated 
3889 en  architecture for context aware adaptive data stream mining resource constrained devices adaptation data stream processing variations data rates availability resources and environment changes crucial for consistency and continuity running applications Context aware adaptation new dimension research data stream mining enhances and optimizes distributed data stream processing tasks Context awareness one the key aspects ubiquitous computing applicationsC¸ successful operations rely detecting changes and adjusting accordingly This paper presents general architecture for context aware adaptive mining data streams that aims dynamically and autonomously adjust data stream mining parameters according changes context and resource availability distributed and heterogeneous computing environments 
3890 en Learning Outlier Robust Kalman Filter this talk introduce modified Kalman filter that performs robust real time outlier detection without the need for manual parameter tuning the user Systems that rely high quality sensory data for instance robotic systems can sensitive data containing outliers The standard Kalman filter not robust outliers and other variations the Kalman filter have been proposed overcome this issue However these methods may require manual parameter tuning use heuristics complicated parameter estimation procedures Our Kalman filter uses weighted least squares like approach introducing weights for each data sample data sample with smaller weight has weaker contribution when estimating the current time step’ state Using incremental variational Expectation Maximization framework learn the weights and system dynamics evaluate our Kalman filter algorithm data from robotic dog 
3891 en  Model for Quality Guaranteed Resource Aware Stream Mining Data streams are produced continuously high speed Most data stream mining techniques address this challenge using adaptation and approximation techniques Adapting available resources has been addressed recently Although these techniques ensure the continuity the data mining process under resource limitation the quality the output still open issue this paper propose generic model that guarantees the quality the output while maintaining efficient resource consumption The model works estimating the quality the output given the available resources Only subset these resources will used that guarantees the minimum quality loss The model generalized for any data stream mining technique 
3892 en Efficient Secure Query Processing XML Data Stream various users and applications require the distribution and sharing information XML documents the need for efficient secure access XML data ubiquitous data stream environment has become very important this paper propose efficient secure XML query processing method solve the two problems using role based prime number labeling and XML fragmentation medical records XML document has the characteristic infinite addition width rather than depth because the increment patients But role based prime number labeling method can fully manage the size documents that increases infinity and can minimize the maintenance cost caused dynamic changes Experimental evaluation clearly demonstrates that our approach efficient and secure 
3893 en Enhanced Anytime Algorithm for Induction Oblivious Decision Trees Real time data mining high speed and non stationary data streams has large potential such fields efficient operation machinery and vehicles wireless sensor networks urban traffic control stock data analysis etc These domains are characterized great volume noisy uncertain data and restricted amount resources mainly computational time Anytime algorithmsoffer tradeoff between solution quality and computation time which has proveduseful applying artificial intelligence techniques time critical problems Inthis paper are presenting new enhanced version anytime algorithm forconstructing classification model called Information Network The algorithmimprovement aimed reducing its computational cost while preservingthe same level model quality The quality the induced model evaluatedby its classification accuracy using the standard fold cross validation Theimprovement the algorithm anytime performance demonstrated severalbenchmark data streams 
3894 en Quasi Incremental Bayesian Classifier This talk describes and empirically evaluates Quasi Incremental Bayesian Classifier QBC designed used when classification task must performed dynamic systems such sensor networks which are continuously receiving new piece information stored huge databases Therefore the knowledge that needs extracted from these databases continuously evolving and the learning process may need almost indefinitely The induction proposed QBC performed two steps the first one traditional Bayesian Network induction algorithm performed using initial amount data far new data available only the numerical parameters the classifier are updated The conducted experiments showed that QBC tends maintain the average correct classification rates obtained with non incremental classifiers while decreasing the time needed induce the classifier 
3895 en State the Art Data Stream Mining
3896 en Resource aware distributed online data mining for wireless sensor networks Online data mining wireless sensor networks concerned with the problem extracting knowledge from large continuous amount data streams with network processing mode Unlike other types networks the limited computational resources require the mining algorithms highly efficient and compact propose distributed resource aware online data mining framework for wireless sensor networks which can used enable existing mining techniques applied sensor network environments have applied the framework develop and implement distributed resource adaptive online clustering algorithm the novel Sun MicrosystemTM Small Programmable Object Technology Sun SPOT platform have evaluated the performance the algorithm the actual sensor nodes Experimental results show that the clustering algorithm can improve significantly resource utilization while maintaining acceptable accuracy level 
3897 en  Semi fuzzy approach for online divisive agglomerative clustering The Online Divisive Agglomerative Clustering ODAC incremental approach for clustering streaming time series using hierarchical procedure over time constructs tree like hierarchy clusters streams using top down strategy based the correlation between streams The system also possesses agglomerative phase enhance dynamic behavior capable structural change detection However the split decision used the algorithm focus the crisp boundary between two groups which implies high risk since has decide based only small subset the entire data this work propose semi fuzzy approach the assignment variables newly created clusters for better trade off between validity and performance Experimental work supports the benefits our approach 
3898 en State the Art Data Stream Mining
3899 en  means similarity driven clustering and its application gravitational wave astronomy data mining Clustering classify unlabeled data into groups has been wellresearched for decades many disciplines Clustering massive amount astronomical data generated multi sensor networks has become emerging new challenge assumptions many existing clustering algorithms are often violated these domains For example means implicitly assumes that underlying distribution data Gaussian Such assumption not necessarily observed astronomical data Another problem the determination which hard decide when prior knowledge lacking While there has been work done discovering the proper value for given only the data most existing works such means means and means assume that the model mixture Gaussians one way another this paper present similarity driven clustering approach for tackling large scale clustering problem similarity threshold used constrain the search space possible clustering models such that only those satisfying the threshold are accepted This forces the search explicitly avoid getting stuck local minima and hence the quality models learned has meaningful lower bound and discover proper value for new clusters have formed merging them into existing ones will violate the constraint given the threshold Experimental results the UCI KDD archive and realistic simulated data generated for the Laser Interferometer Gravitational Wave Observatory LIGO suggest that such approach promising 
3900 en PQStream data stream architecture for electrical power quality this talk data stream architecture presented for electrical power quality which called PQStream PQStream developed process and manage time evolving data coming from the country wide mobile measurements electrical parameters the Turkish Electricity Transmission System full fledged system with data measurement module which carries out processing continuous data stream database which stores the output the measurement module and finally Graphical User Interface for retrospective analysis the data stored the stream database The presented model deployed and available experts academicians and researchers the area further studies data mining methods such classification and clustering algorithms will applied order deduce useful information from this database data 
3901 en Relational Transformation based Tagging for Human Activity Recognition The ability recognize human activities from sensory information essential for developing the next generation smart devices Many human activity recognition tasks are from machine learning perspective quite similar tagging tasks natural language processing Motivated this similarity develop relational transformation based tagging system based inductive logic programming principles which able cope with expressive relational representations well background theory The approach experimentally evaluated two activity recognition tasks and compared Hidden Markov Models one the most popular and successful approaches for tagging 
3902 en Random Labelsets Ensemble Method for Multilabel Classification
3903 en Seeing the Forest through the Trees Learning Comprehensible Model from Ensmble
3904 en Constraint Selection Committee Ensemble Approach Identifying Informative Constraints for Semi Supervised Clustering
3905 en Efficient Weight Learning for Markov Logic Networks
3906 en Separating Precision and Mean Dirichlet enhanced High order Markov Models
3907 en Diskriminative Sequence Labeling score Optimization
3908 en Learning Partially Observable Markov Model from First Passage Times
3909 en Context specific Independence Mixture Modelling for Protein Families
3910 en Clustering Trees with Instance Level Constraints
3911 en  Prediction based Visual Approach for Cluster Exploration and Cluster Valadation HOV3
3912 en Spectral Clustering and Embedding with Hidden Markov Models
3914 en Approximating Gaussian Processes with matrices
3916 en Privacy Preserving Market Basket Data Analysis
3917 en Towards data mining without Information Knowledge Structure
3918 en Generating Social Network Features for Link based Classification
3919 en  Algorithm find OverlappingCommunity Structure Networks
3920 en Bayesian Substructure Learning Approximate Learning Very Large Network Structures
3921 en Shrinkage Estimator for Bayesian Network Parametrs
3923 en Fast optimization for Regularization Evaluation and Two New Approaches
3924 en  Gaphical Model for Content Based Image Suggestion and Feature Selection
3925 en Stability based Sparse LSI PCA Incorporating Feature Selection LSI and PCA
3926 en Classification Very High Dimensional Problems with Handfuls Examples
3927 en Speeding Feature Subset Selection through Mutual Information Relevance Filtering
3928 en Efficient Continuos Time Reinforcement Learning with Adaptive State Graphs
3930 en  Introduction Statistical Relational Learning
3931 en What Semantic Web researchers need know about Machine Learning The tutorial will cover basic topics from the field Machine Learningn explained intuitive way relevant for Semantic Web researchers andn practitioners the first part the topics will cover brief top leveln overview the Machine Learning field its algorithms and data typesn being analyzed the second part will cover relation Semanticn Web and Web2 the last part will perform hands exercise withn some the tools for modeling text semantics and social networks inn analytical way 
3932 en What Semantic Web researchers need know about Machine Learning The tutorial will cover basic topics from the field Machine Learning explained intuitive way relevant for Semantic Web researchers and practitioners the first part the topics will cover brief top level overview the Machine Learning field its algorithms and data types being analyzed the second part will cover relation Semantic Web and Web2 the last part will perform hands exercise with some the tools for modeling text semantics and social networks analytical way 
3933 en What Semantic Web researchers need know about Machine Learning The tutorial will cover basic topics from the field Machine Learning explained intuitive way relevant for Semantic Web researchers and practitioners the first part the topics will cover brief top level overview the Machine Learning field its algorithms and data types being analyzed the second part will cover relation Semantic Web and Web2 the last part will perform hands exercise with some the tools for modeling text semantics and social networks analytical way 
3935 en Introduction and Overview the Semantic Web
3936 en Semantic Interoperability the same way that the Web composed heterogeneous resources the Semantic Web composed heterogeneous ontologies this session Jerome and Natasha will discuss what interoperability means the semantic level Additionally they will outline different techniques which can used address this problem the end this session attendees will understand the notions and issues underlying semantic interoperability 
3937 en Ontology based Data Access this tutorial provide comprehensive understanding the problem ontology based data access from both the theoretical and the practical points view address several problems that are crucial this context such expressiveness efficiency tradeoff query processing impedance mismatch between ontology and data levels and integration multiple data sources present solutions these problems based recent research results the area tractable Description Logics and provide also hands experience with QuOnto state the art system for ontology based data access 
3938 en Ontology based Data Access this tutorial provide comprehensive understanding the problem ontology based data access from both the theoretical and the practical points view address several problems that are crucial this context such expressiveness efficiency tradeoff query processing impedance mismatch between ontology and data levels and integration multiple data sources present solutions these problems based recent research results the area tractable Description Logics and provide also hands experience with QuOnto state the art system for ontology based data access 
3939 en Using Social Network Analysis Geotemporal Reasoning and RDFS Reasoning for Business Intelligence Most the attention the Semantic Web world currently focused using ontologies rdfs and owl reasoning get more value out enterprise data Many enterprise databases are full information about people companies relationships between people and companies places and events The Semantic Web literature also carries the promise analyzing networks people networks companies and events time and space This talk will show how Business Intelligence problems can solved with combination basic semantic web reasoning and complementary techniques such social network analysis and geotemporal reasoning will using AllegroGraph this talk but the concepts learned will transfer other Semantic Web solutions 
3942 en  Generative Model for Rhythms Modeling music involves capturing long term dependencies time series which has proved very difficult achieve with traditional statistical methods The same problem occurs when only considering rhythms this paper introduce generative model for rhythms based the distributions distances between subsequences specific implementation the model when considering Hamming distances over simple rhythm representation described The proposed model consistently outperforms standard Hidden Markov Model terms conditional prediction accuracy two different music databases 
3943 en  Maximum Likelihood Approach Multiple Fundamental Frequency Estimation From the Amplitude Spectrum Peaks This paper presents Maximum Likelihood approach multiple fundamental frequency estimation each frame music signals the frequency domain The frequencies and amplitudes the spectral peaks are viewed observations and the F0s are viewed parameters estimated The proposed method considers the potential errors the peak detection algorithm and treats each peak “true” and “false” separately The likelihood models the “true” and “false” peaks are learned from the monophonic training data with the assumption that the statistics the peaks monophonic and polyphonic signals are similar The proposed method also incorporates rectified Bayesian Information Criteria BIC estimate the number the parameters the polyphony Evaluation held randomly mixed chords which are generated from the previously unseen monophonic tones Experimental results show the feasibility this method 
3944 en Finding Musically Meaningful Words Sparse CCA musically meaningful vocabulary one the keystones building computer audition system that can model the semantics audio content word the vocabulary not clearly represented the underlying acoustic representation the word can considered noisy and should removed from the vocabulary This paper proposes approach construct vocabulary predictive semantic concepts based sparse canonical component analysis sparse CCA The goal find words that are highly correlated with the underlying audio feature representation with the expectation that these words can modeled more accurately Experimental results illustrate that identifying these musically meaningful words can improve the performance previously proposed computer audition system for music annotation and retrieval 
3945 en Can Style Learned Machine Learning Approach Towards ‘Performing’ Famous Pianists this paper novel method for performing music the style famous pianists presented use Kernel Canonical Correlation Analysis KCCA method which looks for common semantic representation between two views learn the correlation between representation musical score and representation artist’ performance that score use the performance representation based the variations beat level global loudness and tempo through time suggested Therefore the crux the matter the representation the musical scores and implication similarity measure between relevant features that capture our prior knowledge music therefore proceed propose novel kernel for musical scores which Gaussian kernel adaptation the distances between rhythm patterns melodic contours and chords progressions 
3946 en Discovering Music Structure via Similarity Fusion Automatic methods for music navigation and music recommendation exploit the structure the music carry out meaningful exploration the “song space” get satisfactory performance from such systems one should incorporate much information about songs similarity possible however how not obvious this paper build the ideas the Probabilistic Latent Semantic Analysis PLSA that have been successfully used the document retrieval community Under this probabilistic framework any song will projected into relatively low dimensional space “latent semantics” such way that all observed similarities can satisfactorily explained using the latent semantics Therefore one can think these semantics the real structure music the sense that they can explain the observed similarities among songs The suitability the PLSA model for representing music structure studied simplified scenario consisting 4412 songs and two similarity measures among them The results suggest that the PLSA model useful framework combine different sources information and provides reasonable space for song representation 
3947 en Modeling Natural Sounds with Modulation Cascade Processes Auditory scene analysis extremely challenging One approach perhaps that adopted the brain shape useful representations sounds prior knowledge about their statistical structure For example sounds with harmonic sections are common and time frequency representations are efficient Most current representations concentrate the shorter components Here propose representations for structures longer time scales like the phonemes and sentences speech decompose sound into product processes each with its own characteristic time scale This demodulation cascade relates classical amplitude demodulation but traditional algorithms fail realise the representation fully new approach probabilistic amplitude demodulation shown out perform the established methods and easily extend representation full demodulation cascade 
3948 en What When Causal Expectation Modelling Monophonic Pitched and Percussive Audio causal system for representing musical stream and generating further expected events presented Starting from auditory front end which extracts low level spectral shape MFCC pitch and mid level features such onsets and beats unsupervised clustering process builds and maintains set symbols aimed representing musical stream events using both timbre and time descriptions The time events are represented using inter onset intervals relative the beats These symbols are then processed expectation module based Predictive Partial Match multiscale technique based grams characterise the system capacity generate expectation that matches its transcription use weighted average measure that takes into account the uncertainty associated with the unsupervised encoding the musical sequence The potential the system demonstrated the case processing audio streams which contain drum loops monophonic singing voice preliminary experiments show that the induced representation useful for generating expectation patterns causal way During exposure observe globally decreasing prediction entropy combined with structure specific variations 
3949 en Modeling and Visualizing Tonality North Indian Classical Music North Indian classical music NICM based raag melodic structure within which musicians improvise Raags define hierarchical pitch relationships that can described tonal The study tonality raag music may help elucidate whether cross culturally valid cognitive model tonal perception exists describe basic model tonality raag music based pitch class distributions derive visualizations tonal raag spaces based self organizing maps trained pitch class distributions calculated actual performances well theoretically derived maps discuss implications the theory and visualizations well anticipated empirical verifications the model 
3950 en Book Adaptive and Book Dependent Models Accelerate Digitization Early Music Optical music recognition OMR enables early music collections digitized large scale The workflow for such digitisation projects also includes scanning and preprocessing but the cost expert human labour correct automatic recognition errors dominates the cost these other two steps reduce the number recognition errors the OMR process present innovative application maximum posteriori MAP adaptation for hidden Markov models HMMs build book adaptive models taking advantage the new learning data generated from human editing work which part any music digitization project also experimented with using the generated data build book dependent models from scratch which sometimes outperform the book adaptive models after enough corrected data available Our experiments show that these approaches can reduce human editing costs more than half and that they are especially well suited highly variable sources like early degraded documents 
3952 en Recipes for Semantic Web Dog Food The ESWC and ISWC Metadata Projects Semantic Web conferences such ESWC and ISWC offer prime opportunities test and showcase semantic technologies Conference metadata about people papers and talks diverse nature and neither too small uninteresting too big unmanageable Many metadata related challenges that may arise the Semantic Web large are also present here Metadata must generated from sources which are often unstructured and hard process and may originate from many different players therefore suitable workflows must established Moreover the generated metadata must use appropriate formats and vocabularies and served way that consistent with the principles linked data This paper reports the metadata efforts from ESWC and ISWC identifies specific issues and barriers encountered during the projects and discusses how these were approached Recommendations are made how these may addressed the future and discuss how these solutions may generalize metadata production for the Semantic Web large 
3953 en EIAW Towards Business friendly Data Warehouse Using Semantic Web Technologies Data warehouse now widely used business analysis and decision making processes adapt the rapidly changing business environment develop tool make data warehouses more business friendly using Semantic Web technologies The main idea make business semantics explicit uniformly representing the business metadata conceptual enterprise data model and multidimensional model with extended OWL language Then mapping from the business metadata the schema the data warehouse built When analysis request raised customized data mart with data populated from the data warehouse can automatically generated with the help this built knowledge This tool called Enterprise Information Asset Workbench EIAW deployed the Taikang Life Insurance Company one the top five insurance companies China User feedback shows that OWL provides excellent basis for the representation business semantics data warehouse but many necessary extensions are also needed the real application The user also deemed this tool very helpful because its flexibility and speeding data mart deployment face business changes 
3954 en DBpedia Nucleus for Web Open Data
3955 en PORE Positive Only Relation Extraction from Wikipedia Text Extracting semantic relations great importance for the creation the Semantic Web content great benefit semi automatically extract relations from the free text Wikipedia using the structured content readily available Pattern matching methods that employ information redundancy cannot work well since there not much redundancy information Wikipedia compared the Web Multi class classification methods are not reasonable since classification relation types available Wikipedia this paper propose PORE Positive Only Relation Extraction for relation extraction from Wikipedia text The core algorithm POL extends state the art positive only learning algorithm using bootstrapping strong negative identification and transductive inference work with fewer positive training examples conducted experiments several relations with different amount training data The experimental results show that POL can work effectively given only small amount positive training examples and significantly outperforms the original positive learning approaches and multi class SVM Furthermore although PORE applied the context Wikipedia the core algorithm POL general approach for Ontology Population and can adapted other domains 
3956 en SALT Weaving the claim web this paper present solution for “weaving the claim web” the creation knowledge networks via called claims stated scientific publications created with the SALT Semantically Annotated LATEX framework attain this objective provide support for claim identification evolved the appropriate ontologies and defined claim citation and reference mechanism also describe prototypical claim search engine which allows reference existing claims and hence weave the web Finally performed small scale evaluation the authoring framework with quite promising outcome 
3957 en Making More Wikipedians Facilitating Semantics Reuse for Wikipedia Authoring Wikipedia killer application Web has embraced the power collaborative editing harness collective intelligence can also serve ideal Semantic Web data source due its abundance influence high quality and well structuring However the heavy burden building and maintain ing such enormous and ever growing online encyclopedic knowledge base still rests very small group people Many casual users may still feel dif ficulties writing high quality Wikipedia articles this paper use RDF graphs model the key elements Wikipedia authoring and propose inte grated solution make Wikipedia authoring easier based RDF graph match ing expecting making more Wikipedians Our solution facilitates semantics reuse and provides users with link suggestion module that suggests and completes internal links between Wikipedia articles for the user catego suggestion module that helps the user place her articles correct categories prototype system implemented and experimental results show significant improvements over existing solutions link and category suggestion tasks The proposed enhancements can applied attract more contributors and relieve the burden professional editors thus enhancing the current Wikipedia make even better Semantic Web data source 
3958 en Ontology based Interpretation Keywords for Semantic Search Current information retrieval approaches not formally capture the explicit meaning keyword query but provide comfortable way for the user specify information needs the basis keywords Ontology based approaches allow for sophisticated semantic search but impose query syntax more difficult handle this paper present approach for translating keyword queries conjunctive queries using background knowledge available ontologies present implementation which shows that this interpretation keywords can then used for both exploration asserted knowledge and for semantics based declarative query answering process also present evaluation our system and discussion the limitations the approach with respect our underlying assumptions which directly points issues for future work 
3959 en HealthFinland Finnish Health Information the Semantic Web This talk shows how semantic web techniques can applied solving problems distributed content creation discovery linking aggregation and reuse health information portals both from end users’ and content publishers’ viewpoints case study the national semantic health portal HEALTHFINLAND presented provides citizens with intelligent searching and browsing services reliable and date health information created various health organizations Finland The system based shared semantic metadata schema ontologies and ontology services The content includes metadata about thousands web documents such web pages articles reports campaign information news services and other information related health 
3960 en Unlocking the Potential Public Sector Information with Semantic Web Technology Governments often hold very rich data and whilst much this information published and available for use others often trapped poor data structures locked legacy data formats fragmented databases One the great benefits that Semantic Web technology offers facilitating the large scale integration and sharing distributed data sources the heart information policy the the Office Public Sector Information OPSI the part the government charged with enabling the greater use public sector information This paper describes the actions findings and lessons learnt from pilot study involving several parts government and the public sector The aim was show government how they can adopt technology for the dissemination sharing and use its data 
3961 en Matching Patient Records Clinical Trials Using Ontologies This talk describes large case study that explores the applicability ontology reasoning problems the medical domain investigate whether possible use such reasoning automate com mon clinical tasks that are currently labor intensive and error prone and focus our case study improving cohort selection for clinical trials obstacle automating such clinical tasks the need bridge the semantic gulf between raw patient data such laboratory tests specific medications and the way clinician interprets this data Our key insight that matching patients clinical trials can formulated problem semantic retrieval describe the technical challenges building realistic case study which include problems related scalability the integration large ontologies and dealing with noisy inconsistent data Our solution based the SNOMED 160 ontology and scales one year patient records approx 240 000 patients 
3962 en  cognitive support framework for ontology mapping Ontology mapping the key data interoperability the semantic web This problem has received lot research attention however the research emphasis has been mostly devoted automating the mapping process even though the creation mappings often involve the user industry interest semantic web technologies grows and the number widely adopted semantic web applications increases must begin support the user this paper combine data gathered from background literature theories cognitive support and decision making and observational case study propose theoretical framework for cognitive support ontology mapping tools also describe tool called COGZ that based this framework 
3963 en Potluck Data Mash Tool for Casual Users more and more reusable structured data appears the Web casual users will want take into their own hands the task mashing data rather than wait for mash sites built that address exactly their individually unique needs this paper present Potluck Web user interface that lets casual users— those without programming skills and data modeling expertise—mash data themselves Potluck novel its use drag and drop for merging fields its integration and extension the faceted browsing paradigm for focusing subsets data align and its application simultaneous editing for cleaning data syntactically Potluck also lets the user construct rich visualizations data place the user aligns and cleans the data This iterative process integrating the data while constructing useful visualizations desirable when the user unfamiliar with the data the beginning— common case—and wishes get immediate value out the data without having spend the overhead completely and perfectly integrating the data first user study Potluck indicated that was usable and learnable and elicited excitement from programmers who even with their programming skills previously had great difficulties performing data integration 
3964 en The Semantic Web and Human Inference Lesson from Cognitive Science For the development Semantic Web technology researchers and developers the Semantic Web community need focus the areas which human reasoning particularly difficult Two studies this paper demonstrate that people are predisposed use class inclusion labels for inductive judgments This tendency appears stem from general characteristic human reasoning – using heuristics solve problems The inference engines and interface designs that incorporate human reasoning need integrate this general characteristic underlying human induction 
3965 en SPARK Adapting Keyword Query Semantic Search Semantic search promises provide more accurate result than present day keyword search However progress with semantic search has been delayed due the complexity its query languages this paper explore novel approach adapting keywords querying the semantic web the approach automatically translates keyword queries into formal logic queries that end users can use familiar keywords perform semantic search prototype system named ‘SPARK’ has been implemented light this approach Given keyword query SPARK outputs ranked list SPARQL queries the translation result The translation SPARK consists three major steps term mapping query graph construction and query ranking Specifically probabilistic query ranking model proposed select the most likely SPARQL query the experiment SPARK achieved encouraging translation result 
3966 en Web Search Personalization via Social Bookmarking and Tagging this talk present new approach web search personalization based user collaboration and sharing information about web documents The proposed personalization technique separates data collection and user profiling from the information system whose contents and indexed documents are being searched for the search engines and uses social bookmarking and tagging rank web search results independent the search engine being used users are free choose the one they prefer even their favorite search engine does not natively support personalization show how design and implement such system practice and investigate its feasibility and usefulness with large sets real word data and user study 
3967 en Purpose Aware Reasoning about Interoperability Heterogeneous Training Systems describe novel approach which software can assess the ability confederation heterogeneous systems interoperate achieve given purpose The approach uses ontologies and knowledge bases KBs capture the salient characteristics systems the one hand and tasks for which these systems will employed the other Rules are used represent the conditions under which the capabilities provided systems can fulfill the capabilities needed support the roles and interactions that make each task Analyzer component employs these KBs and rules determine given confederation will adequate generate suitable confederations from collection available systems pre diagnose potential interoperability problems that might arise and suggest system configuration options that will help make interoperability possible have demonstrated the feasibility this approach using prototype Analyzer and KBs 
3968 en Ontology based Information Extraction for Business Intelligence Business Intelligence requires the acquisition and aggregation key pieces knowledge from multiple sources order provide valuable information customers feed statistical models and tools The massive amount information available business analysts makes information extraction and other natural language processing tools key enablers for the acquisition and use that semantic information describe the application ontology based extraction and merging the context practical business application for the MUSING Project where the goal gather international company intelligence and country region information The results our experiments far are very promising and are now the process building complete end end solution 
3969 en  Collaborative Semantic Web Layer Enhance Legacy Systems This talk introduces framework add semantic web layer legacy organizational information and describes its application the use case provided the Italian National Research Council CNR intraweb Building traditional web based view information from different legacy databases have performed semantic porting data into knowledge base dependent OWL domain ontology have enriched the knowledge base means text mining techniques order discover topic relations Several reasoning techniques have been applied order infer relevant implicit relationships Finally the ontology and the knowledge base have been deployed semantic wiki means theWikiFactory tool which allows users browse the ontology and the knowledge base introduce new relations revise wrong assertions collaborative way and perform semantic queries our experiments have been able easily implement several functionalities such expert finding simply formulating hoc queries from either ontology editor the semantic wiki interface The result intelligent and collaborative front end which allow users add information fill gaps revise existing information semantic basis while keeping the knowledge base automatically updated 
3970 en YARS2 Federated Repository for Querying Graph Structured Data from the Web present the architecture end end semantic search engine that uses graph data model enable interactive query answering over structured and interlinked data collected from many disparate sources the Web particular study distributed indexing methods for graph structured data and parallel query evaluation methods cluster computers evaluate the system dataset with 430 million statements collected from the Web and provide scale experiments billion synthetically generated statements 
3971 en Sindice com Weaving the Open Linked Data Developers SemanticWeb applications face challenge with respect the decentralised publication model where statements about encountered resources The linked data approach which man dates that resource URIs should referenced and yield metadata about the resource helps but only partial solution present Sindice lookup index over resources crawled the Semantic Web Our index lows applications automatically retrieve sources with information about given resource addition allow resource retrieval through inverse functional properties full text search and index SPARQL endpoints 
3972 en Enabling Advanced and Context Dependent Access Control RDF Stores Semantic Web databases allow efficient storage and access RDF statements Applications are able use expressive query languages order retrieve relevant metadata perform different tasks However access metadata may not public just any application service Instead powerful and flexible mechanisms for protecting sets RDF statements are required for many Semantic Web applications Unfortunately current RDF stores not provide fine grained protection This paper fills this gap and presents mechanism which complex and expressive policies can specified order protect access metadata multi service environments 
3973 en Ontology based Controlled Natural Language Editor Using CFG with Lexical Dependency recent years CNL Controlled Natural Language has received much attention with regard ontology based knowledge acquisition systems CNLs subsets natural languages can useful for both humans and computers eliminating ambiguity natural languages Our previous work OntoPath proposed edit natural language like narratives that are structured RDF Resource Description Framework triples using domain specific ontology their language constituents However our previous work and other systems employing CFG for grammar definition have difficulties enlarging the expression capacity newly developed editor which propose this paper permits grammar definitions through CFG Context Free Grammar with Lexical Dependency that includes sequential and semantic structures the grammars With CFG describing the sequential structure grammar lexical dependencies between sentence elements can designated the definition system Through the defined grammars the implemented editor guides users’ narratives more familiar expressions with domain specific ontology and translates the content into RDF triples 
3974 en How Useful are Natural Language Interfaces the Semantic Web for Casual End users Natural language interfaces offer end users familiar and convenient option for querying ontology based knowledge bases Several studies have shown that they can achieve high retrieval performance well domain independence This paper focuses usability and investigates NLIs are useful from end user’ point view that end introduce four interfaces each allowing different query language and present usability study benchmarking these interfaces The results the study reveal clear preference for full sentences query language and confirm that NLIs are useful for querying Semantic Web data 
3975 en Evaluating the Semantic Web Task based Approach The increased availability online knowledge has led the design several algorithms that solve variety tasks harvesting the Semantic Web dynamically selecting and exploring multitude online ontologies Our hypothesis that the performance such novel algorithms implicitly provides insight into the quality the used ontologies and thus opens the way task based evaluation the Semantic Web have investigated this hypothesis studying the lessons learnt about online ontologies when used solve three tasks ontology matching folksonomy enrichment and word sense disambiguation Our analysis leads suit conclusions about the status the Semantic Web which highlight number strengths and weaknesses the semantic information available online and complement the findings other analysis the Semantic Web landscape 
3976 en  Ontology Design Pattern for Representing Relevance OWL Design patterns are widely used software engineering abstractions which define guidelines for modeling common application scenarios Ontology design patterns are the extension software patterns for knowledge acquisition the Semantic Web this work present design pattern for representing relevance depending context OWL ontologies assert which knowledge from the domain ought considered given scenario Besides the formal semantics and the features the pattern describe reasoning procedure extract relevant knowledge the resulting ontology and plug for Prot´ ´ which assists pattern use 
3977 en Lifecycle Support Architectures for Ontology Based Information Systems Ontology based applications play increasingly important role the public and corporate Semantic Web While today there exist range tools and technologies support specific ontology engineering and management activities architectural design guidelines for building ontology based applications are missing this paper present architecture for ontology based applications—covering the complete ontology lifecycle—that intended support software engineers designing and developing ontology based applications illustrate the use the architecture concrete case study using the NeOn toolkit one implementation the architecture 
3978 en COMM Designing Well Founded Multimedia Ontology for the Web Semantic descriptions non textual media available the web can used facilitate retrieval and presentation media assets and documents containing them While technologies for multimedia semantic descriptions already exist there yet formal description high quality multimedia ontology that compatible with existing semantic web technologies explain the complexity the problem using annotation scenario then derive number requirements for specifying formal multimedia ontology before present the developed ontology COMM and evaluate with respect our requirements provide API for generating multimedia annotations that conform COMM 
3979 en How Service Choreography Statistics Reduce the Ontology Mapping Problem
3980 en  method for recommending ontology alignment strategies different areas ontologies have been developed and many these ontologies contain overlapping information Often would therefore want able use multiple ontologies obtain good results need find the relationships between terms the different ontologies need align them Currently there already exist number different alignment strategies However usually difficult for user that needs align two ontologies decide which the different available strategies are the most suitable this paper propose method that provides recommendations alignment strategies for given alignment problem The method based the evaluation the different available alignment strategies several small selected pieces from the ontologies and uses the evaluation results provide recommendations the paper give the basic steps the method and then illustrate and discuss the method the setting alignment problem with two well known biomedical ontologies also experiment with different implementations the steps the method 
3981 en  empirical study instance based ontology matching Instance based ontology mapping promising family solutions class ontology alignment problems crucially depends measuring the similarity between sets annotated instances this paper study how the choice occurrence measures affects the performance instance based mapping this end have implemented number different statistical cooccurrence measures have prepared extensive test case using vocabularies thousands terms millions instances and hundreds thousands annotated items have obtained human Gold Standard judgement for part the mapping space then study how the different occurrence measures and number algorithmic variations perform our benchmark dataset compared against the Gold Standard Our systematic study shows excellent results instance based match ing general where the more simple measures often outperform more sophisticated statistical occurrence measures 
3982 en Discovering Simple Mappings Between Relational Database Schemas and Ontologies Ontologies proliferate with the growth the Semantic Web However most data theWeb are still stored relational databases Therefore important establish interoperability between relational databases and ontologies for creating Web data ®ective way achieve interoperability ¯nding mappings between relational database schemas and ontologies this paper propose new approach discovering simple mappings between relational database schema and ontology exploits simple mappings based virtual documents and eliminates incorrect mappings via validating mapping consistency Additionally also constructs special type semantic mappings called contextual mappings which useful for practical applications Experimental results demonstrate that our approach performs well several data sets from real world domains 
3983 en combiSQORE Ontology Combination Algorithm Automatic knowledge reuse for Semantic Web applications imposes several challenges ontology search Existing ontology retrieval systems merely return lengthy list relevant single ontologies which may not completely cover the specified user requirements Therefore there arises increasing demand for tool algorithm with mechanism check concept adequacy existing ontologies with respect user query and then recommend single combination ontologies which can entirely fulfill the requirements Thus this paper develops algorithm namely combiSQORE determine whether the available collection ontologies able completely satisfy submitted query and return single combinative ontology that guarantees query coverage addition ranks the returned answers based their conceptual closeness and query coverage The experimental results show that the proposed algorithm simple efficient and effective 
3984 en Continuous RDF Query Processing over DHTs study the continuous evaluation conjunctive triple pattern queries over RDF data stored distributed hash tables continuous query scenario network nodes subscribe with long standing queries and receive answers whenever RDF triples satisfying their queries are published present two novel query processing algorithms for this scenario and analyze their properties formally Our performance goal have algorithms that scale large amounts RDF data distribute the storage and query processing load evenly and incur little network traffic possible discuss the various performance tradeoffs that occur through detailed experimental evaluation the proposed algorithms 
3985 en Kernel Methods for Mining Instance Data Ontologies The amount ontologies and meta data available the Web constantly growing The successful application machine learning techniques for learning ontologies from textual data mining for the Semantic Web contributes this trend However principal approaches exist far for mining from the Semantic Web investigate how machine learning algorithms can made amenable for directly taking advantage the rich knowledge expressed ontologies and associated instance data Kernel methods have been successfully employed various learning tasks and provide clean framework for interfacing between non vectorial data and machine learning algorithms this spirit express the problem mining instances ontologies the problem defining valid corresponding kernels present principled framework for designing such kernels means decomposing the kernel computation into specialized kernels for selected characteristics ontology which can flexibly assembled and tuned Initial experiments real world Semantic Web data enjoy promising results and show the usefulness our approach 
3986 en Semplore Approach Scalable Hybrid Query Semantic Web Data extension the current Web Semantic Web will not only contain structured data with machine understandable semantics but also textual information While structured queries can used find information more precisely the Semantic Web keyword searches are still needed help exploit textual information thus becomes very important that can combine precise structured queries with imprecise keyword searches have hybrid query capability addition due the huge volume information the Semantic Web the hybrid query must processed very scalable way this paper define such hybrid query capability that combines unary tree shaped structured queries with keyword searches show how existing information retrieval index structures and functions can reused index semantic web data and its textual information and how the hybrid query evaluated the index structure using engines efficient and scalable manner implemented this approach engine called Semplore Comprehensive experiments its performance show that promising approach leads believe that may possible evolve current web search engines query and search the Semantic Web Finally breifly describe how Semplore used for searching Wikipedia and IBM customer’ product information 
3987 en Prodigy Sociopath The Adolescent Semantic Web
3988 en CLOnE Controlled Language for Ontology Editing This paper presents controlled language for ontology editing and software implementation based partly standard NLP tools for processing that language and manipulating ontology The input sentences are analysed deterministically and compositionally with respect given ontology which the software consults order interpret the input’ semantics this allows the user learn fewer syntactic structures since some them can used refer either classes instances for example repeated measures task based evaluation has been carried out comparison with well known ontology editor our software received favourable results for basic tasks The paper also discusses work progress and future plans for developing this language and tool 
3990 en Invited Tutorial Introduction the Semantic Web This invited tutorial will give overview the Semantic Web enabling conference attendees better understand the technical presentations the main conference and associated workshops Building upon series week long Semantic Web summer schools which have been running successfully since 2003 see http knowledgeweb semanticweb org sssw07 this tutorial brings together some the key researchers the area the Semantic Web 
3992 en Making Value Out Semantic Web Data
3994 en Testing Distributions for Goodness fit Homogeneity and Independence this talk will describe algorithms for several fundamental statistical inference tasks The main focus this research the sample complexity each task function the domain size for the underlying discrete probability distributions The algorithms are given access only samples from the distributions and make inferences based these samples The inference tasks studied here are similarity fixed distribution goodness fit similarity between two distributions homogeneity iii independence joint distributions and entropy estimation For each these tasks algorithm with sublinear sample complexity presented goodness fit test discrete domain size shown require sqrt polylog samples Accompanying lower bound arguments show that all but one these algorithms achieve near optimal performance Given some extra information the distributions such the distribution monotone unimodal with respect fixed total order the domain the sample complexity these tasks become polylogarithmic the domain size 
3997 en The Styrian activities nano Surface Engineering Development nanostructured coatings for the design multifunctional surfaces The surface technical products and components daily life determines properties like visual appearance friction and wear behaviour corrosion and oxidation properties and biocompatibility Well known examples can found the tool industry where the lifetime tools increased hard wear resistant coatings and surfaces the optical industry where reflectance mirrors absorbance lenses controlled via thin films microelectronics where integrated circuits are built from individual layers different electrical properties data storage devices where thin layers with tailored magnetic behaviour are utilized Surface engineering the design surfaces with tailored properties plays dominating role modern engineering emerging from structural components mechanical engineering where significant increase performance and lifetime have been realized functional devices electronics optoelectronics data storage where surface engineering enabling technology For this reason surface engineering being classified all industrial countries key technology The methods available range from well developed techniques which have been industrial use for several decades highly sophisticated processes emerging from their former position experimental laboratory techniques particular modern plasma and laser assisted vapour deposition methods have been developed rapidly where coatings and surfaces are designed atom atom thus enabling their design the nano scale Austria and particular Styria have strong research activities the field Surface Science amp Technology universities and non university research organisations well industry The design functional thin coatings the nanometre range one primary objective Within the frame the Austrian nano initiative research project cluster RPC consisting fundamental and applied research projects has been established Styria Long term scientific goal the RPC entitled “NANOCOAT” Development nanostructured coatings for the design multifunctional surfaces develop the knowledge and the methods which are necessary for load oriented design coatings and surfaces with regard their chemical composition nanostructure morphology phases topography and architecture The activities focus the interrelationship between coating materials the deposition process and the resulting multiphase micro nanostructure and coating architecture the coating properties and the response coatings onto specific loading conditions order strengthen the activities thin film technology the Austrian province Styria Center for Nanostructured Multi functional Coatings and Deposition Technologies has been founded and established Leoben The called nanoSurface Engineering Center nSEC joint venture the University Leoben and JOANNEUM RESEARCH The amp activities the nSEC focus the following three thematic areas • coatings for tools • coatings for components • coatings for functional devices The presentation will give introduction the research project cluster NANOCOAT and the nanoSurface Engineering Center Leoben The scientific part the presentation will show project results and will give benchmarking different plasma and laser assisted vapour deposition techniques addition potential areas application will shown 
3998 en Concurrent Innovation – Vision 2020
4000 en French Pole Competitiveness Living Labs What News
4005 en Living Lab the European Innovation System
4006 en Large Enterprise Open Innovation Strategy NOKIA Open Innvation
4013 en ECOLEAD results and Benefit for CNOs
4014 en Perfomance Measurement and Improvements CNOs
4015 en Legal Best Practices for Collaborative Innovative Clusters
4023 en PVC Legal Entity and Agreements Templates
4025 en ICT developers PVC – Formation Part 
4026 en ICT developers PVC – Formation Part 
4027 en Human Resources PVC Social Interaction
4030 en Realistic Synthetic Data for Testing Association Rule Mining Algorithms for Market Basket Databases
4031 en Learning Multi Dimensional Functions Gas Turbine Engine Modeling
4032 en Constructing High Dimensional Feature Space for Time Series Classification
4033 en  Method for Multi relational Classification Using Single and Multi feature Aggregation Functions
4034 en MINI Mining Informative Non redundant Itemsets
4037 en Matching Partitions over Time Reliably Capture Local Clusters Noisy Domains
4039 en Multilevel Conditional Fuzzy Means Clustering XML Documents
4040 en Uncovering Fraud Direct Marketing Data with Fraud Auditing Case Builder
4041 en Real Time GPU Based Fuzzy ART Skin Recognition
4042 en Dynamic Bayesian Networks for Real Time Classification Seismic Signals
4043 en Robust Visual Mining Data with Error Information
4044 en Automatic Categorization Human Coded and Evolved CoreWar Warriors
4048 en Association Mining Large Databases examination Its Measures
4096 en Pre processing Large Spatial Data Sets with Bayesian Methods
4101 en  the Eye the Beholder Another look Cognitive Systems
4102 en Probabilistic inference methods robotics filling the gap between high level reasoning and low level motion control
4103 en Learning Reason Knowledge Acquisition Cyc
4105 en Report the 2007 PASCAL Bootcamp Machine Learning
4110 en  tour the Pascal Challenge programme
4114 en Challenge Astrophysics The GRavitational lEnsing Accuracy Testing 2008 GREAT08 Challenge focuses problem that crucial importance for future observations cosmology The shapes distant galaxies can used determine the properties dark energy and the nature gravity because light from those galaxies bent gravity from the intervening dark matter The observed galaxy images appear distorted although only slightly and their shapes must precisely disentangled from the effects pixelisation convolution and noise The worldwide gravitational lensing community has made significant progress techniques measure these distortions via the Shear TEsting Program STEP Via STEP have run challenges within our own community and come recognise that this particular image analysis problem ideally matched experts statistical inference inverse problems and computational learning Thus order continue the progress seen recent years are seeking infusion new ideas from these communities This document details the GREAT08 Challenge for potential participants Please visit http www great08challenge info www great08challenge info for the latest information 
4117 en PASCAL within Cognitive Science Research and objectives FP7 call
4118 en Operational overview and historical background scientific programme
4120 en TP1 Leveraging Complex Prior Knowledge for Learning
4124 en Languages Hyperplanes Grammatical Inference with String Kernels
4126 en Learning Stochastic Edit Distances from Structured Data Application Music Retrieval
4127 en Human Motion Modelling through Dimensional Reduction with Gaussian Processes
4128 en Classifying Visual Scenes with Affine Invariant Regions and Text Retrieval Methods
4129 en Dynamics and Interaction BCI and Music Spaces
4130 en Methods for Fusing Eye Movements and Text Content for Information Retrieval
4131 en Online Reinforcement Learning and Sequential Forecasting and Partial Feedback
4132 en Techniques for Learning Multiple Related Tasks
4133 en Large Scale Multilingual and Multimodal Integration
4135 en Outreach demos targeting the general public with web applications
4136 en Why and how this related document 
4137 en Popularising the science and researchers PASCAL
4139 en Text mining for semantically enabled social browsing
4140 en Dynamic Network and Content Visualization Log Files
4142 en The Evolution Aluminum Hydroxides During the AlN Powder Hydrolysis The reaction aluminum nitride AlN powder with water has been known for long time the presence water AlN will decompose forming aluminum hydroxide and ammonia AlN 3H2O NH3 Bowen proposed more detailed reaction scheme for the reaction AlN powder with water room temperature AlN 2H2O AlOOH amorph NH3 NH3 H2O NH4 AlOOH amorph H2O xstal According Bowen AlN powder first reacts with water form amorphous aluminum hydroxide pseudoboehmite AlOOH recryctallizing bayerite with time The kinetics AlN hydrolysis was described using unreacted core model and the chemical reaction the product layer unreacted core interface was proposed the rate controlling step anticipated that the dissolution recrystallization process during AlN hydrolysis very similar that the crystallization aluminum hydroxide gels where pseudoboehmite forms from fresh highly hydrated amorphous hydroxide the present work the influence hydration temperature from ° and ageing time from minutes hours the formation crystalline products found after the AlN powder hydrolysis was investigated The AlN hydrolysis behaviour was observed measuring the the suspension whereas for the characterization the reaction products XRD SEM and TEM analyses were employed After short incubation time minutes which was found temperature dependant the hydrolysis reaction started accompanied with the increase and temperature Higher starting temperatures also increase the reaction rate The starting temperature and especially the ageing time time hydrolysis strongly influence the reaction products and their morphology was confirmed that the main crystalline reaction product bayerite regardless ageing time the mother liquor appears the form large somatoids elevated temperatures the first crystalline product nanostructured boehmite AlOOH also exhibiting high specific surface area With prolonged ageing the bayerite conversion takes place with dissolution pseudoboehmite and recrystallization bayerite After hours ageing the temperature range from ° ° bayerite became the predominant phase higher temperatures ° and ° both phases are present but after hours ageing boehmite remains the predominant phase Fig Based these results extension Bowen ’ model for the AlN powder hydrolysis elevated temperatures proposed anticipated that any temperature the very first solid reaction product formed the surface the AlN particles nanostructured pseudoboehmite Once formed part the pseudoboehmite will transformed crystalline boehmite while the other part will further react with water form bayerite according the reaction scheme AlOOH amorph AlOOH xstal AlOOH amorph H2O xstal 
4143 en Dynamics nanoscopic magnetic clusters MnO3 thin films observed ultrafast magnetooptics Phase separated state thin films Pr0 6Ca0 MnO3 LaAlO3 and SrTiO3 substrates was investigated means the ultrafast time resolved magnetooptics the magnetic field The photoinduced Kerr rotation and ellipticity show remarkably different magnetic field dependence From comparison with the static Kerr rotation and ellipticity conclude that two different magnetic phases are present the samples low temperatures According small angle neutron scattering results one the phases originates from nanoscopic ferromagnetic metallic clusters Temporal dependence the photoinduced Kerr signals indicates that upon photoexcitation changes the volume fraction these phases take place timescale few tens picoseconds 
4144 en Coverage Dependence DNA Hybridization Nanostructured Monolayers Nanografting AFM Study One the main challenges the development new analytical methods for life sciences dramatically reduce the minimum amount DNA and RNA that can directly and precisely characterized Micro arrays can not operate this limit and generally need the use enzymatic amplification processes that introduce statistical uncertainties crucially affecting the performance the device Towards this end new techniques the nano scale for amplification free and label free detection DNA hybridization need explored use nanografting atomic force microscopy AFM based nanolithography technique fabricate nanopatches self assembled monolayers single stranded DNA DNA within matrix other thiols gold surfaces opportunely varying the nanografting parameters establish relative scale for the surface coverage the DNA spots find that the height the patches grows with growing coverage reaching saturation regime very high DNA coverage and that the height each patch increases upon hybridization Not surprisingly maximum sensitivity for hybridization has been obtained before the height the grafted patch reaches saturation and therefore high packing densities Surprisingly however the height packing saturation regime the compressibility hybridized DNA grafted patches much smaller than the one DNA patches but the same that DNA patches grafted such conclude that contrast with several statements present the current literature our nanopatches DNA has little trouble hybridizing even high surface densities The level molecular order the nanopatches with respect that spontaneously assembled DNA monolayers responsible for the different hybridization efficiencies Our findings provide new insights the recombination short DNA fragments surfaces with important consequences for the field solid surface supported DNA hybridization detection 
4145 en Carbon nanotubes wrapped DNA molecules Complexes carbon nanotubes CNTs and nucleic acids allow fully exploit the potential the CNTs nanoelectronic devices both size specific matching the two components and the possibility anchor also non polar CNTs the polar substrates such oxides The wrapping CNTs the nucleic acid molecules allow also transfer CNTs into water solutions and performance for their radii and lengths separation using chromatographical methods the present work for the first time the stability and electronic properties the associates the single walled carbon nanotubes wrapped homopolymeric single stranded DNA molecules CNT DNA are studied using dispersion corrected modification quantum mechanical density functional tight binding method DFTB phenomenological model the CNT DNA formation energy depending the nanotube radii developed which shows that the decoration CNT few not single DNA chains leads high water solubility CNT DNA Pyrimidine based DNAs are found more effective wrap the CNTs whereas purine based DNAs are wrapping more sensitive the change radii The densities states the CNT DNA complexes are close the superposition those the “free” components with some additional states below Fermi level The band gap hybrid CNT DNA system determined the competition between the Fermi levels the “free” DNA and CNT few specific cases complexes polycytosine DNA and chiral metallic CNT considerable charge transfer from the DNA the CNT was observed combined with additional gain the CNT DNA formation energy 
4146 en Verification Biochemical Activity for Protein Monolayers Nanostructured Gold Surfaces demonstrate that Atomic Force Microscope AFM can used immobilize cysteine terminated protein Maltose Binding Protein MBP cys cys for short well defined locations directly gold substrates via nanografting and characterize the situ bioactivity these proteins within the fabricated nanopatterns This method exploits the high spatial and orientational control protein monolayer assembly allowed nanografting combined with the high sensitivity the AFM for detecting ligand binding events The maltose mediated conformational changes within the MBP have been found change the AFM tip protein interaction therefore causing the frictional signal change Our data show that the protein ligand binding function maintained upon the immobilization 
4147 en Analytical electron microscopy nanoparticles Analytical Electron Microscopy AEM essential tool for microstructural investigations nanostructured materials Dedicated FEG instruments enable study nanosized volumes using various methods such high resolution transmission electron microscopy HRTEM hig resolution contrast STEM HAADF imaging different techniques electron diffraction SAED CBED nanodiffraction ray energy dispersive spectroscopy XEDS and electron energy loss spectroscopy EELS the work the main stress will AEM study particles determination their size morphology chemical and structural composition orientation etc Study the nucleation and crystallization nanosized particles from amorphous phase analysis light elements small volumes with complicated geometries determination atomic clusters secondary element monocrystals investigation self assembly quantum dots amorphous matrix are examples that will presented and commented the work Determination the crystallinity many cases quite complicated and ambiguous The boundary between amorphous and crystalline phase certain materials very broad and smeared Amount crystallite size and shape and defectiveness the crystal structure nanoparticles clusters embryos nuclei precipitates nanowires nanorods etc could usual cases determined using classical approaches bright field dark field experiments selected area electron diffraction high resolution TEM specific cases some novel approaches should used extract the useful information from the sample Such approaches are the use chemical composition fluctuations nano regions the determination the presence nanoclusters the comparison calculated and experimental electron diffraction pattern the particle size and the degree crystallinity determination and the use non standard geometries for absorption correction procedures during the chemical composition determination particle using ray energy dispersive spectroscopy 
4148 en Hydroxylapatite coatings ZrO2 and Al2O3 ceramics bio mimetic method The materials that can used for the weight carrying bone implants are titanium Al2O3 ZrO2 ceramics All those materials with appropriate mechanical properties are bio inert When bio inert material implanted into the living body fibrous capsule developed isolate the implant from the surrounding tissue When bio inert implant loaded such that interfacial movement can occur implantation hip knee the fibrous tissue can become very thick and the implant loosens quickly The problem can solved use bio active materials bio active glasses glass ceramics composites hydroxylapatite etc These materials stimulate the growth the bone the soft tissue directly their surface and are strongly bonded the surrounding tissue However the low mechanical strength the known bio active materials does not permit these materials used weight carrying bone implants alternative for weight carrying bone implants the use bio active coatings bio inert material with high mechanical strength The plasma coating the hydroxylapatite mostly used Still there are some problems connected this method difficult control the thickness the coating and the compounds formed during the process due the high temperature during the synthesis the biological active molecules cannot incorporated into the coating With the use bio mimetic methods which imitate the crystallization process the bone the monophase hydroxylapatite coating with uniform thickness can prepared Using this method can also incorporate the biologically active molecules proteins that stimulate the bone formation Compared plasma spraying the bio mimetic methods are also much cheaper When the coated implants are used the adhesion between the implant and its coating becomes very important which the main problem with the use the bio mimetic method The bio mimetic methods are based the soaking the implant supersaturated solution calcium and phosphate ions Besides other solutions the simulated body fluid SBF and its higher concentrations are most commonly used our work the coatings bio active calcium phosphate were prepared the surface ZrO2 and Al2O3 ceramics using from the literature already known supersaturated solution with the ion concentrations Ca2 HCO3 and PO43 The hydroxylapatite coating the surface Al2O3 ceramic which identical ZrO2 ceramic The adhesion between the coating and the ceramic substrate was improved heat treatment 1050 ° for hour Before and after the heat treatment the coating was analysed XRD and TEM equipped with EDS detector and parallel EELS spectrometer order minimise any possible microstructural changes due the electron beam irradiation the TEM the cooling holder was used All the EDS and EELS measurements were carried out when the temperature the cold stage was stabilized approximately 100 After precipitation the coating was composed polycrystal plate like particles orientated perpendicularly the substrate surface Each individual plate like particle was composed poorly crystalline elongated nano crystals The heat treatment increased the coating’ crystallinity and particles grow isotropic 200 Using XRD EDS and EELS the crystal structure was determined apatite The simple vitro bio activity test using SBF solution proved the bio activity the “ prepared” coatings and after heat treatment well After soaking the coated substrates the SBF solution for days the layer hydroxylapatite was formed the coated surface Al2O3 and ZrO2 ceramics The bio mimetic method soaking the solution simple fast and with the use produced the uniform bio active coating the bio inert material which can used weight carrying bone implants 
4149 en  XAFS study local environment amorphous precursors La2Zr2O7 ceramics prepared nitrate modified alkoxide synthesis route prepared La2Zr2O7 the nitrate modified alkoxide based sol gel synthesis route The dehydrated lanthanum nitrate was mixed with zirconium butoxide methoxyethanol and refluxed for The obtained liquid was slowly dried 150oC the sample self ignited According XRD the powder was amorphous upon heating 700oC and crystallization took place 800oC The powder was composed friable agglomerates about sized nano particles EXAFS analysis investigated the and local environment upon transition from the sol the amorphous powder order learn about the distribution the constituent metal atoms the sub nanometer level observed that the EXAFS spectra the sol and the precursor powder dried 150 and heated 500 were similar indicating that the local environment atoms was not affected during the liquid amorphous solid transition – – links were formed already the sol and preserved even the powder heated 500 – – links the sol the amorphous powder were observed The EXAFS spectrum the sol similar the spectrum dehydrated lanthanum nitrate sol while the spectra dried and heated powder vanishing the second peak was noticed corelation could established Since link between and species was confirmed the early stages the synthesis the reaction between the species proceeded solid state reaction when long range diffusion became available leading the pure pyrochlore phase The proposed synthesis route allowed very good mixing the species the nanometre level 
4150 en Detection irreversible fusion iron oxide magnetic nanoparticle into single domain clusters magnetic measurements Ferrofluids are colloidally stable suspensions magnetic nanoparticles suitable carrier liquid Because their unique properties such magnetoviscous effect and wide spectrum possible medical and technical applications they are subject intense research The extent aggregation ferrofluid one its key properties determining the suitability such ferrofluid for applications order synthesize ferrofluids with satisfactory and controllable aggregation properties crucial understand the mechanism aggregate formation and have method for determining the extent aggregation prepared ferrofluid composed maghemite nanoparticles the average size dispersed decane The nanoparticles were prepared coprecipitation Fe2 and Fe3 ions basic medium Dispersion nanoparticles decane was achieved oleic acid coating Ferrofluids with two different concentration concentrated and diluted were prepared TEM images zero field dried and field dried ferrofluids suggest that fusion single nanoparticles into clusters few nanoparticles takes place the ferrofluid exposed external magnetic field Because the bigger size the clusters comparison single particles there stronger interaction between the clusters they easily combine into aggregates The fusion particles into clusters could thus important mechanism the process aggregate formation our work tried detect the irreversible fusion single particles into clusters magnetic measurements the clusters are single domain particles behaving super spins the problem cluster detection reduces the known problem determining the average magnetic particle size Zero field cooled field cooled magnetization ZFC susceptibility and measurements were carried out commercial SQUID based magnetometer Quantum Design MPMS show that the most evident method for detecting single domain clusters diluted well concentrated ferrofluids determining the particle size from magnetic measurement 
4151 en Electron Transport Through Junctions Scanning Differential AFM Investigation Conductive Tip AFM AFM commonly used for electrical characterization organic and inorganic molecular surface systems Understanding charge transport the molecular level crucial importance for developing molecular assemblies with uncommon properties for novel applications such molecular electronic devices and sensors Measurements the charge transport the contacts and through molecules will provide crucial insight into the electronic coupling within and between molecules and the interface From more general point view such studies aim expanding our fundamental understanding electron transport processes that central issue biophysics and chemistry this work follow approach the study Metal molecule Metal surface junctions that uses combination different AFM based techniques first use Nanografting build nanopatches the molecules interest into hosting reference self assembled monolayer SAM typically made alkanethiols After the tip changed conductive one AFM used characterize electrically the whole system recording the same time the system topography Some the advantages this approach are the possibility build and study wide range different monolayers side side relative way overcoming all the problems absolute measure and the situ control the quality both the hosting monolayer and that the grafted patches Preliminary results demonstrating the reliability the technique will presented for alkanethiols spontaneously self assembled and nanografted 111 surfaces Moreover will show that the case alkanethiol molecules one specific length C10 nanografted into SAM carpet the same molecules contrast current images appears that can correlated the higher quality the molecular packing inside the nanopatches with respect the surrounding SAM 
4152 en Recent achievement characterization micro and nano materials scanning photoemission imaging and spectromicroscopy With respect the other photoelectron microscopy techniques Scanning PhotoEmission Microscope SPEM uses the most direct approach photoelectron spectromicroscopy which the use small focused photon probe illuminate the surface The SPEM the Elettra synchrotron light source can operate two modes imaging and spectroscopy the first mode the sample surface mapped synchronized scanning the sample with respect the focused photon beam and collecting photoelectrons with selected kinetic energy The second mode photoelectron spectroscopy from microspot The SPEM the ESCAmicroscopy beamline Elettra has lateral resolution 150 and overall energy resolution which now better than 200 meV Samples can heated cooled liquid and biased during the measurements The beamline open the public and private research community two call for proposals experiment are available per year together with the possibility dedicated collaborations specific projects Some recent achievements the chemical physical and electronic characterization nano and micro structured materials will presented providing overview the capabilities this powerful technique Metallic adsorbate interaction oxidation and supporting properties multiwall carbon semiconducting and metal based nanotubes will presented showing how even dynamic phenomena such mass transport along the nanotube surface can monitored the SPEM special design the samples allows for the investigation single nanotubes with diameter down 60nm The study compositional and electronic properties morphological complex semiconducting structures will presented well Important industrial collaborations with international companies have been established last years first example will report the study the degradation processes occurring Organic Light Emitting Devices OLEDs Results both OLEDs operated ambient atmosphere and grown and operated ultra high vacuum will compared Another example will illustrate the chemical characterization the cathode surfaces Solid Oxide Fuel Cells under operating conditions the elemental distribution and its change under biasing and the observation and explanation the cathode electrochemical activation have been addressed Finally overview the limits the applications the ray photoelectron microscopes imposed the operation principles will given together with the future developments allowing the investigation materials mbar and even ambient pressure 
4153 en Studies Free Clusters and Low Energy Cluster Beam Deposition TASC The understanding the interplay between size and properties necessary step towards the production tailored cluster assembled materials With the aim investigating functional properties clusters their size dependent geometry and electronic structure and the correlations with nanoassembled materials obtained cluster deposition TASC recently acquired new UHV Compatible Roaming Supersonic Cluster Source The procesess cluster production based the pulsed microsputtering localised the surface rotating rod PMCS The material must conductor one semiconductor heated the conductive temperature This apparatus conceived facility able coupled variety UHV compatible systems located TASC INFM both house apparatus and syncrotron radiation beam lines ELETTRA Here presents some our first results obtained within collaboration with the prof Milani’ group the first class experiment concentrated our efforts the study inner shell absorption spectroscopy both free clusters The experiments have been carried out the Gas Phase beamline and for the first time was possible obtain complete set Near Edge ray Absorption Fine Structure spectra free transition metal clusters edge for clusters with size comprised between and 1000 atoms cluster Within the field material science our first measurements were dedicated the study oxidation dynamics nanostructured titanium films performed the Analytical Division Laboratory TASC
4154 en Infrared nanoscopy structured SAMs challenging scientific task the label free and non invasive investigation molecules with nanometer scale resolution Due the significant absorption lines the infrared region the called fingerprint region combination apertureless near field scanning optical microscopy with unique infrared laser spectroscopy provides powerful method for spectroscopic characterization self assembled monolayers SAMs the nanoscale First experiments were performed organic microstructured monolayers octadecanethiol and biotinylated alkylthiol using tunable Laser radiation source the characteristic amide region around 1700 With our scanning near field infrared microscopy SNIM were able record the frequency dependence single monolayer with lateral resolution nm2 corresponding which well below the Abbe limit The detection limit for biotinylated alkylthiol was estimated 5x10 mol corresponding attogram 
4155 en The twin cantilever approach the single molecule detection Detection and manipulation single molecules means mechanical systems has recently received constantly growing attention both for fundamental and applied reasons particular great interest has been aroused sensors based the principle frequency shift detection mechanical resonators the application which medicine and biology has lead very sensitive diagnostic methods However the effort push the sensitivity the single molecule level extreme conditions frequency the GHz range size with oscillating structures sized below all directions vacuum better than mbar and temperatures low few Kelvin have been exploited Here present alternative strategy capable single molecule sensitivity that uses twin cantilever structures several micron size operated room temperature and under ordinary vacuum conditions Two aspects are treated detail The formation tunable gap with controllable size the nanometer range has been obtained two step process first fracture along 100 crystallographic plane has been induced suitable designed silicon suspended structure ensuring the formation two atomically flat edges The controlled opening the gap then induced bending mechanically the wafer analogy with what normally done mechanical break junction The detection one more molecules placed across the gap can then obtained either measuring the perturbation the mechanical eigenfrequency the system detecting the mechanical cross talk induced the molecular link between short driver cantilever and longer follower cantilever that face each other presence molecules bridging the gap the driver moved electrostatically the eigenfrequency the follower the latter experience large oscillations than can easily detected optical piezoresistive methods also for weak binding forces fabricated asymmetric twin cantilever system with link formed multi walled carbon nanotubes across the gap and demonstrated that working room temperature and under normal vacuum conditions driver follower scheme possible detect the presence few molecules Moreover investigated the evolution the mechanical properties the system the molecules bridging the gap change number strength believe that with proper control the bonding chemistry the sensitivity our system could improved reach the single molecule level 
4156 en Novel scanning microscope for visualization individual emission sites flat field emission cathodes present first results obtained novel scanning projection field emission microscope SPFEM designed study flat broad area field emission cathodes The instrument merges capabilities measuring the electron field emission current from individual emitting site and genuine projection electrons onto luminescent screen This achieved optimized shape the anode probe having aperture which generates uniform macroscopic electric field across the investigated area the cathode This fact also enables presentation the relation between the current density and the applied electric field The magnification the electron optical system alone was calculated computational modeling for some cathode – probe distances and for some voltages The unique SPFEM performance demonstrated smooth sulfur doped nanodiamond films synthesized molybdenum substrates 
4157 en PicoNewton Force Spectroscopy Live Neuronal Cells using Optical Tweezers known that migration the axons neuronal cells driven guidance cues sensed receptors located the growth cone Filopodia and lamellipodia the highly motile structures extruding from the tip the growth cone explore the environment Their motion has been analysed but little known about the force these neuronal structures exert the structures they might find during their navigation fact the analysis this force has been limited theoretical considerations and experimental analysis have been restricted samples isolated filaments2 migrating cells this study used optical tweezers4 measure the forces exerted filopodia and lamellipodia with millisecond temporal resolution found that single filopodium exerts force not exceeding contrast the force exerted lamellipodia ranged more with duration varying from less than second more than seconds These measurements suggest that the absence actin polymerisation force can produced and that microtubule polymerisation required order develop forces larger than These results show that neurons not only process information but also they act their environment exerting forces varying orders magnitude Silica beads µm diameter functionalised with amino groups reduce sticking were trapped with 1064 infrared power the sample optical tweezers close the growth cone migrating axon Fig The growth cone displaced the bead both laterally and axially from its equilibrium position even microns Fig the end the bead did not remain attached the growth cone and could return its original position the trap Fig measured the lateral force exerted the growth cone Fneu following the bead position both using back focal interferometry with quadrant photo diode QPD and video tracking When the bead was far from the growth cone the QPD recordings and were quiet with standard deviation approximately Fig upper trace but collisions producing force larger than were observed when the bead was moved near the growth cone Fig lower trace several occasions and increased within seconds reaching values the order Fig and when the growth cone stopped pushing the bead returned its equilibrium position often less than the presence floating debris and wandering filopodia near the bead could affect the light pattern impinging the QPD collision was considered reliable when the bead displacement obtained with the QPD and videotracking were agreement black and yellow traces respectively Fig and the presence colliding filopodium lamellipodium was verified visual inspection the movie have analysed collisions between growth cones and trapped beads more than 200 experiments Each experiment lasted for minutes and many experiments several collisions significant for statistical analysis were observed These collisions produced maximal forces ranging from less than least with maximal rate increase second These collisions lasted from less than sec about seconds Larger forces were usually observed during long lasting collisions these forces extend over wide range intensities and durations measured separately the forces developed filopodia and lamellipodia for hundreds experiments order have good statistics 
4158 en Single atom manipulation and spectroscopy using low temperature STM STM operated under extremely clean and stable conditions became the last decade very powerful nanotechnological tool not only used probe individual atoms and molecules but also displace decompose and assemble individual species into new artificial nanostructures1 These are formed atom atom process precisely controlling the quantum mechanical interactions between the STM tip and the sample Such experiments require cryogenic temperatures below atomically clean pressure below hPa and properly ordered surfaces controlled LEED and AES well extreme mechanical and electrical stability the tip sample tunneling junction The experiments presented were performed with home built Besocke type UHV STM cooled with liquid helium 111 and 112 single crystal surfaces cleaned repeated cycles ion sputtering and annealing were used substrates while STM tips were prepared electronically controlled etching polycrystalline wires NaOH Single adatoms were extracted from the substrate surface controlled dipping the tip into the surface under relatively high tunneling bias voltages Individual adatoms were manipulated controlled manner into desired nanostructures Submonolayer amounts were deposited onto clean substrates from Knudsen source atoms deposited room temperature form agglomerates during deposition already but can separated lower temperatures into individual adatoms means the tip sample interaction The electronic structures both and were studied STS with the lock technique2 Differential conductance spectra proportional LDOS are fully reproducible and can used differentiate between and species 
4159 en  situ comparison hybridization properties nanografted and self assembled DNA monolayers Using conventional AFM and nano patterned low and high density single stranded DNA SAMs have investigated the elastic response surface tethered DNA molecules after various hybridization times and under different loading forces Upon hybridization expected only for the low density single stranded DNA SAM transition the “standing ” phase seen find that high density DNA SAMs are lacking the capability hybridize not because density but because inherent disorder which reflected their low DNA SAM height Nanografting known increase both packing density and molecular order Therefore have performed patch patch experiments nano pattern conventional low density single stranded DNA SAM with subsequent nanografting processes First reference area molecules was created into which second process single stranded DNA was nanografted Thereby accurate situ comparison under equivalent conditions between conventional DNA SAMs and nanografted DNA patches becomes accessible Side side height and compression measurements can provide valuable biophysical insights the organization DNA molecules close solid interface discriminating between molecular order and density effects 
4160 en Crowding effects Enzymatic Restriction Reactions within DNA Nanostructures have studied the effect restriction enzyme digestion reactions DPN within DNA nanostructures flat gold substrates Atomic Force Microscopy AFM Typically work with few patches Self Assembled Monolayers SAMs DNA that are hundred size and are fabricated within alkylthiol SAMs gold films means AFM based lithographical technique known Nanografting start nanografting few patches single stranded DNA ssDNA molecule base pairs bps with recognition sequence bps specific for the DPN enzyme the middle Afterwards obtain reaction ready DNA the nanopatches are hybridized with complementary ssDNA sequence the same length The enzymatic reactions were carried out over nanopatches with different molecular density and different geometries Using nanopatch height measurements carried out with AFM are able show that the capability the DPN enzyme reach and react the recognition site significantly depends the geometry and the molecular density the nanopatches general was found that the digestion the DNA the enzyme strongly inhibited relatively low dsDNA density Reference experiments were similarly carried out with nanopatches DNA sequence without the recognition site and was found that that case the enzymatic reaction didn’ lead digestion the nanopatches These findings suggest that due the enzyme size possible tune the efficiency enzymatic reaction surface changing the crowding conditions the DNA the nanopatches 
4161 en New approach for the determination the hybridation efficiency ssDNA nanopatches Films single stranded DNA ssDNA immobilized surfaces form the basis number important biotechnology applications including DNA micro and nano arrays However the question about how the film structure affects the hybridization process not properly addressed literature While commonly accepted that the hybridization efficiency extensive self assembled monolayers ssDNA basically inversely proportional the molecular density the probes the surface the same agreement has not been reached when the monolayers are confined nanometric structures Using nanografting nanolithographic technique performed liquid environment with AFM tip are able fabricate ssDNA micro and nanostructures with well defined height lateral size The hybridization causes increase height that can monitored AFM microscopy Surprisingly observed the highest efficiency ssDNA hybridization densities halfway saturation moreover this regime the mechanical properties the ssDNA hybridized film and nanografted double stranded DNA film are equivalent quantify the hybridization efficiency our nanostructures and more general the efficiency chemical processes which involve only few molecules the analytical chemistry techniques are longer effective the contrary physical approach offers many suitable solution particular micro and nano mechanical resonating sensors experienced significant progress the last years allowing the measurement enumeration single molecules and mass sensitivity fabricate several devices consisting silicon cantilevers 5x2x15 and 5x2x25 size with mass 350 and 580 and resonance frequency and MHz respectively The top side was covered with ultraflat layer 8nm RMS which organic self assembled monolayer was formed ssDNA nanostructures the free end the cantilevers are fabricated nanografting When the ssDNA hybridizes the mass the cantilever increases and the resonance frequency shifts toward lower values Operating vacuum conditions obtained quality factor better than 104 that allowed attain mass sensitivity 5x10 corresponding the hybridization only 3x3 ssDNA nanostructure 
4162 en  framework programmes and Slovenia Slovenia successfully participated 5th and 6th Framework programmes The FP6 ended the end last year Participants from Slovenia participate all priorities and quite lot have been from business sector FP7 proposed Commissioner Poto nik lasting for the first time for seven years starting the end last year continuation the FP6 but introduces several new items and features The basic research new type research funding with new rules directed the last year established European Research Council ERC Usual research activities are grouped under Collaborative research umbrella which incorporates thematic areas including Nanosciences Nanotechnologies Materials and new Production Technologies NMP Thematic priority and Information and Communication Technologies ICT Thematic priority The first FP7 calls were the last Christmas presents Work programmes defining detailed work plan for each thematic priority and defining calls details are under preparation and adoption for the 2008 calls which are planned announced before the end this year adopted summer 2005 document Nanosciences and nanotechnologies action plan for Europe 2005 2009 the first intermediate report was prepared September 2007 
4163 en MoSIx nanowires funtionalization for molecula scale connectivity report new highly reproducible route recognitive self assembly molecular scale circuits using sulfur terminated subnanometer diameter Mo6S9 xIx MoSIx molecular nanowires demonstrate solution processed attachment MoSIx connecting leads gold nanoparticles GNPs also show that naked nanowires have the potential bind thiolated proteins such green fluorescent protein directly thus providing universal construct which almost any protein could attached further demonstrate three terminal branched circuits with GNPs opening self assembly route multiscale complex molecular scale architectures the single molecule level 
4164 en Director and polarization fluctuations suspensions ferroelectric nanoparticles nematic liquid crystals Phase separated state thin films Pr0 6Ca0 MnO3 LaAlO3 and SrTiO3 substrates was investigated means the ultrafast time resolved magnetooptics the magnetic field The photoinduced Kerr rotation and ellipticity show remarkably different magnetic field dependence From comparison with the static Kerr rotation and ellipticity conclude that two different magnetic phases are present the samples low temperatures According small angle neutron scattering results one the phases originates from nanoscopic ferromagnetic metallic clusters Temporal dependence the photoinduced Kerr signals indicates that upon photoexcitation changes the volume fraction these phases take place timescale few tens picoseconds 
4165 en Self assembled Mo6S9 xIx networks Mo6S9 xIx MoSIx nanowires have been known easily bond golden nanoparticles GNPs due their sulfur terminated ends Solution processed attachment was used for connecting MoSIx nanowires leads GNPs have recently observed irregular self assembled networks consisting small nanoparticles and thin MoSIx nanowires diameter that span scale several tens micrometers One such network has been analyzed measuring heights particles and number diameter and orientation nanowires connected them Results confirm that the bonding between nanowires happens more easily via nanoparticle than without have also monitored this network taking its topographic picture every few weeks for the last six months and degradation the network with time has been observed – the nanoparticles have been reduced size and nanowire diameter has substantially decreased 
4166 en Non equilibrium optical properties MoSI nanowires MoSI nanowires are the one dimensional systems with the weakest known interaction with their neighbours Therefore they are expected show most clearly the effects one dimensionality studied equilibrium and non equilibrium optical properties via optical reflectivity and absorbance well femtosecond pump probe spectra oriented Mo6S3I6 nanowire thin films Absorption light polarised parallel the axis orientation shows series resonances that are absent for perpendicular polarisation The sharp Van Hove features expected from the highly one dimensional character the material are not observed partly because the large density electron sub bands and partly because electron energy damping The electronic relaxation from non equilibrium situation was studied via femtosecond pump probe spectroscopy exciting into the second optical resonance found complex relaxation behaviour involving three distinct excited states and determined the lifetimes the involved states 
4167 en Synthesis metallic and semiconducting ZnS nanoparticles self assembled polyelectrolyte templates Metal and semiconductor nanoparticles have attracted much interest lately due their unique size dependant properties stemming from their quantum confinement effects and large surface areas The main problem nanoparticle synthesis their aggregation which often prohibits tailoring particle size One the convenient methods manipulate and process these nanoparticles technologically useful formulations “ situ formation” nanoparticles polymer matrices which prevents the aggregation the nanoparticles and enables their uniform distribution The polyelectrolyte multilayers PEMs polyallylamine PAH and polyacrylic acid PAA were assembled hydrophilic polystyrene tissue cultured and surface modified quartz substrates alternately dipping the substrates into polyanion and polycation aqueous solutions with various values until the desired thickness the PEMs was obtained The linear charge density concentration free carboxylic acid repeating units PAA was controlled adjusting the the dipping PAA solutions Thus formed PEMs were exposed the metal ion solution nominally neutral subsequent reduction ions sulfidication the ions metallic semiconductor nanoparticles ZnS are formed within the PEMs Since upon nanoparticle formation carboxylic groups PAA are regenerated the synthesis methodology can repeatedly cycled incorporate more metal ions which enables the formation nanoparticulate films where the nanoparticle size and concentration can manipulated The aim this work control the size and concentration the situ formed inorganic nanoparticles varying the synthesis conditions 
4168 en The influence space restriction the formation and stability polymorphic and amorphous forms known from the classical nucleation theory that crystallization can only occur critical nuclei are formed Thus there has enough space available for the formation such nuclei the present work determined theoretical criteria that have satisfied for the occurence crystalline phase from supersaturated solution confinement conditions resulting from entrapment drug solution into porous matrix Similar criteria were determined for the occurence crystallization from amorphous metastable polymorphic phases confinement conditions was shown theoretically that spatial constraint can cause vitrification from solution polymorph selection1 Metastable phases which are formed this manner can effectively protected against crystallization into thermodynamically more stable products through space restriction The theoretical criteria were tested experimentally with nifedipine entrapped into nanoporous silica xerogel matrix with average pore diameter The results thermal analysis and ray powder diffraction have shown that the amorphous nifedipine formed inside the xerogel pores protected against crystallization the temperature interval which chemically stable With combination differential scanning calorymetry and BET analysis estimated the total amount nifedipine that can stabilized the xerogel Also was shown through calculations that entrapment into hypotetical nanoporous matrix with certain pore size allows selective formation sulfathiazole polymorphs the pore radius equal then form formed selectively from toluene solution the pore radius less than amorphous phase formed 
4171 en Automated Character Annotation Multimedia describe progress automatically identifying characters films and series using their detected faces together with readily available annotation the form subtitles and transcripts describe how the subtitles and transcript can aligned give weak supervision the characters present shot well the actions emotions locations etc The supervision weak because correspondence problems and the character may not visible The visual problem face recognition challenging because faces appear images various sizes and pose and also vary considerably expression Fortunately videos contain multiple face examples each person form that can easily associated automatically using straightforward visual tracking These multiple examples reduce the ambiguity recognition show that the text supervision can strengthened speaker detection Although the labelling still incomplete and noisy then sufficient learn visual models for recognition and achieve successful character identification This joint work with Mark Everingham and Josef Sivic 
4172 en Shape modelling via higher order active contours and phase fields For the most part shape modelling has focused modelling families regions consisting deviations around given reference shape with simple topology There are applications however where the family regions involved does not show such constrained behaviour Cases where the number objects unknown priori where the topology the region may otherwise complex for example network shapes require new techniques Higher order active contours HOACs represent one approach modelling such families regions introducing explicit long range interactions between region boundary points HOACs can model families regions sharing geometric properties without overly constraining region topology Representing regions their boundaries often inconvenient however both analytically and numerically especially for complex topologies alternative the approach known phase field modelling The phase field representation and modelling framework offers number advantages both for the simplest region models and for HOACs way illustration the use HOAC and HOAC phase field models estimate the regions corresponding road networks and tree crowns satellite and aerial images will described 
4173 en  contrario matching local features between images
4175 en Person detection and recognition tracking and analysis The presentation describe the work carried out team focusing the multi camera scenarios First the context and applications these scenarios are reviewed Afterwards technique developed during the last year for multi level foreground detection presented tracking multiple people and human body motion capture are presented next Finally some videos showing results other works developed within the team are presented 
4177 en  Sequence Kernels for SVM classification sets vector
4178 en Crossing textual and visual content different application scenarios this presentation present method based Trans media Pseudo Relevance Feedback that allows crossing visual and textual content through multimodal knowledge base The main idea use one the modalities retrieve multimodal documents from the knowledge base and then switch fuse with the other modality the next step The different potentials the method retrieval image annotation text illustration are illustrated within Travel Blog Assistance System example scenario 
4179 en Fully Bayesian Source Separation with Application the CMB Blind source separation refers the inferring the values variables known sources from observations that are linear combinations them The observations and sources are usually vectors Both the sources and the matrix linear coefficients may unknown Here describe approach where the sources are assumed Gaussian mixtures MCMC procedure has been developed that computes the posterior distribution sources and the matrix linear coefficients from observations applied source separation multi channel extra terrestrial microwave data with the goal separating out the cosmic microwave background signal 
4180 en Audio Content Search Joachim Köhler showed several techniques and applications the area audio content search Robust segmentation algorithms were applied detect speech and non speech events and perform speaker segmentation and clustering task Further speech and music alignment techniques were demonstrated generate time code existing textual and score descriptions The current state the art technology for spoken document retrieval was given and alternative approaches and innovative applications were presented avoid the Out Vocabulary problem speech indexing tasks 
4181 en Audio Visual Speech Analysis Recognition Human speech production and perception mechanisms are essentially bimodal Interesting evidence for this audiovisual nature speech provided the called Gurk effect properly account for the complementary visual aspect propose unified framework analyse speech and present our related findings applications such audiovisual speech inversion and recognition Speaker face analysed means Active Appearance Modelling and the extracted visual features are integrated with simultaneously extracted acoustic features recover the underlying articulator properties the movement the speaker tongue tip recognize the recorded utterance the sequence the numbers uttered Possible asynchrony between the audio and visual stream also taken into account For the case recognition also exploit feature uncertainty given the corresponding front ends achieve adaptive fusion Experimental results are presented QSMT MOCHA and CUAVE audiovisual databases 
4182 en Multimodal Interfaces Two important issues multimodal system design the selection and mix input and output modalities and the exploitation the synergies between the modalities order maximize the usability the system this talk propose two new objective metrics relative modality efficiency and multimodal synergy that can provide valuable information and identify usability problems during the evaluation multimodal systems Relative modality efficiency when compared with modality usage can identify suboptimal use modalities due poor interface design information asymmetries Multimodal synergy measures the added value from efficiently combining multiple input modalities and can used single measure the quality modality fusion and fission multimodal system The proposed metrics are used evaluate multimodal system that combines pen and speech input and are compared with traditional evaluation metrics The results provide much insight into multimodal interface usability issues and demonstrate how multimodal systems should adapt maximize modalities synergy resulting efficient natural and intelligent multimodal interfaces 
4183 en Multimodal Processing and Multimedia Understanding Image Retrieval Using Eye Movements His presentation describes experiments that explored eye behaviour when carrying out purely visual tasks Corel database 1000 images Results are reported that indicate that image identification can carried out significantly faster with eye tracker than with mouse Participants performing image search tasks were able reach target images significantly fewer steps with eye tracker than random selection The effects the intrinsic difficulty finding images and the time allowed for successive selections were also investigated Finally the results yielded evidence the use rapid pre attentive vision during visual search 
4184 en Feature extraction from audio and their application music organization and transient enhancement recorded music
4185 en Interactive Visualization tool with Graphic Table Video Contents this paper present interactive visualization called Table Video Contents TOVC for browsing structured programs such news magazines sports these telecasts getting good segmentation can very time consuming especially annotating context Our visualization connected with classical media player offers very handy video browser This system allows global overview showing the temporal structure and giving some semantic information The drawn structure enables non linear video access suggesting relevant key frames The TOVC created from graphic framework designed for computing similarities visual contents and displaying the associated proximities map with graph representation TOVC one its first applications and shows interesting capabilities 
4186 en Relational Learning Collective Matrix Factorization present unified view matrix factorization models including singular value decompositions non negative matrix factorization probabilistic latent semantic indexing and generalizations these models exponential families and non regular Bregman divergences One can model relational data set matrices where each matrix represents the value relation between two entity types Instead single matrix relational data represented set matrices with shared dimensions and tied low rank representation Our example domain augmented collaborative filtering where both user ratings and side information about items are available predict the value relation extend Bregman matrix factorization set related matrices Using alternating minimization scheme show the existence practical Newton step The use stochastic second order methods for large matrices also covered 
4187 en BilVideo MPEG Compliant Video Database Management System BilVideo video database management system that provides integrated support for spatiotemporal semantic low level feature queries These queries were processed rule based system based knowledge base feature and object relational databases the earlier version BilVideo BilVideo now MPEG compatible which standard for describing multimedia content XML native feature database for efficient indexing and MPEG feature extractor tool are used for this purpose New version our video DBMS also based client server architecture where users may specify queries using the visual query interface With the help MPEG support will possible process low level feature queries color shape texture motion and integrate with other multimedia platforms such Multimedia Metadata Management CNR ISTI and Web Content platform CEA LIST MPEG compatibility issues and the new system design are briefly discussed the presentation 
4188 en Open Vocabulary Speech Analysis VITALAS Automatic indexing and radio speech data requires robust components for both speech recognition and spoken document retrieval Due the high topic variability and the resulting large vocabularies classic word based approaches have cope with high number out vocabulary words This talk presents phonetic approach open vocabulary indexing based syllable decoding and retrieval Current experimental results are presented followed demonstration the Fraunhofer IAIS AudioMining system for spoken term detection 
4189 en Implicit feedback learning semantic and collaborative information retrieval systems Information retrieval very wide domain which can involve various types activities and tasks Many complex factors are participating search for information and many systems have been experimented Nowadays general consensus has been established around keyword document matching process which appears efficient large scale and have enough reliability satisfy significant part the users Btu this claim has limited and for some subjects search still difficult task Many reasons can proposed explain these phenomena but the most salient ones are the difficulty for users express their needs while searching for information and the limitation shared knowledge between users and information retrieval systems meaning that both users and machines don really understand the information and knowledge space used references the other This presentation try provide overview one way resolve those gaps using feedback learning The aim make the system learning user behaviour order better define its current needs Machine learning algorithms applied signal coming from user while performing search can lead the understanding what really relevant the users and then can exploited help him during its tasks The work engaged through the VITALAS1 project presented study users search logs and definition feedback learning framework Then research implicit relevance feedback and query optimisation presented first attempt exploit the feedback learning framework Finally overview the next steps within those studies presented and especially their impact the VITALAS project 
4193 en Women science From exclusion complete inclusion Women mass entry into the academic and scientific fields particularly the second part the 20th Century happening social circumstances where sexist patterns are slowly dissolving Therefore the issue women science multifaceted and can separated into two kinds how the »second sex« perceived and considered subject scientific analysis and estimations which especially urgent subject social sciences and humanities and how are women situated direct participants scientific activities which important all the domains science the lecture the author will focused the second aspect particularly the question the politics equal opportunities science from the perspective placement inside historical and socio cultural milieus According this starting point she will represent the key features the political orientation regarding the abolition discrimination against women science and focus the situation Slovenia 160 
4194 en Promoting Women Science Central European Centre for Women and Youth Science aims promoting gender equality research and development and young scientists the Central European region www cec wys org Funded the European Commission the Centre the first regional centre advance the position women scientists and young scientists Central Europe Building report produced group experts the position women science Central and Eastern European countries Enlarge Women Science East Enwise the project focused promoting equal opportunities research and development four Central European countries and examining and improving the position young people science Besides creating user friendly information laden website the Centre established database women experts from the Central European region with view increasing the participation women scientists European research and the European Commission’ expert database 
4196 en Women and Science the Perceptions from the East The issue Women and Science and more specifically women and scientific careers has been attracting considerable attention recent years the level Concern about the considerable waste human resources and the persistence institutional discrimination impeding women’ scientific careers has prompted number significant documents and concerted action the trans national level designed tackle these entrenched problems Although female participation science has increased recent decades women are still rarely seen top scientific positions such professorships other high level research positions Career opportunities science are determined number complex factors which cannot easily described using simple statistical indicators ‘Internal’ factors which depend the organization operation and structuring the scientific community itself play important role The internal factors interact with ‘external’ factors which are determined and shaped society large – such existing gender roles inside and outside the family the changing status women with regard education and the labor market and the political framework The existing differences based the historical and political background from different countries must not stand the way women Europe coming together unified force develop common strategy and agenda for realizing gender equality science enlarged Europe Women the East and the West still know too little and display sometime limited interest what what’ happening the ‘other side’ Women the East express high hopes that the legal rights and directives the and higher standards the older members the will have positive impact gender equality policies the Eastern European countries Using gender sensitive indicators and statistics this lecture will present overview the presence and participation women science and will show gender specific patterns career opportunities Western and Eastern European countries short presentation the existing efforts European level promoting gender equality science and increasing the proportion women scientists will also shown will outlined the initiatives additional measures that need taken order strengthen the role female scientists regional and European level References
4197 en Career Chances Women Nanosciences European Universities – Conditions for International Diversity The lecture will place two different questions the centre What are the reasons for gender inequality relation the chances become University professor Nanosciences How can cross national differences with respect the share women University career positions this field explained The paper combines cultural and institutional perspective argued that institutions like the University are based and reproduce expectations towards the behaviour individuals many European Universities particularly also Western Europe the traditional expectations relation the main qualifications and the behaviour University professor were traditionally mainly also based two cultural constructions the image the male breadwinner who comprehensively available for his profession while another person takes over the organisation his everyday life well housework and childcare ‘male ‘habitus according Bourdieu 1987 this means that specific qualities that the professor expected have are society defined ‘male’ qualities However together with fundamental change European universities the last fifteen years that can called ‘economisation’ Universities also the cultural ideal the University professor and the expectations which are connected with this position have part fundamentally changed Such change has part already started earlier East European countries than the West argued here that this development has opened new options for women for University career However there are considerable cross national differences with respect the chances for women make University career Nanosciences argued that particularly also some cultural factors contribute explaining such differences the respective cultural model the University professor society the societal esteem that connected with this position and the way which “care” constructed the dominant cultural model the family 
4202 en QuestIO Question based Interface Ontologies
4204 en WP2 Learning Web service Domain Ontologies
4208 en FP7 “ICT for Transport” Strategic Objectives
4209 en  Mastering logistics complexity physical challenges and opportunities 
4216 en  Intelligent Cargo Integration Framework Workplan Review
4220 en  Impact Creation Workplan Review
4223 en Project Improve the Logistic Flow the Eyewear Supply Chain
4224 en Lessons learned from innovation diffusion the air traffic control
4225 en Logistics system and state the art critical issues the fishing logistics system
4229 en Knowledge Discovery extensive data sets
4230 en  Management collaboration networks
4232 en Value innovation for the logistic sector
4238 en Joint discussion cooperation between Project and Project 
4239 en Joint discussion cooperation between Project and Project 
4240 en Joint discussion cooperation between Project and Project 
4242 en Overview New Developments Boosting will give overview recent developments boosting focusing three papers which take very different approaches towards making boosting more efficient and effective Boosters iteratively choose base classifiers via weak learner and then update distribution over training examples Roughly the three papers show progress the three issues implicit this one sentence description boosting the number iterations required the computational cost choosing good base classifiers and the time and space complexity from maintaining distribution over training examples Warmuth Liao and Ratsch 2006 propose TotalBoost which totally corrective boosting algorithm Intuitively each round totally corrective boosters choose base classifiers which give more information not present previously chosen base classifiers This leads fewer iterations and smaller final hypotheses Barutcuoglu Long and Servedio 2007 describe alternative model for boosting where assumptions about the diversity base classifiers allow the booster learn single pass over the set base classifiers This eliminates the need optimize over all base classifiers each round Bradley and Schapire 2007 propose algorithm called FilterBoost which trains examples drawn from oracle rather than fixed set examples This alternative learning framework can model learning via single pass over the set training examples and allows the booster train efficiently very large datasets 
4244 en Content Analysis and MPEG Description Tools
4246 en From Representing Knowledge Deploying Metadata the Multimedia Domain
4248 en Truth Fan Fiction The lecture introduction fan fiction amateur fiction The first part comprises philosophy and moves fan fiction itself with examples the end will discuss philosophical puzzels that fan fiction poses wihtin theory fiction the end will solve the problem will atleast try 
4249 en Virtual Worlds Contextualism and the Myth Fiction this lecture will tell you story about exploits Second Life the end that will extract two philosophical conclusions the beginning the lecture will have fun and discuss about various philosophical aspects and the end will get serious and try establish conclusion will start off discussing about two virtual worlds 
4255 en The Concept Time and Space European folklore
4257 en The Concept Time and Space European folklore
4260 en The Concept Time and Space European folklore
4261 en The Concept Time and Space European folklore
4263 en Economy and values after century empirical research
4264 en The economist therapist Behavioural economics and light paternalism review methodological issues that arise designing implementing and evaluating the efficacy light paternalistic policies contrast traditional heavy handed approaches paternalism light paternalistic policies aim enhance individual choice without restricting Although light paternalism growth industry economics number methodological issues that raises have not been adequately addressed The first issue how particular pattern behavior should judged mistake and relatedly how the success paternalistic policies designed rectify such mistakes should evaluated – the welfare criterion that should used judge light paternalistic policies Second paternalism and especially light paternalism introduces new motives for attempting understand the psychological processes underlying economic behavior enhanced understanding process can help explain why people make mistakes the first place and more importantly provide insights into what types policies are likely effective correcting the mistakes Third there acute need for testing different possible policies before implementing them large scale which argue best done the field rather than the lab Fourth addition methodological issues there are pragmatic issues concerning who will implement light paternalistic policies especially when they involve positive expenditures discuss how economic interests can rechanneled supportendeavors consistent with light paternalism 
4266 en Why European Translators Should Want Westernize Translation Studies
4267 en  Test Statistic Homogeneity presentation will divided two parts First will present two simple and explicit procedures for testing homogeneity two independent multivariate samples size The nonparametric tests are based the statistic which the distance between the two empirical distributions restricted finite partition Both tests reject the null hypothesis homogeneity becomes large exceeds threshold will first discuss Chernoff type large deviation properties This results distribution free strong consistent test homogeneity Then the asymptotic null distribution the test statistic obtained leading asymptotically alpha level test procedure the second part will consider the problem selecting unknown multivariate density belonging set densities cal finite associated Vapnik Chervonenkis dimension where the complexity unknown and mathcal subset mathcal for all Given sample size drawn from will show how the statistic can used build estimate hat yielding almost sure convergence the estimated complexity the true but unknown and with the property mathbf int hat mbox sqrt The methodology includes wide range density models such mixture models and exponential families This talk summary two papers written with Cadre ENS Cachan France Devroye McGill University Montreal and Gyorfi Technical University Budapest 
4268 en That close translators interpreters researchers texts and their interrelations
4269 en Adaptive Representations for Efficient Inference for Distributions Permutations Permutations are ubiquitous many real world problems such voting rankings and data association Representing uncertainty over permutations challenging since there are possibilities and typical compact representations such graphical models cannot efficiently capture the mutual exclusivity constraints associated with permutations this talk use the low frequency terms Fourier decomposition represent such distributions compactly first describe how the two standard probabilistic inference operations conditioning and marginalization can performed entirely the Fourier domain terms these low frequency components without ever enumeration terms also describe novel approach for adaptively picking the complexity this representation order control the resulting approximation error demonstrate the effectiveness our approach real camera based multi people tracking setting This presentation joint work with Jon Huang and Leo Guibas 
4272 en  Framework for Probability Density Estimation The talk introduces new framework for learning probability density functions assessing their performance against set test functions theoretical analysis suggests that can tailor distribution for class tasks training fit small subsample There trade off between the complexity the class distributions used for the distribution and the complexity the set tasks Experimental evidence given support the theoretical analysis 
4274 en Kullback Leibler Divergence Estimation Continuous Distributions present universal method for estimating the divergence between continuous densities and prove converges almost surely Divergence estimation typically solved estimating the densities first Our main result shows this intermediate step unnecessary and that the divergence can either estimated using the empirical cdf nearest neighbour density estimation which does not converge the true measure for finite The convergence proof based describing the statistics our estimator using waiting times distributions the exponential Erlang illustrate the proposed estimators and show how they compare existing methods based density estimation and also outline how our divergence estimators can used for solving the two sample problem 
4275 en The Changing Image the Turk Western European Ottoman relations had long and many facet history long the Ottoman Empire was expanding its civil and military institutions were idealised far superior those their contemporaries Western Europe the 15th century Pope Pius even summoned the Sultan Mehmet let himself baptised and become the greatest Christian princes and papal protégé However due Ottoman defeats the late 17th century the overall prestige the Ottoman Empire declined When the 19th century the tables were turned the once formidable empire became ‘the Sick Man Europe ’ Its idealised image had faded away dwindle into obscurity the 1856 Treaty Paris the Ottoman Empire was nevertheless officially recognised permanent part the European power balance such was the first non European political entity gain that status which was codified the Hague Conference 1899 where the Ottoman Empire appeared one the participants and confirmed the 1923 Treaty Lausanne Regardless these changes Turks have been the Western European ‘other’ par excellence ever since the first encounter the two cultures 
4276 en The Influence the Ottoman Regional Policy the Cultural and Economic Life Slovenia The Ottoman State applied various economic and social policies every province even certain districts the boundaries those provinces according their local social and economic structures would proper name this policy ‘regional policy ’ This also the main characteristic the general administrative policy the Ottoman State This paper studies the regional policy the Ottoman State Slovenia and its influences the international trade ports and trade centres and cultural and economic life the local people the 16th and 17th centuries This study focuses particularly the protection legal and economic rights merchants and the local people providing the security and justice the Ottoman State certain districts addition the main subject the paper some information are given the commercial activities merchants from Bursa Belgrad Dubrovnik and Venice important ports and trade centres Slovenia the other hand Ottoman political and military activities some districts under the Venetian administration Dalmatia relation the main political objective the Ottoman State preventing Venetian domination this region also considered The main sources studied for this paper are the accounts eye witnesses and the Ottoman archives 
4277 en Testing with Kernel based Test Statistics Power Against Sequences Local Alternatives Testing for homogeneity between two samples offers natural quantitative framework investigate how compare two distributions from empirical data shall discuss some recently proposed nonparametric test statistics whose common feature share kernel based formulation particular discuss their respective power against different classes alternatives 
4278 en From Indifference and Contempt Love and Hate The Perception ‘Franks’ Ottoman Culture From the very start their rise statehood the Ottomans have been confronted and exposed wide variety western peoples and cultures Venetians and Genoese the 15th French and Austrian the 16th British and Dutch the 17th centuries … Most these early contacts were characterised general feeling indifference mixed with considerable amount contempt deriving from imperial sense superiority and marked bias against infidels falling outside Islamic jurisdiction This general feeling mistrust did not preclude interaction between Ottomans and Westerners diplomatic institutional communal individual level yet they remained superficial and sporadic all the more one considers that contacts were almost exclusively one sided the Ottomans generally comfortably remaining the receiving end such relations Things began change the 18th century result rapidly growing web communication between the West and the Empire and most all due gradual change the rapport force between the two worlds Confronted with the first concrete signs western predominance the Ottomans—especially members the ruling elite—felt greater urge intensify their contacts with and understanding western peoples and culture Though not yet westernisation per this process gradually paved the way the extraordinary intensity that relations with the West would acquire during the 19th century Under these circumstances was inevitable that perceptions the Franks now redefined Europeans and Westerners—with all the civilisational connotations that came with the terms—would change radically indifference was longer possible contempt had lost its justification The Ottomans moved toward love hate relationship with the West which can still felt underlying the complex feelings Turks toward Europe today 
4279 en Subjective Measure for Distribution Similarity propose subjective way defining similarity between probability distributions Our measure parameterized collection subsets the domain over which the probability distributions are defined Intuitively speaking the collection subsets interest with respect theproperties the distributions that one wishes analyze The motivation behind the introduction that measure comes from real life scenarios which one cares only about certain distribution changes contrast with more traditional notions distribution similarity such the Norm our measure can reliably estimated from pair finite samples drawn from the two distributions have demonstrated the usefulness the new measure several areas applications including change detection streaming data the analysis sensor network data and domain adaptation learning 
4280 en Sketching and Streaming for Distributions this talk look the problem sketching distributions the data stream model This model that has become increasingly popular over the last ten years practitioners variety areas have sought design systems that handle massive amounts data time and space efficient manner Problems such estimating the distance between two streams testing independence identifying correlations and determining distribution compressible play important role start reviewing results using stable distributions compute small space sketches that can used estimate the distance between two distributions then present recent results extending this work estimate the strength correlations between two distributions finish with overview work that seeks characterize the limits these techniques with particular emphasis what possible regards sketching information divergences such the Kullback Leibler Jensen Shannon and Hellinger divergences 
4311 en Discovering Cyclic Causal Models Independent Components Analysis This talk will start presenting Shimizu 2006 ICA based approach LiNGAM for discovering acyclic DAG linear Structural Equation Models SEMs from causally sufficient continuous valued observational data This remarkable because determines the direction every causal arrow when experimental data available Our work generalizes the above relaxing the acyclicity constraint our approach LiNG enables the discovery arbitrary directed graph linear SEMs present various algorithm sketches for causal discovery with LiNG and show results simulation for one such algorithm When the error terms are non Gaussian LiNG discovery algorithms output smaller set candidate SEMs than Richardson Cyclic Causal Discovery CCD algorithm prove that all the models output LiNG entail the same observational distribution and are equally simple same number edges This implies that without further assumptions algorithm can reliably narrow the set candidate SEMs output LiNG using just observational data However show that under the additional assumption stability the set candidate models output LiNG can further narrowed down under some conditions single model 
4313 en Networked organizations projects results and lessons learned
4314 en  Project presentation and results
4315 en ToolEast Open source enterprise planning and order management system for eastern european tool and die making workshops
4316 en Managing production networks key performance indicators KPIs 
4317 en Kovinastroj Gastronom Factroy catering equipment 
4319 en ToolEast Open source enterprise planning and order management system for eastern european tool and die making workshops
4320 en TCS Toolmakers Cluster Slovenia
4321 en ToolEast Open source enterprise planning and order management system for eastern european tool and die making workshops
4322 en ToolEast Portal and its Other Functionalities
4328 en Introduction Statistical Machine Learning The first part his tutorial provides brief overview the fundamental methods and applications statistical machine learning The other speakers will detail built upon this introduction Statistical machine learning concerned with the development algorithms and techniques that learn from observed data constructing stochastic models that can used for making predictions and decisions Topics covered include Bayesian inference and maximum likelihood modeling regression classification density estimation clustering principal component analysis parametric semi parametric and non parametric models basis functions neural networks kernel methods and graphical models deterministic and stochastic optimization overfitting regularization and validation 
4329 en Kernel methods and Support Vector Machines The tutorial will introduce the main ideas statistical learning theory support vector machines and kernel feature spaces This includes derivation the support vector optimization problem for classification and regression the trick various kernels and overview over applications kernel methods 
4330 en Monte Carlo Simulation for Statistical Inference Model Selection and Decision Making The first part his course will consist two presentations the first presentation will introduce fundamentals Monte Carlo simulation for statistical inference with emphasis algorithms such importance sampling particle filtering and smoothing for dynamic models Markov chain Monte Carlo Gibbs and Metropolis Hastings blocking and mixtures MCMC kernels Monte Carlo sequential Monte Carlo for static models auxiliary variable methods Swedsen Wang hybrid Monte Carlo and slice sampling and adaptive MCMC The algorithms will illustrated with several examples image tracking robotics image annotation probabilistic graphical models and music analysis The second presentation will target model selection and decision making problems will describe the reversible jump MCMC algorithm and illustrate with application simple mixture models and nonlinear regression with unknown number basis functions will show how apply this algorithm general Markov decision processes MDPs The course will also cover other Monte Carlo simulation methods for partially observed Markov decision processes POMDPs using policy gradients common random number generation and active exploration with Gaussian processes outline some applications these methods robotics and the design computer game architectures will given The presentation will end with the problem Monte Carlo simulation for Bayesian nonlinear experimental design with application financial modeling robot exploration drug treatments dynamic sensor networks optimal measurement and active vision 
4331 en Latent Variable Models for Document Analysis Wray Buntine will consider various problems document analysis named entity recognition natural language parsing information retrieval and look various probabilistic graphical models and algorithms for addressing the problem This will not extensive coverage information extraction natural language processing but rather look some the theory methods and practice particular cases including the use software environments 
4332 en Introduction Reinforcement Learning The tutorial will introduce Reinforcement Learning that learning what actions take and when take them optimize long term performance This may involve sacrificing immediate reward obtain greater reward the long term just obtain more information about the environment The first part the tutorial will cover the basics such Markov decision processes dynamic programming temporal difference learning Monte Carlo methods eligibility traces the role function approximation the second part cover some recent developments namely policy gradient and second order methods such LSPI and the modified Bellman residual minimization algorithm 
4333 en Foundations Machine Learning Machine learning usually taught bunch methods that can solve bunch problems see above The second part the tutorial takes step back and asks about the foundations machine learning particular the philosophical problem inductive inference Bayesian statistics and artificial intelligence concentrates principled unified and exact methods 
4334 en Inference Graphical Models This short course will cover the basics inference graphical models will start explaining the theory probabilistic graphical models including concepts conditional independence and factorisation and how they arise both Markov random fields and Bayesian Networks will then present the fundamental methods for performing exact probabilistic inference such models which include algorithms like variable elimination belief propagation and Junction Trees will also briefly discuss some the current methods for performing approximate inference when exact inference not feasible Finally will illustrate range real problems whose solutions can formulated inference graphical models 
4335 en Contrast Data Mining Methods and Applications The ability distinguish differentiate and contrast between different datasets key objective data mining Such ability can assist domain experts understand their data and can help building classification models His presentation will introduce the principal techniques for contrasting different types data covering the main dataset varieties such relational sequence and graph forms data clusters well data cubes will also focus some important real world application areas that illustrate how mining contrasts advantageous 
4336 en Learning Computer Vision This tutorial will cover some the core fundamentals vision and demonstrate how they can interpreted terms machine learning fundamentals Unbeknownst most researchers the field machine learning the fundamentals object registration and tracking such optical flow interest descriptors SIFT segmentation and correlation filters are inherently related the learning topics regression regularization graphical models generative models and discriminative models result many aspects vision can interpreted applied forms learning From this discussion fundamentals shall also explore advanced topics object registration and tracking such non rigid object alignment tracking and non rigid structure from motion and how the application machine learning continuing improve these technologies 
4338 en Group Theory and Machine Learning Machine Learning Tutorial Lecture The use algebraic methods—specifically group theory representation theory and even some concepts from algebraic geometry— emerging new direction machine learning The purpose this tutorial give entertaining but informative introduction the background these developments and sketch some the many possible applications including multi object tracking learning rankings and constructing translation and rotation invariant features for image recognition The tutorial intended palatable non specialist audience with prior background abstract algebra 
4339 en Spectral Clustering Machine Learning Tutorial Lecture Spectral clustering technique for finding group structure data based viewing the data points nodes connected graph and clusters are found partitioning this graph based its spectral decomposition into subgraphs that posses some desirable properties plan for this talk give review the main spectral clustering algorithms demonstrate their abilities and limitations and offer some insight into when the method can expected successful previous knowledge assumed and anyone who interested clustering fun applications linear algebra might find this talk interesting 
4374 en Treating drop foot hemiplegics the role matrix electrode
4375 en FES treatment lower extremities patients with upper lower motor neuron lesion comparison rehabilitation strategies and stimulation equipment
4376 en Stochastic Rank Correlation novel merit function for dual energy registration image modulated radiation therapy
4378 en Improving Patient Safety Through Clinical Alarms Management
4379 en System for Tracing blood transfusions and RFID
4380 en Optimal Control Walking with Functional Electrical Stimulation Inclusion Physiological Constraints
4381 en Acceleration driven adaptive filter remove motion artifact
4382 en Using Heuristics for the Lung Fields Segmentation Chest Radiographs
4383 en Markov chain based edge detection algorithm for evaluation capillary microscopic images
4384 en The Influence Reduced Breathing During Incremental Bicycle Exercise Some Ventilatory and Gas Exchange Parameters
4386 en The HECE Learning Experience BME Education
4387 en Troubleshooting for DBS patients non invasive method with subsequent amination the implantable device
4390 en How New and Evolving Biomedical Engineering Programs Benefit from EVICAB project
4392 en European Virtual Campus for Biomedical Engineering EVICAB
4394 en Internet Examination New Tool Learning
4401 en Brief presentation editors and respective Journals
4403 en The effect afferent training long term neuroplastic changes the human cerebral cortex
4406 en  Clinical Engineering Initiative within the Irish Healthcare System toward Safer Patient Environment
4407 en Web based Visualization Interface for Knee Cartilage
4408 en Control for Therapeutic Functional Electrical Stimulation
4409 en The Cavitational Potential Single leaflet Virtual MHV Multi Physics and Multiscale Modelling Approach
4410 en Learning Managements System Basis for Virtual Campus Project
4411 en Measuring Red Blood Cell Velocity with Keyhole Tracking Algorithm
4412 en Biomedical Engineering Education Virtual Campuses and the Bologna Process
4413 en  Novel Testing Tool for Balance Sports and Rehabilitation
4414 en Evaluation Tomographic Reconstruction for Small Animals using micro Digital Tomosynthesis microDTS 
4415 en What are most common reasons for rejecting paper 
4416 en Change mean frequency EMG signal during 100 meter maximal free style swimming
4417 en MIDS project National Approach Increase Patient Safety through Improved Use Medical Information Data Systems
4418 en  Pervasive Computing Approach Medical Emergency Environments
4419 en  preliminary setup model and protocol for checking electromagnetic interference between pacemakers and RFID Radio Frequency IDentification 
4420 en  Experimental Test Fuzzy Controller Based Cycle Cycle Control for FES induced Gait Knee Joint Control with Neurologically Intact Subjects
4421 en Methods for Automatic Honeycombing Detection HRCT images the Lung
4423 en Purchasing Process for Medical Devices Swedish Model
4424 en Main ideas EVICABs logistic structure
4425 en Deconstructing The Myth AIDS 1984 were told that HIV was the cause AIDS his provocative documentary film “Deconstructing the Myth AIDS ” Gary Null challenges virtually every statement ever made the American medical industrial complex the virus including those the Centers for Disease Control and Prevention CDC the National Institute for Health NIH and the Food and Drug Administration FDA While presenting the findings Nobel Prize winning scientists and leading virologists the film exposes the political maneuvering conspiracies and cover ups that have provided obstacles the study this human catastrophe from the start While presenting the findings Nobel Prize winning scientists and leading virologists the film exposes the political maneuvering conspiracies and cover ups that have provided obstacles the study this human catastrophe from the start For example there are experts who believe that AIDS the result multiple factors including drug use stress and nutritional deficiency but that government agencies made politically strategic decision emphasize these hypotheses and thus discourage certain researchers and their funding Meanwhile AZT infamously failed treatment for cancer and now the primary FDA approved approach treating AIDS highly toxic and can produce the very symptoms the illness prescribed treat “Deconstructing the Myth AIDS” goes beyond medicine and science question the very foundation our reliance government bureaucracies where concerns matters life and death 
4428 en Digital Technology and Legal Challenges Copyright
4431 en Digital Rights Management the educational sector
4461 en Costs benefits and incentives semantic techologies 
4466 en FP7 Space Work Programme and the 2008 Call for Proposals
4467 en Novel Aspects Plant Microtubule Parmacology Molecular Effects Antimitotic Drugs seen with Tubulin Eyes
4468 en Strengths and Weaknesses Russia CIS cooperation Two Visions Deriving from ISTCExperience
4469 en Safety Risk Assessment GMOs using Crops Example
4470 en Supporting science Slovenia The SRA perspective
4471 en Overview Bio NCP Russia
4474 en Overview Science Research Azerbaijan
4477 en Reusable Multi layer Thermal Protection System Design Manufacture and Test the Mock 
4478 en Systems Biology Approaches Research Department Biotechnology and Systems biology National Institute Biology
4481 en Development Effective Antiviral Agents New Type
4482 en ISTC Contribution ESA EXPERT Project Aero thermodynamics altitude capsule EXPERT
4483 en Structural Properties Antimicrobial Peptides acting Bacterial
4484 en Review Scientific Research Georgia
4485 en Testing Aerodynamics Reentry Space Vehicles EXPERT with Simulation Real Flight Viscous Effects
4488 en Measurements Earth Gravitational Field Satellite Navigation Systems
4491 en ESTEC experience ISTC collaborator Russian contribution EXPERT programme
4492 en Strengths and Weaknesses Russia CIS cooperation Two Visions Deriving from ISTC Experience
4493 en Space Transportation Assets Valorisation Europe
4496 en Examples Successful STCU Projects Future Launcher Program
4497 en New Tools Assure Food Safety 
4499 en Presentation CNES DLR NKAU TacisTwinning Project
4500 en DLR Space Aeronautics Transport andEnergy Experiences cooperation with ISTC
4501 en Overview Science Research Moldova
4503 en Overview Activities the National Academy Sciences
4505 en Experiences with Performed ISTC Projects and Expectations Future ISTC Projects
4508 en Silicon based Minerals for Ecological Agriculture
4509 en Creation high effective solar power facilities the base rigidizable structures step the space solar power development
4516 en Presentation the Institute Radio Engineering and Electronics
4521 en The Future the Internet Perspectives emerging from Europe The Internet world know today has undergone far reaching changes since its early days while becoming critical communications infrastructure underpinning our economic performance and social welfare With more than billion fixed users world wide today the Internet poised become fully pervasive infrastructure providing anywhere anytime connectivity nWith the further deployment wireless technologies the number users the Internet expected jump some billion matter few years the Internet extends its reach and serves ever growing population users sensors and actuators and intelligent devices new innovative services will introduced that contribute turn further developing environment supporting innovation creativity and economic growth nnSuch development has been positively acknowledged the European Union several documents that are emphasizing the European effort and strategy regarding the development the Future Internet nnThe lecture will address the approach and the agenda the technological and associated policy domains that have bearing the network and service infrastructure elements the Internet tomorrow 
4523 en Interview this interview for the Videolectures Net team Joao Schwarz Silva speaks about the problems terrorism internet security wifi and gives overlook about the future the Internet later continues with the Internet relation Science Education and its integration into today society also suggested some ideas about the 3rd world situation and the Internet age also asked him some more fun questions Whether thinks the Internet will die and how aqurate science fiction writers were regarding the future cyber space and the Internet the end also discussed future plans   need ensure that the network tomorrow must safe reliable and secure withstands not only accidents but also threats 
4550 en Perspectives emerging from Europe
4551 en Perspectives emerging from Europe
4552 en Perspectives Emerging from Europe
4553 en The Next Steps the Future the Internet
4555 en Emerging Issues from the Public Policy Aspect
4556 en Exploring Europe’ Asset Critical Concepts for the Future Internet
4557 en Search Technologies the Critical Path the Next Generation Internet
4558 en Participative Web what economic value what challenges 
4559 en Emerging Issues from the Public Policy Aspect
4561 en GENI Global Environment for Network Innovations
4562 en Design for the New Generation Network The Japanese approach
4564 en Towards the Future the Internet
4565 en The Future Internet Architectures
4566 en Challenges Future Internet Mobile Perspectives
4569 en Beyond Images THOMSON’ strategy for the Future Internet
4570 en Towards Future Internet Assembly Europe
4571 en Towards Future Internet Assembly Europe
4572 en Ideas and Questions from the Audience
4574 en Evolved Internet Future for European Leadership Some Thoughts the Future
4581 en Next Step – European Commission
4590 en Probability Distributions Permutations Compact Representations and Inference Permutations arise variety real world problems such voting ranking and data association Representing uncertainty over permutations however difficult since there are permutations and unlike many problems they cannot represented effectively graphical models due the mutual exclusivity constraints typically associated with permutations will present more effective representation which uses the low frequency terms Fourier decomposition represent distributions over permutations compactly For such representations truly useful need able efficiently inference and this end will discuss set useful inference operations including marginalization and conditioning which work completely the Fourier domain Performing inference low frequency Fourier based approximations can often lead functions which not correspond any valid distribution combat such errors will talk about method for projecting approximations relaxed marginal polytope and demonstrate the effectiveness the approach real camera based multi person tracking scenario Finally will talk about approaches for splitting distribution into independent factors and the inverse problem merging independent factors form joint the Fourier domain will discuss how the splitting and joining operations can applied our ongoing work adaptive inference where exploit independence order gain speedups for inference This joint work with Carlos Guestrin and Leonidas Guibas 
4592 en Gaussian process modelling transcription factor networks using Markov Chain Monte Carlo Ordinary differential equations ODEs can provide useful framework for modelling the dynamics biological networks this study focus small biological sub system where set target genes are regulated one transcription factor protein The concentration the protein and the gene specific kinetic parameters such basal rates decay rates and sensitivities are typically unknown The objective modelling estimate these quantities making use set observed gene expression levels consider Bayesian framework for modelling the system ODEs that based Gaussian processes The Gaussian process used the prior for the transcription factor protein and allows infer the concentration the protein time continuous manner present Markov chain Monte Carlo algorithm for full Bayesian statistical inference The essential property our MCMC algorithm that efficiently infer the protein concentration applying novel sampling algorithm for Gaussian process models apply our technique linear and non linear models 
4593 en Data variability could your friend Deterministic modeling the form ordinary differential equations ODE the dominant paradigm systems biology This stems partially from the type data that available Input data gene expression data protein concentrations for these models normally derived from whole cell populations Consequently what modeled the behaviour one average cell rather than multitude individual cells Variability within the data originates mainly from the measurement apparatus technical error from difficult control environmental conditions that precede the measurement biological variability and can constitute impediment clear cut conclusions For example kinetic parameters cannot known with absolute precision and have accompanied with confidence intervals that are generally commensurate with the rather high variability attached biological data Data variability can also put obstacles the way decisive model selection Measurement techniques are however increasingly being applied individual cells possible average the individual cell observations estimate the dispersion this synthetic measurement and use these data along with the modeling paradigms outlined above However inter cell variability can the result intrinsic system noise particular this the case molecular species involved exist very low concentrations such signaling networks argue that because this variability part intrinsic can harnessed rather than tolerated that provides novel insights into the mechanisms governing the system under study This requires paradigm shift –from deterministic stochastic modeling even though ODEs are still central the latter illustrate this the example system use DNA Double Strand Break repair dynamics irradiated human cells Recent assaying techniques allow the quantification DNA Double Strand Break DSB the individual cell level Repeated measurements time form dynamic image the DSB decay process cells after they have been exposed pulse ionising irradiation Crucially individual cell measurements allow the monitoring distributional features the DSB count population Existing deterministic models correctly mimic global features this system particular they can fit very well different decay regimes that are being observed when one focuses the average DSB count the population show however that these models when translated into the stochastic realm provide poor data fit when one considers distributional features such the variance the DSB count Furthermore using simple stochastic models that are partly amenable analytical manipulation show that enriching the existing models with extra feedback loops produces outcome more tune with observations Three independent data sets are used Possible biological consequences are briefly discussed 
4594 en Time delay analysis Bayesian Inference and Markov Chain Monte Carlo methods have been vocated for the estimation model parameters from ODEs Rogers Bayesian model based inference transcription factor activity BMC Bioin formatics 2006 look some the issues involved extend ing Bayesian inference methods systems containing time delays Verdugo and Rand Hopf bifurcation DDE model gene expression Commu nications Nonlinear Science and Numerical Simulation 235 242 2008 apply Lindstedt method the nonlinear system delay ®erential equa tions proposed model Monk Oscillatory Expression Hes1 p53 and ¡· Driven Transcriptional Time Delays Current Biology 1409 1413 2003 for the Hes1 feedback loop resulting closed form approximate expressions for the amplitude and frequency oscillation Analysis shows that oscillatory solutions can arise through Hopf bifurcation the delay rameter extend the work Verdugo and Rand the more realistic case where the decay parameters hes1 mRNA and Hes1 protein key com ponents the feedback are not equal focusing oscillatory behaviours aim for results that explain how the model parameters ®ect the system dynamics and hence could used inform parameter estimation from expression data illustrate our results applying Bayesian inference some real biological data has been observed that mRNAs for Notch signalling molecules such the bHLH factor Hes1 oscillate with hour cycles during somite segmentation Hirata Oscillatory Expression the bHLH Factor Hes1 Regulated Negative Feedback Loop Science 298 840 843 2002 investigated the molec ular mechanism behind observed oscillations mRNAs for Notch signalling molecules They examined the time course hes1 mRNA detail Hirata measured the half lives hes1 mRNA and Hes1 protein and identi¯ the proteases for Hes1 protein degradation Their experiments show that the degradation Hes1 protein required for Hes1 mRNA increase and that novo production the protein required for reduction hes1 mRNA These facts together support their theory that Hes1 essential compo nent two hour cycle clock and not just output primary clock The Hirata data comprises scaled hes1 mRNA expression level every min utes over hour period Monk model was able explain via numerical simulations the oscillation hes1 mRNA and Hes1 protein cultured cells observed Hirata use Bayesian approach the parameter ¯ ting problem which takes into account the inherent uncertainity the data and uses our priori bifurcation analysis inform the choice priors 
4595 en Gaussian process modelling latent chemical species Applications inferring transcription factor activity
4596 en Learning Bayesian networks from postgenomic data with improved structure MCMC sampling scheme Our paper contributes recent research sampling Bayesian network structures from the poste rior distribution with MCMC Two principled paradigms have been applied the past Structure MCMC first proposed Madigan and York defines Markov chain the space graph struc tures applying basic operations individual edges the graph like the creation deletion reversal edge Alternatively order MCMC proposed Friedman and Koller defines Markov chain the space node orders While the second approach has been found sub stantially improve the mixing and convergence the Markov chain does not allow explicit specification the prior distribution over graph structures phrase this difierently incurs distortion the specified prior distribution consequence the marginalization over node ders This distortion can lead problems for applications systems biology where owing the limited number experimental conditions the integration biological prior knowledge into the inference scheme becomes desirable Diferent approaches and modifications have been developed the literature address this shortcoming Ellis Eaton and Murphy Unfortunately these methods incur extra computational costs and are not practically viable for inferring large networks with more than nodes There have been suggestions how improve the classical structure MCMC approach using the concept the inclusion boundary proposed Castelo and Kocka but these methods only partially address the convergence and mixing problems the present paper propose novel structure MCMC scheme which augments the classical structure MCMC method Madigan and York with novel edge reversal move The idea the new move resample the parent sets the two nodes involved such way that the selected edge reversed subject the acyclicity constraint The proposal the new parent sets done efectively adopting ideas from importance sampling this way faster convergence efected For methodological consistency and contrast inclusion driven MCMC have properly derived the Hastings factor which function various partition functions that are straightforward compute The resulting Markov chain reversible satisfies the condition detailed balance and hence guaranteed theoretically converge the desired posterior dis tribution For our empirical evaluation have tested our method various data sets from the UCI repository such Vote Flare Boston Housing and Alarm which have previously been used Friedman and Koller demonstrate that order MCMC outperforms structure MCMC Our experimental results show that integrating the novel edge reversal move yields substantial improvement the resulting MCMC sampler over classical structure MCMC with convergence and mixing properties that are similar those order MCMC demonstrate the avoidance the distortional effect incurred with order MCMC have extended our empirical evaluation analysing cytometry protein concentrations from the Raf Mek Erk signalling pathway The experimental results show that the novel MCMC scheme can lead slight yet significant performance improvement over order MCMC when explicit prior knowledge integrated into the learning scheme This suggests that the avoidance any systematic distortion the prior probability distribution network structures renders our improved structure MCMC sampler preferable order MCMC especially for those contemporary systems biology applications where the number experimental conditions relative the complexity the investigated system and hence the weight the likelihood relatively low and explicit prior knowledge about network structures from publicly accessible data bases included 
4597 en Statistical learning biological networks brief overview Identification biological networks such signalling pathways gene regulatory networks protein protein interaction networks and metabolic networks considered key challenge computational biology Using machine learning framework this problem can addressed using different points view depending course the nature the biological interactions inferred but also the level abstraction the chosen modeling and the amount prior knowledge available Since 2000 research statistical learning biological networks have given rise rich panel approaches whose interest overcomes the field computational biology Network identification has been tackled using large scale data mining approaches supervised predictive approaches and reverse modeling approaches this sole last family very instructive focus the numerous graphical models that have been proposed far such Graphical Gaussian Models Bayesian networks Dynamical Bayesian networks and state space models will present short review these methods discussing among other issues model complexity relevance biology ability deal with hidden variables and scalability will also plead for the construction benchmark repository devoted examples relevant test problems even the true relevant test has always made vivo vitro 
4598 en Validating inferred gene networks using ODE models regulation dynamics Inferring gene regulatory networks from expression data remains one the most important and challenging problems bioinformatics and systems biology Traditionally validation inferred networks performed comparison with experimentally identifiedtrue networks the inferred network more generally one its subnets accurately describes known biological behaviour then will have greater degree belief its validity However inferred networks typically predict many new interactions that have not previously been observed Verifying each these predictions experimentally would difficult time consuming expensive and ultimately tedious task here present data driven method for validating inferred gene regulatory networks the first stage our work infer regulatory network from time course mRNA expression data Assuming the inferred network correct propose parametric ODE model link the observed mRNA expression levels with the hidden transcription factor activity the second stage infer the parameters our ODE system and then assess how well the resulting model describes the dynamic behaviour the observed expression data good description the data would lend support the validity both the inferred network and the ODE model while poor fit would suggest reformulation the model some level The value this approach illustrated applying yeast gene expression data 
4599 en Relationship between structure and dynamics gene regulatory networks Gene regulatory networks living cells are comprised recurring network motifs which perform key functions control cellular responses Mathematical models network motifs are already developed and experimentally validated analyze the stability previously validated mathematical models network motifs against the fluctuations their associated biochemical reaction rates and find that all these elementary functional modules are stable against any perturbation their rates reaction gene regulatory networks the motifs are connected each other directed acyclic manner Any large assembly stable and robust motifs connected with each other directed acyclic manner exhibits stable and robust dynamics All the motifs except those having feedback loops their structure preserve certain dynamic properties when embedded within large operational networks Our study also suggests that evolutionary mechanisms selected stable and robust functional modules with which build regulatory networks order ensure stability and reliability larger scale instead finding the simplest canonical representation with which serve the same purpose 
4600 en Parameter estimation using moment closure methods This poster will give tackle one the key problems the new science systems biology inference for the rate parameters underlying complex stochastic kinetic biochemical network models using partial discrete and noisy time course measurements the system state Although inference for exact stochastic models possible computionally intensive for relatively small networks explore Bayesian estimation stochastic kinetic rate parameters using approximate models based moment closure analysis the underlying stochastic process assuming Gaussian distribution and using moment closure estimates the first two moments can greatly increase the speed parameter inference The parameter space can efficiently explored embedding this approximation into MCMC procedure 
4601 en Parameter estimation biochemical reaction networks observer based approach important bottleneck the modelling biological systems the scarcity experimental data kinetic parameters Recent advances measurement technologies increase the feasibility infer ring these parameters from time series data Anguelova 2007 Voit and Almeida 2004 present methodology for estimating kinetic parameters from time series data way that particularly tailored biological models consisting nonlinear ordinary differential equations particular for systems which the nonlinearities are polynomial such mass action generalised mass action kinetics rational functions the states Michaelis Menten Hill kinetics The proposed approach consists three steps First the system transformed into tended system observer normal form The extended system does only depend structural information not the value the parameters Xia and Zeitz 1997 Fey 2008 This allows design high gain observer estimating the states the extended system Vargas and Moreno 2005 the extended system not observable everywhere but only trajectory servable the observer can only approximate observer However the observer error can chosen arbitrarily small final step the parameters are determined based the observer states the unique solutions simple nonlinear functions these states Thus the proposed parameter scheme estimates global estimation algorithm The parameter estimation methodology illustrated simple model the circadian rhythm neurospora Leloup 1999 The model contains three species six reactions and exhibits autonomous oscillations corresponding the day night cycle The proposed observer based rameter estimation method able recover all parameters even the trajectory comes close singularities the observability 
4603 en BioBayes Bayesian inference for Systems Biology There are several levels uncertainty involved modelling biochemical systems For example the experimental data usually contains considerable amount observation errors and there may alternative hypotheses about the processes involved studied phenomena The methods Bayesian inference provide consistent framework for modelling and predicting uncertain conditions present software package for applying Bayesian inferential methodology problems Systems Biology This software package named BioBayes and provides framework for parameter estimation and evidential hypotheses testing over models biochemical systems defined using ordinary differential equations The package available from http www dcs gla BioBayes The software based modular architecture and allows plugging third party methods and extensions 
4604 en Factor models for QTL studies The recent availability large scale data sets profiling single nucleotide polymorphisms SNPs and gene expression across different human populations has directed much attention towards discovering patterns genetic variation and their association with gene regulation Two aspects the nature expression profiles make the identification and interpretation such associations difficult Firstly expect that variety environmental developmental and other factors influence gene expression which can obscure such associations Secondly the regulatory network linking genes makes difficult pinpoint causal relationships between SNPS and regulatory elements address the first issue proposing eQTL factor model that explicitly takes non genetic variability into account and thereby can significantly improve the power expression Quantitative Trait Loci eQTL study discuss variational Bayesian implementation this model and point out rapid approximations that are applicable certain situations Applying our model simulated and real world data can demonstrate significant improvement performance data from the HapMap project find more than three times many significant associations than standard eQTL method address expression genes further extended eQTL jointly reducing the dimensionality the pression profile and modelling non genetic factors discuss results applying this enhanced QTL model biological data including human well datasets from yeast 
4605 en Probabilistic multi class multi kernel learning protein fold recognition and remote homology detection The problems protein fold recognition and remote homology detection have recently attracted great deal interest they represent challenging multi feature multi class problems for which modern pattern recognition methods achieve only modest levels performance with many pattern recognition problems there are multiple feature spaces groups attributes available such global characteristics like the amino acid composition predicted secondary structure hydrophobicity van der Waals volume polarity polarizability well attributes derived from local sequence alignment such the Smith Waterman scores This raises the need for classification method that able assess the contribution these potentially heterogeneous object descriptors while utilizing such information improve predictive performance that end offer single multi class kernel machine that informatively combines the available feature groups and demonstrated this paper able provide the state the art performance accuracy the fold recognition problem Furthermore the proposed approach provides some insight assessing the significance recently introduced protein features and string kernels The proposed method well founded within Bayesian hierarchical framework and variational Bayes approximation derived which allows for efficient CPU processing times Results The best performance which report the SCOP PDB 40D benchmark data set accuracy combining all the available feature groups from global protein characteristics but also including sequence alignment features offer improvement the best reported performance that combines binary SVM classifiers while the same time reducing computational costs and assessing the predictive power the various available features Furthermore examine the performance our methodology the SCOP benchmark data set that simulates remote homology detection and examine the combination various state the art string kernels that have recently been proposed 
4606 en Predicting anti cancer molecule activity using machine learning algorithms this paper study the anti cancer activity 000 unique compounds against set cell lines Leukemia Prostate Breast Small molecules play important role biology they can used building blocks for more complex molecules and also interact with proteins inhibiting promoting their action this case the consequence adding such compound cell can far reaching the protein may involved very complex chain reaction such possible design small molecules which can useful drugs Here concentrate only predicting property given molecule whether will show anti cancer activity measured causing least cell growing inhibition against given cancerous cell line This computational prediction important there are growing number small molecules databases worldwide and the capacity for proper lab testing limited For instance the Vitro Cell Line Screening Project the National Cancer Institute NCI can currently evaluate only 3000 compounds per year for potential anti cancer activity From machine learning perspective biological problems are good application because datasets are abundant the data real the type algorithms most suitable for particular problem may vary substantial and not unusual for problem highlight research needs machine learning Finally helping solve biological problems may have big impact the wider scientific community The molecule dataset used publicly available the NCI site applied range data mining classification algorithms this problem Decision Trees Inductive Logic Programming and Support Vector Machines SVMs molecular features used for the learning have used molecular weight octanol water partition coefficient logp and fragment counts fragment set connected atoms where each atom fragment simply identified its type carbon look the molecule graph the fragment list consists all connected components with diameter two The experiments demonstrate that our results using support vector machines with RBF kernel are identical previous published state the art work yielding average predictive accuracy having the baseline noticed however our surprise that instead using fragment counts use only atom counts the results are nearly identical about less accuracy although the diference statistical significant important point that must made that although numerical black box algorithms like SVMs tend slightly more accurate than logic models Decision Trees and ILPs this dataset have accuracy below SVMs arguable the relevance this predictive accuracy for important practical applications like drug design drug design setting what useful have set rules that describe what good compound should look like That goal much easily achieved with human readable logic model like the ones also describe the paper 
4617 en EURIDICE European Inter Disciplinary Research Intelligent Cargo for Efficient Safe and Environment friendly Logistics
4644 en Introduction the MIT course The goal introduce the students for the first time physics that say calculus based physics Many students have had that high school and many have not and the first course physics covers not only Newtonian mechanics that the heart the course 
4645 en Lecture Powers Ten Units Dimensions Measurements Uncertainties Dimensional Analysis Scaling Arguments Fundamental Units nnThe fundamental units are length time and mass Powers Ten The Powers Ten © Charles amp Ray Eames and Pyramid Media movie covering orders magnitude has been removed from the video for reasons copyright Dimensions nnDimensions are denoted with brackets some examples are given The Art Making Measurements nnA measurement meaningless without knowledge its uncertainty The lengths aluminum rod and the length student are both measured standing straight and lying down horizontally test whether the student length larger when lying down than when standing straight Within the uncertainty the measurements the difference between standing and lying substantial for the student NOT for the aluminum rod Was Galileo Galilei Reasoning Correct nnWhy are mammals large they are and not much larger The argument suggests that they become too heavy the bones will shatter Galileo Galilei suggested that material properties our bones impose natural limit the size things Professor Lewin brings this test presenting Galilei scaling arguments and compares them with actual measurements Dimensional Analysis nnThe dimensions both sides the equation must the same this non negotiable physics Using this idea Professor Lewin reasons that the time for object fall from certain height independent its mass and proportional the square root the height from which dropped confirms this conclusion dropping apple from 000 and 500 with uncertainty each then shows why his prediction was cheat 
4646 en Lecture Kinematics Speed Velocity Acceleration Introduction Dimensional Motion nnProfessor Lewin describes motion particle talks about average velocity the importance and signs and our free choice origin Average Speed Average Velocity nnThe two are VERY different The average velocity can ZERO while the average speed LARGE Instantaneous Velocity nnConsidering the incremental change position with time arrive The instantaneous velocity the derivative the position with respect time Professor Lewin reviews when the velocity zero positive and negative distinguishes speed from velocity Measuring the Average Speed Bullet nnProfessor Lewin shoots bullet through two wires The average speed can calculated from the distance between the wires and the elapsed time All uncertainties the measurements are discussed they have taken into account the final answer Introducing Average Acceleration nnThe average acceleration between time and the vectorial change velocity divided Instantaneous Acceleration nnThe acceleration the derivative the velocity with time the second derivative the position with time Professor Lewin shows how find the sign the acceleration from the slope plot Quadratic Equation Position Time nnWhen the position proportional the square the time the velocity depends linearly time and the acceleration constant Motion with Constant Acceleration nnProfessor Lewin writes down general quadratic equation for the position function time and relates the constants this equation the initial conditions time The gravitational acceleration constant Boston and independent the mass and shape free falling object air drag can ignored see Lecture You can use this result measure using the free fall time measurements from the falling apples lecture Strobing Object Free Fall Professor Lewin drops apple from and takes polaroid picture the falling apple which illuminated strobe light First two light flashes per second and then ten flashes per second 
4647 en Lecture Vectors Dot Products Cross Products Kinematics Vectors Direction Distinguishes Vectors from Scalars Decomposition Vector nnA vector can projected onto three coordinate axes along which lie unit vectors denoted with roofs Professor Lewin works example Scalar Product nnThe dot product two vectors scalar scalar can positive negative zero and use later the course calculate work and energy Professor Lewin calculates dot couple examples Vector Product nnThe cross product also called vector product two vectors results vector Professor Lewin presents two methods for calculating cross product the vectors and always perpendicular both and The direction easily found using the right hand corkscrew rule use cross products calculate torques and angular momentum later the course Always use Right Handed coordinate systems hat cross hat gives hat you don you get into trouble for which you will have pay dearly Decomposition Vectors and nnProfessor Lewin writes the equations for position velocity and acceleration showing their projection onto the axes and introduces shorthand notation for time derivatives motion can reduced three motions which can greatly simplify matters Projectile Motion the Vertical Plane nnProfessor Lewin throws object and decomposes its initial velocity into horizontal and vertical direction air drag can ignored the horizontal velocity remains constant Gravitational acceleration only the vertical direction and not affected the horizontal motion This acceleration constant the lecture hall air drag can ignored see Lecture 
4648 en Lecture Kinematics Free Falling Reference Frames Shape the Projectile Trajectory nnProfessor Lewin reviews the equations for projectile motion showing that the trajectory parabola derives formulas for the highest point maximum height the time reach the highest point the time flight until impact and the horizontal distance traveled For given initial speed speed scalar velocity vector object thrown degrees from the vertical will the farthest How Measure the Initial Speed nnAn object shot upwards from gun like device measuring the height that reaches can find the initial speed Uncertainties the results are discussed and are taken into account the demonstrations that follow Shoot Ball for Maximum Horizontal Distance nnThe ball shot angle degrees from the vertical the uncertainty the angle estimated about degree Professor Lewin predicts where the ball will hit the long desk the lecture hall takes into account the uncertainty the initial speed the ball and the degree uncertainty the angle marks the locations between which the ball should hit then shoots the ball and indeed lands predicted Shoot Ball and Degrees nnFor given initial speed the horizontal range the same for angles and degrees from the vertical but the ball travels higher for degrees which these trajectories takes the longest Professor Lewin sets the angle degrees and predicts where the ball will hit takes the uncertainties into account The ball lands predicted Shoot Ball Monkey Doll nnSomeone shoots ball and aims straight monkey who hanging tree Gravitational acceleration curves the ball trajectory substantially and there danger that the monkey will get hit However tragically the monkey sees the light flash the gun and lets falls the ground and the ball hits the monkey independent the initial speed the ball provided the speed high enough reach the tree Reference Frame the Falling Monkey nnBoth the monkey and the ball are falling with the same gravitational acceleration From the monkey point view its reference frame the ball coming straight curved trajectory Professor Lewin Dressed Safari Outfit Fires the Gun 
4649 en Lecture Circular Motion Centrifuges Moving Reference Frames Perceived Gravity Uniform Circular Motion and Centripetal Acceleration nnA particle travels circle radius with constant speed The period one rotation sec the frequency the number rotations sec omega the angular velocity radians sec omega 2pi the speed omega The velocity vector constantly changing direction because the centripetal acceleration omega The centripetal acceleration for the rotor vacuum cleaner estimated about 400 sec which times larger than Note that the centripetal acceleration depends linearly the radius There Must Pull Push nnSitting chair bolted fast rotating turntable you feel push your back Alternatively you stand the turntable and you hold onto post mounted the table you will experience pull your arms This pull push responsible for the change velocity centripetal acceleration What Happens there Pull Push nnYour velocity will not change Thus you move along straight line with constant speed Motion Planets around the Sun nnThe gravitational pull provides the centripetal acceleration which inversely proportional the distance squared Swirling Objects Around nnThe idea behind centrifuge and salad spinners Creating Artificial Gravity via Rotation nnProfessor Lewin gives several examples perceived gravity space station could rotate such that astronaut perceives Earth like acceleration However the direction will changing all the time Centrifuge Action nnA glass tube filled with liquid solution with fine particles spun around standard laboratory centrifuge The acceleration about 000 Thus the particles perceive gravitational force about 2000 times larger than normal and they fall the direction this huge gravitational field Professor Lewin demonstrates this mixing NaCl AgNO NaNO AgCl this produces milky solution After spinning for few minutes the AgCl has precipitated the end the glass tube and the remaining solution has become clear Swinging Bucket Water String nnIn order swirl bucket around vertical plane centripetal acceleration required you spin fast enough the water will stay the bucket the bucket upside down the safe side bring umbrella class 
4650 en Lecture Newton Laws Newton First Law and Inertial Reference Frames nnGalilei law inertia and Newton First Law are valid only inertial reference frames those are reference frames which are not accelerating Newton Second Law nnThe pull from extended spring acting object certain mass attached the spring can quantitatively expressed the vector relationship the force the mass and the acceleration This law like Newton First ONLY valid inertial reference frame Superposition Forces and Net Force nnThe gravitational force acting mass Earth mass held your hand doesn accelerate therefore the net force must zero and thus your hand exerting upward force equal Newton Third Law Action —Reaction nnThe contact force between two objects can described pair forces equal magnitude but opposite direction Every day examples are described such snaking garden hose releasing air from balloon jet action and the recoil gun Professor Lewin shows demonstration with Hero engine Consequences Newton Third Law nnWhile apple falling towards the Earth the Earth falling moving towards the apple Decomposing Forces and Directions nnHang object mass from two strings each with negligible mass The net force the object zero The sum the tension vectors the strings must equal pointing vertically Bizarre Demo with Block and Strings nnTwo identical strings one suspending mass the other string suspending from the mass Which one breaks when you pull the lower string the upper string the lower string Professor Lewin pulls fast one 
4651 en Lecture Weight Perceived Gravity Weightlessness Free Fall Zero Gravity Orbit misnomer What Weight nnWeight the force exerted you bathroom scale Your weight increases when you are elevator which accelerated upward you weigh less than your normal weight when the elevator accelerating downward and your weight zero when the elevator free fall When you hang from rope your weight indicated the tension the rope Tension Massless String nnConsider string negligible mass suspending two objects with different mass either side frictionless pin The tension this string everywhere the same because the string massless and the pin frictionless The masses the two objects are NOT equal but the weight the two objects THE SAME Weight when Swinging around String nnAn object swirled around string vertical plane The tension the string evaluated when the object the top and when the bottom its circular trajectory The tension the bottom always higher than the normal weight the object but the tension can zero when the object the top which case the object weightless Objects Free Fall are Weightless nnExploring the weight tennis ball being tossed the air and bottle water Professor Lewin hands when jumps off table The bottle and Lewin are free fall thus both are weightless Weight Measurements Free Falling Object nnBathroom scales have too slow response time indicate your zero weight when you weigh yourself while jumping off table Professor Dave Truemper has built scale with response time uses pressure gauges instead springs Professor Lewin places object the scale and see that the scale indicates this weight then tapes the object firmly the scale and drops the scale with the object from about meters The weight the object zero during free fall Professor Young Zero Gravity Experiments nnNASA has sponsored zero gravity experiments study motion sickness These are zero weight environments not zero gravity created air planes which free fall for seconds The air plane KC135 trajectory discussed detail and one Professor Young video clips shown 
4652 en Lecture Friction Normal and Frictional Forces nnStarting with block rest horizontal surface Professor Lewin describes the normal force the maximum frictional force that must overcome budge the block and the coefficient static friction Once the block budged and begins slide you encounter smaller coefficient kinetic friction Measurements the Coefficient Static Friction nnConsider block rest inclined plane and increase the tilt until the block just starts slide measuring this tilt angle you can calculate the coefficient static friction The friction coefficient only depends the materials contact independent the mass sliding object and independent its surface area this rather non intuitive Another Way Measure Friction nnThe system consists block inclined plane The block counterbalanced second mass connected the block with massless string and near massless frictionless pulley The direction the frictional force depends whether the block the incline wants move uphill downhill stay rest increasing the second mass until the block the incline budges uphill you can measure the coefficient static friction Ways Reduce Friction Fleas are Good for Something nnScenarios for reducing friction are presented including hydroplanes and air tracks Even flea can move very heavy book the friction near zero demonstrated 
4653 en Lecture Exam Review Scaling Arguments nnThe cross sectional area femurs should scale with mass mother nature were protecting the femurs large animals from crushing But that not the case The diameter femur scales with its length That protects the femurs against buckling sideways deformation Dot Products nnTwo methods are reviewed for obtaining the scalar product decomposition and projection Cross Products nnThe magnitude the cross product equals the product the magnitude the two vectors and the sine the angle between them The direction the vector product determined using the right hand corkscrew rule Kinematics nnA graphic example the position given and the velocity and acceleration are derived various points time The average velocity and average speed are calculated plot velocity time constructed Trajectories nnTrajectories lie plane they therefore reduce dimensional problems detailed example worked using the trajectory the zero gravity experiments the KC135 see Lecture Uniform Circular Motion nnThe parameters for uniform constant speed circular motion are reviewed including the equations for angular velocity and centripetal acceleration The numerical example worked out NASA centrifuge test astronauts the centripetal acceleration about 10g Brain Teaser with Yardstick nnProfessor Lewin slides his fingers underneath yardstick towards the center Something strange happens the fingers seem take turns moving they alternate sliding and stopping Can you explain this 
4654 en Lecture Hooke Law Springs Simple Harmonic Motion Pendulum Small Angle Approximation Restoring Force Spring nnThe restoring force spring described Hooke Law introduced Professor Lewin discusses how measure the spring constant and gives brief demonstration Dynamic Equations Displaced Spring nnA differential equation derived for spring the absence damping forces Using springs spray paint and moving target sketch created suggesting sine cosine dependence time The angular frequency and therefore the period shown depend only and you can measure dynamically The amplitude and phase depend initial conditions the displacement and velocity example worked out demonstrate this Measuring the Period Spring System nnThe period oscillation measured for mass spring system air track minimize friction measurement made periods reduce the relative error Professor Lewin demonstrates that the period independent the amplitude The mass doubled the new period predicted and then empirically confirmed Dynamic Equations Pendulum nnA pair differential equations derived for mass suspended near massless string length The small angle approximation quantitatively justified and applied arrive simple differential equation analogous that for spring The period oscillation shown proportional the square root independent Comparing the Spring and Pendulum Periods nnIntuitive insights are presented why the period oscillating spring depends the mass attached the spring and the spring constant Yet the period pendulum independent the mass hanging from the string These insights are reinforced with several experiments with very long pendulum The uncertainties the measurements are taken into account demonstrate that the period independent the mass the bob Professor Lewin places himself the end the meter long cable and measures the period 
4655 en Lecture Work Kinetic Energy Potential Energy Conservative Forces Conservation Mechanical Energy Newton Law Universal Gravitation Work and Kinetic Energy nnThe equation for work and its units are introduced The work energy theorem derived showing that the change kinetic energy equals the work done particle the sum all forces thus the net force Gravity does negative work object thrown upwards until reaches its maximum height its trajectory Work Calculated Dimensions nnWork shown decompose into the sum each component Gravity Conservative Force nnWork done gravity while particle moves upwards vertical distance mgh regardless the path taken When the work done force independent the path that force called conservative force When Gravity the only Force nnThe equation for gravitational potential energy introduced rearranging the work energy theorem Potential energy and kinetic energy can converted back and forth but their sum the mechanical energy conserved only conservative forces are involved Friction not conservative force When friction stake the work energy theorem can applied but mechanical energy not conserved What Matters the Difference Potential Energy nnGravitational potential energy can positive negative zero depending your choice origin really doesn matter where you choose the origin Roller Coaster Upside down nnThe conservation mechanical energy used analyze the velocity object roller coaster The centripetal acceleration when the roller coaster upside down must greater than the mechanical energy must therefore exceed threshold value Newton Law Universal Gravitation nnNewton law universal gravitation introduced The gravitational force falls off one over the distance squared large distances are involved the gravitational potential due object mass taken zero infinity The gravitational potential proportional and inversely proportional the distance from This formalism consistent with the small distance approximation used near the Earth surface Conservation Mechanical Energy and Wrecking Ball nnA wrecking ball converting gravitational potential energy into kinetic energy and back and forth released with zero speed the wrecking ball should NOT swing higher than its height when was released Professor Lewin puts his life the line demonstrating this 
4656 en Lecture Non Conservative Forces Resistive Forces Air Drag Terminal Velocity Resistive and Drag Forces nnResistive forces have viscous term that linear velocity temperature sensitive and reflects the stickiness the medium addition they have pressure term that proportional the speed squared and the fluid density Resistive forces are always the direction opposite the velocity The resistive force grows the speed increases Therefore falling object air liquid will reach terminal velocity Two Regimes and the Critical Velocity nnThe drag resistive force has two terms the viscous and pressure terms They are equal magnitude critical speed speeds much smaller than this the terminal speed for spherical objects all with the same density increases the radius squared the objects speeds much larger than the critical speed the pressure term dominates and the terminal velocity increases the square root the radius Measurements with Steel Balls Syrup nnSmall ball bearings are dropped Karo Corn Syrup Professor Lewin explains why the terminal velocity the ball bearings will vary with the radius squared conducts measurements validate this Reaching Terminal Velocity the Blink Eye nnWhen the ball bearings are dropped the syrup their speeds first increase shown that they reach their terminal velocity very fast Air Drag and the Pressure Term nnThe air drag almost all objects that fall air from considerable height raindrops sky divers dominated the pressure term Thus the terminal speed increases with the square root the radius spheres with given density you want calculate the time takes reach this terminal speed you have include both the and squared terms Lewin graduate student Dave Pooley solved the equation numerically and measurement made with balloon filled with air that dropped from height about meter Numerical Calculations Air Drag Examples nnA pebble dropped from height 475 meters the Empire State Building reaches terminal speed about miles per hour seconds Professor Lewin also discusses the contribution air drag the quantitative experiments done earlier the course with falling apples Resistive Forces and Trajectories nnAir drag will result asymmetric trajectory for object thrown the air The resistive force about the same for tennis ball for styrofoam ball the same radius but the resistive force has much more dramatic effect the lighter ball trajectory 
4657 en Lecture Potential Energy Energy Considerations Derive Simple Harmonic Motion Gravitational Potential Energy nnA review given the spatial dependence the gravitational potential energy both close the Earth surface and large distances from Earth The gravitational force pulls objects the direction decreasing potential energy Calculating from and Vice Versa nnThe potential energy spring system derived and sketched function displacement The force can derived the function known Equilibrium Points nnThe minima and maxima potential energy are positions where the net force zero the stable equilibrium points the 2nd derivative positive the unstable equilibrium points the 2nd derivative negative Parabolic Potential Energy Well SHO nnUsing the parabolic shape the potential energy for spring and the conservation mechanical energy shown that the mass the spring oscillates simple harmonic oscillator SHO Circular Potential Energy Well SHO nnUsing circular potential energy well and the conservation mechanical energy shown that for SMALL ANGLES the oscillations are simple harmonic circular track with very large radius used demonstrate this Sliding Circular Track SHO nnThe known radius circular air track used predict the period oscillation sliding object small angles and measurement made confirm this The process repeated for ball bearing rolling another circular track The period oscillation can now not predicted similar way was possible the case the air track Why has nothing with friction 
4658 en Lecture Escape Velocities Bound and Unbound Orbits Circular Orbits Various Forms Energy Power Escape Velocity nnThe escape velocity the minimum speed required escape the gravitational pull You can calculate using the conservation mechanical energy Circular Orbits nnThe gravitational force provides the centripetal acceleration required for orbiting satellites you know the radius circular orbit satellite around the Earth you can calculate the orbital speed and the orbital period Examples are worked for both the shuttle and the moon around the Earth and for the Earth around the sun The orbital period independent the mass the orbiting object Power nnPower the rate which force does work object Instantaneous power the time derivative work Power the dot product the force acting object and the velocity that object Power scalar can positive negative zero force diagram for bicycle rider discussed The required power delivered the rider scales with the third power the speed Heat and Various Forms Energy nnHeat energy calories and specific heat are discussed Joule experimental apparatus for converting mechanical energy into heat energy described Several sources heat are mentioned including body heat The energy heat bath water calculated Conversion energy from one form another discussed and student asked convert mechanical power electrical power How long will last Energy Conversion nnBatteries convert chemical energy electricity make shift battery constructed sulfuric acid with copper and zinc electrodes briefly light lamp Global Energy Consumption and Sources nnThe has about the world population but accounts for the global energy consumption Harvesting solar radiation numerically considered Nuclear power discussed and the public sentiment have Energy Crisis Fossil fuels could depleted within 100 years Nuclear fusion being explored The presence radioactive uranium Fiestaware glaze demonstrated Professor Lewin has large Fiestaware collection 
4659 en Lecture Momentum Conservation Momentum Center Mass Conservation Momentum nnThe momentum vector internal forces external forces and the conservation momentum are discussed Kinetic Energy and Momentum for Collision nnConservation momentum used calculate the final velocity pair masses that collide and stick together this called completely inelastic collision shown that kinetic energy then always lost but momentum conserved Energy and Momentum for Car Collision nnThe impact time short that the work done the frictional force from the road exerted the cars during the impact can ignored Internal frictional forces between the cars will merge the wrecks into one mass momentum diagram sketched This completely inelastic collision compare the moment just before and just after the collision kinetic energy lost but momentum conserved Scenarios that Increase the Kinetic Energy nnWhen there bomb explosion the momentum and kinetic energy are zero before the explosion Thus the total momentum must remain zero but the kinetic energy clearly increases after the explosion Professor Lewin does some air track experiments where the released energy from compressed spring kinetic energy increases but momentum conserved Center Mass System nnThe definition the center mass described The center mass behaves all the matter were together that point The center mass system objects moves with constant speed along straight line the absence external forces the system internal forces between the objects are allowed the objects can collide example worked calculating the position vector for the center mass for system three masses air track demonstration shows the center mass oscillating system objects moving constant velocity The center mass tennis racket follows parabolic trajectory while tumbles through the air 
4660 en Lecture Collisions Elastic and Inelastic Center Mass Frame Reference Elastic Collisions nnA mass with given speed collides with second mass initially rest one dimensional collision Momentum conserved kinetic energy also conserved the velocities both objects after the collision can calculated Three limiting cases are explored analytically and then demonstrated The equations are used predict the outcome some air track experiments Brain Teaser Elastic Collision with Wall nnA tennis ball bounces off wall elastically The momentum the wall changes but the kinetic energy the wall remains zero How that possible Something think about Center Mass Frame Reference nnA elastic collision considered seen from the frame reference where the total momentum zero Using the velocity the the Lab frame you can transfer between the two frames Inelastic Collision and Internal Energy nnA inelastic collision considered from the laboratory and the frame The kinetic energy calculated both frames and shown that the initial the frame the maximum that can converted heat this called the internal energy system The equations are used predict the results air track experiment Newton Cradle Demonstration nnProfessor Lewin solicits analytical proof his demo showing lineup colliding balls 
4661 en Lecture Impulse Rockets Ballistic Pendulum nnA massive pendulum absorbs bullet and the bullet momentum The kinetic energy which left over after this completely inelastic collision converted potential energy the pendulum The relationship between horizontal displacement the pendulum and bullet velocity derived and empirically observed The initial kinetic energy the bullet almost totally converted into heat Impulse and Impact Time nnImpulse the product force acting object and the brief time that acts This results abrupt change momentum For ball bouncing off the floor the impact time typically milliseconds movie shown demonstrate this Courtesy Peter Dourmashkin MIT Surprising Bounce Demo nnA tennis ball top much heavier basketball dropped from height about The tennis ball bounces way higher than Try calculate how high bounced assuming the basketball bounces off the floor elastically and then collides elastically with the tennis ball Thrust Rocket nnAn analogy drawn between the force felt the target tomato thrower the reaction force felt the thrower and the propulsion thrust rocket The Saturn rockets spewed out about tons sec speed sec relative the rocket provide thrust about million Newton The mass the rocket decreases substantially with time burns its fuel the rocket acceleration increases Fuel Consumption and Rocket Velocity nnConsuming given amount fuel translates into fixed change the rocket momentum not into fixed change the rocket kinetic energy 
4662 en Lecture Exam Review Work Energy Theorem nnThe conservation mechanical energy applies when there are only conservative forces The work energy theorem always applies also when non conservative forces such friction operate block inclined plane with friction analyzed solve for the coefficient static friction The work energy theorem shown provide elegant solution solving for the block velocity Bizarre Spinning Top Part nnA top spun the desk the lecture hall show that friction dissipates the top kinetic energy into heat the friction does negative work and the top quickly falls over Professor Lewin then spins the same top small magic black box The top does not fall over how bizarre Pendulum Work and Energy nnA pendulum problem discussed with set initial conditions The maximum angular swing the pendulum calculated using the initial conditions and the conservation mechanical energy The work energy theorem gives the same result Numerical results are obtained for both the maximum angular swing and the phase angle Bizarre Spinning Top Part nnFifteen minutes later the top still spinning How Earth this possible Spring SHO and Initial Conditions nnConservation mechanical energy used calculate the maximum displacement object attached spring for given initial conditions Newton Law Universal Gravitation nnThe orbital speed the Earth around the sun calculated The kinetic and potential energies the Earth are reviewed The escape velocity leave the solar system discussed Resistive Forces Viscous Term nnThis segment reviews concepts and measurements from lecture such the viscous and pressure drag terms the terminal velocity and the critical velocity Collisions and Conservation Momentum nnIn the absence net external force system momentum the system whole conserved even when objects the system collide and when kinetic energy destroyed rather non intuitive concept Bizarre Spinning Top Part III nnThe top has been spinning now for over minutes what going 
4663 en Lecture Rotating Rigid Bodies Moment Inertia Parallel Axis and Perpendicular Axis Theorem Rotational Kinetic Energy Fly Wheels Neutron Stars Pulsars Angular Acceleration Circular Motion nnAn object circular motion can experience tangential acceleration resulting change its speed Similarities between equations for linear motion and rotational motion are drawn Kinetic Energy Rotation Moments Inertia nnThe kinetic energy rotation disk derived and related its moment inertia and angular velocity The moment inertia depends upon the shape and mass object differs for different axes rotation Parallel Axis and Perpendicular Axis Theorems nnThe Parallel Axis theorem very useful for calculating the moment inertia about axis offset from the center mass The Perpendicular Axis theorem useful for thin objects Energy Management with Flywheels nnA scenario explored where the potential energy car coming down mountain stored flywheel while stepping the brakes rather than dissipated into heat The rotational kinetic energy the flywheel can principle later time used increase the car speed when needed demonstration shows how rotational energy flywheel gets converted into linear motion toy car Flywheels MIT Magnet Lab nnA pair very massive flywheels rotating are used convert rotational kinetic energy into magnetic energy and vice versa for energy storage Rotational Planets and Stars nnThe rotational kinetic energy the sun and Earth due their spin are presented along with data from the Crab pulsar The Crab pulsar with spin period spinning down its spin period increasing nanoseconds day The radiated power the form radio waves light rays and gamma rays results loss rotational kinetic energy other words rotational converted electromagnetic radiation Slides MIT Flywheel and the Crab Nebula nnSlides are shown the Flywheels MIT Magnet Lab and the Crab Nebula home the Crab Pulsar Stroboscopic pictures show that the Crab Pulsar blinks and off optical light rotates about its spin axis ray image the Crab Nebula made with the Chandra Observatory also shown 
4664 en Lecture Angular Momentum Torques Conservation Angular Momentum Spinning Neutron Stars Stellar Collapse Angular Momentum Particle nnAngular momentum defined relative origin whose position can freely chosen Angular momentum therefore not intrinsic property moving object depends the position the origin The angular momentum projectile motion explored The angular momentum changes along its trajectory The angular momentum the Earth orbit measured relative the sun position constant NOT constant measured relative any other origin Rate Change Angular Momentum nnTorque equals the time derivative the angular momentum The torque acting the Earth zero choose the sun our origin NOT zero relative any other origin Thus the orbital angular momentum the Earth sun origin constant Angular Momentum Rigid Bodies nnThe angular momentum disk rotating about its center mass proportional its moment inertia The angular momentum associated with rotational motion rigid body about stationary axis through the center mass called spin angular momentum Spin angular momentum intrinsic property spinning object independent the point origin chosen The Earth spins about axis through its center mass The total angular momentum the Earth with the sun the origin the vectorial sum the spin angular momentum and the orbital angular momentum Ice Skater Delight nnA person stands turntable with weights each hand this person can change her moment inertia moving the weights near and away from her body numerical example worked out showing that the moment inertia can easily change factor three and live demo given Angular momentum conserved the angular velocity increases when the weights are pulled Angular Momentum System and Stellar Spin nnThe angular momentum system objects can only changed external torques stellar collapse resulting neutron stars and black holes there conversion gravitational potential energy into kinetic energy heat the star collapses its moment inertia decreases dramatically but its spin angular momentum conserved solar size star with 100 day spin period collapses into neutron star its spin period will become about Supernova Explosions and Stellar Spin nnSlides and commentary cover Jocelyn Bell discovery radio pulsars first called LGMs for Little Green Men the mis alignment the magnetic dipole axis and the spin axis neutron star the Crab Nebula supernova remnant and other supernova observations 
4665 en Lecture Torques Oscillating Bodies Hoops Key Equations for Angular Momentum and Torque nnA review given equations for angular momentum and torque and the importance choosing the point origin These equations are exercised using example circular orbit the point origin placed the center the circle angular momentum conserved for any other point angular momentum not conserved Dynamics Spinning Rod nnTwo examples are analytically described rod spinning around off center pin and rod spinning around its center mass third example discussed great detail hit rod initially rest frictionless horizontal table The resulting motion can viewed linear motion with constant speed the center mass and rotational motion around the center mass The discussion concludes with demo ruler being struck various places horizontal surface though not frictionless Physical Pendulum nnA ruler suspended from pin offset from the ruler center mass form pendulum The equation motion derived analyzing the torque and moment inertia using the pin the point origin For small angles the motion simple harmonic This analysis also conducted for hoop suspended from pin When gravity the only restoring force the period such pendulum determined solely geometry and independent mass The predicted periods these pendulums are quantitatively confirmed demos Friction Kinetic Energy and Spinning Top nnRemember the bizarre top that kept spinning during lecture Maybe there was something hidden that black box completely new challenge now explain the bizarre behavior spinning blue plastic object which seems defy the laws physics Another brain teaser 
4667 en Lecture The Geometrical View Direction Fields Integral Curves
4668 en Lecture Euler Numerical Method for and its Generalizations
4669 en Lecture Solving First order Linear ODE Steady state and Transient Solutions
4670 en Lecture First order Substitution Methods Bernouilli and Homogeneous ODE 
4671 en Lecture First order Autonomous ODE Qualitative Methods Applications
4672 en Lecture Complex Numbers and Complex Exponentials
4673 en Lecture First order Linear with Constant Coefficients Behavior Solutions Use Complex Methods
4674 en Lecture Continuation Applications Temperature Mixing circuit Decay and Growth Models
4675 en Lecture Solving Second order Linear ODE with Constant Coefficients The Three Cases
4676 en Lecture Continuation Complex Characteristic Roots Undamped and Damped Oscillations
4677 en Lecture Theory General Second order Linear Homogeneous ODE Superposition Uniqueness Wronskians
4678 en Lecture Continuation General Theory for Inhomogeneous ODE Stability Criteria for the Constant coefficient ODE 
4679 en Lecture Finding Particular Sto Inhomogeneous ODE Operator and Solution Formulas Involving Ixponentials
4680 en Lecture Interpretation the Exceptional Case Resonance
4681 en Lecture Introduction Fourier Series Basic Formulas for Period 
4682 en Lecture Continuation More General Periods Even and Odd Functions Periodic Extension
4683 en Lecture Finding Particular Solutions via Fourier Series Resonant Terms Hearing Musical Sounds
4684 en Lecture Introduction the Laplace Transform Basic Formulas
4685 en Lecture Derivative Formulas Using the Laplace Transform Solve Linear ODE 
4686 en Lecture Convolution Formula Proof Connection with Laplace Transform Application Physical Problems
4687 en Lecture Using Laplace Transform Solve ODE with Discontinuous Inputs
4688 en Lecture Use with Impulse Inputs Dirac Delta Function Weight and Transfer Functions
4689 en Lecture Introduction First order Systems ODE Solution Elimination Geometric Interpretation System
4690 en Lecture Homogeneous Linear Systems with Constant Coefficients Solution via Matrix Eigenvalues Real and Distinct Case 
4691 en Lecture Continuation Repeated Real Eigenvalues Complex Eigenvalues
4692 en Lecture Sketching Solutions 2x2 Homogeneous Linear System with Constant Coefficients
4693 en Lecture Matrix Methods for Inhomogeneous Systems Theory Fundamental Matrix Variation Parameters
4694 en Lecture Matrix Exponentials Application Solving Systems
4695 en Lecture Decoupling Linear Systems with Constant Coefficients
4696 en Lecture Non linear Autonomous Systems Finding the Critical Points and Sketching Trajectories the Non linear Pendulum
4697 en Lecture Limit Cycles Existence and Non existence Criteria
4698 en Lecture Relation Between Non linear Systems and First order ODE Structural Stability System Borderline Sketching Cases Illustrations Using Volterra Equation and Principle
4699 en Lecture Kepler Laws Elliptical Orbits Satellites Change Orbits Ham Sandwich Kepler Laws and Elliptical Orbits nnA review equations for the period velocity and mechanical energy circular orbit given Kepler Laws and the planetary data that led him his third law are introduced The equations for elliptical orbits are discussed and compared with the equations for circular orbits Elliptical Orbit from Initial Conditions nnThe elliptical orbit follows from the initial conditions Using the conservation mechanical energy you can find the semimajor axis and this combination with Kepler 3rd law enables you calculate the orbital period numerical example for high eccentricity orbit Earth orbiting satellite worked out Using the conservation angular momentum one can determine the distances apogee and perigee and the satellite velocity apogee and perigee Changing from Circular Elliptical Orbits nnBy firing rocket board spacecraft that circular orbit the spacecraft velocity vector will change and this leads elliptical orbit and change orbital period The new elliptical orbits are sketched along with the original circular orbit setting the stage for how astronauts different spacecrafts can pass sandwich Astronauts Pass Ham Sandwich nnPeter and Mary are astronauts different spacecrafts but the same circular orbit Peter wants throw ham sandwich Mary The question how that There large family solutions which are discussed Simulations the Passing the Sandwich nnA computer model for finding solutions how astronauts Peter and Mary can pass sandwich introduced and exercised its author Dave Pooley GREAT FUN 
4700 en Lecture Doppler Effect Binary Stars Neutron Stars and Black Holes Doppler Shift with Sound Waves Circular Orbits nnThe received frequency changes the source sound moves towards away from observer This the Doppler Effect demonstrated Professor Lewin with tuning fork The fractional change frequency reveals the velocity component along your line sight the moving sound source the source sound circular motion and the observer somewhere the orbital plane you can determine the orbital radius and the speed the source its orbit This demonstrated with rotating wind organ Doppler Shift Electromagnetic Radiation nnElectromagnetic radiation travels the speed light vacuum source light has velocity component towards you the frequencies that you will observe will higher than those the emitted radiation and the received wavelengths will shorter blue shift than the emitted wavelengths the source receding from you the received wavelength longer red shift The spectroscopic Doppler shift used astronomers measure the radial velocity emitters and absorbers light Star Mass Determinations from Doppler Shift nnA binary star system consists pair stars orbiting about their center mass measuring the Doppler shifts both stars function time you can determine the orbital period the radial velocity each star and the observer located the orbital plane the orbital radii can found for both stars The orbital radii and Kepler third Law determine the total mass the system enabling the determination each star mass separately ray Binary Systems nnIn ray binary system there neutron star black hole pulling matter off its donor companion Matter spirals toward the neutron star and potential energy converted kinetic energy This coupled with the high mass transfer rate between the pair generates tremendous power and astronomical temperatures radiates mainly rays The accreting ionized matter gets funnelled onto hot spots the neutron star magnetic field which spins with the neutron star making ray pulsar Doppler shifts the pulsar period and ray eclipses can provide orbital parameters and masses for the stellar system Black Holes nnA black hole massive object with size but with characteristic surface called the event horizon from within which nothing can escape the black hole black hole binary systems the accreting matter radiates rays approaches the event horizon the black hole but the black hole has surface therefore does not exhibit pulsar like behavior You can measure the optical Doppler shift the donor star and from its spectrum estimate the donor mass This then leads the mass the accretor this mass excess about solar masses believed black hole Cygnus was the first such discovery 1972 Its black hole about solar masses 
4701 en Lecture Rolling Motion Gyroscopes VERY NON INTUITIVE Pure Roll Hollow and Solid Cylinders nnIn pure roll the object not skidding slipping and the speed the center mass equals the circumferential speed Professor Lewin derived equation for the acceleration object rolling down ramp under pure roll conditions For solid cylinders with uniform mass density this acceleration independent the mass and radius these cylinders this rather non intuitive However the acceleration higher for solid cylinder than for hollow cylinder This demonstrated Applying Torque Spinning Wheel nnWhen you apply torque fast spinning wheel moves the spin angular momentum the direction the torque torque vector This called precession This very non intuitive concept demonstrated with bicycle wheel Precession Flywheel nnThe bizarre behavior spinning flywheel that experiences torque due gravity explored Professor Lewin demonstrates this suspending the axle fast rotating bicycle wheel from rope increasing the torque the precession frequency increases The direction precession can reversed the direction rotation the bicycle wheel reversed You can also observe this very non intuitive behavior with toy gyroscope Mysterious Suitcase nnA suitcase brought that requires special handling There fast rotating flywheel inside student volunteers carry the suitcase around The suitcase behaves weird manner the student turns around Gyroscope Gimbals nnA spinning object coin edge more stable against falling over than when isn spinning This concept used mechanical inertial guidance systems where spinning wheel mounted gimbals prevent torques the axis the wheel Professor Lewin walks through the lecture hall with such axis gimballed gyroscope The direction the axis rotation the spinning flywheel does not change moves around 
4702 en Lecture Static Equilibrium Stability Rope Walker Rotation Translation nnThe analogy between rotational and translational equations summarized Stability Ladder nnA ladder leaning against the wall analyzed determine the minimum angle can make with the floor without sliding The ladder then set this critical angle and the stability investigated someone climbs the ladder Rope Tension Reduced Friction nnSailors often wind rope around cylinder reduce the tension that needs applied hold object place The tension reduced friction along the wrapped portion the rope You can use this device balance strong force Professor Lewin has constructed device that demonstrates this very dramatic way Locating the Center Mass Rigid Body nnThe center mass always lines below the point suspension such that the net torque relative the suspension point zero When the center mass positioned below the point suspension the system stable Stability Rope Walker nnThe stability rope walker improved lowering her center mass below the rope the walker also wears special shoes that she can slide sideways off the rope she cannot fall 
4703 en Lecture Elasticity Young Modulus Elasticity Materials nnA relationship between stress strain and Young Modulus introduced analogy with springs The properties various metals are compared and the stress strain curve described Measuring Stress Strain nnAn apparatus for measuring very small elongations wire under stress described set measurements are made construct the stress strain curve for copper wire From these both Young modulus and the ultimate tensile strength can calculated Spring Constant Wire nnAt low stress values where the stress strain curve linear one can generate simple harmonic oscillations the vertical direction hanging object from wire Speed Sound Materials nnThe speed sound material depends the stiffness Young modulus and density the material The speed sound and length rod determine the roundtrip time pressure disturbance introduced one end From this follows the fundamental frequency which rod resonates Demo with Block and Two Strings nnA block suspended from one string and identical string suspended from the block Professor Lewin pulls the lower string Which string will break first the upper one the lower one The lower string will break first the force impulsive quick jerk because will elongate faster than the upper string pull slowly the upper string will break first its tension will then always exceed that the lower string 
4704 en Lecture Fluid Mechanics Pascal Principle Hydrostatics Atmospheric Pressure Over Pressure Lungs and Tires Pressure and Pascal Principle nnPressure scalar Pascal Principle explained hydraulic jacks small force applied move large mass small distance Gravity and Hydrostatic Pressure nnBecause gravity pressure increases with depth fluid This called hydrostatic pressure Compressibility Gases Liquids nnUnlike liquids gases are compressible they cushion impacts Liquids not act like cushions This demonstrated very dramatic way firing bullet sealed can filled with air and one filled the brim with liquid Pressure Difference and Column Liquid nnThe pressure difference between the bottom and top vessel liquid depends only the height and density the liquid not the area weight the column This rather non intuitive Atmospheric Barometric Pressure nnThe pressure sea level due the air above determines the atmospheric barometric pressure can measured raising sucking column liquid from open reservoir with tube sealed the end where pump the air out For every meters depth water the hydrostatic pressure increases about one atmosphere Submarines and Overpressure nnCornelis Drebbel credited with inventing the first submarine operating depth meters this depth the hydrostatic pressure about half atmosphere sealed paint can was evacuated demonstrate the enormous forces acting upon with over pressure about one atmosphere The can imploded Overpressure our Lungs nnThe lung capacity our ability overcome hydrostatic pressure measured with manometer This related how deep snorkeling works and why scuba divers use pressurized air tanks Professor Lewin demonstrates that blowing manometer sucking can raise lower column water about meter atmosphere why then was able suck fluid straw several meters long 
4705 en Lecture Hydrostatics Archimedes Principle Fluid Dynamics What Makes Your Boat Float Bernoulli Equation Archimedes Principle nnThe buoyant force immersed body shown equal the weight the displaced fluid Archimedes Principle Such weight measurements can used determine the average density irregular objects and also estimate body fat people Floating Objects nnMost iceberg submerged because its density only little less than the density water Boats float rocks sink Professor Lewin poses another brain teaser Stability Floating Objects nnThe center mass floating object should below the center mass the displaced fluid for stability this important ship design concept Balloons nnThe buoyant force air balloon discussed demonstrated how balloon and pendulum behave accelerated closed containers Fluid Dynamics Bernoulli Equation nnBernoulli equation presented the conservation energy for incompressible fluid flow For flow through pipe varying cross section Bernoulli equation shows that the pressure the lowest the smallest cross section where the velocity the fluid the highest Bernoulli equation also applied syphons Fluid Mechanic Magic nnSome non intuitive demos show how ping pong balls behave air streams 
4706 en Lecture Exam Review Review Collisions nnTwo masses moving one dimension collide completely inelastic manner The equations for elastic collision are also discussed Atwood Machine nnA massless rope runs without slipping over pulley the moment inertia the pulley not negligible The rope has pair masses hanging from The equations rotational pulley and translational the masses motion are related and solved for the acceleration the masses SHO Suspended Rod nnA pendulum consists ruler rod suspended from one end The equation motion derived The moment inertia determined using the parallel axis theorem Rotational kinetic energy also discussed For small angles the motion that simple harmonic oscillator Conservation Laws for Satellite Orbit nnA satellite launched from planet Using the conservation angular momentum and mechanical energy and the maximum distance between the planet and satellite one can calculate the launch velocity and other orbital parameters Doppler Shift Review nnIf stars are receding from the starlight that observe red shifted the observed wavelengths are longer than those emitted the star The Doppler shift depends the component the velocity along the line sight called radial velocity somewhat similar equation applies sound received from moving sound sources However the case sound DOES matter whether the sound source moves whether the observer moves For light only the relative motion between source and observer matters Pure Roll nnThe acceleration cylinder and sphere derived under the condition pure roll sliding object accelerates faster down incline plane than rolling object The static friction coefficient must sufficient support pure roll Kinetic energy for rolling object has both translational and rotational term 
4707 en Lecture Simple Harmonic Oscillations Energy Considerations Torsional Pendulum SHO Physical Pendulum nnThe SHO equation motion small angle approximation for rigid body pendulum derived from the torque equation about the point suspension The periods oscillation are worked out for four different shapes rod hoop disk and for billiard ball hanging from massless string SHO Liquid Tube nnThe SHO equation motion for liquid sloshing shaped tube derived taking the time derivative the conservation mechanical energy The angular frequency and period are calculated and compared empirical data Torsional Pendulum nnThe SHO equation motion for torsional pendulum derived from the torque equation about the center mass The displacement angle the horizontal plane The restoring torque due the twisted wire small angle approximations are required The demo uses piano wire 
4708 en Lecture Forced Oscillations Normal Modes Resonance Natural Frequencies Musical Instruments Forced Oscillations nnWhen applying external sinusoidal force driving force spring system there will transient response addition steady state response When the transient response has died due friction the steady state remains Resonance responses are described Resonances and Normal Modes nnSystems coupled oscillators with multiple resonant frequencies are described including violin string Normal modes oscillating string occur integral multiples harmonics the fundamental these natural frequencies are determined the length the tension and the mass per unit length the string Resonance Wind Instruments nnAir pressure waves boxes cavities and hollow tubes exhibit series resonances determined the velocity sound air and the dimensions the systems The frequency these resonances can altered holes pistons change their effective size Professor Lewin demonstrates this with wooden flute and plays Jingle Bells wooden trombone Nonlinear Response Resonance nnExcitation with spectrum frequencies often reveals some resonant frequencies the object responds most strongly those frequencies Resonance can destructive the driving force strong enough dramatically shown with wine glass driven strong sound waves and the Tacoma Narrows bridge driven the wind Speed Sound Resonant Cavity nnEach person distinctive voice produced manner similar the way sounds are produced wind instruments these instruments were filled with helium instead air the frequencies the sound would very different the speed sound helium substantially larger than that air Professor Lewin inhales helium demonstrate this His familiar voice cannot recognized anymore 
4709 en Lecture Heat Thermal Expansion Heat and Temperature nnVarious temperature scales are discussed Celsius Fahrenheit Kelvin Linear Thermal Expansion nnThe linear thermal expansion coefficient introduced Expansion leads need for expansion joints railroad rails avoid bulging hot days Thermal expansion demonstrated heating and cooling brass rod important application thermal expansion metals which are used thermostats safety devices and thermometers demonstrated Cubical Thermal Expansion nnThe fractional change volume with temperature given the coefficient cubical expansion mercury thermometer discussed Shrink Fitting nnShrink fitting technique that makes use the thermal expansion heating one object two After the two objects are assembled they cool and the fit perfect and for ever Cubical Thermal Expansion Water nnWater has maximum density degrees Celsius between and degrees Celsius the cubic thermal expansion coefficient negative the water expands cools below degrees Celsius The density ice about lower than water ice cubes and icebergs float water 
4710 en Lecture Kinetic Gas Theory Ideal Gas Law Isothermal Atmosphere Phase Diagrams Phase Transitions Intro Ideal Gas Law and Avogadro Number nnLiquids are near incompressible but gases are not the density gases can increased with relative ease increasing the pressure but that not the case for liquids The ideal gas law introduced and explained good approximation for the compressibility most gases Avogadro number the number molecules mole and defined the number atoms grams carbon12 Ideal Gas Law Insights nnThe ideal gas law predicts that the volume mole gas for given temperature and pressure independent the molecular mass the gas The momentum transfer per second from the gas molecules the vessel walls proportional which reminiscent the kinetic energy the molecules This proportional the gas pressure two different gases have the same temperature the molecules must have the same average translational kinetic energy Thus the molecules with the lowest mass must have average the highest speed Ideal Gas Law Experimentally Applied nnA demonstration the ideal gas law uses pressure gauge that measures overpressure the pressure excess the atmospheric pressure The temperature fixed number air molecules fixed volume increased from melting ice temperature 273 pressure 1atm boiling water temperature 373 The resulting pressure increase measured Phase Diagrams and Phase Transitions nnIntroduction phase diagrams and phase transitions Taking gas constant temperature and using piston increase its pressure the gas volume decreases the pressure increases until you approach the gas liquid phase transition constant pressure one atmosphere but with increasing temperature you start with ice low temperature which becomes liquid water 273 and the water will boil 373 and will become water vapor gas above this temperature Fire Extinguisher nnA fire extinguisher filled with CO2 Given the dimensions the tank its volume room temperature 293 the mass CO2 the extinguisher from the label and the ideal gas law this law only valid there ONLY gas inside and liquid the pressure calculated inside the cylinder concluded that can just gas there must also liquid CO2 the fire extinguisher The phase diagram for C02 shows phase transition atm 293 the CO2 gas and liquid would exist thermal equilibrium room temperature and atm you tried further compress room temperature more gas would turn into liquid but the pressure would remain atm until all the gas had turned into liquid after which the pressure can increase Boiling Water Part nnIn Lecture there was discussion hydrostatic pressure the overpressure submarines must survive they deeper the water Conversely the atmospheric barometric pressure should decrease with increasing altitude but with different height dependence because air compressible its density changes with pressure differential equation solved determine that isothermal atmosphere the pressure decreases exponentially with altitude Consequently the boiling point water decreases with altitude demo water boiling room temperature but low pressure shown Boiling Water Part nnWhile waiting for the pressure the bell jar decrease Professor Lewin starts second demo boiling the water 373 and atm can the air the can gets displaced water vapor then seals the can and lets cool Inside the can liquid water and water vapor thermal equilibrium the can cools the vapor condenses into liquid and the pressure the can decreases the pressure the can should drop about about atm the can cools room temperature The can implodes due the external force the atmospheric pressure Meanwhile the water the bell jar boils room temperature third demo involves air filled balloons that shrink much more than naively predicted using the ideal gas law What going 
4711 en Lecture The Wonderful Quantum World Breakdown Classical Mechanics Discrete Energy Levels nnElectrons orbit their atomic nucleus well defined orbits corresponding discrete energy levels The electrons can jump from one energy level vacant energy level but they cannot exist between Transitions between these energy levels gives rise absorption and emission light discrete spectral lines wavelengths The students are encouraged look through their diffraction gratings helium and neon light sources see evidence these discrete wavelengths emitted light Particles and Waves nnQuantum mechanics introduces some very non intuitive concepts light behaves both particle photon and wave and particle behaves like wave with wavelength inversely proportional its momentum Interference wave phenomenon and indeed particles can interfere with each other Both the position and momentum particle cannot accurately specified the same time Heisenberg uncertainty principle Diffraction Slit nnDiffraction light narrow vertical slit well understood classical wave phenomenon consistent with Heisenberg uncertainty principle The narrower the slit the smaller the uncertainty the horizontal position the photons which have sneak through the narrow opening the greater the horizontal spread the transmitted protons uncertainty their momentum Quantum mechanics only allows you predict positions particles with certain probabilities the classical Newtonian world you can predict the position and movement particle any degree accuracy NOT the microscopic quantum world The Newtonian picture perfect for describing the behaviour basketballs and planets the macroscopic world 
4712 en Lecture Farewell Special High energy Astrophysics ray Astronomy from Balloon Flights nnProfessor Lewin takes back 1966 when Professor George Clark and pioneered ray observations from balloon borne telescopes altitudes 145 000 Slides High Altitude Ballooning Expeditions nnA series slides are shown the construction ray telescope the manufacturing the balloons and balloon launches both Alice Springs Australia and Palestine Texas The risks that arise during launch and during flight are shown are some interesting encounters during payload recovery ray Observations nnThe science gained from the balloon borne telescopes described such the first ever flaring event and the minute periodicity observed from previously unknown source now know hundreds binary star systems where gas from donor swirls onto neutron star the accretor The gas reaches the neutron star surface with about the speed light heats its surface few million degrees Kelvin which why the neutron star emits large amounts rays Binary Stars and ray Bursts nnProfessor Lewin reviews the Doppler shift the neutron star pulsar period and the donor star spectral lines ray binaries then talks about ray bursts These are thermonuclear flashes nuclear bomb explosions the surface neutron stars The rays from these flashes temporarily excite the matter the accretion disk resulting delayed optical flashes This delay provided the first measurement the size accretion disk 
4713 en TansSlo – Sustainable Transport Research
4719 en Practical experience with the application alternative tender procedures connection with maintenance regional and local road networks
4720 en  scientific approach research and innovation governance
4722 en Sustainable Pavements for New Member States
4723 en ARCHES gaze Central European highway structures
4724 en Central European Research TRAnsport INfrastructure
4725 en Arena – public private approach for development road user charging
4727 en Establishment road transport research needs Hungary
4728 en Evaluation materials for road upgrading
4729 en The Nordic Road and Transport Research Program enters its 5th year
4730 en Living lab part competitiveness model the automotive sector Slovenia
4733 en International cooperation Road Transport leading improved mobility safety security and prosperity
4734 en Sustainable viability transport systems Sub Saharan Africa which reforms 
4735 en Public transport service design requirements for the changing face the South African customer
4737 en Experimental Evaluation Various Biofuel Diesel Blends Diesel Engine Fuels
4738 en Measures abate green house gas emissions logistics companies
4739 en Air management for lowest emission passenger car diesel engines
4743 en Dynamic speed limits improve local air quality
4744 en ARTEMIS the new European tools for estimating different scales the pollutant emissions from road transport
4745 en Strategies for mitigating road pollution water bodies
4748 en Sustainable mobility for everybody complementary solutions for passenger and commercial transportation
4750 en Welcome MIT OpenCourseWare idea and ideal developed the MIT faculty who share the Institute mission advance knowledge and educate students science technology and other areas scholarship best serve the world 1999 the Faculty considered how use the Internet pursuit this goal and 2000 proposed OCW MIT published the first proof concept site 2002 containing courses November 2007 MIT completed the initial publication virtually the entire curriculum over 800 courses academic disciplines Going forward the OCW team updating existing courses and adding new content and services the site 
4751 en Unlocking Knowledge Empowering Minds December reported the great news that MIT’ Open CourseWare initiative had released their 800th course thereby publishing the entire MIT curriculum OCW MIT has now released comprehensive video recordings the celebratory event all published under Creative Commons Attribution Noncommercial Share Alike license The keynote address was given New York Times columnist Thomas Friedman 
4752 en The World Flat Thomas Friedman author and columnist for the New York Times gave the keynote presentation MIT’ recent event celebration reaching 1800 published OCW courses The speech was insightful and timely but also very well delivered nnThe World Flat Thomas Friedman account the great changes taking place our time lightning swift advances technology and communications put people all over the globe touch never before creating explosion wealth India and China andnchallenging the rest run even faster just stay place nnThe World Flat essential update globalization its opportunities for individual empowerment its achievements lifting millions out poverty and its drawbacks environmental social and political powerfully illuminated the Pulitzer Prize winning author The Lexus and the Olive Tree nnn
4753 en The Future OCW and Education MIT OpenCourseWare continues attract global audience educators students and self learners Nearlynhalf all educators visiting the site have incorporated OCW content into their own teaching materials Students use the site both supplement materials from courses they are taking and study beyond the bounds their formal course study 
4754 en Highlights for High School Announcement MIT President Susan Hockfield announces the launch new web site Highlights for High School that will provide resources improve science technology engineering and math STEM instruction the high school level nnThe web site builds the success MIT revolutionary OpenCourseWare initiative and designed inspire the next generation engineers and scientists and valuable tool for high school teachers 
4755 en Highlights for High School Highlights for High School your guide MIT courses selected specifically help you prepare for exams learn more about the skills and concepts you learned school and get glimpse what you soon study college 
4757 en Interview with Walter Lewin Many the Walter Lewin Lectures Physics MIT have been shown for over six years UWTV Seattle reaching audience about four million people Lewin personally responded hundreds mail requests that received per year from UWTV viewers For fifteen years was MIT Cable with programs aired hours per day helping freshmen with their weekly homework assignments Lewin also teaches video courses Newtonian Mechanics Electricity and Magnetism and Vibrations and Waves which can viewed from the MIT OpenCourseWare web site His MIT lectures for science teachers and for middle school students can viewed MIT World Various lecturers all around the world make use these lectures teach their students 
4758 en Promotional Video Professor Lewin international webstar well known MIT and beyond for his dynamic inspiring and engaging lecture style His courses are also among the most downloaded iTunes Physics Classical Mechanics explains the basic concepts Newtonian mechanics fluid mechanics and kinetic gas theory and variety interesting topics such binary stars neutron stars and black holes nnLewin demonstrations make difficult concepts easier understand Stanley doctor the says had this information presented 1962 while pursuing medical career was never clearly presented was the witty genius Please thank Professor Lewin from old student and tell him that has truly presented the beauty physics nnWatch some Walter Lewin greatest moments see more check out Professor Lewin classes http ocw mit edu MIT OpenCourseWare 
4759 en Online Learning Regret Minimization and Game Theory The first part tha tutorial will discuss adaptive algorithms for making decisions uncertain environments what route should take work have decide before know what traffic will like today and connections central concepts game theory what can say about how traffic will behave overall everyone adapting their behavior such way will discuss the notions external and internal regret algorithms for combining expert advice and sleeping experts problems algorithms for implicitly specified problems and connections game theoretic notions Nash and correlated equilibria The second part tha tutorial will about some recent work learning with similarity functions that are not necessarily legal kernels The high level question here you have measure similarity between data points how closely related does have your classification problem order useful for learning 
4760 en Machine Learning Laboratory The first laboratory has not been recorded but has featured some hands experiments with Elefant http elefant developer nicta com mainly concentrating installing using and developing machine learning algorithms within the Elefant framework will walk through examples implementing simple stochastic gradient descent algorithm part this tutorial This the first part the second session which split with mlss08au vishwanathan mll Vishwanathan title and will feature hands experiments with BNRM Bundle Methods for Regularized Risk Minimization http users rsise anu edu chteo BMRM html The emphasis here will developing various loss function modules which can then plugged into the BMRM solver 
4761 en Machine Learning Laboratory The first laboratory has not been recorded but has featured some hands experiments with Elefant http elefant developer nicta com mainly concentrating installing using and developing machine learning algorithms within the Elefant framework will walk through examples implementing simple stochastic gradient descent algorithm part this tutorial This the second part the second session which split with mlss08au webers mll Christfried Webers title and will feature hands experiments with BNRM Bundle Methods for Regularized Risk Minimization http users rsise anu edu chteo BMRM html The emphasis here will developing various loss function modules which can then plugged into the BMRM solver 
4764 en Magnetic quantum oscillations metals and metallic nanowires Quantum oscillations magnetization and resistivity with the magnetic field are great experimental and theoretical value providing reliable and detailed Fermi surfaces Specifically interest the oscillations almost two dimensional Fermi liquids has recently gone through vigorous revival due experimental discoveries magneto oscillations few high temperature cuprate superconductors Another interesting application the quantum oscillation the field quasi one dimensional nanowires talk review experimental outcome Haas van Alphen and Shubnikov Haas effects and theoretical results obtained our group 
4766 en Research Challenges Enterprise Information Retrieval Information Retrieval major component Knowledge Management systems every business but most the research that being done today focuses the Web and not the needs and challenges businesses This primarily due the availability data the Web for academic researchers well familiarity with the problems Web since all are consumers and can relate the domain contrast for Enterprise Information Retrieval the data not available most researchers and the challenges and needs are not obvious people who are not everyday users such systems this talk will point out some challenges this domain pose open research questions for the Information Retrieval NLP Machine Learning Data Mining communities and describe the experimental infrastructure that being set Accenture Technology Labs undertake those challenges Our experimental test bed for Enterprise Knowledge Management Research has access potentially 150 000 users Accenture and will allow collaborate with researchers and solve large scale Enterprise Information Retrieval problems 
4767 en eBay Searching Finding Buying Selling Story Long tail Online Marketplace this talk will present the personality Online Marketplace This Online Marketplace has all the characteristics Offline Marketplace and more because the simultaneous anonymity and familiarity the buyers and sellers The long tail nature the transactions combined with differing capabilities motives and trust leads vibrant Social Commerce Network will present interesting technical challenges and opportunities Finding Classification merchandizing and reputation systems 
4769 en Climate Change from the Scientific point view
4771 en XML based frameworks managing and archiving not only textual data Text technological application scenarios have become fixed component many fields the Humanities which produce increasing quantities digital data the research process This trend induces the need for strategies for intelligent management and archiving digital resources which are not covered classical content management systems such flexible and web based integration archived data retrieval analysis and interpretation processes Frameworks with XML based system architectures can offer appropriate support here Concentrating the approach two frameworks Cocoon cocoon apache org and FEDORA www fedora commons org the lecture discusses the possibilities limits and experiences such approaches based our long time research project gams uni graz the Centre for Information Modelling the Faculty Humanities the University Graz 
4772 en Policy introduction the Green Paper Urban Mobility and its Action Plan
4773 en Monitoring mobility through innovation the example the city Ljubljana CIVITAS
4774 en Achieving Sustainable Urban Mobility The Challenges
4775 en New solutions for collective transport fuelling bus rapid transit BRT Europe
4779 en CO2 beyond tomorrow fundamental approach
4781 en  board measurements results tool share future emission regulation
4782 en  intelligent model for cleaner environment and citizen rights road transport
4783 en Debate Future Directions for Cleaner Road Transport and Advanced Fuels
4784 en Intelligent Cargo for Efficent Safe and Environment friendly Logistics
4785 en The Road Transport Management System Self regulation initiative promote load optimisation vehicle maintenance and driver wellness heavy vehicle transport South Africa
4786 en  Real Time Decision Support System for the Safe and Efficient Routing dangerous Goods Vehicles
4787 en FIDEUS Innovative logistics for European cities
4788 en Mobility groups and their needs the future
4789 en New tools for linking transport and land use planning
4790 en Public transport service design requirements for the changing face the South African customer
4791 en National Mobility Study Poland Needs and Requirements
4793 en Intelligent car safer roads
4795 en How can inelligent transport systems contribute road safety 
4800 en Proactive role road infastuctures the overall transport system for safety
4804 en Integrated safety the Transpport system
4805 en From black spots grey road sections what the right way
4806 en Implementation rural road safety schemes lessons from the Netherlands
4807 en Best practices for road safety Europe systematic approach
4808 en HeavyRoute Intelligent route guidance for heavy vehicles
4809 en  vision intelligent roads INTRO project 
4810 en Assessing the changes operating traffic conditions due weather conditions
4811 en  operative driving and vehicle based safety applications the perspective the European Integrated Project SAFESPOT 
4812 en Corporate social Responsibility and the road sector
4813 en The results public transport service modelling Zilina county
4814 en Debate Towards Sustainable Society
4815 en Integrating mobility management into the spatial planning State the art analysis
4816 en Transition sustainable mobility theory put into practise
4821 en Welcome TRA 2010 Belgium
4824 en Advances Human Machine Interfaces HMI 
4825 en Real Time Traffic and Travel Information RTTI 
4826 en Vehicle Vehicle and Vehicle Infrastructure Linkages
4830 en Stimulate Telematic Applications ITS the Transport System From research deployment
4831 en Cross Border Integration Traffic Management The PROMET Project
4834 en Systematic Risk Analysis for Safety Assessments Road Systems
4835 en Comparative analysis road safety parameters the European motorways
4836 en The Enhanced Crash Investigation Study ECIS 
4839 en ‘Crash violence’ within the traffic system Risks and their reduction road traffic two lane main roads Finland
4840 en The new Austrian Stopping Distance Model based RoadSTAR skid resistance data
4844 en  Evolution Road User Charging Systems Europe with Focus Poland
4845 en Royal Institute Technology Stockholm
4847 en Improved Mobility Security and Safety Pedestrians and Bicyclists Roads through Small Towns and Villages
4848 en  integrated approach PTW road safety
4849 en European the field secondary passive safety
4850 en Using micro stimulation modelling for driver assistance system assessment
4851 en NICHES Mainstreaming innovation and promoting innovative mobility concepts
4852 en Advanced city cars PRT and cyber cars new froms urban transportation
4853 en Polluition reduction with new vehicle technologies urban logistics FIDEUS field tests the City Hanover
4855 en Sevecom Project – Secure future vehicle communication networks
4856 en eValue project ASTE 
4857 en Security issues related the use cooperative systems eSecurity eSafety
4858 en Good Route Project – Transportation dangerous goods routing monitoring and enforcement
4861 en  Achievements for Global Supply Chains
4862 en Super Light Car Sustainable Production Technologies Emission reduced Light weight Car Concepts
4863 en ECODISM New concept for easy dismantling structural bonded joints auto elv and repair
4864 en LITEBUS Modular Lightweight Sandwich Bus Concept
4870 en Future scenarios for freight transport through Alpine area
4871 en Scenarios policies and impacts for the linked transport and energy systems results the European TRIAS project
4872 en Public Participation and Dialogue the Road Planning and Road Design Process – Example Bypass Norrtälje Sweden
4873 en SatCom part the operational implementation ITS applications – The SISTER Project
4874 en Roads the past The management cultural heritage constraints Irish National Road schemes
4875 en National plan for the protection roads bridges and associated cultural relics
4876 en Modelling the spatial parameters for dynamic road pricing
4877 en Traffic management leisure destinations the countryside integrated approach for transportation and tourism planning
4879 en Graph Mining Techniques for Social Media Analysis
4880 en Decentralization and Interop past present future
4881 en Link PLSA LDA new unsupervised model for topics and influence blogs
4882 en Competing Share Expertise the Taskcn Knowledge Sharing Community
4883 en Finding Influencers and Consumer Insights the Blogosphere
4884 en What Elements Online Social Networking Profile Predict Target Rater Agreement Personality 
4885 en Spontaneous Inference Personality Traits from Online Profiles
4886 en The Psychology Word Use Depression Forums English and Spanish
4887 en Thin Slices Online Profile Attributes
4888 en Document Representation and Query Expansion Models for Blog Recommendation
4889 en Polling the Blogosphere Rule Based Approach Belief Classification
4890 en International Sentiment Analysis for News and Blogs
4892 en Wikipedian Self Governance Action Motivating the Policy Lens
4893 en  Large Scale Study MySpace Observations and Implications for Online Social Networks
4895 en Scaling Innovation Network Effect World
4896 en Recovering Implicit Thread Structure Newsgroup Style Conversations
4897 en  Social Network Based Approach Personalized Recommendation Participatory Media Content
4898 en Wikipedia Ontology for Describing Documents
4900 en BLEWS Using Blogs Provide Context for News Articles
4901 en Exploring Social Media Scenarios for the Television
4902 en The Politics Sourcing Study Journalistic Practices the Blogosphere
4907 en The i2010 Agenda – European Success Story the Making
4908 en Position the Industry Slovenia
4910 en Challenge NGN Networks and Services
4911 en Universal Access All Knowledge Archive org Advances computing and communications mean that can cost effectively store every book sound recording movie software package and public web page ever created and provide access these collections via the Internet students and adults all over the world mostly using existing institutions and funding sources can build this well compensate authors within what the current worldwide library budget The talk offers update the current state progress towards that ideal which would allow bequeath accessible record our cultural heritage our descendants 
4912 en EICTA Building digital Europe Moving Towards Very High Speed Europe
4918 en The Impact important Single Market policies the developement Pan European Services and Products
4919 en Electronic Invoicing 238 bilion reasons begin with 
4920 en How can pan European Public Services Benefit from CIP ICT PSP Pilot eID
4926 en Building Consumer Confidence Ensuring Consumer protection
4927 en How much are Computers able Understand text 
4943 en Interview The discussion with the person who helped put AIESEC the world map AIESEC international non profit non political organisation run students and recent graduates institutions higher education describes itself “The international platform for young people discover and develop their potential have positive impact society” Its international office currently Rotterdam Netherlands The AIESEC network February 2008 includes 000 students 105 countries over 1100 universities across the globe and realizes around 5000 exchanges yearly
4944 en  AIESEC alumnus and this the story our organization
4946 en AIESEC case optimism the world
4948 en Amazon Web Services Amazon has spent over decade and billion building the infrastructure technical knowledge and operational excellence operate world class web scale computing platform Amazon Web Services AWS has now released variety web services programmatic access its open APIs that provide access Amazon robust infrastructure easily and inexpensively These fundamental services allow developers and their companies build web applications reliable scalable and cost effective manner http aws portal amazon com Amazon Web Services Amazon com 
4951 en Goals and Introduction This course intended give newcomers enough background the field HCI make their conference experience much more meaningful provides framework understand how the various topics are related research and practice tried and true introduction and has become CHI conference tradition 
4952 en Psychology Human Computer Interaction This course intended give newcomers enough background the field HCI make their conference experience much more meaningful provides framework understand how the various topics are related research and practice tried and true introduction and has become CHI conference tradition 
4953 en Computer Science and Human Computer Interaction This course intended give newcomers enough backgroundin the field HCI make their conference experience much more meaningful provides framework understand how the various topics are related research and practice tried andtrue introduction and has become CHI conference tradition 
4954 en Communication Chains and Multitasking Observations revealed that information workers interact “chains” interactions switching organizational contexts and communication mediums investigate how communication chains affect workplace stress and discuss chains alignmentwork 
4955 en Effects Intelligent Notification Management Users and Their Tasks Reports the first empirical and behavioral results how scheduling notifications using automated system impacts interruption costs practical settings Results motivate new directions for research interruption management 
4956 en Attention Proxy Issues Audience Awareness for Webcasts Distributed Groups Presents findings from study how classroom instructors pay attention their students and implications for displaying images remote participants classes with both local and remote students 
4958 en The Cost Interrupted Work More Speed and Stress Our study showed interrupted tasks are completed faster with similar quality suggest that people compensate for interruptions working faster but price higher stress frustration and pressure 
4959 en Measuring Trust Hotspots describe novel experimental methodology measure trustin hotspots found that decisions access unfamiliar hotspot may turn locative images its home page 
4960 en Undercover Authentication Usable Front Prying Eyes propose the first authentication scheme rely the humanability combine different sensory inputs demonstrate thesystem usable and resilient eavesdropping and other attacks 
4961 en Access Control Testing for Shared Knowledge propose sharers photos blogs etc protect content withconcise questions like “What Dad’ favorite phrase ” ratherthan explicit authenticated white blacklists Tested via attack byMechanical Turk workers 
4962 en Breaking the Disposable Technology Paradigm Opportunities for Sustainable Interaction Design for Mobile Phones What prompts people replace devices and what people with them when they stop using them explore these issues inform the design sustainable mobile phones 
4963 en Sustainable Millennials Attitudes towards Sustainability and the Material Effects Interactive Technologies This paper describes the design and interprets the results asurvey 435 undergraduate students concerning the attitudes this mainly millennial population towards sustainability apropos the material 
4964 en Aligning Temporal Data Sentinel Events Discovering Patterns Electronic Health Records Finding prevalent precursor occurring and after effect event sin patient records difficult demonstrate how temporal alignment can effectively facilitate discovery patterns incategorical data 
4965 en Celebratory Technology New Directions for Food Research HCI describe the existing and potential HCI design space around human food interaction and particular motivate future researchon designing technology that celebrates the positive interactions people have around food 
4966 en MAHI Investigation Social Scaffolding for Reflective Thinking Diabetes Management describe the design and deployment MAHI ubicompapplication for individuals with diabetes and its effect individuals’ ownership their health and disease management 
4967 en Automatic Whiteout Correcting Mini QWERTY Typing Errors Using Keypress Timing analyzing features users typing Automatic Whiteout detects and corrects the errors made typists while using mini QWERTY RIM Blackberry style keyboard 
4968 en EdgeWrite with Integrated Corner Sequence Help help system that informs users the character shapes the EdgeWrite text entry system was tested can replace printed character charts without hurting novice performances 
4969 en Interlaced QWERTY Accommodating Ease Visual Search and Input Flexibility Shape Writing present iQwerty which offers excellent separation wordshapes for shape writing text input while maintaining low visual search time Many findings also apply traditional touch screen keyboards 
4970 en CareLog Selective Archiving Tool for Behavior Management Schools Identifying the function problem behavior can lead the development more effective interventions One way identifythe function through functional behavior assessment FBA 
4971 en Observing Presenters Use Visual Aids Inform the Design Classroom Presentation Software conducted observational study examine current practice with both traditional blackboards and computer slides with the ultimate goal designing rich presentation tools for high resolution and multiple screens 
4972 en Readability Scanned Books Digital Libraries Readability scanned picture books the International Children’ Digital Library improved using computer vision and DHTML technologies separate the text from the illustrations 
4973 en Collaborating Remember Distributed Cognition Account Families Coping with Memory Impairments study ten families coping with the consequences amnesia applying distributed cognition theory show that the families work together “cognitive systems” combat their memory issues 
4974 en Feasibility and Pragmatics Classifying Working Memory Load with Electroencephalograph demonstrate high accuracies classifying working memory load using electroencephalograph EEG even with little temporallag not much training data and small number EEG channels 
4975 en Human Aided Computing Utilizing Implicit Human Processing Classify Images Human Aided Computing uses electroencephalograph EEG device measure the outcomes implicit cognitive processingto perform image classification even when users are not explicitlyperforming the task 
4976 en Augmented Information Assimilation Social and Algorithmic Web Aids for the Information Long Tail This study examines how users integrate new World Wide Webservices such social bookmarking with everyday information assimilation practices 
4977 en What When Search Fails Finding Information Association Feldspar lets people find personal information their computer specifying chains associated information queries emulating the retrieval process human associative memory 
4978 en Conversation Pivots and Double Pivots Conversation pivots and double pivots allow readers navigate from pages about items relevant conversations and other items that are mentioned the same conversations 
4979 en Query Suggestions for Mobile Search Understanding Usage Patterns Entering search terms mobile phones time consuming and cumbersome task this paper explore the usage patterns query entry interfaces that display suggestions 
4980 en Topobo the Wild Longitudinal Evaluations Educators Appropriating Tangible Interface What issues arise when designing and deploying tangibles for learning long term evaluations 
4981 en You Can Touch but You Can Look Interacting with Vehicle Systems Interacting with vehicle systems while driving car can dangerous examine driver attention and driving behavior for three different interaction techniques 
4982 en Touchers and Mousers Commonalities and Differences located Collaboration with Multiple Input Devices present qualitative analysis multiple touch mouse input device trajectories observe balanced selection preferred device and reveal more commonalities than differences interaction patterns tabletops 
4983 en Information Distance and Orientation Liquid Layout After accounting for vertical scrolling horizontally separated portlets provided task completion time savings over vertically separated portlets study that provided guidelines for liquid page layout 
4984 en Impact Screen Size Performance Awareness and User Satisfaction With Adaptive Graphical User Interfaces conducted study compare adaptive interfaces for small versus desktop sized screens showing that high accuracy adaptive menus have relatively larger positive impact for small screen displays 
4985 en Improving the Performance Motor Impaired Users with Automatically Generated Ability Based Interfaces Interacting with vehicle systems while driving car can dangerous examine driver attention and driving behavior for three different interaction techniques 
4986 en Evaluation Role Based Approach for Customizing Complex Development Environment interview study with software developers identify challenges designing coarse grained approaches customization The findings highlight potentially critical design choices and provide direction for future research 
4987 en Predictability and Accuracy Adaptive User Interfaces examine the relative effects predictability and accuracy the adaptive algorithm the usability user interfaces that automatically adapt users’ tasks 
4988 en BlindSight Eyes Free Access Mobile Phones BlindSight allows mobile phone users access phone calendarand contacts situations where they cannot look the screen such while talking the phone while driving Based auditory feedback 
4989 en One Handed Touchscreen Input for Legacy Applications present two controlled studies aimed understanding therelative tradeoffs that five different input methods includingdirect and indirect offer for operating dense mobile touchscreeninterfaces with one hand 
4990 en Target Acquisition with Camera Phones when used Magic Lenses examine target acquisition magic lens pointing with cameraphones present Fitts’ law extension that models the performance and show that dynamic peephole pointing follows the standard Fitts’ law 
4991 en Cross channel Mobile Social Software empirical study discuss the usage design and effects cross channel mobile tool support group socializing and describe how different other forms group communication 
4993 en Use and Reuse Shared Lists Social Content Type describe the design use and reuse shared lists asocial networking system Our findings suggest that users socialize more around lists than photos and use lists for selfrepresentation 
4994 en How Accurate must Car Information System Consequences Accurate and Inaccurate Information Cars Talking Cars should know their Drivers Investigating how Inaccurate Information Speech based Vehicle Information Systems affects Different Drivers’ Attitude and Driving Performance 
4995 en  Car GPS Navigation Engagement with and Disengagement from the Environment explore how car GPS navigation leads new forms engagement and disengagement with the external environment Fieldwork and theoretical framing lead design suggestions for enriching engagement 
4996 en  car Interaction Using Search Based User Interfaces vehicle information systems IVIS become more complexand offer extended functionalities our research deals with searchbased user interfaces for IVIS explore their suitability for safeand efficient use 
4997 en Evaluating Motion Constraints for Wayfinding Immersive and Desktop Virtual Environments Studies the benefit motion constraints for assisting navigation desktop and immersive environments Presents technique for desktop computers that outperforms immersive displays terms wayfinding efficiency 
4998 en Navigation Techniques for Dual Display Book Readers present the design and evaluation dual display electronic reader which supports wide range reading activities like lightweight navigation global search and multi documentinter actions 
4999 en Idea Navigation Structured Browsing for Unstructured Text Don’ search for keywords Search for ideas Our system extracts subject verb object triples from unstructured text groups them into hierarchies and allows iterative refinement findexactly what you want 
5000 en Rendering Navigation and Information Space with HoneyCombTM introduce the HoneyComb information visualization and browsing paradigm present the design objectives prototype implementation and the results evaluation the context search and browsing 
5060 en Chinese Rings and Hanoi Tower Graphs
5061 en  Habits For Effective Text Editing large percentage time behind the computer screen spent editing text Investing little time learning more efficient ways use text editor pays itself back fairly quickly This presentation will give overview the large number ways using Vim smart way edit programs structured text and documentation Examples will used make clear how learning limited number habits will avoid wasting time and lower the number mistakes bram moolenaar mostly known for being the benevolent dictator the text editor Vim His roots are electrical engineering and for long time worked inventing image processing algorithms and software for big photo copying machines some point his work Open Source software became more important making the development Vim his full time job also did the project between Vim version and Now works for Google Zurich still improving Vim the side His home page http www moolenaar net http wikipedia org wiki Bram Moolenaar Wikipedia article also available 
5067 en OpenMoko hackable Open Source PDA phone
5074 en Processes Linux kernel current and future latest technology
5075 en OpenPCD Free software and hardware RFID reader
5076 en Interview with Machtelt Garrels Machtelt Garrels Linux veteran and freelance consultant trainer she the author books such Introduction Linux hands Guide Bash Guide for Beginners Drupal Installation Guide etc All them freely downlodable nThe Videolectures NET cheif software developer http videolectures net peter kese Peter Kese talked her Zagreb Linux event where asked her What brought you Zagreb Which reading regarding Linux are the most popular this moment What the most usefull ammunition that you use for the ODF propaganda The next step the level Family issues and Linux nnCheck out another online interview http www profoss events june 2008 openoffice speakers machtelt garrels interview Machtelt The interview was terminated bit too early the conference organizers 
5077 en Linux kernel development future 2008
5080 en How create your own language minutes
5097 en Transmission electron microscopy for nanomaterial characterization how far can first part will briefly survey how magnetic field can used order focus electron beam and then how transmission electron microscope works Recent experimental developments such the correction the spherical aberration electron lenses and the resulting atomic resolution will showed will then present how this techniques are now widely used the order solve various problematics such the imaging nanostructures from the industrial oriented characterisation multilayers the imaging nanoparticles into organic matter the structural refinement crystalline defective systems such bonding interfaces the topological description defects functionalised nanotubes Finally will discuss how combining electron spectroscopy and microscopy physical chemical properties such the oxidation state transition metal oxide nanoparticles the plasmonic properties metallic clusters can investigated 
5098 en Videolectures Net Past Pizza Future This recording the lunch seminar the JSIn had Past are just having Pizzan and have Future This seminar overview the problems were facing few months ago 
5099 en  for Research Desktop Analysis Web Site Structures the seminar there will presented two topics User interface design for Research Desktop Social Network Analysis Web Site Structures
5102 en Formalisation Science Ontology Based Projects Aberystwyth University Aberystwyth University have several projects for formalizing descriptions scientific investigations ontology for robot scientist ontology for drug design ontology for description protocols talk will describe the state the art for ontology development these projects and prospects for ontology applications science 
5105 en The Adobe RIA Platform Get first hand information what the Adobe rich internet application platform has offer Enrique will inspire you with real life examples running Flex and AIR 
5108 en Towards More Meaningful Web The Web today near the edge its utility Information sources and services are increasingly fragmented and plentiful Google metaphor page and link outdated Web over The talk will review some the fresh concepts such subjective relevance user centric data management individual reputation and outline how those are applied the upcoming Noovo platform 
5123 en Early stage venture capital investing shaping successful high tech startup companies towards accelerated exits Yoav Andrew Leitersdorf entrepreneur and venture capitalist who founded grew and sold three successful startups discusses his experiences with his own companies and some issues that have been plaguing venture capital financing since the last bubble burst then discusses his firm innovative approach financing which involves calibrating investments today capital efficient startups and widening the exit window down short term medium size exits 
5125 en Start Your Startup the European Way With thousands new services coming out each and every year competition fierce But opportunities are there and probably there are more opportunities then ever Ideas enough but how you know what idea you should work This talk about the web its facilitators passion and how live your dream 
5127 en Your international customers are waiting for you Providing services and products for international market easier than you may think while the same time there are lot pitfalls you need aware But once you apply certain ways thinking making business with lucrative markets will way easier Using the German market example this session will show you ways think different and provide you with tips and ideas for your dream target market 
5132 en Panel discussion Venture Capital the Region
5134 en All Business Angels Panel discussion
5141 en Zemanta Ljubljana London the World Blog What Zemanta learned from Seedcamp Why moving London was necessary How dip toe into international web scene cheaply What Zemanta doing and how see the future content authoring 
5143 en Exceptional Model Mining most databases possible identify small partitions the data where the observeddistribution notably different from that the database whole classical subgroup discovery one considers the distribution single nominal attribute and exceptional subgroups show surprising increase the occurrence one its values this talk introduce Exceptional Model Mining EMM framework that allows for more complicated target concepts Rather than finding subgroups based the distribution single target attribute EMM finds subgroups where model fitted that subgroup somehow exceptional discuss regression well classification models and define quality measures that determine how exceptional given model subgroup Our framework general enough applied many types models even from other paradigms such association analysis and graphical modeling 
5157 en NeOn Glowfest NeOn million Euros project involving European partners and funded the European Commission’ Sixth Framework Programme under grant number IST 2005 027595 NeOn started March 2006 and has duration years Our aim advance the state the art using ontologies for large scale semantic applications the distributed organizations Particularly aim improving the capability handle multiple networked ontologies that exist particular context are created collaboratively and might highly dynamic and constantly evolving The first release the NeOn Toolkit one the core outcomes the NeOn project available for download and testing from the http www neon toolkit org NeOn Toolkit Community site 
5159 en Expected plugins for the new version NeOn toolkit The NeOn toolkit extensible Ontology Engineering Environment part the reference implementation the NeOn architecture contains plugins for ontology management and visualization The core features include Basic Editing Editing Schemasplash jpg Visualization Browsing Import Export Logic subsets RDF and OWL number commercial plugins extend the toolkit various functionalities including Rule Support Graphical Textual editing debugging Mediation Graphical Mapping Editor life interpretation mappings Database Integration Database schema import database access Queries Query Editor and persistent queries
5160 en The Watson plugin for the Neon toolkit Watson Semantic Web gateway way similar seacrh engines the Web Watson collects analyses and indexes semantic documents RDF OWL DAML OIL order provide variety access mechanisms this semantic data for intelligent applications The idea support applications that requires dynamically find select and exploit the increasing amount knowledge available online that call next generation semantic web applications more complete description Watson available its website and the latest development and news concerning Watson are generally announced the Watson Blog number applications have already been developed that dynamically exploit online knowledge thanks Watson particular with the help Fouad Zablith charge the development plugins for ontology editors that allow for large scale reuse existing knowledge the Web also quickly developed application called gowgle that suggests additional keywords query addressed Google using the semantic relations linking these terms online ontologies also contributed the development Scarlet relation discovery engine used particular ontology matching and PowerMagpie Semantic browser based Watson 
5162 en Optoacoustic imaging promising technique for non invasive diagnosis cancer Optoacoustics provides high optical contrast without the handicap poor resolution imaging optically turbid tissues biomedical optoacoustics tissue illuminated with short laser pulses The light scattered inside the tissue and heats absorbing structures such blood vessels hidden deeply inside the tissue Image contrast therefore provided light absorbing chromophores either endogenous such oxy deoxyhemoglobin exogenous dyes nanoparticles quantum dots means the thermoelastic effect the inhomogeneous heating generates pressure transients exactly representing the absorbing structures These acoustic transients propagate the tissue surface and can detected with appropriate ultrasound transducer one dimensional optoacoustic measurements time delay between the laser pulse and detected pressure transient its amplitude and temporal profile provide information about the location strength and spatial dimension the acoustic source Three dimensional images can reconstructed scanning the transducer The image quality depends number factors including the irradiation geometry and image reconstruction algorithm The talk will give overview the possibilities and limitations optoacoustic imaging turbid tissues especially terms image contrast and depth resolution 
5163 en Knowledge Discovery Life Sciences overview case studies complexities and lessons learned Knowledge discovery the process developing and applying strategies discover useful and ideally all previously unknown knowledge from historical real time data Applied biological and life sciences data knowledge discovery processes will help various research and development activities such studying data quality for possible anomalous questionable expressions certain genes experiments identifying relationships between genes and their functions based time series other high throughput genomics profiles iii investigating gene responses treatments under various experimental conditions such vitro vivo studies and discovering models for accurate diagnosis classifications based expression profiles among two more classes This presentation consists three parts part one provide overview knowledge discovery focusing bioinformatics domain and describe the BioMine project where share our experiences initiating and managing data mining project involving several groups part two this talk describe few our case studies using some existing newly developed methods These are all cases which real genomics data sets obtained from public private sources have been used for tasks such gene function identification and gene response analysis the last part this talk will describe complexities and challenges dealing with real data demonstrate important areas that need carefully understood typical data mining application and share some our experiences gained over the past years 
5172 en Tailoring Density Estimation via Reproducing Kernel Moment Matching Moment matching popular means parametric density estimation extend this technique nonparametric estimation mixture models Our approach works embedding distributions into reproducing kernel Hilbert space and performing moment matching that space This allows tailor density estimators function class interest for which would like compute expectations show our density estimation approach useful applications such message compression graphical models and image classification and retrieval 
5173 en Nonextensive Entropic Kernels Positive definite kernels probability measures have been recently applied structured data classification problems Some these kernels are related classic information theoretic quantities such mutual information and the Jensen Shannon divergence Meanwhile driven recent advances Tsallis statistics nonextensive generalizations Shannon’ information theory have been proposed This paper bridges these two trends introduce the Jensen Tsallis difference generalization the Jensen Shannon divergence then define new family nonextensive mutual information kernels which allow weights assigned their arguments and which includes the Boolean Jensen Shannon and linear kernels particular cases illustrate the performance these kernels text categorization tasks 
5174 en  Support Vector Machine Conditional Value Risk Minimization The support vector classification SVC algorithm was shown work well and provide intuitive interpretations the parameter roughly specifies the fraction support vectors Although corresponds fraction cannot take the entire range between and its original form This problem was settled non convex extension SVC and the extended method was experimentally shown generalize better than original SVC However its good generalization performance and convergence properties the optimization algorithm have not been studied yet this paper provide new theoretical insights into these issues and propose novel SVC algorithm that has guaranteed generalization performance and convergence properties
5175 en  Generalization Haussler Convolution Kernel Mapping Kernel Haussler convolution kernel provides successful framework for engineering new positive semidefinite kernels and has been applied wide range data types and applications the framework each data object represents finite set finer grained components Then Haussler convolution kernel takes pair data objects input and returns the sum the return values the predetermined primitive kernel calculated for all the possible pairs the components the input data objects Due the definition Haussler convolution kernel also known the cross product kernel and positive semidefinite the primitive kernel the other hand the mapping kernel that introduce this paper natural generalization Haussler convolution kernel that the input the primitive kernel moves over predetermined subset rather than the entire cross product Although have plural instances the mapping kernel the literature their positive semidefiniteness was investigated case case manners and worse yet was sometimes incorrectly concluded fact there exists simple and easily checkable necessary and sufficient condition which generic the sense that enables investigate the positive semidefiniteness arbitrary instance the mapping kernel This the first paper that presents and proves the validity the condition addition introduce two important instances the mapping kernel which refer the size index structure distribution kernel and the edit cost distribution kernel Both them are naturally derived from well known dis similarity measurements the literature the maximum agreement tree the edit distance and are reasonably expected improve the performance the existing measures evaluating their distributional features rather than their peak maximum minimum features 
5176 en Hierarchical sampling for active learning present active learning scheme that exploits cluster structure data 
5177 en Active Kernel Learning Identifying the appropriate kernel function matrix for given dataset essential all kernel based learning techniques the past number kernel learning algorithms have been proposed learn kernel functions matrices from side information the form labeled examples pairwise constraints However most previous studies are limited the passive kernel learning which the side information provided beforehand this paper present framework Active Kernel Learning AKL that able actively identify the most informative pairwise constraints for kernel learning The key challenge active kernel learning how measure the informativeness each example pair given its class label unknown this end propose min max approach for active kernel learning that selects the example pairs that will lead the largest classification margin even when the class assignments the selected pairs are incorrect furthermore approximate the related optimization problem into convex programming problem evaluate the effectiveness the proposed active kernel learning algorithm comparing with two other implementations active kernel learning Empirical study with nine datasets data clustering shows that the proposed algorithm considerably more effective than its competitors 
5178 en Actively Learning Level Sets Composite Functions Scientists frequently have multiple types experiments and data sets which they can test the validity their parametrized models and locate plausible regions for the model parameters examining multiple data sets these scientists can obtain inferences for their problems which typically are much more informative than the deductions derived from each the data sources independently Several standard data combination techniques result target function which weighted sum the observed data sources Computing constraints the plausible regions the model parameter space can formulated that finding specified level set the target function propose active learning algorithm for this problem which each step selects both parameter setting from the parameter space and experiment type upon which compute the next sample Empirical tests synthetic functions and real data for eight parameter cosmological model show that our algorithm significantly reduces the number samples required identify desired regions 
5179 en Learning from Incomplete Data with Infinite Imputations address the problem learning decision functions from training data which some attribute values are unobserved This problem can arise for instance when training data aggregated from multiple sources and some sources record only subset attributes derive joint optimization problem for the final classifier which the distribution governing the missing values free parameter show that the optimal solution concentrates the density mass finitely many atoms and provide corresponding algorithm for learning from incomplete data report empirical results benchmark data and the email spam application that motivates the problem setting
5185 en Accurate Max margin Training for Structured Output Spaces Tsochantaridis 2005 proposed two formulations for maximum margin training structured spaces margin scaling and slack scaling While margin scaling has been extensively used since requires the same kind MAP inference normal structured prediction slack scaling believed more accurate and better behaved present efficient variational approximation the slack scaling method that solves its inference bottleneck while retaining its accuracy advantage over margin scaling further argue that existing scaling approaches not separate the true labeling comprehensively while generating violating constraints propose new max margin trainer PosLearn that generates violators ensure separation each position decomposable loss function Empirical results real datasets illustrate that PosLearn can reduce test error Further PosLearn violators can generated more efficiently than slack violators for many structured tasks the time required just twice that MAP inference 
5186 en Training Structural SVMs when Exact Inference Intractable While discriminative training CRF structural SVM holds much promise for machine translation image segmentation and clustering the complex inference these applications require make exact training intractable This leads need for approximate training methods Unfortunately knowledge about how perform efficient and effective approximate training limited Focusing structural SVMs provide and explore algorithms for two different classes approximate training algorithms which call undergenerating greedy and overgenerating relaxations algorithms provide theoretical and empirical analysis both types approximate trained structural SVMs focusing fully connected pairwise Markov random fields find that models trained with overgenerating methods have theoretic advantages over undergenerating methods are empirically robust relative their undergenerating brethren and relaxed trained models favor non fractional predictions from relaxed predictor
5187 en Discriminative Structure and Parameter Learning for Markov Logic Networks Markov logic networks MLNs are expressive representation for statistical relational learning that generalizes both first order logic and graphical models Existing methods for learning the logical structure MLN are not discriminative however many relational learning problems involve specific target predicates that must inferred from given background information found that existing MLN methods perform very poorly several such ILP benchmark problems and present improved discriminative methods for learning MLN clauses and weights that outperform existing MLN and traditional ILP methods 
5188 en Laplace Maximum Margin Markov Networks Learning sparse Markov networks based the maximum margin principle remains open problem structured prediction this paper proposed the Laplace max margin Markov network LapM3N and general class Bayesian M3N BM3N which the LapM3N special case and enjoys sparse representation The BM3N built novel Structured Maximum Entropy Discrimination SMED formalism which offers general framework for combining Bayesian learning and max margin learning log linear models for structured prediction and subsumes the unsparsified M3N special case present efficient iterative learning algorithm based variational approximation and existing convex optimization methods employed M3N show that our method outperforms competing ones both synthetic and real OCR data 
5189 en Fast Estimation Relational Pattern Coverage through Randomization and Maximum Likelihood inductive logic programming theta subsumption widely used coverage test Unfortunately testing theta subsumption complete which represents crucial efficiency bottleneck for many relational learners this paper present probabilistic estimator clause coverage based randomized restarted search strategy Under distribution assumption our algorithm can estimate clause coverage without having decide subsumption for all examples implement this algorithm program ReCovEr generated graph data and real world datasets show that ReCovEr provides reasonably accurate estimates while achieving dramatic runtimes improvements compared state the art algorithm
5190 en Fast Gaussian Process Methods for Point Process Intensity Estimation Point processes are difficult analyze because they provide only sparse and noisy observation the intensity function driving the process Gaussian Processes offer attractive theoretical framework which infer optimal estimates these underlying intensity functions The result this inference continuous function defined across time that typically more amenable analytical efforts However naive implementation this intensity estimation will become computationally infeasible any problem reasonable size both memory and run time requirements demonstrate problem specific methods for class renewal processes that eliminate the memory burden and reduce the solve time orders magnitude 
5191 en Gaussian Process Product Models for Nonparametric Nonstationarity Stationarity often unrealistic prior assumption for Gaussian process regression One solution predefine explicit nonstationary covariance function but such covariance functions can difficult specify and require detailed prior knowledge the nonstationarity propose the Gaussian process product model GPPM which models data the pointwise product two latent Gaussian processes nonparametrically infer nonstationary variations amplitude This approach differs from other nonparametric approaches covariance function inference that operates the outputs rather than the inputs resulting significant reduction computational cost and required data for inference while improving scalability high dimensional input spaces present approximate inference scheme using Expectation Propagation This variational approximation yields convenient hyperparameter selection and compact approximate predictive distributions 
5192 en Sparse Multiscale Gaussian Process Regression Most existing sparse Gaussian process models seek computational advantages basing their computations set basis functions that are the covariance function the with one its two inputs fixed generalise this for the case Gaussian covariance function basing our computations Gaussian basis functions with arbitrary diagonal covariance matrices length scales For fixed number basis functions and any given criteria this additional flexibility permits approximations worse and typically better than was previously possible perform gradient based optimisation the marginal likelihood which costs m2n time where the number data points and compare the method various other sparse methods Although focus regression the central idea applicable all kernel based algorithms and also provide some results for the support vector machine and kernel ridge regression Our approach outperforms the other methods particularly for the case very few basis functions very high sparsity ratio 
5193 en Topologically Constrained Latent Variable Models dimensionality reduction approaches the data are typically embedded Euclidean latent space However for some data sets this inappropriate For example human motion data expect latent spaces that are cylindrical toroidal that are poorly captured with Euclidean space this paper present range approaches for embedding data non Euclidean latent space Our focus the Gaussian Process latent variable model the context human motion modeling this allows learn models with interpretable latent directions enabling for example style content separation and generalize beyond the data set enabling learn transitions between motion styles even though such transitions are not present the data
5194 en  Level Path Following for Cross Validated Solution Kernel Quantile Regression Modeling conditional quantiles requires specification the quantile being estimated and can thus viewed parameterized predictive modeling problem Quantile loss typically used and indeed parameterized quantile parameter this paper show how follow the path cross validated solutions regularized kernel quantile regression Even though the level optimization problem encounter for every quantile non convex the manner which the optimal cross validated solution evolves with the parameter the loss function allows tracking this solution prove this property construct the resulting algorithm and demonstrate data This algorithm allows efficiently solve the whole family level problems 
5196 en Discriminative Parameter Learning for Bayesian Networks Bayesian network classifiers have been widely used for classification problems Given fixed Bayesian network structure parameter learning can take two different approaches generative and discriminative learning While generative parameter learning more efficient discriminative parameter learning more effective this paper propose simple efficient and effective discriminative parameter learning method called Discriminative Frequency Estimate DFE which learns parameters discriminatively computing frequencies from data Empirical studies show that the DFE algorithm integrates the advantages both generative and discriminative learning performs well the state the art discriminative parameter learning method ELR accuracy but significantly more efficient 
5197 en  the Quantitative Analysis Deep Belief Networks Deep Belief Networks DBN are generative models that contain many layers hidden variables Efficient greedy algorithms for learning and approximate inference have allowed these models applied successfully many application domains The main building block DBN bipartite undirected graphical model called restricted Boltzmann machine RBM Due the presence the partition function model selection complexity control and exact maximum likelihood learning RBM are intractable Annealed Importance Sampling AIS can used efficiently estimate the partition function RBM present novel AIS scheme for comparing RBM with different architectures further show how AIS estimator along with approximate inference can used estimate lower bound the log probability that DBN model with multiple hidden layers assigns the test data This our knowledge the first step towards obtaining quantitative results that would allow directly assess the performance Deep Belief Networks generative models data 
5198 en Training Restricted Boltzmann Machines using Approximations the Likelihood Gradient new algorithm for training Restricted Boltzmann Machines introduced The algorithm named Persistent Contrastive Divergence different from the standard Contrastive Divergence algorithms that aims draw samples from almost exactly the model distribution compared some standard Contrastive Divergence algorithms the tasks modeling handwritten digits and classifying digit images learning model the joint distribution images and labels The Persistent Contrastive Divergence algorithm outperforms other Contrastive Divergence algorithms and equally fast and simple 
5199 en  New Admixture Model for Inference Population Structure Light Both Genetic Admixing and Allele Mutations Traditional methods for analyzing population structure such the Structure program ignore the influence mutational effects propose mStruct admixture population specific mixtures inheritance models that addresses the task structure inference and mutation estimation jointly through hierarchical Bayesian framework and variational algorithm for inference validated our method synthetic data and used analyze the HGDP CEPH cell line panel microsatellites used Rosenberg 2002 and the HGDP SNP data used Conrad 2006 comparison the structural maps world populations estimated mStruct and Structure presented and also report potentially interesting mutation patterns world populations estimated mStruct which not possible Structure 
5200 en Memory Bounded Inference Topic Models What type algorithms and statistical techniques support learning from very large datasets over long stretches time address this question through memory bounded version variational algorithm that approximates inference topic model The algorithm alternates two phases model building and model compression order always satisfy given memory constraint The model building phase grows its internal representation the number topics more data arrives through Bayesian model selection Compression achieved merging data items clumps and only caching their sufficient statistics Empirically the resulting algorithm able handle datasets that are orders magnitude larger than the standard batch version 
5201 en Nonnegative Matrix Factorization via Rank One Downdate Nonnegative matrix factorization NMF was popularized tool for data mining Lee and Seung 1999 NMF attempts approximate matrix with nonnegative entries product two low rank matrices also with nonnegative entries propose algorithm called rank one downdate R1D for computing NMF that partly motivated singular value decomposition This algorithm computes the dominant singular values and vectors adaptively determined submatrices matrix each iteration R1D extracts rank one submatrix from the dataset according objective function establish theoretical result that maximizing this objective function corresponds correctly classifying articles nearly separable corpus also provide computational experiments showing the success this method identifying features realistic datasets The method much faster than either LSI other NMF routines 
5202 en Dirichlet Component Analysis Feature Extraction for Compositional Data consider feature extraction dimensionality reduction for compositional data where the data vectors are constrained positive and constant sum real world problems the data components variables usually have complicated correlations while their total number huge Such scenario demands feature extraction That shall correlate the components and reduce their dimensionality Traditional techniques such the Principle Component Analysis PCA are not suitable for these problems due unique statistical properties and the need satisfy the constraints compositional data This paper presents novel approach feature extraction for compositional data Our method first identifies family dimensionality reduction projections that preserve all relevant constraints and then finds the optimal projection that maximizes the estimated Dirichlet precision projected data reduces the compositional data given lower dimensionality while the components the lower dimensional space are correlated much possible develop theoretical foundation our approach and validate its effectiveness some synthetic and real world datasets 
5203 en Learning Sportscast Test Grounded Language Acquisition present novel commentator system that learns language from sportscasts simulated soccer games The system learns parse and generate commentaries without any engineered knowledge about the English language Training done using only ambiguous supervision the form textual human commentaries and simulation states the soccer games The system simultaneously tries establish correspondences between the commentaries and the simulation states well build translation model also present novel algorithm Iterative Generation Strategy Learning IGSL for deciding which events comment Human evaluations the generated commentaries indicate they are reasonable quality compared human commentaries 
5204 en  Unified Architecture for Natural Language Processing Deep Neural Networks with Multitask Learning describe single convolutional neural network architecture that given sentence outputs host language processing predictions part speech tags chunks named entity tags semantic roles semantically similar words and the likelihood that the sentence makes sense grammatically and semantically using language model The entire network trained jointly all these tasks using weight sharing instance multitask learning All the tasks use labeled data except the language model which learnt from unlabeled text and represents novel way performing semi supervised learning for the shared tasks show how both multitask learning and semi supervised learning improve the generalization the shared tasks resulting learnt model with state the art performance 
5205 en Fully Distributed for Very Large Datasets and related algorithms step computations distribute easily because data items are independent given parameters For very large data sets however even storing all the parameters single node for the step can impractical present framework which fully distributes the entire procedure Each node interacts with only parameters relevant its data sending messages other nodes along junction tree topology demonstrate improvements over MapReduce approach two tasks word alignment and topic modeling 
5206 en Structure Compilation Trading Structure for Features Structured models often achieve excellent performance but can slow test time investigate structure compilation where replace structure with features which are often computationally simpler but unfortunately statistically more complex analyze this tradeoff theoretically and empirically three natural language processing tasks also introduce simple method transfer predictive power from structure features via unlabeled data while incurring minimal statistical penalty 
5211 en Multi modal interaction involving speech and language technologies
5212 en Phrase based and factored statistical machine translation
5213 en Applying unsupervised learning creating language models for information retrieval and machine translation
5214 en Speech production models for automatic speech recognition
5217 en Change Management the Product Development Process Challenge for OEMs Partners System Vendord and Research Organisations
5218 en Challenges and Strategies for Services Heterogeneous Enterprise Environments
5219 en Enterprise Architecture Service Interoperability Analysis Framework
5220 en Logical Foundations for the Infrastructure the Information Market
5221 en The Advantages Hybrid Architectural Approaches for the Integrating Middleware
5222 en MDA Technology Support China Aviation Industry
5224 en Supporting Adaptive Enterprise Collaboration through Semantic Knowledge Services
5231 en Musical Source Separation using Generalised Non Negative Tensor Factorisation Models
5234 en The Potential Reinforcement Learning for Live Musical Agents
5236 en Identifying Cover Songs Using Normalized Compression Distance
5237 en Towards Logic based Representations Musical Harmony for Classification Retrieval and Knowledge Discovery
5238 en Metropolis Hastings Sampling FilterBoost Music Classifier
5241 en Training Music Sequence Recognizers with Linear Dynamic Programming
5242 en Genre Classification Music Tonal Harmony
5243 en Using Mathematical Morphology for Geometric Music Retrieval
5245 en Chorale Harmonization the Style Bach Machine Learning Approach
5246 en  information dynamic model melodic segmentation
5247 en Melody Characterization Fuzzy Rule System
5252 en Opening ceremony Transition metal chalco halide nanostructures
5253 en Opening ceremony The broader context nanotechnology development The integrated safe and responsible policy the European Union
5256 en Bioactive nanoparticles and carbon nanotubes for new generation tissue engineering scaffolds
5257 en Molybdenum chalcohalide nanowire mysteries Structure rigidity and quantum transport
5260 en Force clamp spectroscopy single proteins
5261 en Probabilistic models for understanding images Getting computer understand image challenging due the numerous sources variability that influence the imaging process The pixels typical photograph will depend the scene type and geometry the number shape and appearance objects present the scene their positions and orientations well effects such occlusion shading and shadows The good news that research into physics and computer graphics has given detailed understanding how these variables affect the resulting image This understanding can help build the right prior knowledge into our probabilistic models images theory building model containing all this knowledge would solve the image understanding problem practice such model would intractable for current inference methods The open challenge for machine learning and machine vision researchers create model which captures the imaging process accurately possible whilst remaining tractable for accurate inference illustrate this challenge will show how different aspects the imaging process can incorporated into models for object detection and segmentation and discuss techniques for making inference tractable such models Disclaimer Videolectures Net emphasises that the quality this video can not improved because low light quality conditions provided the lecture auditorium 
5262 en Structured Prediction Problems Natural Language Processing Modeling language the syntactic semantic level key problem natural language processing and involves challenging set structured prediction problems this talk describe work machine learning approaches for syntax and semantics with particular focus lexicalized grammar formalisms such dependency grammars tree adjoining grammars and categorial grammars address key issues the following areas the design learning algorithms for structured linguistic data the design representations that are used within these learning algorithms the design efficient approximate inference algorithms for lexicalized grammars cases where exact inference can very expensive nnIn addition describe applications machine translation and natural language interfaces 
5263 en STAIR The STanford Artificial Intelligence Robot project This talk will describe the STAIR home assistant robot project and several satellite projects that led key STAIR components such robotic grasping previously unknown objects depth perception from single still image and iii apprenticeship learning for control Since its birth 1956 the dream has been build systems that exhibit broad spectrum competence and intelligence STAIR revisits this dream and seeks integrate onto single robot platform tools drawn from all areas including learning vision navigation manipulation planning and speech NLP This distinct contrast and also represents attempt reverse the year old trend working fragmented sub fields STAIR goal useful home assistant robot and over the long term envision single robot that can perform tasks such tidying room using dishwasher fetching and delivering items and preparing meals STAIR still young project and this talk report our progress far having STAIR fetch items from around the office Specifically describe learning grasp previously unseen objects including its application unloading items from dishwasher probabilistic multi resolution maps which enable the robot open use doors iii robotic foveal peripheral vision system for object recognition and tracking also outline some the main technical ideas such learning reconstructions from single still image and reinforcement learning algorithms for robotic control that played key roles enabling these STAIR components 
5265 en  Asymptotic Analysis Generative Discriminative and Pseudolikelihood Estimators Statistical and computational concerns have motivated parameter estimators based various forms likelihood joint conditional and pseudolikelihood this paper present unified framework for studying these estimators which allows compare their relative statistical efficiencies Our asymptotic analysis suggests that modeling more the data tends reduce variance but the cost being more sensitive model misspecification present experiments validating our analysis 
5266 en Knows What Knows Framework For Self Aware Learning introduce learning framework that combines elements the well known PAC and mistake bound models The KWIK knows what knows framework was designed particularly for its utility learning settings where active exploration can impact the training examples the learner exposed true reinforcement learning and active learning problems catalog several KWIK learnable classes and list some open problems this area 
5267 en SVM Optimization Inverse Dependence Training Set Size discuss how the runtime SVM optimization should decrease the size the training data increases present theoretical and empirical results demonstrating how simple subgradient descent approach indeed displays such behavior least for linear kernels 
5268 en  Year Best Paper Combining Labeled and Unlabeled Data with Training consider the problem using large unlabeled sample boost performance learning algorithm when only small set labeled examples available particular consider problem setting motivated the task learning classify web pages which the description each example can partitioned into two distinct views For example the description web page can partitioned into the words occurring that page and the words occurring hyperlinks that point that page assume that either view the examplewould sufficient for learning had enough labeled data but our goal use both views together allow inexpensive unlabeled data augment much smaller set labeled examples Specically the presence two distinct views each example suggests strategies which two learning algorithms are trained separately each view and then each algorithms predictions new unlabeled examples are used enlarge the training set the other Our goal this paper provide PAC style analysis for this setting and more broadly PAC style framework for the general problem learning from both labeled and unlabeled data also provide empirical results real web page data indicating that this use unlabeled examples can lead significant improvement hypotheses practice Boltzmann Machines RBMs have been developed for large variety learning problems However RBMs are usually used feature extractors for another learning algorithm provide good initialization for deep feed forward neural network classifiers and are not considered stand alone solution classification problems this paper argue that RBMs provide self contained framework for deriving competitive non linear classifiers present evaluation different learning algorithms for RBMs which aim introducing discriminative component RBM training and improve their performance classifiers This approach simple that RBMs are used directly build classifier rather than stepping stone Finally demonstrate how discriminative RBMs can also successfully employed semi supervised setting 
5274 en Ontology Engineering and Plug Development with the NeOn Toolkit Introduction Our tutorial targets ontology modelers and engineers The tutorial provides guidance for the development ontologies and ontology based applications with respect the complete ontology lifecycle will start with introduction variety use cases for applications ontologies including information integration and knowledge management Based these use cases will illustrate typical ontology lifecycle and discuss specific ontology lifecycle activities such ontology development selection and reuse ontology mapping and ontology evolution After short introduction the NeOn toolkit and its functionalities will take closer look how the lifecycle activities are realized using the NeOn toolkit example will demonstrate how support ontology selection and reuse with plug that integrates with the Watson Semantic Web gateway the hands exercises the participants will work practical activities from real world use case the second half the tutorial will demonstrate how extend the functionalities the ontology engineering environment developing NeOn plug support additional lifecycle activity from the initial use case Therefore first provide further insights into the NeOn reference architecture its plug concept and APIs will then demonstrate how develop plug easy follow step step way After that the participants will create their own working plug hands exercise 
5281 en Classification using Discriminative Restricted Boltzmann Machines Recently many applications for Restricted Boltzmann Machines RBMs have been developed for large variety learning problems However RBMs are usually used feature extractors for another learning algorithm provide good initialization for deep feed forward neural network classifiers and are not considered stand alone solution classification problems this paper argue that RBMs provide self contained framework for deriving competitive non linear classifiers present evaluation different learning algorithms for RBMs which aim introducing discriminative component RBM training and improve their performance classifiers This approach simple that RBMs are used directly build classifier rather than stepping stone Finally demonstrate how discriminative RBMs can also successfully employed semi supervised setting 
5285 en Ontology Engineering and Plug Development with the NeOn Toolkit Ontology Lifecycle and Methodology Our tutorial targets ontology modelers and engineers The tutorial provides guidance for the development ontologies and ontology based applications with respect the complete ontology lifecycle will start with introduction variety use cases for applications ontologies including information integration and knowledge management Based these use cases will illustrate typical ontology lifecycle and discuss specific ontology lifecycle activities such ontology development selection and reuse ontology mapping and ontology evolution After short introduction the NeOn toolkit and its functionalities will take closer look how the lifecycle activities are realized using the NeOn toolkit example will demonstrate how support ontology selection and reuse with plug that integrates with the Watson Semantic Web gateway the hands exercises the participants will work practical activities from real world use case the second half the tutorial will demonstrate how extend the functionalities the ontology engineering environment developing NeOn plug support additional lifecycle activity from the initial use case Therefore first provide further insights into the NeOn reference architecture its plug concept and APIs will then demonstrate how develop plug easy follow step step way After that the participants will create their own working plug hands exercise 
5286 en IMS and the Manufacturing Technology Platform Initiative IMS international program support manufacturing among the advanced developed countries Japan USA European Union Korea and Switzerland the first government supported program offer multi lateral global approach research advanced manufacturing IMS continues innovate and reinvent itself order relevant researchers around the globe its latest response researchers input from the IMS Vision Forum IMS has launched the “Manufacturing Technology Platform Initiative” MTP The MTP initiative unique program that threads research and researchers together simple way solve manufacturing challenges today and the future The program not only simplifies the process for organizing research under the IMS banner but also promotes spark new ideas through wider networks that are created MTPs are focused knowledge sharing platforms for researcher groups that are already engaged specific domain There overlap much research that conducted Rather than duplicate work MTP initiative seeks cooperation conduct joint research projects that are already running This ultimately saves resources for the “golden nuggets” their research and finds common solutions manufacturing challenges the process MTP’ also provide opportunity for researchers meet exchange information and generate new ideas for research 
5287 en Ontology Engineering and Plug Development with the NeOn Toolkit Neon toolkit overview Our tutorial targets ontology modelers and engineers The tutorial provides guidance for the development ontologies and ontology based applications with respect the complete ontology lifecycle will start with introduction variety use cases for applications ontologies including information integration and knowledge management Based these use cases will illustrate typical ontology lifecycle and discuss specific ontology lifecycle activities such ontology development selection and reuse ontology mapping and ontology evolution After short introduction the NeOn toolkit and its functionalities will take closer look how the lifecycle activities are realized using the NeOn toolkit example will demonstrate how support ontology selection and reuse with plug that integrates with the Watson Semantic Web gateway the hands exercises the participants will work practical activities from real world use case the second half the tutorial will demonstrate how extend the functionalities the ontology engineering environment developing NeOn plug support additional lifecycle activity from the initial use case Therefore first provide further insights into the NeOn reference architecture its plug concept and APIs will then demonstrate how develop plug easy follow step step way After that the participants will create their own working plug hands exercise 
5288 en Ontology Engineering and Plug Development with the NeOn Toolkit Our tutorial targets ontology modelers and engineers The tutorial provides guidance for the development ontologies and ontology based applications with respect the complete ontology lifecycle will start with introduction variety use cases for applications ontologies including information integration and knowledge management Based these use cases will illustrate typical ontology lifecycle and discuss specific ontology lifecycle activities such ontology development selection and reuse ontology mapping and ontology evolution After short introduction the NeOn toolkit and its functionalities will take closer look how the lifecycle activities are realized using the NeOn toolkit example will demonstrate how support ontology selection and reuse with plug that integrates with the Watson Semantic Web gateway the hands exercises the participants will work practical activities from real world use case the second half the tutorial will demonstrate how extend the functionalities the ontology engineering environment developing NeOn plug support additional lifecycle activity from the initial use case Therefore first provide further insights into the NeOn reference architecture its plug concept and APIs will then demonstrate how develop plug easy follow step step way After that the participants will create their own working plug hands exercise 
5289 en Ontology Engineering and Plug Development with the NeOn Toolkit Our tutorial targets ontology modelers and engineers The tutorial provides guidance for the development ontologies and ontology based applications with respect the complete ontology lifecycle will start with introduction variety use cases for applications ontologies including information integration and knowledge management Based these use cases will illustrate typical ontology lifecycle and discuss specific ontology lifecycle activities such ontology development selection and reuse ontology mapping and ontology evolution After short introduction the NeOn toolkit and its functionalities will take closer look how the lifecycle activities are realized using the NeOn toolkit example will demonstrate how support ontology selection and reuse with plug that integrates with the Watson Semantic Web gateway the hands exercises the participants will work practical activities from real world use case the second half the tutorial will demonstrate how extend the functionalities the ontology engineering environment developing NeOn plug support additional lifecycle activity from the initial use case Therefore first provide further insights into the NeOn reference architecture its plug concept and APIs will then demonstrate how develop plug easy follow step step way After that the participants will create their own working plug hands exercise 
5290 en Ontology Engineering and Plug Development with the NeOn Toolkit Our tutorial targets ontology modelers and engineers The tutorial provides guidance for the development ontologies and ontology based applications with respect the complete ontology lifecycle will start with introduction variety use cases for applications ontologies including information integration and knowledge management Based these use cases will illustrate typical ontology lifecycle and discuss specific ontology lifecycle activities such ontology development selection and reuse ontology mapping and ontology evolution After short introduction the NeOn toolkit and its functionalities will take closer look how the lifecycle activities are realized using the NeOn toolkit example will demonstrate how support ontology selection and reuse with plug that integrates with the Watson Semantic Web gateway the hands exercises the participants will work practical activities from real world use case the second half the tutorial will demonstrate how extend the functionalities the ontology engineering environment developing NeOn plug support additional lifecycle activity from the initial use case Therefore first provide further insights into the NeOn reference architecture its plug concept and APIs will then demonstrate how develop plug easy follow step step way After that the participants will create their own working plug hands exercise 
5291 en Challenges Developing Collaborative Workspaces for Solving Complex Problems This talk was mainly focused industrial human and technical challenges creating collaborative workspaces for sectors such aerospace automotive construction and urban planning initially took the complexity designing aircraft example and illustrated the distributed nature the team need for maintaining large amount information during the lifecycle and the need for assessing various design view points ensure successful delivery This part the talk was mainly focused creating appreciation the need for collaborative tools for design teams work together more effectively The talk then went explain the barriers and challenges terms deploying collaborative technology with engineering organisations Issues such unwillingness adapt change generation gap change lack social cues misunderstandings language unfamiliarity collaborators with one another cultural barriers lack training guidelines and lack accessibility for technology were considered the current barriers deploy collaborative technologies industry was suggested that there are several drivers which might force people overcome those barriers order survive the future Some the examples these barriers are global competition migration design and manufacturing facilities low cost markets Eastern Europe and Far East and new economical powers China India and the need for implementing concurrent engineering achieve low cost and high quality products time The talk then focused the creating collaborative workspace for distributed engineering organsiations first discussed the future scenarios developed the project and discussed the need for innovative technologies for supporting collaboration among stakeholders The scenario presented the talk included DMU scenario aerospace design toilet for disable people design car mirrors and mobile maintenance for aircrafts The following issues were identified the key challenges creating collaborative workspaces for these scenarios Information Sharing Creation Workspaces Support Different Working Styles Virtual Infrastructure Enhanced Sense Presence Physical Environments Communication View Points 
5292 en Transitioning legacy applications ontologies Hands tutorial TAO Bootstrapping Methodology
5293 en Transitioning legacy applications ontologies Hands tutorial Learning Domain Ontologies
5294 en Transitioning legacy applications ontologies Hands tutorial Semantic Annotation and search Software Artefacts
5295 en Transitioning legacy applications ontologies Hands tutorial Transitioning Relational Databases Ontologies
5296 en Transitioning legacy applications ontologies Hands tutorial Heterogeneous Knowledge repositories for storing legacy content requirements scalability and applicability
5297 en Transitioning legacy applications ontologies Hands tutorial
5298 en Living Labs ENoLL Research Challenges What are the challenges basic research still addressed Living Labs and the European Network Living Labs further improve the concept How can the European Union assist this this purpose will present roadmap potential funding instruments the period 2009 2010 proposed Research FP7 Innovation CIP and Regional Funds 
5299 en Semantic Wikis Introduction semantic wikis Semantic Wikis combine properties wikis ease use low technological barrier collaboration easy linking with Semantic Web technologies structuring knowledge linking with background knowledge models Since 2005 when development the first systems startet Semantic Wikis have matured and are now state where they are increasingly deployed even domains outside the Semantic Web community even outside Computer Science Reasons for this are that Semantic Wikis require advanced knowledge and are thus usable also laymen and that Semantic Wikis provide immeadiate benefit over „Non Semantic“ Wikis addition Semantic Wikis are also interesting testbed for the envisioned Semantic Web and associated technologies Wikis have structural similarities the Web whole and hence share many the potential chances and pitfalls This tutorial introduces into the setup and usage the two currently most popular Semantic Wiki systems Semantic MediaWiki and IkeWiki Both systems will have official releases the time the tutorial takes place and both systems are the focus two upcoming funded projects that will start March 2008 
5300 en Semantic Wikis Semantic MediaWiki Semantic Wikis combine properties wikis ease use low technological barrier collaboration easy linking with Semantic Web technologies structuring knowledge linking with background knowledge models Since 2005 when development the first systems startet Semantic Wikis have matured and are now state where they are increasingly deployed even domains outside the Semantic Web community even outside Computer Science Reasons for this are that Semantic Wikis require advanced knowledge and are thus usable also laymen and that Semantic Wikis provide immeadiate benefit over „Non Semantic“ Wikis addition Semantic Wikis are also interesting testbed for the envisioned Semantic Web and associated technologies Wikis have structural similarities the Web whole and hence share many the potential chances and pitfalls This tutorial introduces into the setup and usage the two currently most popular Semantic Wiki systems Semantic MediaWiki and IkeWiki Both systems will have official releases the time the tutorial takes place and both systems are the focus two upcoming funded projects that will start March 2008 
5301 en Semantic Wikis IkeWiki Semantic Wiki for Collaborative Knowledge Management Semantic Wikis combine properties wikis ease use low technological barrier collaboration easy linking with Semantic Web technologies structuring knowledge linking with background knowledge models Since 2005 when development the first systems startet Semantic Wikis have matured and are now state where they are increasingly deployed even domains outside the Semantic Web community even outside Computer Science Reasons for this are that Semantic Wikis require advanced knowledge and are thus usable also laymen and that Semantic Wikis provide immeadiate benefit over „Non Semantic“ Wikis addition Semantic Wikis are also interesting testbed for the envisioned Semantic Web and associated technologies Wikis have structural similarities the Web whole and hence share many the potential chances and pitfalls This tutorial introduces into the setup and usage the two currently most popular Semantic Wiki systems Semantic MediaWiki and IkeWiki Both systems will have official releases the time the tutorial takes place and both systems are the focus two upcoming funded projects that will start March 2008 
5302 en The Future Internet vision from European Research The infrastructure the Internet has and will continually evolve support and enable new services trends and businesses Europe committed take leading role exploring the emerging visions for the Future Internet that will drive the requirements for its underlying network and service infrastructure Also ICT evolving from facet business operation and collection consumer gadgets critical infrastructure that underpins the economy and society parallel the mechanisms for and even the nature innovation are changing The next Work Programme for Research ICT will reflect this unavoidable move towards larger share the economy social activities moving line with need make the Internet capable supporting larger number usages whilst remedying the current deficiencies terms presentation security trust scalability mobility etc All the visions presented would then become use cases relation all encompassing research objective federated under and driving the requirements towards Future Internet Challenge 
5303 en Workshop semantic search Enhancing Semantic Search using Levels Document Representation recent years have witnessed tremendous interest and substantial economic exploitation search technologies the other hand semantic repositories and reasoning engines have advanced state where querying and processing this knowledge can scale realistic scenarios such semantic technologies are now state provide significant contributions problems This workshop intends investigate the potential and the challenges Semantic Search systems Main topics interest the workshop cluster around the areas Tasks and Interaction Paradigms for Semantic Search Query Construction and Resource Modelling for Semantic Search iii Algorithms and Infrastructures for Semantic Search and Evaluation Semantic Search 
5304 en Workshop semantic search The Interaction Between Automatic Annotation and Query Expansion retrieval experiment large cultural heritage archive recent years have witnessed tremendous interest and substantial economic exploitation search technologies the other hand semantic repositories and reasoning engines have advanced state where querying and processing this knowledge can scale realistic scenarios such semantic technologies are now state provide significant contributions problems This workshop intends investigate the potential and the challenges Semantic Search systems Main topics interest the workshop cluster around the areas Tasks and Interaction Paradigms for Semantic Search Query Construction and Resource Modelling for Semantic Search iii Algorithms and Infrastructures for Semantic Search and Evaluation Semantic Search 
5305 en Workshop semantic search Search Natural Language Generation and Record Display Configuration Research Directions Stemming From Digital Library Application Development Experience recent years have witnessed tremendous interest and substantial economic exploitation search technologies the other hand semantic repositories and reasoning engines have advanced state where querying and processing this knowledge can scale realistic scenarios such semantic technologies are now state provide significant contributions problems This workshop intends investigate the potential and the challenges Semantic Search systems Main topics interest the workshop cluster around the areas Tasks and Interaction Paradigms for Semantic Search Query Construction and Resource Modelling for Semantic Search iii Algorithms and Infrastructures for Semantic Search and Evaluation Semantic Search 
5306 en Workshop semantic search Integration semantic metadata and image search engines with engine for patent retrieval recent years have witnessed tremendous interest and substantial economic exploitation search technologies the other hand semantic repositories and reasoning engines have advanced state where querying and processing this knowledge can scale realistic scenarios such semantic technologies are now state provide significant contributions problems This workshop intends investigate the potential and the challenges Semantic Search systems Main topics interest the workshop cluster around the areas Tasks and Interaction Paradigms for Semantic Search Query Construction and Resource Modelling for Semantic Search iii Algorithms and Infrastructures for Semantic Search and Evaluation Semantic Search 
5307 en Workshop semantic search QuiKey recent years have witnessed tremendous interest and substantial economic exploitation search technologies the other hand semantic repositories and reasoning engines have advanced state where querying and processing this knowledge can scale realistic scenarios such semantic technologies are now state provide significant contributions problems This workshop intends investigate the potential and the challenges Semantic Search systems Main topics interest the workshop cluster around the areas Tasks and Interaction Paradigms for Semantic Search Query Construction and Resource Modelling for Semantic Search iii Algorithms and Infrastructures for Semantic Search and Evaluation Semantic Search 
5308 en Workshop semantic search Large Scale Search Improvement needs Large Scale Knowledge recent years have witnessed tremendous interest and substantial economic exploitation search technologies the other hand semantic repositories and reasoning engines have advanced state where querying and processing this knowledge can scale realistic scenarios such semantic technologies are now state provide significant contributions problems This workshop intends investigate the potential and the challenges Semantic Search systems Main topics interest the workshop cluster around the areas Tasks and Interaction Paradigms for Semantic Search Query Construction and Resource Modelling for Semantic Search iii Algorithms and Infrastructures for Semantic Search and Evaluation Semantic Search 
5310 en Workshop semantic search Concept Search Semantics Enabled Syntactic Search recent years have witnessed tremendous interest and substantial economic exploitation search technologies the other hand semantic repositories and reasoning engines have advanced state where querying and processing this knowledge can scale realistic scenarios such semantic technologies are now state provide significant contributions problems This workshop intends investigate the potential and the challenges Semantic Search systems Main topics interest the workshop cluster around the areas Tasks and Interaction Paradigms for Semantic Search Query Construction and Resource Modelling for Semantic Search iii Algorithms and Infrastructures for Semantic Search and Evaluation Semantic Search 
5311 en Workshop semantic search Microsearch Interface for Semantic Search recent years have witnessed tremendous interest and substantial economic exploitation search technologies the other hand semantic repositories and reasoning engines have advanced state where querying and processing this knowledge can scale realistic scenarios such semantic technologies are now state provide significant contributions problems This workshop intends investigate the potential and the challenges Semantic Search systems Main topics interest the workshop cluster around the areas Tasks and Interaction Paradigms for Semantic Search Query Construction and Resource Modelling for Semantic Search iii Algorithms and Infrastructures for Semantic Search and Evaluation Semantic Search 
5312 en Workshop semantic search Exploring the Knowledge Semi Structured Data Sets with Rich Queries recent years have witnessed tremendous interest and substantial economic exploitation search technologies the other hand semantic repositories and reasoning engines have advanced state where querying and processing this knowledge can scale realistic scenarios such semantic technologies are now state provide significant contributions problems This workshop intends investigate the potential and the challenges Semantic Search systems Main topics interest the workshop cluster around the areas Tasks and Interaction Paradigms for Semantic Search Query Construction and Resource Modelling for Semantic Search iii Algorithms and Infrastructures for Semantic Search and Evaluation Semantic Search 
5313 en Collective Semantics Collective Intelligence the Semantic Web Information Retrieval Knowledge Retrieval social network perspective Web has introduced new style information sharing featuring mass user participation social networking heterogeneity data sources and huge scale information and knowledge posing difficulties discovering relevant information The Semantic Web may contribute providing language basis and ontologies support structuring introducing new ways explore the information space This may achieved combining semantics from semantic web resources with structure the sharing platforms tags social acquaintances etc and automatic content analysis tools This workshop targets integration arising from the mining Web information multimedia content and knowledge with help the Semantic Web 
5314 en Collective Semantics Collective Intelligence the Semantic Web Enriching Ontological User Profiles with Tagging History for Multi Domain Recommendations Web has introduced new style information sharing featuring mass user participation social networking heterogeneity data sources and huge scale information and knowledge posing difficulties discovering relevant information The Semantic Web may contribute providing language basis and ontologies support structuring introducing new ways explore the information space This may achieved combining semantics from semantic web resources with structure the sharing platforms tags social acquaintances etc and automatic content analysis tools This workshop targets integration arising from the mining Web information multimedia content and knowledge with help the Semantic Web 
5315 en Collective Semantics Collective Intelligence the Semantic Web From Web Semantic Web Semi Automated Approach Web has introduced new style information sharing featuring mass user participation social networking heterogeneity data sources and huge scale information and knowledge posing difficulties discovering relevant information The Semantic Web may contribute providing language basis and ontologies support structuring introducing new ways explore the information space This may achieved combining semantics from semantic web resources with structure the sharing platforms tags social acquaintances etc and automatic content analysis tools This workshop targets integration arising from the mining Web information multimedia content and knowledge with help the Semantic Web 
5316 en Collective Semantics Collective Intelligence the Semantic Web Use multiple background ontologies ontology matching Web has introduced new style information sharing featuring mass user participation social networking heterogeneity data sources and huge scale information and knowledge posing difficulties discovering relevant information The Semantic Web may contribute providing language basis and ontologies support structuring introducing new ways explore the information space This may achieved combining semantics from semantic web resources with structure the sharing platforms tags social acquaintances etc and automatic content analysis tools This workshop targets integration arising from the mining Web information multimedia content and knowledge with help the Semantic Web 
5317 en Collective Semantics Collective Intelligence the Semantic Web Flickring Our World Web has introduced new style information sharing featuring mass user participation social networking heterogeneity data sources and huge scale information and knowledge posing difficulties discovering relevant information The Semantic Web may contribute providing language basis and ontologies support structuring introducing new ways explore the information space This may achieved combining semantics from semantic web resources with structure the sharing platforms tags social acquaintances etc and automatic content analysis tools This workshop targets integration arising from the mining Web information multimedia content and knowledge with help the Semantic Web 
5318 en Collective Semantics Collective Intelligence the Semantic Web Semantically enriching folksonomies with flor Web has introduced new style information sharing featuring mass user participation social networking heterogeneity data sources and huge scale information and knowledge posing difficulties discovering relevant information The Semantic Web may contribute providing language basis and ontologies support structuring introducing new ways explore the information space This may achieved combining semantics from semantic web resources with structure the sharing platforms tags social acquaintances etc and automatic content analysis tools This workshop targets integration arising from the mining Web information multimedia content and knowledge with help the Semantic Web 
5319 en Workshop Semantic Business Process Management Using Semantics Aid Scenario Based Analysis The degree automation the management the business process space single enterprises and whole value chains still unsatisfying key source problems are representational heterogeneities between the various perspectives and the various stages the life cycles business processes Typical examples are incompatible representations the managerial the perspective the gap between normative modeling for compliance purposes and process execution log data early the 1990s researchers have evaluated the potential using ontologies for improving business process management the context the TOVE project however the impact that work remained beyond initial expectations Since 2005 there now renewed and growing interest exploiting ontologies varying expressivity and focus for advancing the state the art business process management particular ERP centric landscapes The term “Semantic Business Process Management” has been suggested for the described branch research early 2005 paper which now frequently cited the first description the overall vision flagship activity the field the European research project “SUPER” with more than dozen premier industrial and academic partners among them SAP IDS Scheer and IBM the past two years substantial advancement has been made investigating the theoretical and practical branches this vision However the interdisciplinary nature the topic requires tight collaboration researcher from multiple fields namely the BPM SOA Semantic Web Semantic Web services and Economics communities There clear need for annual event which those communities meet debate challenge each others approaches and eventually align their research efforts Due the strong involvement Semantic Web researchers the field ESWC the ideal target venue for this event this workshop want bring together experts from the relevant communities and help reach agreement roadmap for SBPM research aim bundling experiences and prototypes from the successful application Semantic Web technology BPM various industries like automotive engineering chemical and pharmaceutical and services domains The particular focus deriving reusable best practices from such experiences and yield convincing showcases semantic technology 
5320 en Workshop Semantic Business Process Management Bussiness process excellence The degree automation the management the business process space single enterprises and whole value chains still unsatisfying key source problems are representational heterogeneities between the various perspectives and the various stages the life cycles business processes Typical examples are incompatible representations the managerial the perspective the gap between normative modeling for compliance purposes and process execution log data early the 1990s researchers have evaluated the potential using ontologies for improving business process management the context the TOVE project however the impact that work remained beyond initial expectations Since 2005 there now renewed and growing interest exploiting ontologies varying expressivity and focus for advancing the state the art business process management particular ERP centric landscapes The term “Semantic Business Process Management” has been suggested for the described branch research early 2005 paper which now frequently cited the first description the overall vision flagship activity the field the European research project “SUPER” with more than dozen premier industrial and academic partners among them SAP IDS Scheer and IBM the past two years substantial advancement has been made investigating the theoretical and practical branches this vision However the interdisciplinary nature the topic requires tight collaboration researcher from multiple fields namely the BPM SOA Semantic Web Semantic Web services and Economics communities There clear need for annual event which those communities meet debate challenge each others approaches and eventually align their research efforts Due the strong involvement Semantic Web researchers the field ESWC the ideal target venue for this event this workshop want bring together experts from the relevant communities and help reach agreement roadmap for SBPM research aim bundling experiences and prototypes from the successful application Semantic Web technology BPM various industries like automotive engineering chemical and pharmaceutical and services domains The particular focus deriving reusable best practices from such experiences and yield convincing showcases semantic technology 
5321 en Workshop Semantic Business Process Management Semantic business process validation The degree automation the management the business process space single enterprises and whole value chains still unsatisfying key source problems are representational heterogeneities between the various perspectives and the various stages the life cycles business processes Typical examples are incompatible representations the managerial the perspective the gap between normative modeling for compliance purposes and process execution log data early the 1990s researchers have evaluated the potential using ontologies for improving business process management the context the TOVE project however the impact that work remained beyond initial expectations Since 2005 there now renewed and growing interest exploiting ontologies varying expressivity and focus for advancing the state the art business process management particular ERP centric landscapes The term “Semantic Business Process Management” has been suggested for the described branch research early 2005 paper which now frequently cited the first description the overall vision flagship activity the field the European research project “SUPER” with more than dozen premier industrial and academic partners among them SAP IDS Scheer and IBM the past two years substantial advancement has been made investigating the theoretical and practical branches this vision However the interdisciplinary nature the topic requires tight collaboration researcher from multiple fields namely the BPM SOA Semantic Web Semantic Web services and Economics communities There clear need for annual event which those communities meet debate challenge each others approaches and eventually align their research efforts Due the strong involvement Semantic Web researchers the field ESWC the ideal target venue for this event this workshop want bring together experts from the relevant communities and help reach agreement roadmap for SBPM research aim bundling experiences and prototypes from the successful application Semantic Web technology BPM various industries like automotive engineering chemical and pharmaceutical and services domains The particular focus deriving reusable best practices from such experiences and yield convincing showcases semantic technology 
5322 en Workshop Semantic Business Process Management GoMoKIT Towards applicable goal oriented Business Process Modelling approach for knowledge intensive Tasks The degree automation the management the business process space single enterprises and whole value chains still unsatisfying key source problems are representational heterogeneities between the various perspectives and the various stages the life cycles business processes Typical examples are incompatible representations the managerial the perspective the gap between normative modeling for compliance purposes and process execution log data early the 1990s researchers have evaluated the potential using ontologies for improving business process management the context the TOVE project however the impact that work remained beyond initial expectations Since 2005 there now renewed and growing interest exploiting ontologies varying expressivity and focus for advancing the state the art business process management particular ERP centric landscapes The term “Semantic Business Process Management” has been suggested for the described branch research early 2005 paper which now frequently cited the first description the overall vision flagship activity the field the European research project “SUPER” with more than dozen premier industrial and academic partners among them SAP IDS Scheer and IBM the past two years substantial advancement has been made investigating the theoretical and practical branches this vision However the interdisciplinary nature the topic requires tight collaboration researcher from multiple fields namely the BPM SOA Semantic Web Semantic Web services and Economics communities There clear need for annual event which those communities meet debate challenge each others approaches and eventually align their research efforts Due the strong involvement Semantic Web researchers the field ESWC the ideal target venue for this event this workshop want bring together experts from the relevant communities and help reach agreement roadmap for SBPM research aim bundling experiences and prototypes from the successful application Semantic Web technology BPM various industries like automotive engineering chemical and pharmaceutical and services domains The particular focus deriving reusable best practices from such experiences and yield convincing showcases semantic technology 
5323 en Workshop Semantic Business Process Management Organization Structure Description for the Needs Semantic Business Process Management The degree automation the management the business process space single enterprises and whole value chains still unsatisfying key source problems are representational heterogeneities between the various perspectives and the various stages the life cycles business processes Typical examples are incompatible representations the managerial the perspective the gap between normative modeling for compliance purposes and process execution log data early the 1990s researchers have evaluated the potential using ontologies for improving business process management the context the TOVE project however the impact that work remained beyond initial expectations Since 2005 there now renewed and growing interest exploiting ontologies varying expressivity and focus for advancing the state the art business process management particular ERP centric landscapes The term “Semantic Business Process Management” has been suggested for the described branch research early 2005 paper which now frequently cited the first description the overall vision flagship activity the field the European research project “SUPER” with more than dozen premier industrial and academic partners among them SAP IDS Scheer and IBM the past two years substantial advancement has been made investigating the theoretical and practical branches this vision However the interdisciplinary nature the topic requires tight collaboration researcher from multiple fields namely the BPM SOA Semantic Web Semantic Web services and Economics communities There clear need for annual event which those communities meet debate challenge each others approaches and eventually align their research efforts Due the strong involvement Semantic Web researchers the field ESWC the ideal target venue for this event this workshop want bring together experts from the relevant communities and help reach agreement roadmap for SBPM research aim bundling experiences and prototypes from the successful application Semantic Web technology BPM various industries like automotive engineering chemical and pharmaceutical and services domains The particular focus deriving reusable best practices from such experiences and yield convincing showcases semantic technology 
5324 en Workshop Semantic Business Process Management Enterprise Attention Management System The degree automation the management the business process space single enterprises and whole value chains still unsatisfying key source problems are representational heterogeneities between the various perspectives and the various stages the life cycles business processes Typical examples are incompatible representations the managerial the perspective the gap between normative modeling for compliance purposes and process execution log data early the 1990s researchers have evaluated the potential using ontologies for improving business process management the context the TOVE project however the impact that work remained beyond initial expectations Since 2005 there now renewed and growing interest exploiting ontologies varying expressivity and focus for advancing the state the art business process management particular ERP centric landscapes The term “Semantic Business Process Management” has been suggested for the described branch research early 2005 paper which now frequently cited the first description the overall vision flagship activity the field the European research project “SUPER” with more than dozen premier industrial and academic partners among them SAP IDS Scheer and IBM the past two years substantial advancement has been made investigating the theoretical and practical branches this vision However the interdisciplinary nature the topic requires tight collaboration researcher from multiple fields namely the BPM SOA Semantic Web Semantic Web services and Economics communities There clear need for annual event which those communities meet debate challenge each others approaches and eventually align their research efforts Due the strong involvement Semantic Web researchers the field ESWC the ideal target venue for this event this workshop want bring together experts from the relevant communities and help reach agreement roadmap for SBPM research aim bundling experiences and prototypes from the successful application Semantic Web technology BPM various industries like automotive engineering chemical and pharmaceutical and services domains The particular focus deriving reusable best practices from such experiences and yield convincing showcases semantic technology 
5325 en Workshop Semantic Business Process Management Event driven Reactivity Survey and Requirements Analysis The degree automation the management the business process space single enterprises and whole value chains still unsatisfying key source problems are representational heterogeneities between the various perspectives and the various stages the life cycles business processes Typical examples are incompatible representations the managerial the perspective the gap between normative modeling for compliance purposes and process execution log data early the 1990s researchers have evaluated the potential using ontologies for improving business process management the context the TOVE project however the impact that work remained beyond initial expectations Since 2005 there now renewed and growing interest exploiting ontologies varying expressivity and focus for advancing the state the art business process management particular ERP centric landscapes The term “Semantic Business Process Management” has been suggested for the described branch research early 2005 paper which now frequently cited the first description the overall vision flagship activity the field the European research project “SUPER” with more than dozen premier industrial and academic partners among them SAP IDS Scheer and IBM the past two years substantial advancement has been made investigating the theoretical and practical branches this vision However the interdisciplinary nature the topic requires tight collaboration researcher from multiple fields namely the BPM SOA Semantic Web Semantic Web services and Economics communities There clear need for annual event which those communities meet debate challenge each others approaches and eventually align their research efforts Due the strong involvement Semantic Web researchers the field ESWC the ideal target venue for this event this workshop want bring together experts from the relevant communities and help reach agreement roadmap for SBPM research aim bundling experiences and prototypes from the successful application Semantic Web technology BPM various industries like automotive engineering chemical and pharmaceutical and services domains The particular focus deriving reusable best practices from such experiences and yield convincing showcases semantic technology 
5326 en Workshop Semantic Business Process Management Toolkit for Business Process Owners Capture Early System Requirements The degree automation the management the business process space single enterprises and whole value chains still unsatisfying key source problems are representational heterogeneities between the various perspectives and the various stages the life cycles business processes Typical examples are incompatible representations the managerial the perspective the gap between normative modeling for compliance purposes and process execution log data early the 1990s researchers have evaluated the potential using ontologies for improving business process management the context the TOVE project however the impact that work remained beyond initial expectations Since 2005 there now renewed and growing interest exploiting ontologies varying expressivity and focus for advancing the state the art business process management particular ERP centric landscapes The term “Semantic Business Process Management” has been suggested for the described branch research early 2005 paper which now frequently cited the first description the overall vision flagship activity the field the European research project “SUPER” with more than dozen premier industrial and academic partners among them SAP IDS Scheer and IBM the past two years substantial advancement has been made investigating the theoretical and practical branches this vision However the interdisciplinary nature the topic requires tight collaboration researcher from multiple fields namely the BPM SOA Semantic Web Semantic Web services and Economics communities There clear need for annual event which those communities meet debate challenge each others approaches and eventually align their research efforts Due the strong involvement Semantic Web researchers the field ESWC the ideal target venue for this event this workshop want bring together experts from the relevant communities and help reach agreement roadmap for SBPM research aim bundling experiences and prototypes from the successful application Semantic Web technology BPM various industries like automotive engineering chemical and pharmaceutical and services domains The particular focus deriving reusable best practices from such experiences and yield convincing showcases semantic technology 
5328 en Graph Kernels Between Point Clouds Point clouds are sets points two three dimensions Most kernel methods for learning sets points have not yet dealt with the specific geometrical invariances and practical constraints associated with point clouds computer vision and graphics this paper present extensions graph kernels for point clouds which allow use kernel methods for such objects shapes line drawings any three dimensional point clouds order design rich and numerically efficient kernels with few free parameters possible use kernels between covariance matrices and their factorizations graphical models derive polynomial time dynamic programming recursions and present applications recognition handwritten digits and Chinese characters from few training examples 
5329 en Building National Semantic Web Ontology and Ontology Service Infrastructure The FinnONTO Approach
5330 en KonneXSALT First Steps towards Semantic Claim Federation Infrastructure
5331 en Semantic Email Communication Medium for the Social Semantic Desktop
5332 en IVEA Information Visualization Tool for Personalized Exploratory Document Collection Analysis
5333 en Message passing for Graph structured Linear Programs Linear programming relaxations are one promising approach solving the MAP estimation problem Markov random fields particular body past work has focused the first order tree based relaxation for the MAP problem Although variety algorithms with interesting connections this have been proposed date none guaranteed always solve the for any problem this paper develop family provably convergent solvers based proximal minimization schemes using Bregman divergences that exploit the underlying graphical structure and scale well large problems All our algorithms have double loop character with the outer loop corresponding the proximal sequence and inner loop cyclic Bregman divergences used compute each proximal update The inner loop updates are distributed and respect the graph structure and thus can cast message passing algorithms establish various convergence guarantees for our algorithms illustrate their performance medium large scale problems and also present tree based rounding scheme with provable optimality guarantees 
5334 en Combining SAWSDL OWL and UDDI for Semantically Enhanced Web Service Discovery
5335 en Enhancing Workflow with Semantic Description Scientific Intent
5336 en Conceptual Situation Spaces for Semantic Situation Driven Processes
5337 en Fast Incremental Proximity Search Large Graphs this paper investigate two aspects ranking problems large graphs First augment the deterministic pruning algorithm Sarkar and Moore 2007 with sampling techniques compute approximately correct rankings with high probability under random walk based proximity measures query time Second prove some surprising locality properties these proximity measures examining the short term behavior random walks The proposed algorithm can answer queries the fly without caching any information about the entire graph present empirical results 600 000 node author word citation graph from the Citeseer domain single CPU machine where the average query processing time around seconds present quantifiable link prediction tasks most them our techniques outperform Personalized Pagerank well known diffusion based proximity measure 
5338 en Statistical Models for Partial Membership present principled Bayesian framework for modeling partial memberships data points clusters Unlike standard mixture model which assumes that each data point belongs one and only one mixture component cluster partial membership model allows data points have fractional membership multiple clusters Algorithms which assign data points partial memberships clusters can useful for tasks such clustering genes based microarray data and global positioning and orbit determination Our Bayesian Partial Membership Model BPM uses exponential family distributions model each cluster and product these distibtutions with weighted parameters model each datapoint Here the weights correspond the degree which the datapoint belongs each cluster All parameters the BPM are continuous can use Hybrid Monte Carlo perform inference and learning discuss relationships between the BPM and Latent Dirichlet Allocation Mixed Membership models Exponential Family PCA and fuzzy clustering Lastly show some experimental results and discuss nonparametric extensions our model 
5340 en Hierarchical Kernel Stick Breaking Process for Multi Task Image Analysis The kernel stick breaking process KSBP employed segment general imagery imposing the condition that patches small blocks pixels that are spatially proximate are more likely associated with the same cluster segment The number clusters not set priori and inferred from the hierarchical Bayesian model Further KSBP integrated with shared Dirichlet process prior simultaneously model multiple images inferring their inter relationships This latter application may useful for sorting and learning relationships between multiple images The Bayesian inference algorithm based hybrid variational Bayesian analysis and local sampling addition providing details the model and associated inference framework example results are presented for several image analysis problems 
5341 en Rabbit Developing Control Natural Language for Authoring Ontologies
5342 en Data Spectroscopy Learning Mixture Models using Eigenspaces Convolution Operators this paper develop spectral framework for estimating mixture distributions specifically Gaussian mixture models physics spectroscopy often used for the identification substances through their spectrum Treating kernel function light and the sampled data substance the spectrum their interaction eigenvalues and eigenvectors the kernel matrix unveils certain aspects the underlying parametric distribution such the parameters Gaussian mixture Our approach extends the intuitions and analyses underlying the existing spectral techniques such spectral clustering and Kernel Principal Components Analysis KPCA construct algorithms estimate parameters Gaussian mixture models including the number mixture components their means and covariance matrices which are important many practical applications provide theoretical framework and show encouraging experimental results 
5343 en  Natural Language Query Interface Structured Information
5344 en Ontologies and Natural Language Enriching Ontology with Multilingual Information
5345 en Distinguishing Between Instances and Classes the Wikipedia Taxonomy
5346 en Semi supervised Learning Compact Document Representations with Deep Networks Finding good representation text documents crucial document retrieval and classification systems Nowadays the most popular representation simply based vector counts storing the number occurrences each word the document This representation falls short describing the dependence existing between similar words and cannot disambiguate phenomena like synonymy and polysemy words this paper propose algorithm learn text document representations based the recent advances training deep networks This technique can efficiently produce very compact and informative representation document Our experiments compare favorably this algorithm against similar algorithms but producing sparse and binary representations Unlike other models this method trained taking into account both unsupervised and supervised objective show that very advantageous exploit even few labeled samples during training and that can learn extremely compact representations using deep and non linear models 
5347 en Large Scale Manifold Transduction show how the regularizer Transductive Support Vector Machines TSVM can trained stochastic gradient descent for linear models and multi layer architectures The resulting methods can trained online have vastly superior training and testing speed existing TSVM algorithms can encode prior knowledge the network architecture and obtain competitive error rates then propose natural generalization the TSVM loss function that takes into account neighborhood and manifold information directly unifying the two stage Low Density Separation method into single criterion and leading state the art results 
5348 en Semantic Web Technology for Agent Communication Protocols
5349 en Graph Transduction via Alternating Minimization Graph transduction methods label input data learning classification function that regularized exhibit smoothness along graph over labeled and unlabeled samples practice these algorithms are sensitive the initial set labels provided the user For instance classification accuracy drops the training set contains weak labels imbalances exist across label classes the labeled portion the data not chosen random This paper introduces propagation algorithm that more reliably minimizes cost function over both function the graph and binary label matrix The cost function generalizes prior work graph transduction and also introduces node normalization terms for resilience label imbalances demonstrate that global minimization the function intractable but instead provide alternating minimization scheme that incrementally adjusts the function and the labels towards reliable local minimum Unlike prior methods the resulting propagation labels does not prematurely commit erroneous labeling and obtains more consistent labels Experiments are shown for synthetic and real classification tasks including digit and text recognition substantial improvement accuracy compared state the art semi supervised methods achieved The advantage are even more dramatic when labeled instances are limited 
5350 en xOperator Interconnecting the Semantic Web and Instant Messaging Networks
5351 en Stability Transductive Regression Algorithms This paper uses the notion algorithmic stability derive novel generalization bounds for several families transductive regression algorithms both using convexity and closed form solutions Our analysis helps compare the stability these algorithms suggests that several existing algorithms might not stable but prescribes technique make them stable also reports the results experiments with local transductive regression demonstrating the benefit our stability bounds for model selection particular for determining the radius the local neighborhood used the algorithm 
5352 en  Ontology for Software Models and its Practical Implications for Semantic Web Reasoning
5353 en  Core Ontology for Business Process Analysis
5354 en  Multi View Active Learning and the Combination with Semi Supervised Learning Multi view learning has become hot topic during the past few years this paper first characterize the sample complexity multi view active learning Under the expansion assumption get exponential improvement the sample complexity from usual Õ Õ log requiring neither strong assumption data distribution such the data distributed uniformly over the unit sphere nor strong assumption hypothesis class such linear separators through the origin also give upper bound the error rate when the expansion assumption does not hold Then analyze the combination multi view active learning and semi supervised learning and get further improvement the sample complexity Finally study the empirical behavior the two paradigms which verifies that the combination multi view active learning and semi supervised learning efficient 
5355 en Combining Fact and Document Retrieval with Spreading Activation for Semantic Desktop Search
5356 en Hybrid Search Effectively Combining Keywords and Semantic Searches
5357 en Q2Semantic Lightweight Keyword Interface Semantic Search
5358 en Estimating Labels from Label Proportions Consider the following problem given sets unlabeled observations each set with known label proportions predict the labels another set observations also with known label proportions This problem appears areas like commerce spam filtering and improper content detection present consistent estimators which can reconstruct the correct labels with high probability uniform convergence sense Experiments show that our method works well practice 
5359 en Query Answering and Ontology Population Inductive Approach
5360 en Instance Based Clustering Semantic Web Resources
5361 en Conceptual Clustering and its Application Concept Drift and Novelty Detection
5363 en  Entity Name System ENS for the Semantic Web
5364 en Semantic Sitemaps Efficient and Flexible Access Datasets the Semantic Web
5365 en Self taught Clustering This paper focuses new clustering task called self taught clustering Self taught clustering instance unsupervised transfer learning which aims clustering small collection target unlabeled data with the help large amount auxiliary unlabeled data The target and auxiliary data can different topic distribution show that even when the target data are not sufficient allow effective learning high quality feature representation possible learn the useful features with the help the auxiliary data which the target data can clustered effectively propose clustering based self taught clustering algorithm tackle this problem clustering the target and auxiliary data simultaneously allow the feature representation from the auxiliary data influence the target data through common set features Under the new data representation clustering the target data can improved Our experiments image clustering show that our algorithm can greatly outperform several state the art clustering methods when utilizing irrelevant unlabeled auxiliary data 
5366 en  Storage Policies for Semantic Web Repositories that Support Versioning
5367 en Spectral Clustering with Inconsistent Advice Clustering with advice often known constrained clustering has been recent focus the data mining community Success has been achieved incorporating advice into the means framework well spectral clustering Although the theory community has explored inconsistent advice has not yet been incorporated into spectral clustering Extending work Bie and Cristianini set out framework for finding minimum normalized cuts subject inconsistent advice Our results suggest that the framework will successful many situations 
5368 en Putting Ontology Alignment Context Usage Scenarios Deployment and Evaluation Library Case
5369 en Two Variations Ontology Alignment Methodological Issues
5370 en CSR Discovering Subsumption Relations for the Alignment Ontologies
5371 en Pairwise Constraint Propagation Semidefinite Programming for Semi Supervised Classification consider the general problem learning from pairwise constraints and unlabeled data The pairwise constraints specify whether two objects belong the same class not known the must link constraints and the cannot link constraints propose learn mapping that smooth over the data graph and maps the data onto unit hypersphere where two must link objects are mapped the same point while two cannot link objects are mapped orthogonal show that such mapping can achieved formulating semidefinite programming problem which convex and can solved globally Our approach can effectively propagate pairwise constraints the whole data set can directly applied multi class classification and can handle data labels pairwise constraints mixture them unified framework Promising experimental results are presented for classification tasks variety synthetic and real data sets 
5372 en Semantic Reasoning Path New Possibilities Personalization
5373 en OntoGame Weaving the Semantic Web Online Games
5374 en  User Interface Adaptation Architecture for Rich Internet Applications
5375 en Listwise Approach Learning Rank Theory and Algorithm This paper aims conduct comprehensive study the listwise approach learning rank The listwise approach learns ranking function taking individual lists instances and minimizing loss function defined two lists one predicted result and the other ground truth Existing work the approach mainly focused the development new algorithms methods such RankCosine and ListNet have been proposed and better performances them have also been observed Unfortunately the underlying theory was not sufficiently studied far amend the problem this paper proposes conducting theoretical analysis learning rank algorithms through investigation the properties the loss functions including consistency soundness continuity differentiability convexity and efficiency sufficient condition consistency for ranking given which seems the first such result obtained related research The paper then conducts analysis three loss functions likelihood loss cosine loss and cross entropy loss The latter two were used RankCosine and ListNet respectively The use likelihood loss leads the development new listwise method called ListMLE whose loss function offers better properties Experimental results have also verified the correctness the theoretical results obtained the paper 
5376 en Query Level Stability and Generalization Learning Rank This paper concerned with the generalization ability learning rank algorithms for information retrieval point out that the key for addressing the learning problem look from the viewpoint query and give formulation learning rank for based the consideration define number new concepts within the framework including query level loss query level risk and query level stability then analyze the generalization ability learning rank algorithms giving query level generalization bounds them using query level stability tool Such analysis very helpful for derive more advanced algorithms for apply the proposed theory the existing algorithms Ranking SVM and IRSVM Experimental results the two algorithms verify the correctness the theoretical analysis 
5377 en Predicting Diverse Subsets Using Structural SVMs many retrieval tasks one important goal involves retrieving diverse set results documents covering wide range topics for search query First all this reduces redundancy effectively presenting more information with the presented results Secondly search queries are often ambiguous some level For example the query “Jaguar” can refer many different topics such the car the feline set documents with high topic diversity ensures that fewer users abandon the query because none the results are relevant them Unlike existing approaches learning retrieval functions present method that explicitly trains diversify results particular formulate the learning problem predicting diverse subset and derive training algorithm based structural SVMs 
5378 en Learning Diverse Rankings with Multi Armed Bandits Algorithms for learning rank Web documents usually assume document relevance independent other documents This leads learned ranking functions that produce rankings with redundant results contrast user studies have shown that diversity high ranks often preferred present two new learning algorithms that directly learn diverse ranking documents based users clicking behavior show that these algorithms minimize abandonment alternatively maximize the probability that relevant document found the top positions ranking show that one our algorithms asymptotically achieves the best possible payoff obtainable polynomial time even user interests change The other performs better empirically when user interests are static and still theoretically near optimal that case 
5379 en Confidence Weighted Linear Classification introduce confidence weighted linear classifiers new class algorithms that maintain confidence information about classifier parameters Learning this framework updates parameters estimating weights and increasing model confidence investigate new online algorithm that maintains Gaussian distribution over weight vectors updating the mean and variance the model with each instance Empirical evaluation range NLP tasks show that our algorithm improves over other state the art online and batch methods learns faster the online setting and lends itself better classifier combination after parallel training 
5380 en The Projectron Bounded Kernel Based Perceptron present discriminative online algorithm with bounded memory growth which based the kernel based Perceptron Generally the required memory the kernel based Perceptron for storing the online hypothesis not bounded Previous work has been focused discarding part the instances order keep the memory bounded the proposed algorithm the instances are not discarded but projected onto the space spanned the previous online hypothesis derive relative mistake bound and compare our algorithm both analytically and empirically the state the art Forgetron algorithm Dekel 2007 The first variant our algorithm called Projectron outperforms the Forgetron The second variant called Projectron outperforms even the Perceptron 
5381 en Efficient Bandit Algorithms for Online Multiclass Prediction This paper introduces the Banditron variant the Perceptron for the multiclass bandit setting The multiclass bandit setting models wide range practical supervised learning applications where the learner only receives partial feedback referred bandit feedback the spirit multi armed bandit models with respect the true label many web applications users often only provide positive click feedback which does not necessarily fully disclose true label The Banditron has the ability learn multiclass classification setting with the bandit feedback which only reveals whether not the prediction made the algorithm was correct not but does not necessarily reveal the true label provide relative mistake bounds which show how the Banditron enjoys favorable performance and our experiments demonstrate the practicality the algorithm Furthermore this paper pays close attention the important special case when the data linearly separable problem which has been exhaustively studied the full information setting yet novel the bandit setting 
5382 en  Dual Coordinate Descent Method for Large scale Linear SVM many applications data appear with huge number instances well features Linear Support Vector Machines SVM one the most popular tools deal with such large scale sparse data This paper presents novel dual coordinate descent method for linear SVM with and loss functions The proposed method simple and reaches epsilon accurate solution log epsilon iterations Experiments indicate that our method much faster than state the art solvers such Pegasos Tron svmperf and recent primal coordinate descent implementation 
5383 en Optimized Cutting Plane Algorithm for Support Vector Machines have developed new Linear Support Vector Machine SVM training algorithm called OCAS Its computational effort scales linearly with the sample size extensive empirical evaluation OCAS significantly outperforms current state the art SVM solvers like SVMLight SVMPerf and BMRM achieving speedups over 000 some datasets over SVMLight and over SVMPerf while obtaining the same precise Support Vector solution OCAS even the early optimization steps shows often faster convergence than the far this domain prevailing approximative methods SGD and Pegasos Effectively parallelizing OCAS were able train dataset size million examples itself about 32GB size just 671 seconds competing string kernel SVM required 484 seconds train million examples sub sampled from this dataset 
5384 en Fast Support Vector Machine Training and Classification Graphics Processors Recent developments programmable highly parallel Graphics Processing Units GPUs have enabled high performance implementations machine learning algorithms describe solver for Support Vector Machine training using Platt Sequential Minimal Optimization algorithm and adaptive first and second order working set selection heuristic which achieves speedups 35x over LIBSVM running traditional processor also present GPU based system for SVM classification which achieves speedups 138x over LibSVM 24x over our own CPU based SVM classifier 
5385 en Improved Nystrom Low Rank Approximation and Error Analysis Low rank matrix approximation effective tool alleviating the memory and computational burdens kernel methods and sampling the mainstream such algorithms has drawn considerable attention both theory and practice This paper presents detailed studies the Nystrom sampling scheme and particular error analysis that directly relates the Nystrom approximation quality with the encoding powers the landmark points summarizing the data The resultant error bound suggests simple and efficient sampling scheme the means clustering algorithm for Nystrom low rank approximation compare with state the art approaches that range from greedy schemes probabilistic sampling Our algorithm achieves significant performance gains number supervised unsupervised learning tasks including kernel PCA and least squares SVM 
5386 en Polyhedral Classifier for Target Detection Case Study this study introduce novel algorithm for learning polyhedron describe the target class The proposed approach takes advantage the limited subclass information made available for the negative samples and jointly optimizes multiple hyperplane classifiers each which designed classify positive samples from subclass the negative samples The flat faces the polyhedron provides robustness whereas multiple faces contributes the flexibility required deal with complex datasets Apart from improving the prediction accuracy the system the proposed polyhedral classifier also provides run time speedups product when executed cascaded framework real time introduce the Computer Aided Detection for Colon Cancer case study and evaluate the performance the proposed technique real world Colon dataset both terms prediction accuracy and online execution speed also compare the proposed technique against some benchmark classifiers 
5388 en Time Dependent Stick Breaking Processes The stick breaking construction the Dirichlet process has been popular starting point for many dependent nonparametric processes This talk considers temporal version the Order Based Dependent Dirichlet Process which can extended more general stick breaking marginal processes Interestingly the simplest constructions lead marginal Dirichlet and Poisson Dirichlet processes Usefully the first process also has “Chinese restaurant” type representation which will described Applications time dependent mixture modelling will presented 
5389 en The Infinite Factorial Hidden Markov Model The nite factorial hidden Markov model non parametric extension the factorial hidden Markov model Our model nes probability distribution over nite num ber independent binary hidden Markov chains which together produce observable sequence random variables Central our model new type non parametric prior distribution inspired the Indian Buf fet Process which call the Markov Indian Process 
5390 en Dynamic Non Parametric Mixture Models and The Recurrent Chinese Restaurant Process Dirichlet process mixture models provide °exible Bayesian framework for estimating distribution ¯nite mixture simpler distributions that could identify latent classes the data However the full exchangeability assumption they employ makes them unappealing choice for modeling longitudinal data such text audio and video streams that can arrive accumulate epochs where data points inside the same epoch can assumed fully exchangeable whereas across the epochs both the structure the number mixture components and the parameteriza tions the data distributions can evolve and therefore unexchangeable 
5392 en Nonparametric Bayesian Density Modeling with Gaussian Processes present the Gaussian Process Density Sampler GPDS exchangeable generative model for use nonparametric Bayesian density estimation Samples drawn from the GPDS are consistent with exact independent samples from fixed density function that transformation function drawn from Gaussian process prior Our formulation allows infer unknown density from data using Markov chain Monte Carlo which gives samples from the posterior distribution over density functions and from the predictive distribution data space describe two such MCMC methods Both methods also allow inference the hyperparameters the Gaussian process 
5393 en Topic Models Conditioned Arbitrary Features with Dirichlet multinomial Regression Although fully generative models have been successfully used model the contents text documents they are often awkward apply combinations text data and document metadata this paper propose Dirichlet multinomial regression DMR topic model that includes log linear prior document topic distributions that function observed features the document such author publication venue references and dates show that selecting appropriate features DMR topic models can meet exceed the performance several previously published topic models designed for specific data 
5394 en Latent Topic Models for Hypertext Latent topic models have been successfully applied unsupervised topic discovery technique large document collections With the proliferation hypertext document collection such the Internet there has also been great interest extending these approaches hypertext These approaches typically model links analogous fashion how they model words the document link occurrence matrix modeled the same way that the document word occurrence matrix modeled standard topic models this paper present probabilistic generative model for hypertext document collections that explicitly models the generation links Specifically links from word document depend directly how frequent the topic addition the degree show how perform learning this model efficiently not modeling links analogous words end using far fewer free parameters and obtain better link prediction results 
5395 en Flexible Priors for Exemplar based Clustering Exemplar based clustering methods have been shown produce state the art results number synthetic and real world clustering problems They are appealing because they offer computational benefits over latent mean models and can handle arbitrary pairwise similarity measures between data points However when trying recover underlying structure clustering problems tailored similarity measures are often not enough also desire control over the distribution cluster sizes Priors such Dirichlet process priors allow the number clusters unspecified while expressing priors over data partitions our knowledge they have not been applied exemplar based models show how incorporate priors including Dirichlet process priors into the recently introduced affinity propagation algorithm develop efficient max product belief propagation algorithm for our new model and demonstrate experimentally how the expanded range clustering priors allows better recover true clusterings situations where have some information about the generating process 
5397 en The Catch Phenomenon Bayesian Inference Standard Bayesian model selection averaging sometimes learn too slowly there exist other learning methods that lead better predictions based less data give novel analysis this catch phenomenon Based this analysis propose the switching method modification Bayesian model averaging that never learns slower but sometimes learns much faster than Bayes The method related expert tracking algorithms developed the COLT literature and has time complexity comparable Bayes The switching method resolves long standing debate statistics known the AIC BIC dilemma model selection averaging methods like BIC Bayes and MDL are consistent they eventually infer the correct model but when used for prediction the rate which predictions improve can suboptimal Methods like AIC and leave one out cross validation are inconsistent but typically converge the optimal rate Our method the first that provably achieves both Experiments with nonparametric density estimation confirm that these large sample theoretical results also hold practice small samples 
5398 en Convergent Message Passing Algorithms for Inference over General Graphs with Convex Free Energies Inference problems graphical models can represented constrained optimization free energy function known that when the Bethe free energy used the fixed points the belief propagation algorithm correspond the local minima the free energy However fails converge many cases interest Moreover the Bethe free energy non convex for graphical models with cycles thus introducing great difficulty deriving efficient algorithms for finding local minima the free energy for general graphs this paper introduce two efficient like algorithms one sequential and the other parallel that are guaranteed converge the global minimum for any graph over the class energies known ”convex free energies” addition propose efficient heuristic for setting the parameters the convex free energy based the structure the graph 
5399 en Tightening Relaxations for MAP using Message Passing Linear Programming relaxations have become powerful tools for finding the most probable MAP configuration graphical models These relaxations can solved efficiently using message passing algorithms such belief propagation and when the relaxationis tight provably find the MAP configuration The standard relaxation not tight enough many real world problems however and this has lead the use higher order cluster based relaxations The computational cost increases exponentially with the size the clusters and limits the number and type clusters can use propose solve the cluster selection problem monotonically the dual iteratively selecting clusters with guaranteed improvement and quickly solving with the added clusters reusing the existing solution Our dual message passing algorithm finds the MAP configuration protein side chain placement protein design and stereo problems cases where the standard relaxation fails 
5400 en Learning Convex Inference Marginals Graphical models trained using maximum likelihood are common tool for probabilistic inference marginal distributions However this approach suffers difficulties when either the inference process the model approximate this paper the inference process first defined the minimization convex function inspired free energy approximations Learning then done directly terms the performance the inference process univariate marginal prediction The main novelty that this direct minimization empirical risk where the risk measures the accuracy predicted marginals 
5401 en Combinatorial Prediction Markets Several hundred organizations are now using prediction markets forecast sales project completion dates and more This number has been doubling annually for several years Most however are simple prediction markets with one market per number forecast and several traders per market contrast single combinatorial prediction market lets few traders manage entire combinatorial space forecasts For millions numbers less implementation easy and lab experiments have confirmed feasibility and accuracy For larger spaces however many open computational problems remain 
5402 en Learning and Solving Many Player Games through Cluster Based Representation addressing the challenge exponential scaling with the number agents adopt cluster based representation approximately solve asymmetric games very many players cluster groups together agents with similar “strategic view” the game learn the clustered approximation from data consisting strategy profiles and payoffs which may obtained from observations play access simulator Using our clustering construct reduced “twins” game which each cluster associated with two players the reduced game This allows our representation individually responsive because align the interests every individual agent with the strategy its cluster Our approach provides agents with higher payoffs and lower regret average than model free methods well previous cluster based methods and requires only few observations for learning successful The “twins” approach shown important component providing these low regret approximations 
5403 en  Polynomial time Nash Equilibrium Algorithm for Repeated Stochastic Games present polynomial time algorithm that always finds approximate Nash equilibrium for repeated two player stochastic games The algorithm exploits the folk theorem derive strategy profile that forms equilibrium buttressing mutually beneficial behavior with threats where possible One component our algorithm efficiently searches for approximation the egalitarian point the fairest pareto efficient solution The paper concludes applying the algorithm set grid games illustrate typical solutions the algorithm finds These solutions compare very favorably those found competing algorithms resulting strategies with higher social welfare well guaranteed computational efficiency 
5404 en Strategy Selection Influence Diagrams using Imprecise Probabilities This paper describes new algorithm solve the decision making problem Influence Diagrams based algorithms for credal networks Decision nodes are associated imprecise probability distributions and reformulation introduced that finds the global maximum strategy with respect the expected utility work with Limited Memory Influence Diagrams which generalize most Influence Diagram proposals and handle simultaneous decisions Besides the global optimum method explore anytime approximate solution with guaranteed maximum error and show that imprecise probabilities are handled straightforward way Complexity issues and experiments with random diagrams and effects based military planning problem are discussed 
5405 en Multi View Learning over Structured and Non Identical Outputs many machine learning problems labeled training data limited but unlabeled data ample Some these problems have instances that can factored into multiple views each which nearly sufficient determining the correct labels this paper present new algorithm for probabilistic multi view learning which uses the idea stochastic agreement between views regularization Our algorithm works structured and unstructured problems and easily generalizes partial agreement scenarios For the full agreement case our algorithm minimizes the Bhattacharyya distance between the models each view and performs better than CoBoosting and two view Perceptron several flat and structured classification problems 
5406 en Multi View Learning the Presence View Disagreement Traditional multi view learning approaches suffer the presence view disagreement when samples each view not belong the same class due view corruption occlusion other noise processes this paper present multi view learning approach that uses conditional entropy criterion detect view disagreement Once detected samples with view disagreement are filtered and standard multi view learning methods can successfully applied the remaining samples Experimental evaluation synthetic and audio visual databases demonstrates that the detection and filtering view disagreement considerably increases the performance traditional multi view learning approaches 
5407 en Convex Point Estimation using Undirected Bayesian Transfer Hierarchies When related learning tasks are naturally arranged hierarchy appealing approach for coping with scarcity instances that transfer learning using hierarchical Bayes framework fully Bayesian computations can difficult and computationally demanding often desirable use posterior point estimates that facilitate relatively efficient prediction However the hierarchical Bayes framework does not always lend itself naturally this maximum posteriori goal this work propose undirected reformulation hierarchical Bayes that relies priors the form similarity measures introduce the notion “degree transfer” weights components these similarity measures and show how they can automatically learned within joint probabilistic framework Importantly our reformulation results convex objective for many learning problems thus facilitating optimal posterior point estimation using standard optimization techniques addition longer require proper priors allowing for flexible and straightforward specification joint distributions over transfer hierarchies show that our framework effective for learning models that are part transfer hierarchies for two real life tasks object shape modeling using Gaussian density estimation and document classification 
5408 en Concentration Inequalities this talk concentration inequalities mean inequalities that bound the deviations function independent random variables from its mean Due their generality and elegance many such results have served standard tools variety areas including statistical learning theory probabilistic combinatorics and the geometry Banach spaces illustrate some the basic ideas start showing simple ways bounding the variance general function several independent random variables show how use these inequalities few key quantities statistical learning theory the past two decades several techniques have been introduced improve such variance inequalities exponential tail inequalities focus particularly elegant and effective method the called entropy method based logarithmic Sobolev inequalities and their modifications Similar ideas appear variety areas mathematics including discrete and Gaussian isoperimetric problems and estimation mixing times Markov chains intend shed some light some these connections particular mention some closely related results influences variables Boolean functions phase transitions and threshold phenomena 
5409 en CORL Continuous state Offset dynamics Reinforcement Learner Continuous state spaces and stochastic switching dynamics characterize number rich real world domains such robot navigation across varying terrain describe reinforcement learning algorithm for learning these domains and prove for certain environments the algorithm probably approximately correct with sample complexity that scales polynomially with the state space dimension Unfortunately optimal planning techniques exist general for such problems instead use fitted value iteration solve the learned MDP and include the error due approximate planning our bounds Finally report experiment using robotic car driving over varying terrain demonstrate that these dynamics representations adequately capture real world dynamics and that our algorithm can used efficiently solve such problems 
5410 en Partitioned Linear Programming Approximations for MDPs Approximate linear programming ALP efficient approach solving large factored Markov decision processes MDPs The main idea the method approximate the optimal value function set basis functions and optimize their weights linear programming This paper proposes new ALP approximation Comparing the standard ALP formulation decompose the constraint space into set low dimensional spaces This structure allows for solving the new efficiently particular the constraints the can satisfied compact form without exponential dependence the tree width ALP constraints study both practical and theoretical aspects the proposed approach Moreover demonstrate its scale potential MDP with more than 2100 states 
5411 en Hierarchical POMDP Controller Optimization Likelihood Maximization Planning can often simplified decomposing the task into smaller tasks arranged hierarchically Charlin recently showed that the hierarchy discovery problem can framed non convex optimization problem However the inherent computational difficulty solving such optimization problem makes hard scale real world problems another line research Toussaint developed method solve planning problems maximum likelihood estimation this paper show how the hierarchy discovery problem partially observable domains can tackled using similar maximum likelihood approach Our technique first transforms the problem into dynamic Bayesian network through which hierarchical structure can naturally discovered while optimizing the policy Experimental results demonstrate that this approach scales better than previous techniques based non convex optimization 
5412 en Unsupervised Learning for Natural Language Processing Given the abundance text data unsupervised approaches are very appealing for natural language processing present three latent variable systems which achieve state the art results domains previously dominated fully supervised systems For syntactic parsing describe grammar induction technique which begins with coarse syntactic structures and iteratively refines them unsupervised fashion The resulting coarse fine grammars admit efficient coarse fine inference schemes and have produced the best parsing results variety languages For reference resolution describe discourse model which entities are shared across documents using hierarchical Dirichlet process each document entities are repeatedly rendered into mention strings sequential model attentional state and anaphoric constraint Despite being fully unsupervised this approach competitive with the best supervised approaches Finally for machine translation present model which learns translation lexicons from non parallel corpora Alignments between word types are modeled prior over matchings Given any fixed alignment joint density over word vectors derives from probabilistic canonical correlation analysis This approach capable discovering high precision translations even when the underlying corpora and languages are divergent 
5413 en Explanation Trees for Causal Bayesian Networks Bayesian networks can used extract explanations about the observed state subset variables this paper explicate the desiderata explanation and confront them with the concept explanation proposed existing methods The necessity taking into account causal approaches when causal graph available discussed then introduce causal explanation trees based the construction explanation trees using the measure causal information flow and Polani 2006 This approach compared several other methods known networks 
5414 en  stochastic programming perspective nonparametric Bayes use Church Turing universal language for stochastic generative processes and the probability distributions they induce study and extend several objects nonparametric Bayesian statistics connect exchangeability and Finetti measures with notions purity and closures from functional programming exploit delayed evaluation provide finite machine executable representations for various nonparametric Bayesian objects relate common uses the Dirichlet process stochastic generalization memoization and use this abstraction compactly describe and extend several nonparametric models Finally briefly discuss issues computability and inference 
5415 en Identifying Optimal Sequential Decisions consider conditions that allow find optimal strategy for sequential decisions from given data situation For the case where all interventions are unconditional atomic identifiability has been discussed Pearl Robins 1995 argue here that optimal strategy must conditional take the information available each decision point into account show that the identification optimal sequential decision strategy more restrictive the sense that conditional interventions might not always identified when atomic interventions are further demonstrate that simple graphical criterion for the identifiability optimal strategy can given 
5416 en Identifying Dynamic Sequential Plans address the problem identifying dynamic sequential plans the framework causal Bayesian networks and show that the problem reduced identifying causal effects for which there are complete identification algorithms available the literature 
5417 en Learning the Bayesian Network Structure Dirichlet Prior versus Data the Bayesian approach structure learning graphical models the equivalent sample size ESS the Dirichlet prior over the model parameters was recently shown have important effect the maximum posteriori estimate the Bayesian network structure our first contribution theoretically analyze the case large ESS values which complements previous work among other results find that the presence edge Bayesian network favored over its absence even both the Dirichlet prior and the data imply independence long the conditional empirical distribution notably different from uniform our second contribution focus realistic ESS values and provide analytical approximation the ‘optimal’ ESS value predictive sense its accuracy also validated experimentally this approximation provides understanding which properties the data have the main effect determining the ‘optimal’ ESS value 
5418 en Discovering Cyclic Causal Models Independent Components Analysis generalize Shimizu 2006 ICA based approach for discovering linear non Gaussian acyclic LiNGAM Structural Equation Models SEMs from causally sufficient continuous valued observational data relaxing the assumption that the generating SEM graph acyclic solve the more general problem linear non Gaussian LiNG SEM discovery LiNG discovery algorithms output the distribution equivalence class SEMs which the large sample limit represents the population distribution apply LiNG discovery algorithm simulated data Finally give sufficient conditions under which only one the SEMs the output class stable 
5419 en Constrained Approximate Maximum Entropy Learning Markov Random Fields Parameter estimation Markov random fields MRFs difficult task which inference over the network run the inner loop gradient descent procedure Replacing exact inference with approximate methods such loopy belief propagation LBP can suffer from poor convergence this paper provide different approach for combining MRF learning and Bethe approximation consider the dual maximum likelihood Markov network learning maximizing entropy with moment matching constraints and then approximate both the objective and the constraints the resulting optimization problem Unlike previous work along these lines Teh Welling 2003 our formulation allows parameter sharing between features general log linear model parameter regularization and conditional training show that piecewise training Sutton McCallum 2005 very restricted special case this formulation study two optimization strategies one based single convex approximation and one that uses repeated convex approximations show results several real world networks that demonstrate that these algorithms can significantly outperform learning with loopy and piecewise Our results also provide framework for analyzing the trade offs different relaxations the entropy objective and the constraints 
5422 en Covariate Dependent Random Partitions propose model for covariate dependent clustering develop probability model for random partitions that indexed covariates The motivating application inference for clinical trial part the desired inference wish define clusters patients Defining prior probability model for cluster memberships should include regression patient baseline covariates build product partition models PPM define extension the PPM include the desired regression This achieved including the cohesion function new factor that increases the probability experimental units with similar covariates included the same cluster discuss implementations suitable for continuous categorical count and ordinal covariates 
5423 en The Mondrian Process describe novel stochastic process that can used construct multidimensional generalization the stick breaking process and which related the classic stick breaking process described Sethuraman 1994 one dimension describe how the process can applied relational data modeling using the Finetti representation for infinitely and partially exchangeable arrays 
5424 en  introduction Levy processes with financial modelling mind this talk will take some care introduce the general class Levy processes well the most relevant parametric families will explain how these can used for modelling purposes directly driving processes for more general stochastic processes application discuss stochastic volatility modelling and some questions arising when doing inference the presence jumps based joint work with Ole Barndorff Nielsen and Neil Shephard 
5425 en Variational filtering generated coordinates motion This presentation reviews variational treatment dynamic models that furnishes time dependent conditional densities the path trajectory system states and the time independent densities its parameters These obtain maximizing variational action with respect conditional densities under fixed form assumption about their form The action path integral free energy represents lower bound the model’ log evidence marginal likelihood required for model selection and averaging This approach rests formulating the optimization generalized ordinates motion The resulting scheme can used for line Bayesian inversion nonlinear dynamic causal models and shown outperform existing approaches such Kalman and particle filtering Furthermore provides for dual and triple inference system’ states parameters and hyperparameters using exactly the same principles Free form Variational filtering and fixed form Dynamic Expectation Maximization variants the scheme will demonstrated using simulated bird song and real data from hemodynamic systems studied neuroimaging 
5426 en Density estimation initial conditions for populations dynamical systems computational approach that estimates the probability density the initial conditions for population dynamical systems presented Its scope extends family problems which includes the described protein degradation example permits the formulation hypotheses that can justify the discrepancy between single cell and population dynamics The approach based preprocessing regression that permits the incorporation domain knowledge This knowledge given under the form prior information about the trajectory single cell and about the dynamical behavior the noisy observations similar problems additional knowledge can available prior over functions This advantage not possible with purely data driven approaches and when existing must exploited systems biology the chemical reactions are often understood quite well but complex systems networks are still under investigation However integration prior knowledge comes with high cost and general feasible approaches compute inference must approximated 
5427 en Sparse Multi output Gaussian Processes this work propose sparse approximation for the full covariance matrix involved the multiple output convolution process exploit the fact that each the outputs conditional independent all others given the input process This leads approximation for the covariance matrix which keeps intact the covariances each output and approximates the cross covariances terms with low rank matrix has similar form the Partially Independent Training Conditional PITC approximation for single output 
5428 en Estimating the probability rare climate events inference from large deterministic computer code Anthropogenic emission greenhouse gases means that vital that can predict future climates One aspect such possible future climates are called low probability high impact events These include things like the collapse ice sheets that hope are unlikely but they did happen would have very major impacts the climate The only way can address these problems through computer models not have any data that applicable Such models are very large and complex and require huge amounts computer time Thus simple Monte Carlo methods inference cannot used Instead use statistical methods investigate the properties the model These are based around the concept emulator emulator statistical approximation the model output given the model inputs and includes measure its own uncertainty use Gaussian processes for our emulators but principle other functions could used Having built emulator can use perform our inference rather than the computer model itself will illustrate these methods estimate the risk the collapse the thermohaline circulation the North Atlantic and discuss future improvements 
5429 en Approximate inference for continuous time Markov processes Continuous time Markov processes such jump processes and diffusions play important role the modelling dynamical systems many scientific areas variety applications the stochastic state the system function time not directly observed One has only access set nolsy observations taken discrete set times The problem then infer the unknown state path best possible addition model parameters like diffusion constants transition rates may also unknown and have estimated from the data While fairly straightforward present theoretical solution these estimation problems practical solution terms PDEs Monte Carlo sampling can very time consuming and one looking for efficient approximations will discuss approximate solutions this problem such variational approximations the probability measure over paths and weak noise expansions 
5430 en Variational inference and learning for continuous time nonlinear state space models Inference continuous time stochastic dynamical models challenging problem complement existing sampling based methods variational methods have recently been developed for this problem Our approach solves the variational continuous time inference problem discretisation that essentially reduces discrete time problem Our framework makes learning the model addition inference easy Other extensions such heteroscedastic models are also relatively easy consider within this framework 
5431 en  efficient Monte Carlo algorithm for the Type parameter estimation nonlinear diffusions The mathematical framework non linear diffusions has been playing important role modelling natural phenomena Recently much efforts have been made developing inferential methods for such stochastic dynamical systems Both state and parameter estimation are interests The state art Hybrid Monte Carlo method has been applied state estimation non linear diffusions For parameter estimation the data augmentation strategy often adopted Accordingly state and parameters are sampled Gibbs sampler setting However has been reported that such Monte Carlo algorithm has very poor mixing property This due strong correlations between state and parameter samples this paper propose maximal likelihood type approach parameter estimation Equipped with the Wang Landau algorithm from statistical physics the novel algorithm shown both accurate and efficient 
5432 en MCMC schemes for partially observed diffusions Some recent advances well known that likelihood inference for arbitrary nonlinear diffusion processes observed discrete times problematic since closed form transition densities are rarely tractable One widely used solution involves the introduction latent data points between every pair observations allow sufficiently accurate Euler Maruyama approximation the true transition densities recent literature Markov chain Monte Carlo MCMC methods have been used sample the posterior distribution latent data and model parameters however naive schemes suffer from mixing problem that worsens with the degree augmentation will consider some recently developed MCMC schemes that are not adversely affected the amount augmentation particular sampling parameters conditional skeleton the driving Brownian motion rather than the sample path the mixing problem can overcome The methodology will illustrated estimating parameters governing the diffusion approximations some interesting systems biological models 
5433 en Normalized kernel weighted random measures This talk discusses wide class probability measure valued processes used nonparametric priors for problems with time varying patially varying covariate dependent distributions They are constructed normalizing correlated random measures which are stationary and have known marginal process Dependence modelled using kernels method that has become popular spatial modelling The ideas extend Griffin 2007 which used exponential kernel time series problems arbitrary kernel functions Computational issues will discussed and the ideas will illustrated examples financial time series 
5434 en Solving the data association problem multi object tracking Fourier analysis the symmetric group addition modeling the position individual targets multi object tracking must also address the combinatorial problem matching objects corresponding tracks general maintaining probability distribution over all possibilities clearly infeasible while just maintaining matrix “first order marginals” very impoverished representation this work explain how harness the theory harmonic analysis the symmetric group get hierarchy approximations increasing fidelity this problem Importatantly not only are such band limited approximations theoretically well justifiable but they also admit efficient observations updates based some ideas from Clausen’ FFT for the symmetric group 
5435 en Approximate Bayesian computation simulation based approach inference There large class stochastic models for which can simulate observations from the model but for which the likelihood function unknown Without knowledge the likelihood function standard inference techniques such Markov Chain Monte Carlo are impossible the unnormalized likelihood function explicitly required for the calculation acceptance rate this talk shall introduce group Monte Carlo methods that can used perform inference for stochastic models from which can cheaply simulate observations 
5436 en Exact simulation jump diffusions this talk will present the Exact Algorithm for simulation diffusions proposed Beskos Papaspiliopoulos and Roberts 2006 and its extension for simulation jump diffusions proposed Casella and Roberts 2008 The algorithm exact the sense that there discretisation error will show some simulation results where the Exact Algorithm compared the Euler Approximation the simulation jump diffusions 
5437 en  efficient approach stochastic optimal control Stochastic optimal control theory principled approach compute optimal actions with delayed rewards The use this approach and machine learning has been limited due the computational intractabilities this talk introduce class control problems where the intractabilities appear the computation partition sum statistical mechanical system This opens the possibility study phase transitions and apply exisiting approximation methods such and the variational method optimal control theory The talk gives gentle introduction into control theory and illustrates these new phenomena with number examples 
5438 en Information evolution optimal learning widely accepted that learning closely related theories optimisation and information Indeed there need learn there nothing optimise one possesses full information then there simply nothing new learn The paper considers learning optimisation problem with dynamical information constraints Unlike the standard approach the optimal control theory where the solutions are given the Hamilton–Jacobi–Bellman equation for Markov time evolution the optimal solution presented the system canonical Euler equations defining the optimal information–utility trajectory the conjugate space The optimal trajectory parameterised theinformation–utility constraints which are illustrated examples for finite and infinite–dimensional cases 
5439 en Approximate system identification Misfit versus latency Two fundamentally different approaches system identification which are used for quantification the model–data mismatch are misfit and latency The aim this talk explain the rationale behind them and link them statistical estimation methods—errors variables regression and classical regression—respectively 
5440 en Sigma point and particle approximations stochastic differential equations optimal filtering The unscented transform relatively recent method for approximating non linear transformations random variables Instead the classical Taylor series approximations based forming set sigma points which are propagated through the non linearity The unscented Kalman filter UKF alternative the extended Kalman filter EKF which utilizes the unscented transform the filter computations However its original form the UKF discrete time algorithm and cannot directly applied estimation problems where the state dynamics are modeled continuous time stochastic differential equations the talk will review the Taylor series sigma point unscented and particle approximations stochastic differential equations optimal Bayesian filtering context and present some applications the methods navigation systems and monitoring chemical processes 
5441 en State estimation and prediction based dynamic spike train decoding noise adaptation and multisensory integration key requirement facing organisms agents general acting uncertain dynamic environments the real time estimation and prediction environmental states based upon which effective actions can selected this work show how agent may use simple real time neural network receiving noisy multisensory input signals solve these tasks effectively 
5442 en Gaussian process toolkit for modelling the dynamics transcriptional regulation The complex dynamics cells and tissues are regulated part networks interacting genes and proteins The structure the interaction network dictates which genes are regulated which transcription factors TFs Particularly number experimental and computational methods have been proposed explore the mechanisms transcriptional regulation key problem with the analysis transcription network that the concentration the activated difficult measure directly whereas the target mRNA quantities are relatively easy obtain with microarray Therefore focus the problem inferring the transcription factor activity given the mRNA expression level data 
5443 en  stratified path sampling the Thermodynamic Integral computing Bayes factors for nonlinear dynamical systems models Bayes factors provide means objectively ranking number plausible statistical models based their evidential support Computing Bayes factors far from straightforward and methodology based thermodynamic integration can provide stable estimates the integrated likelihood This talk will consider stratified sampling strategy estimating the thermodynamic integral and will consider issues such optimal paths and the variance the overall estimator The main application considered will the computation Bayes factors for dynamical biochemical pathway models based systems nonlinear ordinary differential equations ODE large scale study the ExtraCellular Regulated Kinase ERK pathway will discussed where recent Small Interfering RNA siRNA experimental validation the predictions made using the computed Bayes factors presented 
5456 en Garlik Semantic Technology for the Consumer under decade the internet has changed our lives Now can shop bank date research learn and communicate online and every time leave behind trail personal information Organisations have wealth structured information about individuals large numbers databases What does the intersection this information mean for the individual How much your personal data out there and more importantly just who has access stories identity theft and online fraud fill the media internet users are becoming increasingly nervous about their online data security Also what opportunities arise for individuals exploit this information for their own benefit Garlik was formed give individuals and their family real power over the use their personal information the digital world Garlik technology base has exploited and extended results from research the Semantic Web has built the world largest SPARQL compliant native format RDF triple store The store implemented low cost network cluster with over 100 servers supporting 24x7 operation Garlik has built semantically informed search and harvesting used industrial strength language engineering technologies across many millions people centric Web pages Methods have been developed for extracting information from structured and semi structured databases All this information organised against people centric ontology with facilities integrate these various fragments Garlik has received two substantial rounds venture capital funding March 2008 has established active user base tens thousands individuals and adding paying customers increasing rate This talk reviews the consumer need describes the technology and engineering and discusses the lessons can draw about the challenges deploying Semantic Technologies 
5457 en From Capturing Semantics Semantic Search Virtuous Cycle Semantic search seems elusive and fuzzy target and NLP researchers One reason that this challenge lies between all those fields which implies broad scope issues and tech nologies that must mastered this extended abstract survey the work Yahoo Research Barcelona approach this problem Our research intended produce virtuous feedback circuit using chine learning for capturing semantics and ultimately for better search 
5459 en Panel Does the Semantic Web Need Web Science 
5460 en Panel Social Network Portability the Semantic Web Ready Panelists Dan Brickley ASemantics Danny Ayers Talis Stefan Decker DERI Galway and Kingsley Idehen OpenLink and Peter Mika Yahoo Research Barcelona and Alexandre Passant LaLIC University Paris Sorbonne 
5463 en  Rate Distortion One Class Model and its Applications Clustering study the problem one class classification which seek rule separate coherent subset instances similar few positive examples from large pool instances find that the problem can formulated naturally terms rate distortion tradeoff which can analyzed precisely and leads efficient algorithm that competes well with two previous one class methods also show that our model can extended naturally clustering problems which important remove background clutter improve cluster purity 
5464 en Estimating Local Optimums Algorithm over Gaussian Mixture Model algorithm very popular method estimate the parameters Gaussian Mixture Model from large observation set However most cases algorithm not guaranteed converge the global optimum Instead stops some local optimums which can much worse than the global optimum Therefore usually required run multiple procedures algorithm with different initial configurations and return the best solution improve the efficiency this scheme propose new method which can estimate upper bound the logarithm likelihood the local optimum based the current configuration after the latest iteration This accomplished first deriving some region bounding the possible locations local optimum followed some upper bound estimation the maximum likelihood With this estimation can terminate algorithm procedure the estimated local optimum definitely worse than the best solution seen far Extensive experiments show that our method can effectively and efficiently accelerate conventional algorithm 
5465 en  Decoupled Approach Exemplar based Unsupervised Learning recent trend exemplar based unsupervised learning formulate the learning problem convex optimization problem Convexity achieved restricting the set possible prototypes training exemplars particular this has been done for clustering vector quantization and mixture model density estimation this paper propose novel algorithm that theoretically and practically superior these convex formulations This possible posing the unsupervised learning problem single convex master problem with non convex subproblems show that for the above learning tasks the subproblems are extremely well behaved and can solved efficiently 
5466 en Efficient MultiClass Maximum Margin Clustering This paper presents cutting plane algorithm for multiclass maximum margin clustering MMC The proposed algorithm constructs nested sequence successively tighter relaxations the original MMC problem and each optimization problem this sequence could efficiently solved using the constrained concave convex procedure CCCP Experimental evaluations several real world datasets show that our algorithm converges much faster than existing MMC methods with guaranteed accuracy and can thus handle much larger datasets efficiently 
5467 en Fast Solvers and Efficient Implementations for Distance Metric Learning this paper study how improve nearest neighbor classification learning Mahalanobis distance metric build recently proposed framework for distance metric learning known large margin nearest neighbor LMNN classification Within this framework focus specifically the challenges scalability and adaptability posed large data sets Our paper makes three contributions First describe highly efficient solver for the particular instance semidefinite programming that arises LMNN classification our solver can handle problems with billions large margin constraints few hours Second show how reduce both training and testing times using metric ball trees the speedups from ball trees are further magnified learning low dimensional representations the input space Third show how learn different Mahalanobis distance metrics different parts the input space For large data sets these mixtures locally adaptive metrics lead even lower error rates 
5468 en Nearest Hyperdisk Methods for High Dimensional Classification high dimensional classification problems infeasible include enough training samples cover the class regions densely Irregularities the resulting sparse sample distributions cause local classifiers such Nearest Neighbors and kernel methods have irregular decision boundaries One solution fill the holes building convex model the region spanned the training samples each class and classifying examples based their distances these approximate models Methods this kind based affine and convex hulls and bounding hyperspheres have already been studied Here propose method based the bounding hyperdisk each class the intersection the affine hull and the smallest bounding hypersphere its training samples argue that many cases hyperdisks are preferable affine and convex hulls and hyperspheres they bound the classes more tightly than affine hulls hyperspheres while avoiding much the sample overfitting and computational complexity that inherent high dimensional convex hulls show that the hyperdisk method can kernelized provide nonlinear classifiers based non Euclidean distance metrics Experiments several classification problems show promising results 
5469 en Fast Nearest Neighbor Retrieval for Bregman Divergences present data structure enabling efficient retrieval for bregman divergences The family bregman divergences includes many popular dissimilarity measures including divergence relative entropy Mahalanobis distance and Itakura Saito divergence These divergences present challenge for efficient retrieval because they are not general metrics for which most data structures are designed The data structure introduced this work shares the same basic structure the popular metric ball tree but employs convexity properties bregman divergences place the triangle inequality Experiments demonstrate speedups over brute force search several orders magnitude 
5470 en Deep Learning via Semi Supervised Embedding show how nonlinear embedding algorithms popular for use with shallow semi supervised learning techniques such kernel methods can applied deep multi layer architectures either regularizer the output layer each layer the architecture This provides simple alternative existing approaches deep learning whilst yielding competitive error rates compared those methods and existing shallow semi supervised techniques 
5471 en Localized Multiple Kernel Learning Recently instead selecting single kernel multiple kernel learning MKL has been proposed which uses convex combination kernels where the weight each kernel optimized during training However MKL assigns the same weight kernel over the whole input space this paper develop localized multiple kernel learning LMKL algorithm using gating model for selecting the appropriate kernel function locally The localizing gating model and the kernel based classifier are coupled and their optimization done joint manner Empirical results ten benchmark and two bioinformatics data sets validate the applicability our approach LMKL achieves statistically similar accuracy results compared with MKL storing fewer support vectors LMKL can also combine multiple copies the same kernel function localized different parts For example LMKL with multiple linear kernels gives better accuracy results than using single linear kernel bioinformatics data sets 
5472 en Composite Kernel Learning The Support Vector Machine SVM acknowledged powerful tool for building classifiers but lacks flexibility the sense that the kernel chosen prior learning Multiple Kernel Learning MKL enables learn the kernel from ensemble basis kernels whose combination optimized the learning process Here propose Composite Kernel Learning address the situation where distinct components give rise group structure among kernels Our formulation the learning problem encompasses several setups putting more less emphasis the group structure characterize the convexity the learning problem and provide general wrapper algorithm for computing solutions Finally illustrate the behavior our method multi channel data where groups correspond channels 
5473 en Training SVM with Indefinite Kernels Similarity matrices generated from many applications may not positive semidefinite and hence can fit into the kernel machine framework this paper study the problem training support vector machines with indefinite kernel consider regularized SVM formulation which the indefinite kernel matrix treated noisy observation some unknown positive semidefinite one proxy kernel and the support vectors and the proxy kernel can computed simultaneously propose semi infinite quadratically constrained linear program formulation for the optimization which can solved iteratively find global optimum solution further propose employ additional pruning strategy which significantly improves the efficiency the algorithm while retaining the convergence property the algorithm addition show the close relationship between the proposed formulation and multiple kernel learning Experiments collection benchmark data sets demonstrate the efficiency and effectiveness the proposed algorithm 
5474 en Robust Matching and Recognition using Context Dependent Kernels The success kernel methods including support vector machines SVMs strongly depends the design appropriate kernels While initially kernels were designed order handle fixed length data their extension unordered variable length data became more than necessary for real pattern recognition problems such object recognition and bioinformatics focus this paper object recognition using new type kernel referred context dependent Objects seen constellations local features interest points regions etc are matched minimizing energy function mixing fidelity term which measures the quality feature matching neighborhood criteria which captures the object geometry and regularization term will show that the fixed point this energy context dependent kernel CDK which also satisfies the Mercer condition Experiments conducted object recognition show that when plugging our kernel SVMs clearly outperform SVMs with context free kernels 
5475 en  RKHS for Multi View Learning and Manifold Regularization Inspired training many multi view semi supervised kernel methods implement the following idea find function each multiple Reproducing Kernel Hilbert Spaces RKHSs such that the chosen functions make similar predictions unlabeled examples and the average prediction given the chosen functions performs well labeled examples this paper construct single RKHS with data dependent “ regularization” norm that reduces these approaches standard supervised learning The reproducing kernel for this RKHS can explicitly derived and plugged into any kernel method greatly extending the theoretical and algorithmic scope regularization particular with this development the Rademacher complexity bound for regularization given Rosenberg Bartlett 2007 follows easily from well known results Furthermore more refined bounds given localized Rademacher complexity can also easily applied propose regularization based algorithmic alternative manifold regularization Belkin 2006 Sindhwani 2005a that leads major empirical improvements semi supervised tasks Unlike the recently proposed transductive approach 2008 our RKHS formulation truly semi supervised and naturally extends unseen test data 
5476 en  Distance Model for Rhythms Modeling long term dependencies time series has proved very difficult achieve with traditional machine learning methods This problem occurs when considering music data this paper introduce model for rhythms based the distributions distances between subsequences specific implementation the model when considering Hamming distances over simple rhythm representation described The proposed model consistently outperforms standard Hidden Markov Model terms conditional prediction accuracy two different music databases 
5477 en  Reproducing Kernel Hilbert Space Framework for Pairwise Time Series Distances good distance measure for time series needs properly incorporate the temporal structure and should applicable sequences with unequal lengths this paper propose distance measure principled solution the two requirements Unlike the unconventional feature vector representation our approach represents each time series with summarizing smooth curve reproducing kernel Hilbert space RKHS and therefore translate the distance between time series into distances between curves Moreover propose learn the kernel this RKHS from population time series with discrete observations using Gaussian process based non parametric mixed effect models Experiments two vastly different real world problems show that the proposed distance measure leads improved classification accuracy over the conventional distance measures 
5478 en Sequence Kernels for Predicting Protein Essentiality The problem identifying the minimal gene set required sustain life crucial importance understanding cellular mechanisms and designing therapeutic drugs This work describes several kernel based solutions for predicting essential genes that outperform existing models while using less training data Our first solution based semi manually designed kernel derived from the Pfam database which includes several Pfam domains then present novel and general domain based sequence kernels that capture sequence similarity with respect several domains made large sets protein sequences show how deal with the large size the problem – several thousands domains with individual domains sometimes containing thousands sequences – representing and efficiently computing these kernels using automata report results extensive experiments demonstrating that they compare favorably with the Pfam kernel predicting protein essentiality while requiring manual tuning 
5479 en Local Likelihood Modeling Temporal Text Streams Temporal text data often generated time changing process distribution Such drift the underlying distribution cannot captured stationary likelihood techniques consider the application local likelihood methods generative and conditional modeling temporal document sequences examine the asymptotic bias and variance and present experimental study using the RCV1 dataset containing temporal sequence Reuters news stories 
5480 en Causal Modelling Combining Instantaneous and Lagged Effects Identifiable Model Based Non Gaussianity Causal analysis continuous valued variables typically uses either autoregressive models linear Gaussian Bayesian networks with instantaneous effects Estimation Gaussian Bayesian networks poses serious identifiability problems which why was recently proposed use non Gaussian models Here show how combine the non Gaussian instantaneous model with autoregressive models show that such non Gaussian model identifiable without prior knowledge network structure and propose estimation method shown consistent This approach also points out how neglecting instantaneous effects can lead completely wrong estimates the autoregressive coefficients 
5481 en Manifold Boost Stagewise Function Approximation for Fully Semi and supervised Learning describe manifold learning framework that naturally accommodates supervised learning manifold learning partially supervised learning and unsupervised clustering particular cases Our method chooses function minimizing loss subject manifold regularization penalty This augmented cost minimized using greedy stagewise functional minimization procedure Gradientboost Each stage boosting fast and efficient demonstrate our approach using both radial basis function approximations and classification trees The performance our method the state the art standard problems 
5482 en Boosting with Incomplete Information real world machine learning problems very common that part the input feature vector incomplete either not available missing corrupted this paper present boosting approach that integrates features with incomplete information and those with complete information form strong classifier introducing hidden variables model missing information form loss functions that combine fully labeled data with partially labeled data effectively learn normalized and unnormalized models The primal problems the proposed optimization problems with these loss functions are provided show their close relationships and the motivations behind them use auxiliary functions bound the change the loss functions and derive explicit parameter update rules for the learning algorithms demonstrate encouraging results two real world problems visual object recognition computer vision and named entity recognition natural language processing show the effectiveness the proposed boosting approach 
5483 en Maximum Likelihood Rule Ensembles propose new rule induction algorithm for solving classification problems via probability estimation The main advantage decision rules their simplicity and good interpretability While the early approaches rule induction were based sequential covering follow approach which single decision rule treated base classifier ensemble The ensemble built greedily minimizing the negative loglikelihood which results estimating the class conditional probability distribution The introduced approach compared with other decision rule induction algorithms such SLIPPER LRI and RuleFit 
5484 en Random Classification Noise Defeats All Convex Potential Boosters broad class boosting algorithms can interpreted performing coordinate wise gradient descent minimize some potential function the margins data set This class includes AdaBoost LogitBoost and other widely used and well studied boosters this paper show that for broad class convex potential functions any such boosting algorithm highly susceptible random classification noise this showing that for any such booster and any nonzero random classification noise rate there simple data set examples which efficiently learnable such booster there noise but which cannot learned accuracy better than there random classification noise rate This negative result contrast with known branching program based boosters which not fall into the convex potential function framework and which can provably learn high accuracy the presence random classification noise 
5485 en Uncorrelated Multilinear Principal Component Analysis through Successive Variance Maximization Tensorial data are frequently encountered various machine learning tasks today and dimensionality reduction one their most important applications This paper extends the classical principal component analysis PCA its multilinear version proposing novel dimensionality reduction algorithm for tensorial data named uncorrelated multilinear PCA UMPCA UMPCA seeks tensor vector projection that captures most the variation the original tensorial input while producing uncorrelated features through successive variance maximization evaluate the proposed algorithm second order tensorial problem face recognition and the experimental results show its superiority especially low dimensional spaces through the comparison with three other PCA based algorithms 
5486 en Expectation Maximization for Sparse and Non Negative PCA study the problem finding the dominant eigenvector the sample covariance matrix under additional constraints its elements cardinality constraint limits the number non zero elements and non negativity forces the elements have equal sign This problem known sparse and non negative principal component analysis PCA and has many applications including dimensionality reduction and feature selection Based expectation maximization for probabilistic PCA present algorithm for any combination these constraints Its complexity most quadratic the number dimensions the data demonstrate significant improvements performance and computational efficiency compared the state the art using large data sets from biology and computer vision 
5487 en ICA and ISA Using Schweizer Wolff Measure Dependence propose new algorithm for independent component and independent subspace analysis problems This algorithm uses contrast based the Schweizer Wolff measure pairwise dependence non parametric measure based pairwise ranks the variables Our algorithm frequently outperforms state the art ICA methods the normal setting significantly more robust outliers the mixed signals and performs well even the presence noise Since pairwise dependence evaluated explicitly using Cardoso conjecture our method can applied solve independence subspace analysis ISA problems grouping signals recovered ICA methods provide extensive empirical evaluation using simulated sound and image data 
5488 en Bayesian Probabilistic Matrix Factorization using Markov Chain Monte Carlo Low rank matrix approximation methods provide one the simplest and most effective approaches collaborative filtering Such models are usually fitted data finding MAP estimate the model parameters procedure that can efficiently performed even very large datasets However unless the regularization parameters are tuned carefully this approach prone overfitting because finds single point estimate the parameters this paper present fully Bayesian treatment the Probabilistic Matrix Factorization PMF model which model capacity controlled automatically integrating over all model parameters and hyperparameters show that Bayesian PMF models can efficiently trained using Markov chain Monte Carlo methods applying them the Netflix dataset which consists over 100 million user movie ratings The resulting models achieve significantly higher prediction accuracy than PMF models trained using MAP estimation 
5489 en Adaptive Posterior Mixture Model Kernels for Multiple Instance Learning multiple instance learning MIL how the instances determine the bag labels essential issue both algorithmically and intrinsically this paper show that the mechanism how the instances determine the bag labels different for different application domains and does not necessarily obey the traditional assumptions MIL therefore propose adaptive framework for MIL that adapts different application domains learning the domain specific mechanisms merely from labeled bags Our approach especially attractive when are encountered with novel application domains for which the mechanisms may different and unknown Specifically exploit mixture models represent the composition each bag and adaptable kernel function represent the relationship between the bags validate synthetic MIL datasets that the kernel function automatically adapts different mechanisms how the instances determine the bag labels also compare our approach with state the art MIL techniques real world benchmark datasets 
5490 en Multiple Instance Ranking This paper introduces novel machine learning model called multiple instance ranking MIRank that enables ranking performed multiple instance learning setting The motivation for MIRank stems from the hydrogen abstraction problem computational chemistry that predicting the grouping hydrogen atoms from which hydrogen abstracted removed during metabolism The model predicts the preferred hydrogen grouping within molecule ranking the groups with the ambiguity not knowing which hydrogen within the preferred grouping actually abstracted This paper formulates MIRank its general context and proposes algorithm for solving MIRank problems using successive linear programming The method outperforms multiple instance classification models several real and synthetic datasets 
5491 en Bayesian Multiple Instance Learning Automatic Feature Selection and Inductive Transfer propose novel Bayesian multiple instance learning algorithm This algorithm automatically identifies the relevant feature subset and utilizes inductive transfer when learning multiple conceptually related classifiers Experimental results indicate that the proposed baseline MIL method more accurate than previous MIL algorithms and selects much smaller set useful features Inductive transfer further improves the accuracy the classifier compared learning each task individually 
5492 en Learning Classify with Missing and Corrupted Features After classifier trained using machine learning algorithm and put use real world system often faces noise which did not appear the training data Particularly some subset features may missing may become corrupted present two novel machine learning techniques that are robust this type classification time noise First solve approximation the learning problem using linear programming analyze the tightness our approximation and prove statistical risk bounds for this approach Second define the online learning variant our problem address this variant using modified Perceptron and obtain statistical learning algorithm using online batch technique conclude with set experiments that demonstrate the effectiveness our algorithms 
5493 en Multi Classification Categorical Features via Clustering derive generalization bound for multi classification schemes based grid clustering categorical parameter product spaces Grid clustering partitions the parameter space the form Cartesian product partitions for each the parameters The derived bound provides means evaluate clustering solutions terms the generalization power built classifier For classification based single feature the bound serves find globally optimal classification rule Comparison the generalization power individual features can then used for feature ranking Our experiments show that this role the bound much more precise than mutual information normalized correlation indices 
5497 en Learning Rules From PCFGs Adaptor Grammars
5499 en Some thoughts prior knowledge deep architectures and NLP
5500 en Poster Using Participant Role Multiparty Meetings Prior Knowledge for Nonparametric Topic Modeling this paper introduce our attempts incorporate the participant role information multiparty meetings for document modeling using the hierarchical Dirichlet process The perplexity and automatic speech recognition results demonstrate that the participant role information promising prior knowledge source combined with language models for automatic speech recognition and interaction modeling for multiparty meetings 
5501 en Poster Knowledge Constraint Uncertainty for Unsupervised Classification Study Part Speech Tagging This paper evaluates the use prior knowledge limit bias the choices classifer during otherwise unsupervised training and classifcation Focusing effects the uncertainty the model decisions quantify the contributions the knowledge source reduction the conditional entropy the label distribution given the input corpus Allowing compare diffrent sets knowledge without annotated data find that label entropy highly predictive final performance for standard Hidden Markov Model HMM the task part speech tagging Our results show too that even basic levels knowledge integrated labeling constraints have considerable effect classification accuracy addition more stable and effcient training convergence Finally for cases where the model internal classes need interpreted and mapped sired label set find that for constrained models the requirements for annotated data make quality assignments are greatly reduced 
5502 en Poster Using Prior Domain Knowledge Build HMM Based Semantic Tagger Trained Completely Unannotated Data this paper propose robust statistical semantic tagging model trained completely unannotated data The approach relies mainly prior domain knowledge counterbalance the lack semantically annotated treebank data The proposed method encodes longer contextual information grouping strongly related semantic concepts together into cohesive units The method based hidden Markov model HMM and offers high ambiguity resolution power outputs semantically rich information and requires relatively low human effort The approach yields high performance models that are evaluated two different corpora two application domains English and German 
5504 en Poster Dirichlet Process Mixture Models for Verb Clustering this work apply Dirichlet Process Mixture Models learning task natural language processing NLP lexical semantic verb clustering assess the performance dataset based Levin’ 1993 verb classes using the recently introduced measure metric present method add human supervision the model order influence the solution with respect some prior knowledge The quantitative evaluation performed highlights the benefits the chosen method compared previously used clustering approaches 
5505 en Incorporating Prior Knowledge into NLP with Markov Logic
5506 en Expanding Gazetteer Based Approach for Geo Parsing Disease Alerts Discovering text the geographic references may contain task that human readers perform using both their lexical and contextual knowledge Using gazetteer label such targeted references dataset this paper proposes approach learning the context which they appear and this means extending the prior knowledge encoded the gazetteer The present work was carried the particular framework system for disease outbreak alerts detection and geo indexing 
5507 en Bayesian Modeling Dependency Trees Using Hierarchical Pitman Yor Priors
5509 en Encoding prior knowledge text processing
5510 en Why isn’ linguistics more useful NLP 
5512 en Panel Complex Model Rich Prior Knowledge
5513 en Panel Priors Deep Architectures and NLP YOU ARE DOING EVERYTHING WRONG 
5514 en DRASO Declaratively Regularized Alternating Structural Optimization Recent work has shown that Alternating Structural Optimization ASO can improve supervised learners learning feature representations from unlabeled data However there natural way include prior knowledge about features into this frame work this paper present Declar atively Regularized Alternating Structural Optimization DRASO principled way for injecting prior knowledge into the ASO framework also provide some analysis the representations learned our method 
5515 en  Object Oriented Representation for Efficient Reinforcement Learning Rich representations reinforcement learning have been studied for the purpose enabling generalization and making learning feasible large state spaces introduce Object Oriented MDPs MDPs representation based objects and their interactions which natural way modeling environments and offers important generalization opportunities introduce learning algorithm for deterministic MDPs and prove polynomial bound its sample complexity illustrate the performance gains our representation and algorithm the well known Taxi domain plus real life videogame 
5516 en Hierarchical Model Based Reinforcement Learning Hierarchical decomposition promises help scale reinforcement learning algorithms naturally real world problems exploiting their underlying structure Model based algorithms which provided the first finite time convergence guarantees for reinforcement learning may also play important role coping with the relative scarcity data large environments this paper introduce algorithm that fully integrates modern hierarchical and model learning methods the standard reinforcement learning setting Our algorithm maxq inherits the efficient model based exploration the max algorithm and the opportunities for abstraction provided the MAXQ framework analyze the sample complexity our algorithm and our experiments standard simulation environment illustrate the advantages combining hierarchies and models 
5517 en  the Hardness Finding Symmetries Markov Decision Processes this work address the question finding symmetries given MDP show that the problem Isomorphism Complete that the problem polynomially equivalent verifying whether two graphs are isomorphic Apart from the theoretical importance this result has important practical application The reduction presented can used together with any off the shelf Graph Isomorphism solver which performs well the average case find symmetries MDP fact present results using NAutY the best Graph Isomorphism solver currently available find symmetries MDPs 
5518 en Reinforcement Learning the Presence Rare Events consider the task reinforcement learning environment which rare significant events occur independently the actions selected the controlling agent these events are sampled according their natural probability occurring convergence standard reinforcement learning algorithms likely very slow and the learning algorithms may exhibit high variance this work assume that have access simulator which the rare event probabilities can artificially altered Then importance sampling can used learn with this simulation data introduce algorithms for policy evaluation both using tabular and function approximation representation the value function prove that both cases the reinforcement learning algorithms converge the tabular case also analyze the bias and variance our approach compared learning evaluate empirically the performance the algorithm random Markov Decision Processes well large network planning task 
5519 en Online Kernel Selection for Bayesian Reinforcement Learning Kernel based Bayesian methods for Reinforcement Learning such Gaussian Process Temporal Difference GPTD are particularly promising because they rigorously treat uncertainty the value function and make easy specify prior knowledge However the choice prior distribution significantly affects the empirical performance the learning agent and little work has been done extending existing methods for prior model selection the online setting This paper develops Replacing Kernel online model selection method for GPTD using population based search Replacing Kernel compared standard GPTD and tile coding several domains and shown yield significantly better asymptotic performance for many different kernel families Furthermore the resulting kernels capture intuitively useful notion prior state covariance that may nevertheless difficult capture manually 
5521 en  line Discovery Temporal Difference Networks present algorithm for line incremental discovery temporal difference networks The key contribution the establishment three criteria expand node network node expanded when the node well known independent and has prediction error that requires further explanation Since none these criteria requires centralized calculation operations they are easily computed parallel and distributed manner and scalable for bigger problems compared other discovery methods predictive state representations Through computer experiments demonstrate the empirical effectiveness our algorithm 
5522 en Prediction with Expert Advice for the Brier Game show that the Brier game prediction mixable and find the optimal learning rate and substitution function for The resulting prediction algorithm applied predict results football and tennis matches The theoretical performance guarantee turns out rather tight these data sets especially the case the more extensive tennis data 
5523 en Non Parametric Policy Gradients Unified Treatment Propositional and Relational Domains Policy gradient approaches are powerful instrument for learning how interact with the environment Existing approaches have focused propositional and continuous domains only Without extensive feature engineering difficult not impossible apply them within structured domains which there varying number objects and relations among them this paper describe non parametric policy gradient approach called NPPG that overcomes this limitation The key idea apply Friedmann gradient boosting policies are represented weighted sum regression models grown stage wise optimization Employing off the shelf regression learners NPPG can deal with propositional continuous and relational domains unified way Our experimental results show that can even improve established results 
5524 en Space indexed Dynamic Programming Learning Follow Trajectories consider the task learning accurately follow trajectory vehicle such car helicopter number dynamic programming algorithms such Differential Dynamic Programming DDP and Policy Search Dynamic Programming PSDP can efficiently compute non stationary policies for these tasks such policies general are well suited trajectory following since they can easily generate different control actions different times order follow the trajectory However weakness these algorithms that their policies are time indexed that they apply different policies depending the current time This problematic since the current time may not correspond well where are along the trajectory and the uncertainty over future states can prevent these algorithms from finding any good policies all this paper propose method for space indexed dynamic programming that overcomes both these difficulties begin showing how dynamical system can rewritten terms spatial index variable how far along the trajectory are rather than function time then use these space indexed dynamical systems derive space indexed version the DDP and PSDP algorithms Finally show that these algorithms perform well variety control tasks both simulation and real systems 
5525 en Privacy Preserving Reinforcement Learning Distributed reinforcement learning DRL has been studied approach learn control policies thorough interactions between distributed agents and environments The main emphasis DRL has been put the way learn sub optimal policies with the least limited sharing agents perceptions this study introduce new concept privacy preservation into DRL our setting agents perceptions such states rewards and actions are not only distributed but also are desired kept private This can occur when agents perceptions include private confidential information Conventional DRL algorithms could applied such problems but not theoretically guarantee privacy preservation design solutions that achieve optimal policies standard reinforcement leering settings without requiring the agents share their private information means well known cryptographic primitive secure function evaluation 
5526 en Learning All Optimal Policies with Multiple Criteria describe algorithm for learning the presence multiple criteria Our technique generalizes previous approaches that can learn optimal policies for any linear preference assignment over the multiple reward criteria The algorithm can viewed extension standard reinforcement learning for MDPs where instead repeatedly backing maximal expected rewards back the set expected rewards that are maximal for some set linear preferences given weight vector present the algorithm along with proof correctness showing that our solution gives the optimal policy for any linear preference function The solution reduces the standard value iteration algorithm for specific weight vector 
5527 en Active Reinforcement Learning When the transition probabilities and rewards Markov Decision Process MDP are known the agent can obtain the optimal policy without any interaction with the environment However exact transition probabilities are difficult for experts specify One option left agent long and potentially costly exploration the environment this paper propose another alternative given initial possibly inaccurate specification the MDP the agent determines the sensitivity the optimal policy changes transitions and rewards then focuses its exploration the regions space which the optimal policy most sensitive show that the proposed exploration strategy performs well several control and planning problems 
5528 en Reinforcement Learning with Limited Reinforcement Using Bayes Risk for Active Learning POMDPs Partially Observable Markov Decision Processes POMDPs have succeeded planning domains because they optimally trade between actions that increase agent knowledge and actions that increase agent reward Unfortunately most POMDPs are defined with large number parameters which are difficult specify only from domain knowledge this paper treat the POMDP model parameters additional hidden state model uncertainty POMDP and develop approximate algorithm for planning the this larger POMDP The approximation coupled with model directed queries allows the planner actively learn good policies demonstrate our approach several standard POMDP problems 
5529 en The Many Faces Optimism Unifying Approach The exploration exploitation dilemma has been intriguing and unsolved problem within the framework reinforcement learning Optimism the face uncertainty and model building play central roles advanced exploration methods Here integrate several concepts and obtain fast and simple algorithm show that the proposed algorithm finds near optimal policy polynomial time and give experimental evidence that robust and efficient compared its ascendants 
5530 en Transfer Samples Batch Reinforcement Learning The main objective transfer learning reduce the complexity learning the solution target task effectively reusing the knowledge retained from solving one more source tasks this paper introduce novel algorithm that transfers samples experience tuples from source target tasks Under the assumption that tasks defined the same environment often have similar transition models and reward functions propose method select samples from the source tasks that are mostly similar the target task and then use them input for batch reinforcement learning algorithms result the number samples that the agent needs collect from the target task learn its solution reduced empirically show that following the proposed approach the transfer samples effective reducing the learning complexity even when the source tasks are significantly different from the target task 
5531 en Exploration Scavenging examine the problem evaluating policy the contextual bandit setting using only observations collected during the execution another policy show that policy evaluation can impossible the exploration policy chooses actions based the side information provided each time step then propose and prove the correctness principled method for policy evaluation which works when this not the case even when the exploration policy deterministic long each action explored sufficiently often apply this general technique the problem offline evaluation internet advertising policies Although our theoretical results hold only when the exploration policy chooses ads independent side information assumption that typically violated commercial systems show how clever uses the theory provide non trivial and realistic applications also provide empirical demonstration the effectiveness our techniques real placement data 
5532 en  Analysis Linear Models Linear Value Function Approximation and Feature Selection for Reinforcement Learning show that linear value function approximation equivalent form linear model approximation derive relationship between the model approximation error and the Bellman error and show how this relationship can guide feature selection for model improvement and value function improvement also show how these results give insight into the behavior existing feature selection algorithms 
5533 en  Analysis Reinforcement Learning with Function Approximation address the problem computing the optimal function Markov decision problems with infinite state space analyze the convergence properties several variations learning when combined with function approximation extending the analysis learning Tsitsilis and Van Roy 1996 stochastic control settings identify conditions under which such approximate methods converge with probability conclude with brief discussion the general applicability our results and compare them with several related works 
5534 en Apprenticeship Learning Using Linear Programming apprenticeship learning the goal learn policy Markov decision process that least good policy demonstrated expert The difficulty arises that the MDP true reward function assumed unknown show how frame apprenticeship learning linear programming problem and show that using off the shelf solver solve this problem results substantial improvement running time over existing methods two orders magnitude faster our experiments Additionally our approach produces stationary policies while all existing methods for apprenticeship learning output policies that are mixed randomized combinations stationary policies The technique used general enough convert any mixed policy stationary policy 
5535 en Preconditioned Temporal Difference Learning This paper extends many the recent popular reinforcement learning algorithms generalized framework that includes least squares temporal difference LSTD learning least squares policy evaluation LSPE and variant incremental LSTD iLSTD The basis this extension preconditioning technique that tries solve stochastic model equation This paper also studies three signicant issues the new framework presents new rule step size that can computed online provides iterative way apply preconditioning and reduces the complexity related algorithms near that temporal difference learning 
5536 en Automatic Discovery and Transfer MAXQ Hierarchies present algorithm MAT Hierarchy Induction via Models And Trajectories that discovers MAXQ task hierarchies applying dynamic Bayesian network models successful trajectory from source reinforcement learning task MAT discovers subtasks analyzing the causal and temporal relationships among the actions the trajectory Under appropriate assumptions MAT induces hierarchies that are consistent with the observed trajectory and have compact value function tables employing safe state abstractions demonstrate empirically that MAT constructs compact hierarchies that are comparable manually engineered hierarchies and facilitate significant speedup learning when transferred target task 
5537 en Sample Based Learning and Search with Permanent and Transient Memories present reinforcement learning architecture Dyna that encompasses both sample based learning and sample based search and that generalises across states during both learning and search apply Dyna high performance Computer this domain the most successful planning methods are based sample based search algorithms such UCT which states are treated individually and the most successful learning methods are based temporal difference learning algorithms such Sarsa which linear function approximation used both cases estimate the value function formed but the first case transient computed and then discarded after each move whereas the second case more permanent slowly accumulating over many moves and games The idea Dyna for the transient planning memory and the permanent learning memory remain separate but for both based linear function approximation and both updated Sarsa apply Dyna 9x9 Computer use million binary features the function approximator based templates matching small fragments the board Using only the transient memory Dyna performed least well UCT Using both memories combined significantly outperformed UCT Our program based Dyna achieved higher rating the Computer Online Server than any handcrafted traditional search based program 
5538 en Efficiently Learning Linear Linear Exponential Family Predictive Representations State Exponential Family PSR EFPSR models capture stochastic dynamical systems representing state the parameters exponential family distribution over short term window future observations They are appealing from learning perspective because they are fully observed meaning expressions for maximum likelihood not involve hidden quantities but are still expressive enough both capture existing models such POMDPs and linear dynamical systems and predict new models While learning algorithms based maximizing exact likelihood exist they are not computationally feasible present new computationally efficient learning algorithm based approximate likelihood function The algorithm can interpreted attempting induce stationary distributions observations features and states which match their empirically observed counterparts The approximate likelihood and the idea matching stationary distributions may have application other models 
5539 en  Semi parametric Statistical Approach Model free Policy Evaluation Reinforcement learning methods based least squares temporal difference LSTD have been developed recently and have shown good practical performance However the quality their estimation has not been well elucidated this article discuss LSTD based policy evaluation from the new viewpoint semiparametric statistical inference fact the estimator can obtained from particular estimating function which guarantees its convergence the true value asymptotically without specifying model the environment Based these observations analyze the asymptotic variance LSTD based estimator derive the optimal estimating function with the minimum asymptotic estimation variance and derive suboptimal estimator reduce the computational burden obtaining the optimal estimating function 
5540 en Learning Learn Implicit Queries from Gaze Patterns the absence explicit queries alternative try infer users interests from implicit feedback signals such clickstreams eye tracking The interests formulated implicit query can then used further searches formulate this task probabilistic model which can interpreted kind transfer learning and meta learning The probabilistic model demonstrated outperform earlier kernel based method small scale information retrieval task 
5541 en Multi Task Learning for HIV Therapy Screening address the problem learning classifiers for large number tasks derive solution that produces resampling weights which match the pool all examples the target distribution any given task Our work motivated the problem predicting the outcome therapy attempt for patient who carries HIV virus with set observed genetic properties Such predictions need made for hundreds possible combinations drugs some which use similar biochemical mechanisms Multi task learning enables make predictions even for drug combinations with few training examples and substantially improves the overall prediction accuracy 
5542 en Manifold Alignment using Procrustes Analysis this paper introduce novel approach manifold alignment based Procrustes analysis Our approach differs from semi supervised alignment that results mapping that defined everywhere when used with suitable dimensionality reduction method rather than just the training data points describe and evaluate our approach both theoretically and experimentally providing results showing useful knowledge transfer from one domain another Novel applications our method including cross lingual information retrieval and transfer learning Markov decision processes are presented 
5543 en  Regret Learning Convex Games Quite bit known about minimizing different kinds regret experts problems and how these regret types relate types equilibria the multiagent setting repeated matrix games Much less known about the possible kinds regret online convex programming problems OCPs about equilibria the analogous multiagent setting repeated convex games This gap unfortunate since convex games are much more expressive than matrix games and since many important machine learning problems can expressed OCPs this paper work close this gap analyze spectrum regret types which lie between external and swap regret along with their corresponding equilibria which lie between coarse correlated and correlated equilibrium also analyze algorithms for minimizing these regret types examples our framework derive algorithms for learning correlated equilibria polyhedral convex games and extensive form correlated equilibria extensive form games The former exponentially more efficient than previous algorithms and the latter the first its type 
5545 en Strategy Evaluation Extensive Games with Importance Sampling Typically agent evaluation done through Monte Carlo estimation However stochastic agent decisions and stochastic outcomes can make this approach inefficient requiring many samples for accurate estimate present new technique that can used simultaneously evaluate many strategies while playing single strategy the context extensive game This technique based importance sampling but utilizes two new mechanisms for significantly reducing variance the estimates demonstrate its effectiveness the domain poker where stochasticity makes traditional evaluation problematic 
5546 en MDL Tutorial give self contained tutorial the Minimum Description Length MDL approach modeling learning and prediction focus the recent post 1995 formulations MDL which can quite different from the older methods that are often still called MDL the machine learning and UAI communities its modern guise MDL based the concept universal model explain this concept length show that previous versions MDL based called two part codes Bayesian model selection and predictive validation variation cross validation can all interpreted approximations model selection based universal models Modern MDL prescribes the use certain optimal universal model the called normalized maximum likelihood model Shtarkov distribution This related yet different from Bayesian model selection with non informative priors leads penalization complex models that can given intuitive differential geometric interpretation Roughly speaking the complexity parametric model directly related the number distinguishable probability distributions that contains also discuss some recent extensions such the luckiness principle which can used the Shtarkov distribution undefined and the switch distribution which allows for resolution the AIC BIC dilemma 
5547 en Fast computation NML for Bayesian networks Bayesian networks are parametric models for multidimensional domains exhibiting complex dependencies between the dimensions domain variables central problem learning such models how regularize the number parameters other words how determine which dependencies are significant and which are not The normalized maximum likelihood NML distribution code offers information theoretic solution this problem Unfortunately computing for arbitrary Bayesian network models appears computationally infeasible but show how can computed efficiently for certain restricted type Bayesian networks 
5548 en Extensions MDL denoising The minimum description length principle wavelet denoising can extended from the standard linear quadratic setting several ways describe briefly three extensions soft thresholding histogram modeling and multicomponent approach The MDL hard thresholding approach based the normalized maximum likelihood universal modeling can extended include soft thresholding shrinkage which can considered give better results some applications MDL histogram denoising approach the assumptions the parametric density models for the data can relaxed The informative and noise components the data are modeled with equal bin width histograms The method can cope with different noise distributions multicomponent approach more than one non noise components are included the model because possible that addition the random noise there may other disturbing signal elements that the informative signal comprised several different components which may want observe separate remove these cases adding informative components the model may result result better performance than the NML denoising approach 
5549 en Nonparametric density estimation switching According standard MDL and Bayesian model selection should roughly prefer the model that minimises overall prediction error But the goal predict well may well depend the sample size which model most useful predict the next outcome interpreting the Bayesian prediction strategies associated with the models experts can use the various algorithms for expert tracking improve model selection for prediction without introducing substantial computational overhead 
5550 en Sequential and factorized NML models Currently the most popular model selection criterion for learning Bayesian networks the Bayesian mixture with conjugate prior This method has recently been reported very sensitive the choice prior hyper parameters the other hand the general model selection criteria AIC and BIC are derived through asymptotics and their behavior suboptimal for small sample sizes this work introduce new effective scoring criterion for learning Bayesian network structures the factorized normalized maximum likelihood This score features tunable parameters thus avoiding the sensitivity problems Bayesian scores The new scoring method also suggests parametrization the Bayesian network that based the conditional normalized maximum likelihood predictive distribution 
5551 en Generalization theory two part code MDL estimator will present finite sample generalization analysis two part code MDL estimator This method selects model that minimizes the sum the model description length plus the data description length given the model can shown that under various conditions optimal rate convergence can achieved through extended family two part code MDL that over penalize the model description length example apply MDL learning sparse linear representations when the system dimension much larger than the number training examples This problem that has attracted considerable attention recent years The generalization performance two part code MDL estimator calculated based our theory and compares favorably other methods such norm regularization 
5552 en Normalized maximum likelihood models genomics The normalized maximum likelihood NML model Rissanen 1996 Rissanen 2001 Shtarkov 1987 for class Markov sources Tabus and Korodi 2008 was recently used for the compression full genomes obtaining for the human genome the best existing compression results Korodi and Tabus 2007 show that one the underlying biological features that the compression algorithm implicitly uncovers the existence approximate gene duplication proposed refined method based the same NML models for the segmentation DNA sequences for uncovering gene duplications Tabus Yang and Astola 2008 Several analysis tasks genomic sequences involve preliminary segmentation clustering the data which can performed number techniques based various similarity measures Here review and further pursue the application MDL techniques for genomic sequence analysis The process sequence matching will used for solving the problem uncovering gene duplications with the help preliminary segmentation complex DNA locus known have evolved through series duplications 
5553 en Information consistency nonparametric Gaussian process methods present information consistency results for nonparametric sequential prediction with Gaussian processes The connection nonparametric MDL through the prequential approach detailed Gruenwald 2007 book Sect Our proof technique elementary making use convex duality previously useful obtain PAC Bayesian bounds also obtain precise information consistency rates for wide range kernels and input distributions using kernel eigenvalue asymptotics all these cases the linear expert space infinite dimensional function space but still very reasonable rates are obtained 
5556 en Nonparametric Learning Switching Autoregressive Processes Vector autoregressive VAR processes are useful describing dynamical phenomena diverse speech financial time series and the dancing honey bees However such phenomena often exhibit structural changes over time and the VAR which describe them must also change For example the vocal tract speaker contracts country experiences recession central bank intervention some national global event honey bee changes from waggle turn right dance Some these changes will appear fre quently while others are only rarely observed dition there always the possibility previously unseen dynamic behavior Thus propose non parametric approach for learning switching VAR pro cesses where take the state sequence Markov 
5557 en Rank Minimization via Online Learning Minimum rank problems arise frequently machine learning applications and are notoriously difficult solve due the non convex nature the rank objective this paper present the first online learning approach for the problem rank minimization matrices over polyhedral sets particular present two online learning algorithms for rank minimization our first algorithm multiplicative update method based generalized experts framework while our second algorithm novel application the online convex programming framework Zinkevich 2003 the latter flip the role the decision maker making the decision maker search over the constraint space instead feasible points usually the case online convex programming salient feature our online learning approach that allows give the first provable approximation guarantees for the rank minimization problem over polyhedral sets demonstrate the effectiveness our methods synthetic examples and the real life application low rank kernel learning 
5558 en The Asymptotics Semi Supervised Learning Discriminative Probabilistic Models Semi supervised learning aims taking advantage unlabeled data improve the efficiency supervised learning procedures For discriminative models however this challenging task this contribution introduce original methodology for using unlabeled data through the design simple semi supervised objective function prove that the corresponding semi supervised estimator asymptotically optimal The practical consequences this result are discussed for the case the logistic regression model 
5571 en The Skew Spectrum Graphs The central issue representing graph structured data instances learning algorithms designing features which are invariant permuting the numbering the vertices present new system invariant graph features which call the skew spectrum graphs The skew spectrum based mapping the adjacency matrix function the symmetric group and computing bispectral invariants The reduced form the skew spectrum computable time and experiments show that several benchmark datasets can outperform state the art graph kernels 
5576 en Combining near optimal feature selection with gSpan Graph classification increasingly important step numerous application domains such function prediction molecules and proteins computerized scene analysis and anomaly detection program flows Among the various approaches proposed the literature graph classification based frequent subgraphs popular branch Graphs are represented usually binary vectors with components indicating whether graph contains particular subgraph that frequent across the dataset large graphs however one faces the enormous problem that the number these frequent subgraphs may grow exponentially with the size the graphs but only few them possess enough discriminative power make them useful for graph classification Efficient and discriminative feature selection among frequent subgraphs hence key challenge for graph mining this article propose approach feature selection frequent subgraphs called CORK that combines two central advantages First optimizes sub modular quality criterion which means that can yield near optimal solution using greedy feature selection Second our sub modular quality function criterion can integrated into gSpan the state the art tool for frequent subgraph mining and help prune the search space for discriminative frequent subgraphs even during frequent subgraph mining 
5577 en Efficient Discriminative Training Method for Structured Predictions propose efficient discriminative training method for generative models under supervised learning our setting fully observed instances are given training examples together with specification variables interest for prediction formulate the training convex programming problem incorporating the SVM type large margin constraints favor parameters under which the maximum posteriori MAP estimates the prediction variables conditioned the rest are close their true values given the training instances The resulting optimization problem however more complex than its quadratic programming counterpart resulting from the SVM type training conditional models because the presence non linear constraints the parameters present efficient optimization method which combines several techniques namely data dependent reparametrization dual variables restricted simplicial decomposition and the proximal point algorithm Our method extends the one for solving the aforementioned counterpart proposed earlier some the authors 
5579 en Learning for Control from Multiple Demonstrations consider the problem learning follow desired trajectory when given small number demonstrations from sub optimal expert present algorithm that extracts the initially unknown desired trajectory from the sub optimal expert demonstrations and learns local model suitable for control along the learned trajectory apply our algorithm the problem autonomous helicopter flight all cases the autonomous helicopter performance exceeds that our expert helicopter pilot demonstrations Even stronger our results significantly extend the state the art autonomous helicopter aerobatics particular our results include the first autonomous tic tocs loops and hurricane vastly superior performance previously performed aerobatic maneuvers such place flips and rolls and complete airshow which requires autonomous transitions between these and various other maneuvers 
5580 en Computers versus Common Sense way past 2001 now where the heck HAL For several decades now had high hopes for computers amplifying our mental abilities not just giving access relevant stored information but answering our complex contextual questions Even applications like human level unrestricted speech understanding continue dangle close but just out reach What been holding The short answer that while computers make fine idiot savants they lack common sense the millions pieces general knowledge all share and fall back needed cope with the rough edges the real world 
5581 en The Science and Art User Experience Google Focus the user and all else will follow From its inception Google has focused providing the best user experience possible Jen Fitzpatrick will take you through the art and science behind Google design process and share examples how design usability and engineering come together Google unique culture create great products
5582 en Git When you have hundreds people simultaneously patching 25000 files the Linux Kernel sometimes conflicting ways you might need some scheme plan sort all that out before you can build your next kernel and reboot The Linux team uses git for their source code repository management homegrown solution that optimized for highly distributed development working with huge sets files merging independent work multiple levels and seeing who broke what Git has also since been notably adopted the Cairo org and Wine teams and being transitioned the Mozilla codebase talk describe what git and isn and why you should use instead CVS Subversion SVK Arch Darcs Mercurial Monotone Bazaar and just about every other repository manager also walk though the basic concepts that the manpages might start making sense have time even live walkthrough where you can watch how fast make typos 
5585 en Representative Subgraph Sampling using Markov Chain Monte Carlo Methods Bioinformatics and the Internet keep generating graph data with thousands nodes Most traditional graph algorithms for data analysis are too slow for analyzing these large graphs One way work around this problem sample smaller ‘representative subgraph’ from the original large graph Existing representative subgraph sampling algorithms either randomly select sets nodes edges they explore the vicinity randomly drawn node All these existing approaches not make use topological properties the original graph and provide good samples down sample sizes approximately the number nodes the original graph this article propose novel sampling methods for representative subgraph sampling based the Metropolis algorithm and Simulated Annealing The key idea find subgraph that preserves properties the original graph that are efficient compute approximate our experiments improve over the pioneering work Leskovec and Faloutsos KDD 2006 producing representative subgraph samples that are both smaller and higher quality than those produced other methods from the literature 
5586 en Inferring the structure and scale modular networks present efficient principled and interpretable technique for inferring module assignments and for identifying the optimal number modules given network based variational Bayesian inference for stochastic block models show how our method extends previous work and addresses the “resolution limit problem” apply the technique synthetic and real networks 
5587 en Min Max and PTIME Anti Monotonic Overlap Graph Measures The main contributions this paper are extend the anti monotonicity results Vanetik Gudes and Shimony all combinations iso homo homeomorphism labeled unlabeled directed undirected graphs with edge vertex overlap show that under reasonable assumptions the maximum independent set measure MIS Vanetik Gudes and Shimony 2006 the smallest anti monotonic measure the class overlap graph based frequency measures also introduce the new minimum clique partition measure MCP which represents the largest possible one general both theMIS and theMCP measure are hard the size the overlap graph introduce the polynomial time computable Lovasz measure which sandwiched between the former two and show that anti monotonic 
5588 en Influence and Correlation Social Networks many online social systems social ties between users play important role dictating users behavior One the ways this can happen through social influence the phenomenon that the actions user can induce his her friends behave similar way systems where social influence exists ideas modes behavior new technologies can diffuse through the network like epidemic Therefore identifying and understanding social influence tremendous interest from both analysis predicting the future the system and design designing viral marketing strategies point view this talk will give general overview models for diffusion social network and then discuss the problem identifying social influence the data This difficult task general since there are many other factors such homophily unobserved confounding variables that can induce statistical correlation between the actions friends social network Thus distinguishing influence from those other factors essentially the problem distinguishing correlation from causality notoriously hard problem Despite this will show how environment where the time stamp the actions are observable can design simple statistical tests that distinguish between models social influence and those that replicate the aforementioned sources social correlation will sketch the proof theoretical justification one the tests and present simulation results randomly generated data and real tagging data from Flickr The results exhibit that while there significant social correlation tagging behavior this system this correlation cannot attributed social influence 
5589 en Classification Graphs using Discriminative Random Walks This paper describes novel technique called walks tackle semi supervised classification problems large graphs introduce here betweenness measure based passage times during random walks bounded lengths the input graph The class unlabeled nodes predicted maximizing the betweenness with labeled nodes This approach can deal with directed undirected graphs with linear time complexity with respect the number edges the maximum walk length considered and the number classes Preliminary experiments the CORA database show that walks outperforms NetKit Macskassy Provost 2007 well Zhou algorithm Zhou 2005 both classification rate and computing time 
5590 en  Online Algorithm for Learning Labeling Graph This short report analyzes simple and intuitive online learning algorithm termed the graphtron for learning labeling over fixed graph given sequence labels The contribution twofold give theoretical characterization the possible sequence mistakes and indicate the use for extremely large scale problems due sublinear space complexity and nearly linear time complexity This work originated from numerous discussions with John Mark and with Johan 
5591 en  New Kernel for Classification Networked Entitiess Statistical machine learning techniques for data classification usually assume that all entities are independent and identically distributed However real world entities often interconnect with each other through explicit implicit relationships form complex network Although some graph based classification methods have emerged recent years they are not really suitable for complex networks they not take the degree distribution network into consideration this paper propose new technique Modularity Kernel that can effectively exploit the latent community structure networked entities for their classification number experiments hypertext datasets show that our proposed approach leads excellent classification performance comparison with the state the art methods 
5592 en Induction Node Label Controlled Graph Grammar Rules Algorithms for inducing graph grammars from sets graphs have been proposed before important class such algorithms are those based the Subdue graph mining system But the rules learned Subdue and its derivatives not fit easily any the well studied graph grammars formalisms this paper discuss how Subdue like algorithms could made work the context NLC grammars important class node replacement graph grammars More specifically show how given set occurrences subgraph NLC grammar rule can induced such that the given occurrences could have been generated 
5594 en Structured Output Prediction with Structural SVMs This talk explores large margin approaches predicting graph based objects like trees clusterings alignments Such problems arise for example when natural language parser needs predict the correct parse tree for given sentence when one needs determine the reference relationships noun phrases document when predicting the alignment between two proteins particular the talk will show how structural SVMs can learn such complex prediction rules using the problems supervised clustering protein sequence alignment and diversification search engines application examples Furthermore the talk will present new cutting plane algorithms that allows training structural SVMs time linear the number training examples 
5595 en Structure and tie strengths mobile communication network examine the communication patterns millions anonymized mobile phone users Based call records construct communication network where vertices are subscribers and edge weights are defined aggregated duration calls reflecting the strengths social ties between callers observe coupling between tie strengths and network topology the ”local” level strong ties are associated with densely connected network neighborhoods providing the first large scale confirmation the Granovetter hypothesis Based fragmentation analysis weak ties are seen play important role the network level accounting for global connectivity The observed coupling shown significantly slow down the spreading random information resulting dynamic trapping information communities 
5596 en Improved Software Fault Detection with Graph Mining This work addresses the problem discovering bugs software development investigate the utilization call graphs program executions and graph mining algorithms approach this problem propose novel reduction technique for call graphs which introduces edge weights Then present analysis technique for such weighted call graphs based graph mining and traditional feature selection Our new approach finds bugs which could not detected far With regard bugs which can already localized our technique also doubles the precision finding them 
5597 en Biomine search engine for probabilistic graphs Biomine search engine prototype under development can used find biological entities that are indirectly related given query entities well display and evaluate the relations Biomine based integrated index number public biological databases The representation probabilistic graph where nodes correspond biological entities typically record biological database and edges their relationships typically cross reference between database records Edges are annotated with probabilities that reflect the strength the reliability the relation will discuss research problems and challenges for search such graphs 
5598 en Parameter Learning Probabilistic Databases Least Squares Approach Probabilistic databases compute the success probabilities queries introduce the problem learning the parameters the probabilistic database ProbLog Given the observed success probabilities set queries compute the probabilities attached facts that have low approximation error the training data well unseen examples Assuming Gaussian error terms the observed success probabilities this naturally leads least squares optimization problem Experiments real world data show the usefulness and effectiveness this least squares calibration probabilistic databases 
5599 en Infinite mixtures for multi relational categorical data Large relational datasets are prevalent many fields propose unsupervised component model for relational data for heterogeneous collections categorical occurrences The occurrences can dyadic adic and over the same different categorical variables Graphs are special case collections dyadic occurrences edges over set vertices The model simple with only one latent variable This allows wide applicability long global latent component solution preferred and the generative process fits the application Estimation with collapsed Gibbs sampler straightforward demonstrate the model with graphs enriched with multinomial vertex properties more concretely with two sets scientific papers with both content and citation information available 
5600 en Markov Logic Improves Protein Partners Prediction Protein partners prediction important problem protein structure that can naturally formulated supervised link prediction show that prediction performance can improved using hybrid solution based Markov logic networks with grounding specific weights 
5601 en  Hilbert Schmidt Dependence Maximization Approach Unsupervised Structure Discovery recent work Song 2007 has been proposed perform clustering maximizing Hilbert Schmidt independence criterion with respect predefined cluster structure solving for the partition matrix extend this approach here the case where the cluster structure not fixed but quantity optimized and use independence criterion which has been shown more sensitive small sample sizes the Hilbert Schmidt Normalized Information Criterion HSNIC Fukumizu 2008 demonstrate the use this framework two scenarios the first adopt cluster structure selection approach which the HSNIC used select structure from several candidates the second consider the case where discover structure directly optimizing 
5602 en Four graph partitioning algorithms will discuss four partitioning algorithms using eigenvectors random walks PageRank and their variations particular will examine local partitioning algorithms which find cut near specified starting vertex with running time that depends the size the small side the cut rather than the size the input graph which can prohibitively large Three the four partitioning algorithms are local algorithms and are particularly appropriate for applications for massive data sets 
5603 en Inverting the Viterbi Algorithm Abstract Framework for Structure Design Probabilistic grammatical formalisms such hidden Markov models HMMs and stochastic context free grammars SCFGs have been extensively studied and widely applied number fields Here introduce new algorithmic problem HMMs and SCFGs that arises naturally from protein and RNA design and which has not been previously studied The problem can viewed inverse the one solved the Viterbi algorithm HMMs the CKY algorithm SCFGs study this problem theoretically and obtain the first algorithmic results prove that the problem complete even for letter emission alphabet via reduction from SAT result that has implications for the hardness RNA secondary structure design then develop number approaches for making the problem tractable particular for HMMs develop branch and bound algorithm which can shown have fixed parameter tractable worst case running time exponential the number states the HMM but linear the length the structure also show how cast the problem Mixed Integer Linear Program 
5604 en  HDP HMM for Systems with State Persistence The hierarchical Dirichlet process hidden Markov model HDP HMM flexible nonparametric model which allows state spaces unknown size learned from data demonstrate some limitations the original HDP HMM formulation and propose sticky extension which allows more robust learning smoothly varying dynamics Using mixtures this formulation also allows learning more complex multimodal emission distributions further develop sampling algorithm that employs truncated approximation the jointly resample the full state sequence greatly improving mixing rates Via extensive experiments with synthetic data and the NIST speaker diarization database demonstrate the advantages our sticky extension and the utility the HDP HMM real world applications 
5605 en Modeling Interleaved Hidden Processes Hidden Markov models assume that observations time series data stem from some hidden process that can compactly represented Markov chain generalize this model assuming that the observed data stems from multiple hidden processes whose outputs interleave form the sequence observations Exact inference this model hard However tractable and effective inference algorithm obtained extending structured approximate inference methods used factorial hidden Markov models The proposed model evaluated activity recognition domain where multiple activities interleave and together generate stream sensor observations shown more accurate than standard hidden Markov model this domain 
5606 en Beam Sampling for the Infinite Hidden Markov Model The infinite hidden Markov model nonparametric extension the widely used hidden Markov model Our paper introduces new inference algorithm for the infinite hidden Markov model called beam sampling Beam sampling combines slice sampling which limits the number states considered each time step finite number with dynamic programming which samples whole state trajectories efficiently Our algorithm typically outperforms the Gibbs sampler and more robust present applications iHMM inference using the beam sampler changepoint detection and text prediction problems 
5607 en Efficiently Solving Convex Relaxations for MAP Estimation The problem obtaining the maximum posteriori MAP estimate discrete random field fundamental importance many areas Computer Science this work build the tree reweighted message passing TRW framework Kolmogorov and Wainwright TRW iteratively optimizes the Lagrangian dual linear programming relaxation for MAP estimation show how the dual formulation TRW can extended include linear cycle inequalities then consider the inclusion some recently proposed second order cone SOC constraints the dual propose efficient iterative algorithms for solving the resulting duals Similar the method described Kolmogorov these methods are guaranteed converge test our algorithms large set synthetic data well real data Our experiments show that the additional constraints cycle inequalities and SOC constraints provide better results cases where the TRW framework fails namely MAP estimation for non submodular energy functions 
5608 en  Quasi Newton Approach Nonsmooth Convex Optimization extend the well known BFGS quasi Newton method and its limited memory variant LBFGS the optimization nonsmooth convex objectives This done rigorous fashion generalizing three components BFGS subdifferentials The local quadratic model the identification descent direction and the Wolfe line search conditions apply the resulting sub BFGS algorithm regularized risk minimization with binary hinge loss and its direction finding component regularized risk minimization with logistic loss both settings our generic algorithms perform comparable better than their counterparts specialized state the art solvers 
5609 en Stopping Conditions for Exact Computation Leave One Out Error Support Vector Machines propose new stopping condition for Support Vector Machine SVM solver which precisely reflects the objective the Leave One Out error computation The stopping condition guarantees that the output intermediate SVM solution identical the output the optimal SVM solution with one data point excluded from the training set simple augmentation general SVM training algorithm allows one use stopping criterion equivalent the proposed sufficient condition comprehensive experimental evaluation our method shows consistent speedup the exact LOO computation our method the factor for the linear kernel The new algorithm can seen example constructive guidance optimization algorithm towards achieving the best attainable expected risk optimal computational cost 
5610 en  Partial Optimality Multi label MRFs consider the problem optimizing multi label MRFs which general hard and ubiquitous low level computer vision One approach for its solution formulate integer programming problem and relax the integrality constraints The approach consider this paper first convert the multi label MRF into equivalent binary label MRF and then relax Our key contribution theoretical study this new relaxation also show how this approach can used combination with recently developed optimization techniques based roof duality which have the desired property that partial sometimes the complete optimal solution the binary MRF can found This property enables localize restrict the range labels where the optimal label for any random variable the multi label MRF lies many cases these localizations lead partially optimal solution the multi label MRF Further running standard MRF solvers TRW this restricted energy much faster than running them the original unrestricted energy demonstrate the use our methods challenging computer vision problems Our experimental results show that methods derived from our study outperform competing methods for minimizing multi label MRFs 
5611 en Democratic Approximation Lexicographic Preference Models Previous algorithms for learning lexicographic preference models LPMs produce best guess LPM that consistent with the observations Our approach more democratic not commit single LPM Instead approximate the target using the votes collection consistent LPMs present two variations this method variable voting and model voting and empirically show that these democratic algorithms outperform the existing methods also introduce intuitive yet powerful learning bias prune some the possible LPMs demonstrate how this learning bias can used with variable and model voting and show that the learning bias improves the learning curve significantly especially when the number observations small 
5612 en Unsupervised Rank Aggregation with Distance Based Models The need meaningfully combine sets rankings often comes when one deals with ranked data Although number heuristic and supervised learning approaches rank aggregation exist they require domain knowledge supervised ranked data both which are expensive acquire order address these limitations propose mathematical and algorithmic framework for learning aggregate partial rankings without supervision instantiate the framework for the cases combining permutations and combining top lists and propose novel metric for the latter Experiments both scenarios demonstrate the effectiveness the proposed formalism 
5613 en Learning Dissimilarities Ranking From SDP consider the problem learning dissimilarities between points via formulations which preserve specified ordering between points rather than the numerical values the dissimilarities Dissimilarity ranking ranking learns from instances like more similar than The distance between and larger than that between and Three formulations ranking problems are presented and new algorithms are presented for two them one semidefinite programming SDP and one quadratic programming Among the novel capabilities these approaches are out sample prediction and scalability large problems 
5614 en Optimizing Estimated Loss Reduction for Active Sampling Rank Learning Learning rank becoming increasingly popular research area machine learning The ranking problem aims induce ordering preference relations among set instances the input space However collecting labeled data growing into burden many rank applications since labeling requires eliciting the relative ordering over the set alternatives this paper propose novel active learning framework for SVM based and boosting based rank learning Our approach suggests sampling based maximizing the estimated loss differential over unlabeled data Experimental results two benchmark corpora show that the proposed model substantially reduces the labeling effort and achieves superior performance rapidly with much relative improvement over the margin based sampling baseline 
5615 en Bayes Optimal Classification for Decision Trees present the first algorithm for exact Bayes optimal classification from the hypothesis space decision trees satisfying leaf constraints Our contribution that reduce this problem the problem finding rule based classifier with appropriate weights show that these rules and weights can computed linear time from the output modified frequent itemset mining algorithm which means that can compute the classifier practice despite the exponential worst case complexity perform experiments which compare the Bayes optimal predictions with those the maximum posteriori hypothesis 
5616 en Detecting Statistical Interactions with Additive Groves Trees Discovering additive structure important step towards understanding complex multi dimensional function because allows the function expressed the sum lower dimensional components When variables interact however their effects are not additive and must modeled and interpreted simultaneously present new approach for the problem interaction detection Our method based comparing the performance unrestricted and restricted prediction models where restricted models are prevented from modeling interaction question show that additive model based regression ensemble Additive Groves can restricted appropriately for use with this framework and thus has the right properties for accurately detecting variable interactions 
5617 en Sparse Bayesian Nonparametric Regression One the most common problems machine learning and statistics consists estimating the mean response beta from vector observations assuming beta epsilon where known beta vector parameters interest and epsilon vector stochastic errors are particularly interested here the case where the dimension beta much higher than the dimension propose some flexible Bayesian models which can yield sparse estimates beta show that tends infinity these models are closely related class Levy processes Simulations demonstrate that our models outperform significantly range popular alternatives 
5618 en Bolasso Model Consistent Lasso Estimation through the Bootstrap consider the least square linear regression problem with regularization the norm problem usually referred the Lasso this paper present detailed asymptotic analysis model consistency the Lasso For various decays the regularization parameter compute asymptotic equivalents the probability correct model selection variable selection For specific rate decay show that the Lasso selects all the variables that should enter the model with probability tending one exponentially fast while selects all other variables with strictly positive probability show that this property implies that run the Lasso for several bootstrapped replications given sample then intersecting the supports the Lasso bootstrap estimates leads consistent model selection This novel variable selection algorithm referred the Bolasso compared favorably other linear regression methods synthetic data and datasets from the UCI machine learning repository 
5619 en The GroupLASSO for Generalized Linear Models Uniqueness Solutions and Efficient Algorithms The GroupLASSO method for finding important explanatory factors suffers from the potential non uniqueness solutions and also from high computational costs formulate conditions for the uniqueness GroupLASSO solutions which lead easily implementable test procedure addition merely detecting ambiguities solutions this testing procedure identifies all potentially active groups These results are used derive efficient algorithm that can deal with input dimensions the millions and can approximate the solution path efficiently The derived methods are applied large scale learning problems where they exhibit excellent performance show that the proposed testing procedure helps avoid misinterpretations GroupLASSO solutions 
5620 en  the Chance Accuracies Large Collections Classifiers provide theoretical analysis the chance accuracies large collections classifiers show that problems with small numbers examples some classifier can perform well random chance and derive theorem explicitly calculate this accuracy use this theorem provide principled feature selection criteria for sparse high dimensional problems evaluate this method both microarray and fMRI datasets and show that performs very close the optimal accuracy obtained from oracle also show that the fMRI dataset this technique chooses relevant features successfully while another state the art method the False Discovery Rate FDR completely fails standard significance levels 
5621 en Autonomous Geometric Precision Error Estimation Low level Computer Vision Tasks Errors map making tasks using computer vision are sparse demonstrate this considering the construction digital elevation models that employ stereo matching algorithms triangulate real world points This sparsity coupled with geometric theory errors recently developed the authors allows for autonomous agents calculate their own precision independently ground truth connect these developments with recent advances the mathematics sparse signal reconstruction compressed sensing The theory presented here extends the autonomy model reconstructions discovered the 1990s their errors 
5622 en Multi Task Compressive Sensing with Dirichlet Process Priors Compressive sensing emerging field that under appropriate conditions can significantly reduce the number measurements required for given signal many applications one interested multiple signals that may measured multiple type measurements where here each signal corresponds sensing task this paper propose novel multi task compressive sensing framework based Bayesian formalism where Dirichlet process prior employed yielding principled means simultaneously inferring the appropriate sharing mechanisms well inversion for each task variational Bayesian inference algorithm employed estimate the full posterior the model parameters 
5623 en Compressed Sensing and Bayesian Experimental Design relate compressed sensing with Bayesian experimental design and provide novel efficient approximate method for the latter based expectation propagation large comparative study about linearly measuring natural images show that the simple standard heuristic measuring Wavelet coefficients top down systematically outperforms methods using random measurements the sequential projection optimisation approach Carin 2007 performs even worse also show that our own approximate Bayesian method able learn measurement filters full images efficiently which outperform the Wavelet heuristic our knowledge ours the first successful attempt learning compressed sensing for images realistic size contrast common methods our framework not restricted sparse signals but can readily applied other notions signal complexity noise models give concrete ideas how our method can scaled large signal representations 
5624 en Efficient Projections onto the Ball for Learning High Dimensions describe efficient algorithms for projecting vector onto the ball present two methods for projection The first performs exact projection time where the dimension the space The second works vectors whose elements are perturbed outside the ball projecting log time This setting especially useful for online learning sparse feature spaces such text categorization applications demonstrate the merits and effectiveness our algorithms numerous batch and online learning tasks show that variants stochastic gradient projection methods augmented with our efficient projection procedures outperform state the art optimization techniques such interior point methods also show that online settings gradient updates with projections outperform the algorithm while obtaining models with high degrees sparsity 
5625 en Empirical Bernstein Stopping Sampling popular way scaling machine learning algorithms large datasets The question often how many samples are needed Adaptive stopping algorithms monitor the performance online fashion and make possible stop early sparing valuable computation time concentrate the setting where probabilistic guarantees are desired and demonstrate how recently introduced empirical Bernstein bounds can used design stopping rules that are efficient provide upper bounds the sample complexity the new rules well empirical results model selection and boosting the filtering setting 
5626 en Pointwise Exact Bootstrap Distributions Cost Curves Cost curves have recently been introduced alternative complement ROC curves order visualize binary classifiers performance importance both cost and ROC curves the computation confidence intervals along with the curves themselves that the reliability classifier performance can assessed Computing confidence intervals for the difference performance between two classifiers allows determine whether one classifier performs significantly better than another simple procedure obtain confidence intervals for costs the difference between two costs under various operating conditions perform bootstrap resampling the testset this paper derive exact bootstrap distributions these values and use these distributions obtain confidence intervals under various operating conditions Performances these confidence intervals are measured terms coverage accuracies Simulations show excellent results 
5627 en  Empirical Evaluation Supervised Learning High Dimensions this paper perform empirical evaluation supervised learning methods high dimensional data evaluate learning performance three metrics accuracy AUC and squared loss also study the effect increasing dimensionality the relative performance the learning algorithms Our findings are consistent with previous studies for problems relatively low dimension but suggest that dimensionality increases the relative performance the various learning algorithms changes our surprise the methods that seem best able learn from high dimensional data are random forests and neural nets 
5628 en Cost Sensitive Multi class Classification from Probability Estimates For two class classification common classify setting threshold class probability estimates where the threshold determined ROC curve analysis analog for multi class classification learning new class partitioning the multiclass probability simplex minimize empirical misclassification costs analyze the interplay between systematic errors the class probability estimates and cost matrices for multi class classification explore the effect the class partitioning five different transformations the cost matrix Experiments benchmark datasets with naive Bayes and quadratic discriminant analysis show the effectiveness learning new partition matrix compared previously proposed methods 
5629 en  Least Squares Formulation for Canonical Correlation Analysis Canonical Correlation Analysis CCA well known technique for finding the correlations between two sets multi dimensional variables projects both sets variables into lower dimensional space which they are maximally correlated CCA commonly applied for supervised dimensionality reduction which one the multi dimensional variables derived from the class label has been shown that CCA can formulated least squares problem the binary class case However their relationship the more general setting remains unclear this paper show that under mild condition which tends hold for high dimensional data CCA multi label classifications can formulated least squares problem Based this equivalence relationship propose several CCA extensions including sparse CCA using norm regularization Experiments multi label data sets confirm the established equivalence relationship Results also demonstrate the effectiveness the proposed CCA extensions
5630 en Closed form Supervised Dimensionality Reduction with Generalized Linear Models propose family supervised dimensionality reduction SDR algorithms that combine feature extraction dimensionality reduction with learning predictive model unified optimization framework using data and class appropriate generalized linear models GLMs and handling both classification and regression problems Our approach uses simple closed form update rules and provably convergent Promising empirical results are demonstrated variety high dimensional datasets 
5631 en Subspace based Learning with Grassmann Kernels this paper propose discriminant learning framework for problems which data consist linear subspaces instead vectors treating subspaces basic elements can make learning algorithms adapt naturally the problems with linear invariant structures propose unifying view the subspace based learning method formulating the problems the Grassmann manifold which the set fixed dimensional subspaces Euclidean space Previous methods the problem typically adopt inconsistent strategy feature extraction performed the Euclidean space while non Euclidean dissimilarity measures are used our approach treat each subspace point the Grassmann space and perform feature extraction and classification the same space show feasibility the approach using the Grassmann kernel functions such the Projection kernel and the Binet Cauchy kernel Experiments with real image databases show that the proposed method performs well compared with state the art algorithms 
5632 en Metric Embedding for Kernel Classification Rules this paper consider smoothing kernel based classification rule and propose algorithm for optimizing the performance the rule learning the bandwidth the smoothing kernel along with data dependent distance metric The data dependent distance metric obtained learning function that embeds arbitrary metric space into Euclidean space while minimizing upper bound the resubstitution estimate the error probability the kernel classification rule restricting this embedding function reproducing kernel Hilbert space reduce the problem solving semidefinite program and show the resulting kernel classification rule variation the nearest neighbor rule compare the performance the kernel rule using the learned data dependent distance metric state the art distance metric learning algorithms designed for nearest neighbor classification some benchmark datasets The results show that the proposed rule has either better good classification accuracy the other metric learning algorithms 
5633 en Extracting and Composing Robust Features with Denoising Autoencoders Previous work has shown that the difficulties learning deep generative discriminative models can overcome initial unsupervised learning step that maps inputs useful itermediate representations introduce and motivate new training principle for unsupervised learning representation based the idea making the learned representations robust partial corruption the input pattern This approach can used train autoencoders and these denoising autoencoders can stacked initialize deep architectures The algorithm can motivated from manifold learning and information theoretic perspective from generative model perspective Comparative experiments clearly show the surprising advantage corrupting the input autoencoders pattern classification benchmark suite 
5634 en Large Scale Learning Challenge With the exceptional increase computing power storage capacity and network bandwidth the past decades ever growing datasets are collected fields such bioinformatics Splice Sites Gene Boundaries etc security Network traffic Text Classification Spam Non Spam name but few While the data size growth leaves computational methods the only viable way dealing with data poses new challenges methods This workshop concerned with the scalability and efficiency existing approaches with respect computational memory communication resources resulting from high algorithmic complexity from the size dimensionality the data set and from the trade off between distributed resolution and communication costs 
5635 en Large Scale Learning Which Actually Useful
5637 en Pascal Challenge Linear Support Vector Machines participate the linear SVM Track the Pascal Large Scale Learning Challenge ICML 2008 consider the LIBLINEAR package which can handle and loss linear SVMs The SVM solver implemented LIBLINEAR employes coordinate descent method solve the dual problem This method very useful for large sparse data with huge number instances and features However most data sets this challenges have quite small number features work the competition data slightly modify LIBLINEAR 
5638 en Parallel streaming decision trees new algorithm for building decision tree classifiers proposed The algorithm executed distributed environment and especially designed for classifying large datasets and streaming data empirically shown accurate standard decision tree classifiers while being scalable infinite streaming data and multiple processors 
5639 en CTJLSVM Componentwise Triple Jump Acceleration for Training Linear SVM The triple jump extrapolation method effective approximation Aitken’ acceleration for accelerating the convergence many machine learning algorithms that can formulated fixedpoint iteration the remainder this abstract briefly review the general idea the triple jump method and then describe how apply accelerate stochastic gradient descent SGD for training linear support vector machines SVM 
5640 en  Efficient Parameter Free Method for Large Scale Offline Learning With the rapid growth computer storage capacities available data and demand for scoring models both follow increasing trend sharper than that the processing power However the main limitation wide spread data mining solutions the non increasing availability skilled data analysts which play key role data preparation and model selection this paper present parameter free scalable classification method which step towards fully automatic data mining The method based Bayes optimal univariate conditional density estimators naive Bayes classification enhanced with Bayesian variable selection scheme and averaging models using logarithmic smoothing the posterior distribution focus the complexity the algorithms and show how they can cope with datasets that are far larger than the available central memory finally report results the Large Scale Learning challenge where our method obtains state the art performance within practicable computation time 
5641 en Training Support Vector Machines Status and Challenges
5642 en Interior Point SVM Support vector machine training can represented large quadratic program present efficient and numerically stable algorithm for this problem using primal dual interior point methods Reformulating the problem exploit separability the Hessian eliminates the main source computational complexity resulting algorithm which requires only operations per iteration Extensive use BLAS functions enables good parallel efficiency shared memory processors the algorithm works primal and dual spaces simultaneously our approach has the advantage obtaining the hyperplane weights and bias directly from the solver 
5644 en LaRank SGD Fast Optimizers for Linear SVM Originally proposed for solving multiclass SVM the LaRank algorithm dual coordinate ascent algorithm relying randomized exploration inspired the perceptron algorithm Bordes05 Bordes07 This approach competitive with gradient based optimizers simple binary and multiclass problems Furthermore very few LaRank passes over the training examples delivers test error rates that are nearly good those the final solution For this entry ran several epochs the LaRank algorithm until reaching the convergence criterion The SGD algorithm uses stochastic gradient descent modified using efficient method estimate the diagonal the inverse Hessian The estimation method inspired oLBFGS Schraudolph Since there little need update this estimated matrix each iteration this approximate second order stochastic gradient method iterates nearly fast than classical stochastic gradient descent Bottou98 Bottou07 but requires less iterations 
5645 en Large Scale Learning Challenge Discussion and Summary
5646 en Averaging Support Vector Machines for Processing Large Data Sets The handling large data sets support vector machines SVMs Vapnik 1998 employing nonlinear kernel suffers from the non linear scaling the numerical solution techniques for the underlying optimisation problem This particular valid the kernel matrix cannot stored the main memory anymore and therefore the evaluation the kernel given data points needs recomputed again and again investigate simple approach allow the processing larger data sets separate the large data set into number smaller ones each small enough allow the caching the kernel matrix and learn support vector machine for each these data sets For the evaluation data points then just simply average the results the different SVMs 
5653 en Lecture Atomic Theory Matter People History nnA AristotlennB DemocritusnnC Continuum Modelnn Robert Boylenn Joseph Priestlynn Antoine Lavoisiernn Joseph Proustnn John Dalton Atomic Theory Matternn Scanning Tunneling Microscopy III End the Century nnA Major Advancesnn Newtonian mechanicsnn Thermodynamicsnn Statistical Mechanicsnn Classical ElectromagnetismnnB Non “Classical” Observationsnn Discovery electron and nucleusnn Photoelectric effectnn Discovery the Electron 
5654 en Lecture Discovery Nucleus Rutherford 1911 nnA Discovery the NucleusnnB Backscattering experimentnn Classical Description Atom nnA Coulombic interactionnnB Classical equation motion Newton’ Second Lawnn III Wave Particle Duality Matter and Radiation nnA Wave Nature LightnnB Electromagnetic Radiation – periodic variation electromagnetic field
5655 en Lecture Wavelike Properties Radiation Light Periodic Variation Electromagnetic Field nnA Oscillation propagationnnB Calculating speed wavennC Visible lightnn Wave Nature Light nnA SuperpositionnnB Constructive and destructive interferencenn III Wavelike Properties Radiation nnA Young’ two slit experimentnnB General condition for constructive interferencennC General condition for destructive interference
5656 en Lecture Particle like Nature Light Photoelectric Effect nnA Threshold frequency nnB Kinetic energy frequencynn Classical predictionsnn Planck’ constantnn nnC Threshold energynn Photon Momentum nnA 
5657 en Lecture Matter Wave Electron Diffraction Experiment 1927 nnA Wave like properties snnB Calculating from nnC Broglie wavelengthnn Schrödinger’ Equation – Equation Motion for Matter Waves 
5658 en Lecture The Hydrogen Atom Binding energy nucleus nnA QuantizednnB quantum numbernnC Binding energy Verification Energy Levels for Atom nnA Photon emissionnnB transitions between two statesnnC Photon absorptionnn III Wavefuntions for Atom nnA Stationary state wavefunctionnnB Three quantum numbers describe wave 3Dnn Principle quantum number nnn Angular momentum quantum number Magnetic quantum number 
5659 en Lecture Hydrogen Atom Wavefunctions Hydrogen Atom Wavefunctions nnA OrbitalsnnB Degeneracynn Shapes Atom Orbitals nnA Probability densitynnB Radial probability distributionnnC wavefunctionsnnD Radial nodesnn III Bohr Model and the Uncertainty Principle 
5660 en Lecture Orbitals Orbitals nnA Nodal planesnnB Angular nodesnnC Radial probability distributionsnn Wavefunctions for Multielectron Atoms nnA Electron configurationnnB Spin and the Pauli exclusion principlennC One wavefunctions for multielectron atoms
5661 en Lecture Electronic Structure Multielectron Atoms Electron Configurations nnA Aufbau Principlenn Pauli Exclusion Principlenn Hund’ RulennB Core electrons and valence electronsnn Shielding and eff III Electron Configurations Ions Photoelectron Spectroscopy 
5662 en Lecture Periodic Trends Elemental Properties Periodic Table nnA HistorynnB Periodic trendsnn Ionization energynn Electron affinitynn Electronegativitynn Atomic Sizesnnn Isoelectronic 
5663 en Lecture Covalent Bonds Energy Interaction nnA Nuclear nuclear repulsionnnB Electron electron repulsionnnC Electron nuclear attraction
5664 en Lecture Lewis Diagrams Lewis Structures nnA Example Cyanide Ion nnB Example Thionyl Chloride SOCl Formal Charge nnA Assigning formal charge atomnnB SignificancennC Formal charge Oxidation numbernn III Skeletal Structure nnA Methyl groupsnnB Chain moleculesnn Resonance nnA Example nnB Resonance hybrid
5665 en Lecture Breakdown Octet Rule Breakdown Octet Rule nnA Odd number valence electronsnn Example • Example •NOnnB Octet deficient moleculesnnC Valence shell expansionnn Example PCl Example CrO Example Ionic Bonds – Classical Model and Mechanism nnA Harpoon MechanismnnB Limitations the modelnnC Energy Interaction 
5666 en Lecture Molecular Orbital Theory Linear combination atomic orbitals LCAO nnA Molecular orbitals MOs nnB Bonding orbitalnnC Antibonding orbitalnnD Electron configurationsnn Example Example nnE Bond Ordernn MOs formed LCAO nnA MOs formed LCAO – 2snn Example Example nnB Bonding MOs formed LCAO – and Example Example nnC Bonding formed LCAO – nnD Antibonding formed LCAO – and nnE Antibonding formed LCAO – III Molecular Orbital Theory Heteronuclear Diatomics 
5667 en Lecture Valence Bond Theory and Hybridization Hybridization nnA Example Methane nnB Example Ethane nnC Example Ammonia nnD Example Water Onn sp2 Hybridization nnA Example Borane nnB Example Ethylene nnC Example Benzene III Hybridization 
5668 en Lecture Hybridization and Chemical Bonding Example Methyl nitrate ONO nnA Finding the lowest energy Lewis structurennB Bond symmetrynnC Hybrid orbitalsnnD Atomic orbitalsnn Intramolecular Interactions Origin Bad Hair Day nnA Hydrogen bondingnnB WaternnC Keratin
5669 en Lecture Bond Energies Bond Enthalpies Bond Enthalpy Average bond enthalpiesnnnB Enthalpy chemical reactionsnnC Endothermic ExothermicnnD Heat Formation ° nnE State functionnnF Hess’ Lawnn Thermodynamics and Spontaneous Change nnA Gibbs free energy °nnB Entropy ° for Reactionsnn Law Thermodynamicsnn Internal degrees freedom reactants
5670 en Lecture Free Energy Formation Gof Standard Gibbs Free Energy Formation nnA Thermodynamic stabilitynnB Calculating ° for reactionnn Second Law Thermodynamics nnA Controlling spontaneity with temperaturennB any pressure ideal gases III Chemical Equilibrium nnA Thermodynamic equilibrium constantnnB Reaction quotient and direction change
5671 en Lecture Chemical Equilibrium Nature Chemical Equilibrium nnA Free energy Progress reactionnnB Reaction quotientnn Partial pressure gas Concentration solute nnC Relationship between and Qnn Meaning nnA Concentration products equilibriumnnB 1nnC Relationship between ° and the magnitude Knn III Relationship Between Equilibrium Expressions External Effects nnA Principle ChâteliernnB Adding and removing reagentsnn Adding more reactantnn Adding more productnn Removing product
5672 en Lecture Chemical Equilibrium cont External Effects nnA Changing the volumennB Adding inert gasnnC Changing the temperaturenn Temperature dependence KnnD Maximizing the yield reactionnnE Châteier and hemoglobinnn Significant Rules for Logs and Exponentials 
5674 en Lecture Acid Base Equilibrium Classification Acids and Bases nnA ArrheniusnnB Brønsted Lowrynn Conjugate acid base pairsnn Amphoteric moleculesnnC Lewis acid and basenn Autoionization Water III Function pOH Function Strength Acids and Bases Acid waternn Base waternn Conjugate acids and basesnn Relative strengths acidsnn Types Acid Base Problems VII Equilibrium Involving Weak Acids 
5675 en Lecture Acid Base Equilibrium cont Types Acid Base Problems Equilibrium Involving Weak Acids III Salt Solutions Buffers nnA Acid buffernnB Base buffernnC Designing buffernn Henderson Hasselbalch equation
5676 en Lecture Acid Base Equilibrium Titrations Titrations Involving Strong Acid and Strong Base nnA Equivalence pointnnB End pointnn Calculating Points Curve nnA Calculating before the equivalence pointnnB Calculating volume HCl needed reach equivalence pointnnC Calculating after the equivalence pointnn III Titration Curves for Weak Acid Strong Base and for Weak Base Strong Acid 
5678 en Lecture Acid Base Titrations and Oxidation Reduction Acid Base Titration How Calculate nnA Weak acid Strong basennB Weak base Strong acidnn Oxidation Reduction Reactions nnA Guidelines for assigning oxidation numbersnnB Definitionsnn Oxidationnn Reductionnn Oxidizing agentnn Reducing agentnnC Disproportionation reactionnnD Balancing redox reactions
5679 en Lecture Oxidation Reduction Electrochemical Cells nnA BatterynnB Anode oxidation nnC Cathode reduction nnD Faraday’ LawnnE Electrodesnn electrodenn Hydrogen electrodenn Relationship Between Cell Potential cell and Gibbs Free Energy nnA Standard states and cell potentialsnn ° cell ° cell Galvanic cellnn Electrolytic cellnnB Standard reduction potential °
5681 en Lecture Oxidation Reduction cont Adding and Subtracting Half Cell Reactions Nernst Equation nnA Example Calculate ° cell which the concentration ions and 0010 nnB Example What ° nnC Reduction vitamin 
5682 en Lecture Transition Metals Formation Coordination Complexes nnA Donor atoms ligandsnnB Acceptor atomsnnC Coordination complexesnnD Coordination numbernnE Coordination complex notationnn Structures Coordination Complexes nnA Chelate effectnn Vitamin Ethylenediamine tetraacetic acid EDTA nnB Geometric isomersnnC Optical isomers enantiomers III Electron Counting Coordination Complexes Orbitals 
5683 en Lecture Transition Metals Crystal Field Theory Crystal Field and Ligand Field Theories Crystal Field Theory nnA Octahedral field splitting energy nnB Octahedral crystal field splitting diagramnC High spinnnD Low spinnnE Examples 3Br 3nn octahedral coordination complex
5684 en Lecture The Shapes Molecules VSEPR Theory Valence Shell Electron Pair Repulsion VSEPR Theory nnA Prediction geometrynnB Nomenclaturenn VSEPR Rules nnA Steric Number nnB Resonance structuresnnC Molecules without lone pairsnnD Molecules with lone pairsnn Attractive forces exerted nucleinn Repulsive forcesnn III Rationalization shapes based VSEPR theory nnA Atomic sizennB Bond lengths
5686 en Lecture Transition Metals Crystal Field Theory Tetrahedral Case nnA Tetrahedral crystal field splitting energy nnB Orbital destabilizationnnC compared Crystal Field Theory Square Planar Case III Spectrochemical Series nnA Strong field ligandsnnB Weak field ligandsnn Color octahedral coordination complexes Magnetism nnA ParamagneticnnB Diamagnetic
5687 en Lecture Kinetics Rates Chemical Reactions nnA KineticsnnB Oxidation glucosennC Factors affecting rates reactionsnnD Measuring reaction ratesnnE Rate expressionsnn Rate Laws nnA Order reaction reactants productsnnB Overall reaction ordernnC Units for knnD Integrated rate lawsnn First order half life 
5688 en Lecture Kinetics cont Radioactive Decay nnA Nuclear kineticsnnB Decay rate activity nnC Becquerel nnD Medical usesnn Second Order Integrated Rate Laws nnA Second order half lifenn III Kinetics and Chemical Equilibrium nnA Equilibrium constantnnB Elementary reactionsnnC Example decomposition ozone
5689 en Lecture Kinetics cont Investigating Reaction Mechanisms nnA RatennB OrdernnC MolecularitynnD Steady state approximationnnE Rate determining step
5690 en Lecture Kinetics cont Effect Temperature Reaction Rates nnA Gas phasenn Arrhenius equationnnB Activation energy Using activation energy predict rate constantnnC Reaction Coordinate and the Activation Complexnn Activated complex transition statenn Relationship between and knn Relationship between and Knn Rate constants and temperaturenn Equilibrium constants and temperaturenn Châtelier’ Principlenn Large small 
5691 en Lecture Kinetics Catalysis Kinetics Catalysis nnA CatalystnnB InhibitornnC Types Catalystsnn Homogeneous catalystsnn Heterogneous catalystsnn Catalysts life enzymesnn Enzyme Catalysis nnA SubstratesnnB Active sitennC Deriving the rate expression for Pnn Michaelis Menten EquationnnD Enzyme inhibition
5692 en Lecture Review Case Study Methionine Synthase nnA Kineticsnn Enzymenn InhibitionnnB Transition metalsnn Tetradentate ligandnn electron countnn Chelate effectnnC VSEPRnn Steric numbernn Geometrynn AnglesnnD Oxidation Reductionnn Review nnA Reducing agentnnB Spontaneous reactionnnC ° III Acid Base Equilibrium nnA DeprotonationnnB pKannC Lewis acidnn Chemical Equilibrium nnA Conformational changes
5696 en Lecture Periodic Phenomena Oscillations Waves SHO Complex Notation Differential Equations Physical Pendulum
5697 en Lecture Beats Damped Free Oscillations Under Over and Critically Damped Quality 
5698 en Lecture Forced Oscillations with Damping Information about the Tacoma Narrows Bridge Collapse Information about the Tacoma Narrows Bridge Collapse http www pbs org wgbh nova bridge tacoma3 html and nhttp www ketchum org bridgecollapse html
5699 en Lecture Forced Oscillations Power Resonance Resonance Absorption Resonance Width Quality Transient Phenomena General Solutions including Initial Conditions 
5701 en Lecture Driven Coupled Oscillators Triple Pendulum Steady State and Transient Solutions Cramer Rule
5702 en Lecture Many Coupled Oscillators Wave Equation Transverse Traveling Pulses and Waves
5703 en Lecture Traveling Waves Boundary Conditions Standing Waves Sound Longitudinal Waves Energy Waves
5704 en Lecture Musical Instruments Sound Cavities Normal Modes
5705 en Lecture Exam Review
5706 en Lecture Fourier Analysis Time Evolution Pulses Strings
5707 en Lecture Dispersion Phase Velocity Group Velocity
5708 en Lecture Electromagnetic Waves Plane Wave Solutions Maxwell Equations Polarization Malus Law
5709 en Lecture Accelerated Charges Poynting Vector Power Rayleigh Scattering Polarization
5710 en Lecture Doppler Effect Sound Radiation Binary Stars Neutron Stars and Black Holes Expanding Universe
5711 en Lecture Boundary Conditions Perfect Conductors Reflection Standing Waves Transmission Lines Radiation Pressure
5712 en Lecture Wave Guides Resonance Cavities radiation and Sound
5713 en Lecture Boundary Conditions for Dielectrics Index Refraction Snell Law Total Internal Reflection Fresnel Equations Brewster Angle
5714 en Lecture Exam Review
5715 en Lecture Huygens Principle Interference Thin films Soap Oil Light double slit interference 
5716 en Lecture Diffraction Gratings Pin Holes Angular Resolution
5717 en Lecture Rainbows Haloes Coronae Glories
5718 en Lecture Farewell Special Bring Friend 
5719 en Lecture Introduction and lumped abstraction
5720 en Lecture Basic circuit analysis method KVL and KCL mMethod 
5721 en Lecture Superposition Thévenin and Norton
5722 en Lecture The digital abstraction
5723 en Lecture Inside the digital gate
5726 en Lecture Dependent sources and amplifiers
5727 en Lecture MOSFET amplifier large signal analysis
5728 en Lecture Amplifiers small signal model
5729 en Lecture Small signal circuits
5730 en Lecture Capacitors and first order systems
5731 en Lecture Digital circuit speed
5732 en Lecture State and memory
5733 en Lecture Second order systems
5734 en Lecture Sinusoidal steady state
5735 en Lecture The impedance model
5737 en Lecture The operational amplifier abstraction
5738 en Lecture Operational amplifier circuits
5739 en Lecture amps positive feedback
5740 en Lecture Energy and power
5741 en Lecture Energy CMOS
5742 en Lecture Violating the abstraction barrier
5743 en Lecture What holds our world together Electric Charges Historical Polarization Electric Force Coulomb Law Walter Lewin lectures will general not repeat your book but they will complementary the book The book will support lectures lectures will support the book You will not see any tedious derivations lectures For that have the book But will stress the concepts and will make you see beyond the equations beyond the concepts will show you whether you like not that physics beautiful And you may even start like suggest you not slip not even one day eight two not easy have new concepts every week and before you know you may too far behind Electricity and magnetism all around have electric lights Electric clocks have microphones calculators televisions VCRs radio computers Light itself electromagnetic phenomenon radio waves are The colors the rainbow the blue sky are there because electricity And will teach you about that this course Cars planes trains can only run because electricity Horses need electricity because muscle contractions require electricity 
5744 en Lecture Electric Field Field Lines Superposition Inductive Charging Dipoles Induced Dipoles Today going work with you new concept and that the concept what call electric field spend the whole lecture electric fields have charge just choose capital and plus particular location and another location have another charge little think that test charge And there separation between the two which The unit vector from capital little this vector And now know that the two charges they were positive let suppose that little positive they would repel each other Little negative they would attract each other And let this force and last time introduced Coulomb law that force equals little times capital times Coulomb constant divided squared the direction roof The two have the same sign this direction they have opposite sign the other direction And now introduce the idea electric field for which write the symbol capital 
5745 en Lecture Electric Flux Gauss Law Examples Today going work whole new concept and that the concept electric flux come long way started out with Coulomb law got electric field lines And now have electric flux Suppose have electric field which like and bring that electric field surface open surface like handkerchief piece paper And here Something like that And carve this surface very small surface elements each with size that the area teeny weeny little area and let this the normal roof the normal that surface now the local electric field say that location would for instance this vector 
5746 en Lecture Electrostatic Potential Electric Energy Conservative Field Equipotential Surfaces going talk about again some new concepts And that the concept electrostatic potential electrostatic potential energy For which will use the symbol and independently electric potential Which very different for which will use the symbol Imagine that have charge one here and that plus plus charge and here have charge plus two and they have distant they distance apart And that point very clear that order bring these charges this distance from each other had work bring them there because they repel each other like pushing spring you release the spring you get the energy back 
5747 en Lecture grad More Equipotential Surfaces Conductors Electrostatic Shielding Faraday Cage today new concepts new ideas you can release little bit and want discuss with you the connection between electric potential and electric fields Imagine you have electric field here space and that take charge pocket start position and walk around and return that point Since these forces are conservative forces the electric field static electric field there are moving charges but that becomes more difficult then the forces are conservative forces and the work that when march around and coming back point must zero clear when you look the equation number three that the potential difference between point and point obviously zero start point and end point and that the integral going from back point dot and that then has zero And normally indicate such integral with circle which means you end where you started This line now this not closed surface had equation one 
5748 en Lecture High Voltage Breakdown Lightning Sparks Elmo Fire Last time mentioned you that charge resides the surface solid conductors but that not uniformly distributed Perhaps you remember that unless happens sphere And want pursue that today had solid conductor which say had this shape and going convince you today that right here the surface charge density will higher than there Because the curvature stronger than here And the way want approach that follows Suppose have here solid conductor which has radius and very very far away maybe tens meters away have solid conductor with radius and they are connected through conducting wire That essential they are connected through conducting wire then equipotential They all have the same potential going charge them until get charge distribution here and get there The potential about the same that would were not there 
5749 en Lecture Capacitance Field Energy assemble charges have work discussed that earlier And call that electrostatic potential energy Today will look this energy concept different way and will evaluate the energy terms the electric field Suppose have two parallel plates and charge this one with positive charge which the surface charge density times the area the plate and this one negative charge which the surface charge density negative times the area the plate And let assume that the separation between these two and have electric field which approximately constant and the electric field here sigma divided epsilon zero And now going take the upper plate and going move And that have apply force because these two plates attract each other have work And move this and will move over distance creating here electric field that wasn there before 
5750 en Lecture Polarization Dielectrics The Van Graaff More Capacitors Electric fields can induce dipoles insulators Electrons and insulators are bound the atoms and the molecules unlike conductors where they can freely move and when apply external field for instance field this direction then even though the molecules the atoms may completely spherical they will become little bit elongated the sense that the electrons will spend little bit more time there than they used and this part become negatively charged and this part becomes positively charged and that creates dipole discussed that with you already during the first lecture because there something quite remarkable about this that you have insulator notice the pluses and the minuses indicate neutral atoms and now apply electric field which comes down from the top then you see slight shift the electrons they spend little bit more time than down and what you see now you see layer negative charge being created the top and layer positive charge being created the bottom That the result induction call that also sometimes polarization You are polarizing way the electric charge 
5751 en Lecture Currents Resistivity Ohm Law When positive charges move unintelligible directions then per definition say the current goes this direction When negative charges this direction also say the current goes that direction that just our convention apply potential difference over conductor then going create electric field that conductor And the electrons there are free electrons conductor they can move but the ions cannot move because they are frozen into the solid into the crystal And when current flows conductor always the electrons that are responsible for the current The electrons fuel the electric fields and then the electrons try make the electric field zero but they can succeed because keep the potential difference over the conductor 
5752 en Lecture Batteries EMF Energy Conservation Power Kirchhoff Rules Circuits Kelvin Water Dropper
5753 en Lecture Magnetic field Lorentz Force Torques Electric Motors Oscilloscope
5754 en Lecture Review Exam Secret Top 
5755 en Lecture Moving Charges fields Cyclotron Synchrotron Mass Spectrometer Cloud Chamber
5756 en Lecture Biot Savart Law Gauss Law for Magnetic Fields Revisit the Leyden Jar High Voltage Power Lines
5757 en Lecture Ampere Law Solenoids Revisit the Kelvin Water Dropper Midterm Evaluation
5758 en Lecture Electromagnetic Induction Faraday Law Lenz Law Complete Breakdown Intuition Non Conservative Fields
5759 en Lecture Motional EMF Dynamos Eddy Currents Magnetic Braking
5760 en Lecture Displacement Current Difficult Concept Synchronous Motors Induction Motors Secret Top How does work 
5761 en Lecture How Magicians levitate women with demo Electric Shock Treatment demo Electrocardiogram with demo Pacemakers Superconductivity with demo Levitating Bullet Trains Aurora Borealis
5762 en Lecture Inductance Circuits Magnetic Field Energy
5763 en Lecture Magnetic Materials Dia Para and Ferromagnetism Prize Ceremony Motor Contest
5764 en Lecture Hysteresis Electromagnets Bohr Magneton Maxwell Equations 600 daffodils
5765 en Lecture Review Exam 
5766 en Lecture Transformers Car Coils Circuits
5767 en Lecture Driven LRC Circuits Resonance Metal Detectors Beach Airport 
5768 en Lecture Traveling Waves Standing Waves Musical Instruments
5769 en Lecture Resonance Destructive Resonance Electromagnetic Waves Speed Light Radio Distance Determinations using Radar and Lasers Information about the Tacoma Narrows Bridge Collapse nhttp www pbs org wgbh nova bridge tacoma3 html and http www ketchum org bridgecollapse html
5770 en Lecture Index Refraction Poynting Vector Oscillating Charges Radiation Pressure Comet Tails Polarization Linear Elliptical and Circular 
5771 en Lecture Snell Law Refraction Total Reflection Dispersion Prisms Huygens Principle The Illusion Color The Weird Benham Top Land Famous Demo
5772 en Lecture Polarizers Malus Law Brewster Angle Polarization Reflection and Scattering Why the sky blue Why are sunsets red The sun will set the lecture hall 
5773 en Lecture Rainbows modest rainbow will appear the lecture hall Fog Bows Supernumerary Bows Polarization the Bows Halos around the Sun and the Moon Mock Suns
5774 en Lecture Review Exam 
5775 en Lecture Double Slit Interference Interferometers
5776 en Lecture Gratings Resolving Power Single Slit Diffraction Angular Resolution Human Eye Telescopes
5777 en Lecture Doppler Effect The Big Bang Cosmology
5778 en Lecture Farewell Special Bring Friend The charming MIT Muses surprise Walter Lewin during his last lecture Photo Markos Hankin MIT Physics Department Lecture Demonstration Group Used with permission The Muses MIT all women cappella group 
5779 en Lecture The Geometry Linear Equations
5780 en Lecture Administrivia Introduction Analysis Algorithms Insertion Sort Mergesort going get started Handouts are the the door anybody didn pick one name Charles Leiserson will lecturing this course this term Introduction Algorithms with Erik Demaine addition this SMA course Singapore MIT Alliance course which will run Singapore David Hsu And all the lectures will videotaped and made available the Web for the Singapore students well for MIT students who choose watch them the Web you have issue not wanting the videotape you should sit the back row Otherwise you will 
5781 en Lecture Asymptotic Notation Recurrences Substitution Master Method name Erik Demaine You should call Erik Welcome back 046 This Lecture And today are going essentially fill some the more mathematical underpinnings Lecture Lecture just sort barely got our feet wet with some analysis algorithms insertion sort and mergesort And needed couple tools had this big idea asymptotics and forgetting about constants just looking the lead term And today going develop asymptotic notation that know that mathematically And also ended with recurrence with mergesort the running time mergesort need see how solve recurrences And will those two things today Question Yes will speak louder Thanks Good 
5782 en Lecture Divide and Conquer Strassen Fibonacci Polynomial Multiplication Good morning everyone Today are going some algorithms back algorithms and are going use lot the well some the simpler mathematics that developed last class like the master theorem for solving recurrences are going use this lot Because are going talk about recursive algorithms today And will find their running time using the master theorem This just the same was last time hope unless made mistake couple reminders You should all recitation Friday That required you want you can homework lab Sunday That may good excuse for you actually work your problem set few hours early 
5783 en Lecture Quicksort Randomized Algorithms Today are going talk about very interesting algorithm called Quicksort which was invented Tony Hoare 1962 And has ended being really interesting algorithm from many points view And because that turns out today lecture going both hard and fast you see the person next you sleeping you will want say let get going divide and conquer algorithm 
5784 en Lecture Linear time Sorting Lower Bounds Counting Sort Radix Sort Today going talk about sorting which may not come such big surprise talked about sorting for while but going talk about somewhat higher level and question some the assumptions that been making far And going ask the question how fast can sort pretty natural question You may think you know the answer Perhaps you Any suggestions what the answer this question might There are several possible answers Many them are partially correct Let hear any kinds answers you like and start waking this fresh morning Sorry 
5785 en Lecture Order Statistics Median Today going not talk about sorting This exciting new development going talk about another problem related problem but different problem going talk about another problem that would like solve linear time Last class talked about could sorting linear time that needed some additional assumptions Today going look problem that really only needs linear time even though first glance might look like requires sorting this going easier problem The problem give you bunch numbers 
5786 en Lecture Hashing Hash Functions Today starts two lecture sequence the topic hashing which really great technique that shows lot places going introduce through problem that comes often compilers called the symbol table problem And the idea that have table holding records where each record just little more explicit here each record typically has bunch this record usually pointer the actual data when talk about the record what usually means some pointer the data And the data the record this record there key called key 
5787 en Lecture Universal Hashing Perfect Hashing Hashing Today going some amazing stuff with hashing And really this such neat stuff amazing going start addressing fundamental weakness hashing And that that for any choice hash function There exists bad set keys that all hash the same slot you pick hash function looked some that seem work well practice that are easy put into your code But whichever one you pick there always some bad set keys you can imagine just drive this point home little bit 
5788 en Lecture Relation BSTs Quicksort Analysis Random BST going talk today about binary search trees something called randomly built binary search trees And abbreviate binary search trees BST throughout the lecture And you all seen binary search trees one place another particular recitation Friday going build the basic ideas presented there and talk about how randomize them and make them good you know that there are good binary search trees which are relatively balanced something like this The height log 
5789 en Lecture Red black Trees Rotations Insertions Deletions Good morning looks like getting earlier and earlier for everyone Hello all the people watching home think there should requirement that you watching the video you can only watch Sunday least start watching then just you can all feel our mornings Today going talk about balanced search trees Now hinted this for while Our goal today get search tree data structure can insert delete and search all log time for operations want tree that guaranteed log height that balanced search tree data structure 
5790 en Lecture Augmenting Data Structures Dynamic Order Statistics Interval Trees Good morning Today going talk about augmenting data structures And this Normally rather than designing data structures from scratch you tend take existing data structures and build your functionality into them And that process call data structure augmentation And this also today marks sort the start the design phase the class spent lot time doing analysis this point And now still going learn some new analytical techniques 
5791 en Lecture Skip Lists Good morning Today going talk about balanced search structure data structure that maintains dynamic set subject insertion deletion and search called skip lists call this dynamic search structure because data structure supports search and dynamic meaning insert and delete what other dynamic search structures know just for sake comparison and wake everyone Shut them out efficient should say also good logarithmic time per operation this really easy question get off the ground 
5792 en Lecture Amortized Algorithms Table Doubling Potential Method good morning today are going mentioned last week started the part the course where are doing more things having with design than purely analysis Today actually going analysis but the type analysis that leads really interesting design issues And going follow Wednesday with application the methods going learn today with really interesting and practical problem talking today about amortized analysis 
5793 en Lecture Competitive Analysis Self organizing And this going use some the techniques learned last time with respect amortized analysis And what neat about what going talk about today way comparing algorithms that are called online algorithms And going introduce this notion with problem which called self organizing lists and the set for this problem that have list elements And have operation Woops got spell things right access which accesses item the list 
5794 en Lecture Dynamic Programming Longest Common Subsequence the topic today dynamic programming The term programming the name this term doesn refer computer programming programming old word that means any tabular method for accomplishing something you hear about linear programming and dynamic programming Either those even though now incorporate those algorithms computer programs originally computer programming you were given datasheet and you put one line per line code tabular method for giving the machine instructions what 
5795 en Lecture Greedy Algorithms Minimum Spanning Trees today going start talking about particular class algorithms called greedy algorithms But going the context graphs want review little bit about graphs which mostly you can find the textbook appendix And you haven reviewed appendix recently please sit down and review appendix will pay off especially during our take home quiz just reminder digraph what digraph What that short for Directed graph Directed graph equals has set vertices 
5796 en Lecture Shortest Paths Properties Dijkstra Algorithm Breadth first Search going talk about shortest paths and going talk about shortest paths for three lectures this trilogy Today will Shortest Paths One been watching far too many versions Star Wars this weekend saw the musical yesterday matinee That was MIT musical That was fun all three movies about four hours That was bit long and then saw the one man show Friday One man Star Wars the original three movies one hour That was the opposite too long Both were fun get trilogy fix All episodes first going start with The New Hope and going talk about the shortest paths problem and solve one particular problem very interesting version 
5797 en Lecture Shortest Paths Bellman Ford Linear Programming Difference Constraints Good morning everyone Glad you are all here bright and early counting the days till the outnumber the students They show return familiar story This part two the Empire Strikes Back last time our adversary the graph came with problem have source and had directed graph and had weights the edges and they were all nonnegative And there was happiness And triumphed over the Empire designing Dijkstra algorithm and very efficiently finding single source shortest paths shortest path weight from every other vertex 
5798 en Lecture Shortest Paths III All pairs Shortest Paths Matrix Multiplication Floyd Warshall Johnson shortest paths This the finale Hopefully was worth waiting for Remind you there quiz coming soon you should studying for There problem set due the same time the quiz because you should studying now take home exam required that you come class Monday course you all come but everyone watching home should also come next Monday get the quiz the required lecture need bit recap the trilogy far the last two lectures the last two episodes about single source shortest paths 
5799 en Lecture Advanced Topics only have four more lectures left and what Professor Demaine and have decided give two series lectures sort advanced topics today Wednesday going talk about parallel algorithms algorithms where you have more than one processor whacking away your problem And this very hot topic right now because all the chip manufacturers are now producing called multicore processors where you have more than one processor per chip knowing something about that good The second topic going cover going caching and how you design algorithms for systems with cache 
5800 en Lecture Advanced Topics cont good morning today going continue our exploration multithreaded algorithms Last time talked about some aspects scheduling and little bit about linguistics describe multithreaded competition And today going actually deal with some algorithms going start out with really simple actually what fun about this actually that everything going teach you today could have taught you week two because basically just taking the divide and conquer hammer and just smashing problem after problem with 
5801 en Lecture Advanced Topics cont week 046 Woohoo The topic this final week among our advanced topics cache oblivious algorithms This particularly fun area one dear heart because done lot research this area This area founded Professor Leiserson fact the first context which met Professor Leiserson was him giving talk about cache oblivious algorithms WADS Vancouver think Yeah that has odd year learned about cache oblivious algorithms then started working the area and been fun place play But this topic some sense was also developed the context this class think there was one semester probably also where all the problem sets were about cache oblivious algorithms 
5802 en Lecture Advanced Topics cont Discussion Follow Classes The last lecture 046 are here today talk more about cache oblivious algorithms Last class saw several cache oblivious algorithms although none them quite too difficult Today will see two difficult cache oblivious algorithms little bit more advanced figure should something advanced for the last class just get some exciting climax without further ado let get started Last time looked the binary search problem 
5804 en Lecture Fault Isolation with Clients and Servers
5805 en Lecture Virtualization Virtual Memory
5806 en Lecture Virtual Processors Threads and Coordination
5808 en Lecture Introduction Networks
5809 en Lecture Layering and Link Layer
5810 en Lecture Network Layer Routing
5811 en Lecture End end Layer
5818 en Lecture Transactions and Consistency
5819 en Lecture Multi site Atomicity
5822 en Lecture Authorization and Confidentiality
5824 en Lecture Complex Trusted Systems
5825 en Lecture Positive definite matrices 
5826 en Lecture One dimensional applications difference matrix
5827 en Lecture Network applications incidence matrix
5828 en Lecture Applications linear estimation least squares
5829 en Lecture Applications dynamics eigenvalues solution 
5830 en Lecture Underlying theory applied linear algebra
5831 en Lecture Discrete continuous differences and derivatives
5832 en Lecture Applications boundary value problems Laplace equation
5833 en Lecture Solutions Laplace equation complex variables
5834 en Lecture Delta function and Green function
5835 en Lecture Initial value problems wave equation and heat equation
5836 en Lecture Solutions initial value problems eigenfunctions
5837 en Lecture Numerical linear algebra orthogonalization and 
5838 en Lecture Numerical linear algebra SVD and applications
5839 en Lecture Numerical methods estimation recursive least squares and covariance matrix
5840 en Lecture Dynamic estimation Kalman filter and square root filter
5841 en Lecture Finite difference methods equilibrium problems
5842 en Lecture Finite difference methods stability and convergence
5843 en Lecture Optimization and minimum principles Euler equation
5844 en Lecture Finite element method equilibrium equations
5845 en Lecture Spectral method dynamic equations
5846 en Lecture Fourier expansions and convolution
5847 en Lecture Fast fourier transform and circulant matrices
5848 en Lecture Discrete filters lowpass and highpass
5849 en Lecture Filters the time and frequency domain
5850 en Lecture Filter banks and perfect reconstruction
5851 en Lecture Multiresolution wavelet transform and scaling function
5852 en Lecture Splines and orthogonal wavelets Daubechies construction
5853 en Lecture Applications signal and image processing compression
5854 en Lecture Network flows and combinatorics max flow min cut
5855 en Lecture Simplex method linear programming
5856 en Lecture Nonlinear optimization algorithms and theory
5884 en Why Only Atheist Can Believe Politics Between Fear and Trembling addresses the complicated relationship between belief what take belief and our desire see all The lecture followed brief period questions and answers 
5885 en The Spectator Malevolent Neutrality Slavoj philosopher and Psychoanalyst from Ljubljana His lecture the specific roles viewers and doers entitled The Spectator´ Malevolent Neutrality and was held June 2004 during the Theaterformen festival Brunswick 
5886 en Lecture Elimination with Matrices
5887 en Lecture Multiplication and Inverse Matrices
5888 en Lecture Factorization into 
5889 en Lecture Transposes Permutations Spaces 
5890 en Lecture Column Space and Nullspace
5891 en Lecture Solving Pivot Variables Special Solutions
5892 en Lecture Solving Row Reduced Form 
5893 en Lecture Independence Basis and Dimension
5894 en Lecture The Four Fundamental Subspaces
5895 en Lecture Matrix Spaces Rank Small World Graphs
5896 en Lecture Graphs Networks Incidence Matrices
5897 en Lecture Quiz Review
5898 en Lecture Orthogonal Vectors and Subspaces
5899 en Lecture Projections onto Subspaces
5900 en Lecture Projection Matrices and Least Squares
5901 en Lecture Orthogonal Matrices and Gram Schmidt
5902 en Lecture Properties Determinants
5903 en Lecture Determinant Formulas and Cofactors
5904 en Lecture Cramer Rule Inverse Matrix and Volume
5905 en Lecture Eigenvalues and Eigenvectors
5906 en Lecture Diagonalization and Powers 
5907 en Lecture Differential Equations and exp 
5908 en Lecture Markov Matrices Fourier Series
5909 en Lecture 24b Quiz Review
5910 en Lecture Symmetric Matrices and Positive Definiteness
5911 en Lecture Complex Matrices Fast Fourier Transform
5912 en Lecture Positive Definite Matrices and Minima
5913 en Lecture Similar Matrices and Jordan Form
5914 en Lecture Singular Value Decomposition
5915 en Lecture Linear Transformations and Their Matrices
5916 en Lecture Change Basis Image Compression
5917 en Lecture Quiz Review
5918 en Lecture Left and Right Inverses Pseudoinverse
5919 en Lecture Final Course Review
5920 en Politeness and Civility the Function Contemporary Ideology Maybe just need different chicken Slavoj spoke Powell City Books downtown Portland Oregon September 2008
5925 en Agents and avatars new era computational social science
5926 en Emergence cooperation social interactions space and time
5927 en Adaptive networks The intriguing interplay dynamics and networks
5929 en The costs interaction and how they shape the social network
5930 en Econophysics and economic complexity What Econophysics Via Wikipedia nnEconophysics interdisciplinary research field applying theories and methods originally developed physicists order solve problems economics usually those including uncertainty stochastic processes and nonlinear dynamics Its application the study financial markets has also been termed statistical finance referring its roots statistical physics Physicists’ interest the social sciences not new Daniel Bernoulli example was the originator utility based preferences One the founders neoclassical economic theory former Yale University Professor Economics Irving Fisher was originally trained under the renowned Yale physicist Josiah Willard Gibbs 
5931 en Five Principles for the Unification the Behavioral Sciences
5932 en New complex networks for social systems
5933 en Taking the avatar approximation throughput social science virtual worlds
5934 en Agent based simulation emergence through monetary incentives and social pressure
5935 en The saturation threshold public opinion Are agressive media campaigns always effective 
5936 en Adressing the validation problem for social simulations
5937 en Illusory and genuine control optimizing games and financial markets
5938 en Discussion Modeling and Simulation Challenges
5940 en The dangers time aggregation little knowledge dangerous thing and sampling social systems
5942 en Group formation Fragmentation transitions network coevolution dynamics
5943 en Human dynamics revealed through Web analytics
5944 en Injecting Data into Simulation Can Agent Based Modelling Learn from Microsimulation 
5945 en Data driven hypothesis driven research the social sciences
5946 en Measuring science Fears challenges and opportunities
5947 en Models and tools for the analysis human behaviour third generation metropolis
5948 en Observing society through tags Using tags help society
5949 en Nationalism and its geopolitical consequences distributional perspective
5952 en The emotional content large scale texts The happiness bloggers song lyrics and presidents
5953 en Modeling reality without sacrificing data Inferentially tractable models for complex social systems
5954 en How should the 21st century democracy organised Studying online communities answer 
5956 en  What earth must assume explain increasing opinion differences between subgroups without assuming negative influence 
5957 en Signalling models and experiments research perspective
5958 en Discussion challenges Interdisciplinary research
5968 en Representations Graphs and their Symmetries
5971 en Lecture Introduction What Film • Chemistry Novelty Manufactured object Social formationnn Think Away iPods • The novelty movement Early films and early audiencesnn The Fred Ott Principle Three Phases Media Evolution • Imitation Technical Advance Maturitynn And there was Charlie Film cultural form nnRequired films nnPorter Edwin http memory loc gov cgi bin query ammem papr filreq field NUMBER band edmp 2443s3 field COLLID edison The Great Train Robbery view film nnGriffith http www tcf edu classes Jbutler T112 Lonedale index1 htm The Lonedale Operator view stills href http www surveymonkey com videolectures Click here take survey 
5972 en Lecture Keaton The Fred Ott Principle continued • The myth technological determinism paradox capitalism and the moviesnn The Great Train Robbery 1903 The Lonedale Operator 1911 Buster Keaton • Acrobat actor Technician director Metaphysician artistnn The multiplicity principle entertainment art The General 1927 • culminating text Structure The Keaton hero steadfast muddlingnnRequired films nnGriffith http www youtube com watch YMqGbEEP528 feature related Beast Bay view film nnKeaton Buster http www archive org details OneWeek One Week view film nnKeaton Buster http www archive org details Cops Cops view film nnKeaton Buster http www archive org details TheGeneral The General view film 
5973 en Lecture Chaplin Movies before Chaplin Enter Chaplin Chaplin career • The multiplicity principle continuednn The Tramp myth Chaplin world elemental themes nnRequired films nnChaplin Charlie http www archive org details 1917 TheImmigrant The Immigrant view film 
5974 en Lecture Sica Bicycle Thieves Vittorio Sica 1902 • 1942 The Children Are Watching Usnn• 1946 Shoeshinenn• 1948 Bicycle Thievesnn• 1950 Miracle Milannn• 1952 Umberto Dnn• 1960 Two Womennn• 1971 The Garden the Finzi Continisnn Bicycle Thieves • Structure organic formnn• Social themesnn• Character father and sonnn• The titlennRequired films nnDe Sica Vittorio http www imdb com title tt0040522 Bicycle Thieves 
5975 en Final Class Presentation For IAP 2007 the class design projects were focused two student teams nnVDS Vehicle Design SummitnnMITSET Space Elevator TeamnnThe two teams were assigned Define pick the current baseline configuration Create performance model the baseline configuration Optimize for these factors VDS miles per gallon mpg MITSET time climb sec Pick most critical components and subsystems based performance sensitivity nnThe work the students presented below along with video their final class presentations The deliverables are based upon the assignments from the class All work courtesy the students named and used with permission 
5976 en Day Introductory Lecture Morning Introduction and Shop Safety Rulesn Primer Coursenno Define Goals Classn give Students Experience Early Boat Design Technology from Carving Half model Eye and then Translating that Shape into Lines Plan which can Analyzed and then Developed into Building Plann give Students Experience Understanding how Early Design Techniques Worked Refine design Intuition and Boat Sense Half Model Readily Recognized and Interpretable Representation the Performance the Boatn Beyond Simple Esthetic Trained Eye Experience Sailor Designer Builder Could Look Form and Consider Dynamic State Using Mind Computational Tool Understand How Features the form Assimilaten Process Developing Lines More Opportunity Refine the Shapen Process Lofting Yet Another Opportunity Refine Formn Essential that the Modeller Always Remain Skeptical and Critical the Shape Their Creatingn Give Students Awareness How Design Methods Can Limit and Enable Developmentn Development Half Model Designing Techniques Replacing Whole Molding and Rule Thumb Design Opened Hull Design Development Once Adoptedn System Lifting Lines Creating Lines Plan and Lofting Allowed for Scientific Analysis Hull well Allowing Designer Exert Great Influence the Final Productn But the System has Many Shortcomings Time consuming Bad for Asymmetic Hulls etc What are Advantages and Shortcomings CAD nno Define Process Class Design your own Boat Carving Half model Create Lines Analyze Linesn Goal Use the Half model Method Explore Idea Designn Show How the Half model Design Process Iterative and How Ideas are Refined Each Step Process How Thoughtfulness and Awareness Process Every Step Influences Outcomen Grade Based How Well the Students Use the Method Challenge their Own Assumptions and Develop their Ideasn Requirements are Attendance and Participation Morning Lectures Every Day Presence Requirednn Morning Lecturenno Brief Overview History Boat Design Techniquesnno Give Basics How the Form Half model Translated into Something that Can Built From Jign Herreshoff Methodsn Mawing Model Separating Liftsnno Begin Process Going Around the Room and Extemporizing Developing Ideas for Design Encourage Students Start with then Challenge their Own Assumptionsn Type Boatn Use Boatn Power Boatn Develop Idea Essention Lines Start Withn Explain Usefulness Different Sheer Shapesn Bow Linesn Stern Shapesn Basically What Can Prime the Class Make the Most the Visit the Model Roomnn Lunch advise People Bring Lunchn Getting Started Designsnno Half Model Roomn Once Back Begin Developing Essential Lines Drawn onto the Blocks Wood
5977 en Day MIT Museum Nautical Collections and Introductory Demonstration
5978 en Day Model Building Morning Lecturen Demonstrate Carving Techniques and Tools Influence Tools and Method Form Limitations Ideasn Familiarity with Toolsn Understanding Intuitively How Tools will Help Create Readily built Formn Understanding Intuitively How the Resistance the Wood Influences Shape
5979 en Day Finishing and Drawing Plans Morning Lecture Introduction Lines Drawingn Techniques Layout Method etc Opportunity think Designn Afternoon Pulling Shapes Off Modelsn Expanding Other Views Papern Interpreting You 
5980 en Day Conclusion and More the MIT Museum Nautical Collections Finish Lines Plansn Analyze One Twon Discussion How Method Informs Idean Discussion Difference Computer Draftingn Discussion Model Roomn Discussion Plans Collectionn Shop Cleanup
5981 en Lecture MIT Center for Advanced Visual Studies Lecture Series Lost Highway Expedition will begin Ljubljana and travel through Zagreb Novi Sad Belgrade Skopje Pristina Tirana Podgorica conclude Sarajevo comprised two days events each city and one day travel between The events may include guided tours presentations and forums local experts workshops between the participating travelers and local participants discussions exhibitions radio shows picnics and other events that can self produced the host cities nnMembers the Lost Highway Expedition not have travel stay together and can enter and exit the expedition for any length time and any point Participants are self organize support and realize their journey the “Highway Post Brotherhood and Non Unity ”nnEveryone free participate any the events bring their own the highway Word the expedition will travel like rumor from friends friends colleagues colleagues 
5982 en Lecture MIT Center for Advanced Visual Studies Lecture Series Artist director and performer John Malpede will talk with artist Harrell Fletcher about three decades Malpede aesthetically and politically uncompromising brand art social action 
5985 en Chapter Maxwell integral laws free space Introductionnn Overview subjectnn1 The Lorentz law free spacen1 Charge and current densitiesn1 Gauss integral law electric field densitynn Singular charge distributionsn Gauss continuity conditionnn1 Ampere integral lawnn Singular current distributionn Ampere continuity conditionnn1 Charge conservation integral formnn Charge conservation continuity conditionnn1 Faraday integral lawnn Electric field intensity having circulationn Electric field intensity with circulationn Faraday continuity conditionnn1 Gauss integral law magnetic fluxnn Magnetic flux continuity conditionnn1 Summary
5986 en Chapter Electroquasistatic fields the superposition integral point view Introductionn4 Irrotational field represented scalar potential the gradient operator and the gradient integral theoremnn Visualization two dimensional irrotational fieldsnn4 Poisson equationn4 Superposition principlen4 Fields associated with charge singularitiesnn Dipole the originn Pair charges infinity having equal magnitude and opposite signn Other charge singularitiesnn4 Solution Poisson equation for specified charge distributionsnn Superposition integral for surface charge densityn Superposition integral for line charge densityn Two dimensional charge and field distributionsn Potential uniform dipole layer nn4 Electroquasistatic fields the presence perfect conductorsnn Capacitancenn4 Method imagesnn4 Charge simulation approach boundary value problemsnn4 Summary
5987 en Chapter Electroquasistatic fields from the boundary value point view Introductionnn5 Particular and homogeneous solutions Poisson and Laplace equationsnn Superposition satisfy boundary conditionsn Capacitance matrixnn5 Uniqueness solutions Poisson equationnn5 Continuity conditionsnn5 Solutions Laplace equation Cartesian coordinatesnn5 Modal expansions satisfy boundary conditionsnn5 Solutions Poisson equation with boundary conditionsnn5 Solutions Laplace equation polar coordinatesnn5 Examples polar coordinatesnn Simple solutionsn Azimuthal modesn Radial modesnn5 Three solutions Laplace equation spherical coordinatesnn5 Three dimensional solutions Laplace equationnn Cartesian coordinate product solutionsn Modal expansion Cartesian coordinatesn Modal expansion other coordinatesnn5 Summary
5988 en Chapter Polarization Introductionnn6 Polarization densitynn6 Laws and continuity conditions with polarizationnn Polarization current density and Ampere lawn Displacement flux densitynn6 Permanent polarizationnn6 Polarization constitutive lawsnn6 Fields the presence electrically linear dielectricsnn Capacitancen Induced polarization chargenn6 Piece wise uniform electrically linear dielectricsnn Uniform dielectricsn Piece wise uniform dielectricsnn6 Smoothly inhomogeneous electrically linear dielectricsnn6 Summary
5989 en Chapter Conduction and electroquasistatic charge relaxation Introductionnn7 Conduction constitutive lawsnn Ohmic conductionn Unipolar conductionnn7 Steady Ohmic conductionnn Continuity conditionsn Conductancen Qualitative view fields conductorsnn7 Distributed current sources and associated fieldsnn Distributed current source singularitiesn Fields associated with current source singularitiesn Method imagesnn7 Superposition and uniqueness steady conduction solutionsnn Superposition satisfy boundary conditionsn The conductance matrixn Uniquenessnn7 Steady currents piece wise uniform conductorsnn Analogy fields linear dielectricsn Inside outside approximationsnn7 Conduction analogsnn Mapping fields that satisfy Laplace equationnn7 Charge relaxation uniform conductorsnn Net charge bodies immersed uniform materialsnn7 Electroquasistatic conduction laws for inhomogeneous materialnn Evolution unpaired charge densityn Electroquasistatic potential distributionn Uniquenessnn7 Charge relaxation uniform and piece wise uniform systemsnn Fields regions having uniform propertiesn Continuity conditions piece wise uniform systemsn Nonuniform fields piece wise uniform systemsnn7 Summary
5990 en Chapter Magnetoquasistatic fields superposition integral and boundary value points view Introductionnn Vector field uniquely specifiednn8 The vector potential and the vector Poisson equationnn Two dimensional current and vector potential distributionsnn8 The Biot Savart superposition integralnn Stick model for computing fields electromagnetnn8 The scalar magnetic potentialnn The scalar potential current loopnn8 Magnetoquasistatic fields the presence perfect conductorsnn Boundary conditions and evaluation induced surface current densityn Voltage the terminals perfectly conducting coiln Inductancenn8 Piece wise magnetic fieldsn8 Vector potential and the boundary value point viewnn Vector potential for two dimensional fieldsn Vector potential for axisymmetric fields spherical coordinatesn Boundary value solution Inspection Method imagesn Two dimensional boundary value problemsnn8 Summary
5991 en Chapter Magnetization Introductionnn9 Magnetization densitynn9 Laws and continuity conditions with magnetizationnn Faraday law including magnetizationn Magnetic flux densityn Terminal voltage with magnetizationnn9 Permanent magnetizationnn9 Magnetization constitutive lawsnn9 Fields the presence magnetically linear insulating materialsnn Inductance the presence linearly magnetizable materialsn Induced magnetic charge demagnetizationnn9 Fields piece wise uniform magnetically linear materialsnn Excitation region high permeabilityn Excitation region low permeabilitynn9 Magnetic circuitsnn Electrical terminal relations and characteristicsnn9 Summary
5992 en Chapter Magnetoquasistatic relaxation and diffusion Introductionnn10 Magnetoquasistatic electric fields systems perfect conductorsnn10 Nature fields induced finite conductorsnn10 Diffusion axial magnetic fields through thin conductorsnn10 Diffusion transverse magnetic fields through thin conductorsnn Response step applied fieldnn10 Magnetic diffusion lawsnn Physical interpretationnn10 Magnetic diffusion transient responsenn Product solutions the one dimensional diffusion equationnn10 Skin effectnn10 Summar
5993 en Chapter Energy power flow and forces Introductionnn Power flow circuitn Overviewnn11 Integral and differential conservation statementsn11 Poynting theoremnn Systems composed perfect conductors and free spacenn11 Ohmic conductors with linear polarization and magnetizationnn alternative conservation theorem for electroquasistatic systemsn Poynting power density related circuit power inputn Poynting flux and electromagnetic radiationnn11 Energy storagenn Energy densitiesn Energy storage terms terminal variablesnn11 Electromagnetic dissipationnn Energy conservation for temporarily periodic systemsn Induction heatingn Dielectric heatingn Hysteresis lossesnn11 Electrical forces macroscopic median11 Macroscopic magnetic forcesnn Reciprocity conditionsn Finding the coenergyn Evaluation the forcen The torque electrical originnn11 Forces macroscopic electric and magnetic dipolesnn Force electric dipolen Force electric charge derived from energy principlen Force magnetic charge and magnetic dipolen Comparison Coulomb force the force magnetic dipolenn11 Macroscopic force densitiesnn The Lorentz force densityn The Kelvin polarization force densityn The Kelvin magnetization force densityn Alternative force densitiesnn11 Summary
5994 en Chapter Electrodynamic fields the boundary value point view Introductionnn13 Introduction transverse electromagnetic TEM wavesnn The magnetoquasistatic MQS limitnnThe MQS approximationnn The electroquasistatic EQS limitn The EQS approximationnn13 Two dimensional modes between parallel platesnn13 Transverse and transverse magnetic standing waves between parallel platesnn13 Rectangular waveguide modesnn13 Dielectric waveguides optical fibersnn13 Summar
6015 en SMEs Production Networks Open Sourced Software
6016 en Open Source Enterprise Resource Planning and Order Management System for Eastern European Tool and Die Making Workshops
6017 en Software Tutorial ToolEast Training Environment
6023 en Lecture MIT Center for Advanced Visual Studies Lecture Series Simon Starling fascinated the processes involved transforming one object substance into another makes objects installations and pilgrimage like journeys which draw out array ideas About nature technology and economics Starling describes his work ‘the physical manifestation thought process’ revealing hidden histories and relationships nnFor Tabernas Desert Run 2004 Starling crossed the Tabernas desert Spain improvised electric bicycle The only waste product the vehicle produced was water which used paint illustration cactus The contrast between the supremely efficient cactus and the contrived efforts man both comic and insightful highlighting the commercial exploitation natural resources the region nnShedboatshed Mobile Architecture 2005 has similar circularity Starling dismantled shed and turned into boat loaded with the remains the shed the boat was paddled down the Rhine museum Basel dismantled and made into shed Both pilgrimages provide kind buttress against the pressures modernity mass production and global capitalism nnStarling’ new work One Ton 2005 focuses attention energy consumption the huge amounts energy used produce tiny quantities platinum One ton ore mined from the South African open cast mine pictured the images was needed produce the five handmade platinum prints exhibited here nnSimon Starling has been nominated for his solo exhibitions The Modern Institute Glasgow and the Fundació Joan Miró Barcelona 
6055 en Opening Remarks ICGI 2008 the ninth series successful biennial international conferences the area grammatical inference Grammatical inference has been extensively addressed researchers information theory automata theory language acquisition computational linguistics machine learning pattern recognition computational learning theory and neural networks 
6056 en Learning languages from bounded resources the case the DFA and the balls strings
6057 en  learning regular expressions and patterns via membership and correction queries
6058 en  note the relationship between different types correction queries
6059 en Polynomial time probabilistic learning subclass linear languages with queries
6060 en Learning context sensitive languages from linear structural information
6061 en Grammatical Inference news from the Machine Translation front
6063 en Identification the limit substitutable context free languages
6064 en  polynomial algorithm for the inference context free languages
6067 en State merging DFA induction algorithms with mandatory merge constraints
6068 en Evaluation and Comparison inferred regular grammars
6069 en Towards feasible PAC learning probabilistic deterministic finite automata
6070 en Relevant representations for the inference rational stochastic tree languages
6071 en Unsupervised learning probabilistic context free grammar using iterative biclustering
6072 en Bio molecular computing finite state automata
6073 en Learning right left and left right iterative languages
6074 en Learning bounded unions Noetherian closed set systems via characteristic sets
6075 en  learning algorithm for multi dimensional trees learning beyond context freeness
6077 en Schema guided induction monadic queries
6078 en Using Multiplicity automata identify transducer Relations from membership and equivalence queries
6079 en Should all Machine Learning Bayesian Should all Bayesian models non parametric present some thoughts and research directions Bayesian machine learning contrast black box approaches machine learning with model based Bayesian statistics Can meaningfully create Bayesian black boxes what should the prior non parametrics the only way Since often can control the effect using approximate inference are coherence arguments meaningless How can convert the pagan majority researchers Bayesianism the audience gets bored these philosophical musings will switch talking about our latest technical work Indian buffet processes 
6081 en  the relation between Bayesian inference and certain solvable problems stochastic control Optimal control for nonlinear stochastic dynamical systems requires thesolution nonlinear PDE the called Hamilton Jacobi Bellman equation Recently Bert Kappen and Emanuel Todorov have shown that for certain types cost functions this equationcan transformed linear problem which mathematically related Bayesian estimation problem This has led novel efficient algorithms for optimal control such systems will show simple proof for this surprising result and discuss some possible implications 
6082 en Multi task Learning with Gaussian Processes consider the problem multi task learning the setup where there are multiple related prediction problems tasks and seek improve predictive performance sharing information across the different tasks address this problem using Gaussian process predictors using model that learns shared covariance function input dependent features and free form covariance matrix that specifies inter task similarity discuss the application the method number real world problems such compiler performance prediction and learning robot inverse dynamics nJoint work with Kian Ming Chai Edwin Bonilla Stefan Klanke Sethu Vijayakumar Edinburgh 
6083 en Latent Force Models with Gaussian Processes are used dealing with the situation where have latent variable Often assume this latent variable independently drawn from distribution probabilistic PCA factor analysis This simplification often extended for temporal data where tractable Markovian independence assumptions are used Kalman filters hidden Markov models nIn this talk will consider the more general case where the latent variable forcing function differential equation model will show how for some simple ordinary differential equations the latent variable can dealt with analytically for particular Gaussian process priors over the latent force this talk will introduce the general framework present results systems biology preview extensions nnJoint work with Magnus Rattray Mauricio Alvarez Pei Gao Antti Honkela David Luengo Guido Sanguinetti and Michalis Titsias 
6084 en Bayesian learning sparse factor loadings Learning sparse structure useful many applications For example gene regulatory networks are sparsely connected since each gene typically only regulated small number other genes this case factor analysis models with sparse loading matrices have been used uncover the regulatory network from gene expression data this talk will examine the performance sparsity priors such mixture and priors calculating learning curves for Bayesian PCA the limit large data dimension This allows address number questions how well can estimate sparsity using the marginal likelihood when the prior not well matched the data generating process 
6085 en Covariance functions and Bayes errors for regression random graphs consider learning functions defined the nodes random graph Covariance functions proposed for this scenario based diffusion processes the graph are shown have some counter intuitive properties particular graphs with tree like structure where loops can neglected typically the case for randomly generated graphs the obvious limit large correlation length scale does not produce constant covariance function nIn the second part look Bayes errors for regression graphs and study how the learning curves depend the size the graph its connectivity and the number training examples nnJoint work with Camille Coti 
6087 en The role mechanistic models Bayesian inference outline the role mechanistic models simulators defining priors Bayesian inference setting particular will focus two main cases where process based understanding the system allows construct stochastic simulator for the system which translates inference stochastic processes where existing typically deterministic mechanistic model exists which can then emulate and treat correctly Bayesian manner will pay special attention the relation between the simulator and reality since reality that typically sampled generate the observations used for inference the model will outline ideas from emulation and show the challenges think remain solved nThis joint work with lots people Alexis Boukouvalas Yuan Shen Michael Vrettas Manfred Opper and many others the MUCM project 
6088 en Probabilistic models for ranking and information extraction will summarize some current approaches information extraction which aims obtain structured information from unstructured text sources such the web will then discuss whether Bayesian modelling may useful this area and describe first attempt extracting class attributes from web search query logs time remains will move discuss various models for probabilistic ranking and where possible appropriate Bayesian inference techniques 
6089 en Well known shortcomings advantages and computational challenges Bayesian modelling few case stories Bayesian inference can used judge the data fit quantitatively through the marginal likelihood many practical cases only one model considered and parameter averaging simply used avoid overfitting show such example for large data set genomic sequence tags where want predict how many new unique tags will find perform new sequencing The two parameter Yor Pitman process used and the results illustrate few well known facts parameter averaging can crucial and large data sets will expose the inadequacy the model seen unrealistically narrow error bars cross validated predictions This indicates that should come with better models and being able calculate the marginal likelihood for these models perform model selection the second part the talk will discuss some the computational challenges calculating marginal likelihoods Gaussian process classification used example illustrate that this hard even for uni modal posterior 
6090 en Variational Model Selection for Sparse Gaussian Process Regression Model selection for sparse Gaussian process models important problem that involves the selection both the inducing active variables and the kernel parameters describe auxiliary variational method for sparse regression that jointly learns the inducing variables and kernel parameters minimizing the Kullback Leibler divergence between approximate distribution and the true posterior over the latent function values The variational distribution parametrized using unconstrained distribution over inducing variables and conditional prior This framework allows compute lower bound the true log marginal likelihood which can reliably maximized over the inducing inputs and the kernel parameters will show how can reformulate several the most advanced sparse methods such the subset data DTC FITC and PITC method based the above framework 
6091 en Negotiated Interaction Iterative Inference and Feedback Intention HCI will talk about approach human computer interaction which makes the uncertainty the computer interpretation the user intentions tangible supporting efficient and enjoyable interaction will present liquid cursor demonstration example making Bayesian inference concrete and visible evidence flows between the user and computer will present some current research challenges which hope the BARK audience can engage with including the use complex models shape interaction dynamics and measures interaction between agents Application examples from mobile interaction and Brain Computer Interaction will used 
6092 en Introduction the MIT course largely about Electricity and Magnetism and the heart Electricity and Magnetism are the famous four equations call the Maxwell Equations Its quite difficoult course for students and out way also introduce many phenomena that they see around them and make those phenomena connect with electricity and magnetism 
6094 en Introduction the MIT course the Physics Vibrations and Waves the third course physics not general institute requrement ofcourse except physics majors will have take the course covered the traditional materials that you find all Vibrations and Waves Oscilators resonance phenomenon mechanical oscilations electro magnetic oscilations and over and above try wherever possible make students see also throught the familiar world around them atleast the world that they have heard about 
6095 en Embedded Machine Learning Using Support Vector Machines Wireless Sensor Networks using TinyOS and Lego Mindstorms NXT The tutorial embedded machine learning will present case study implementing and using binary support vector machine wireless sensor networks will use very popular operating system for wireless sensor networks called TinyOS and the new exciting open hardware software platform Lego Mindstorms NXT from LEGO Outline the tutorial structured list topics nThe tutorial provides overview embedded machine learning and Overview wireless sensor networks TinyOS and the programming language nesC provides introduction LEGO MINDSTORMS and the main hardware items needed engage the problem meaningful way The mapping the binary support vector machine the constraints the embedded machine learning problem given memory battery little CPU 
6096 en Knowledge Discovery from Evolving Data Data mining has traditionally concentrated the analysis static world which data instances are collected stored and analyzed derive models and take decisions according them More recent research stream mining has put forward the need deal with data that cannot collected and stored statically but must analyzed the fly the same time the need store maintain query and update models derived from the data has been recognized and advocated LT08 However these are only two aspects the dynamic world that must analyzed with data mining The world changing and the accumulating data and ultimately the models derived from them nThe challenges for Knowledge Discovery changing world have two forms adapting the patterns the changes the population and capturing understanding and highlighting the changes nIn this tutorial discuss the topics associated with data mining for changing environments and elaborate research advances this area Relevant research comes among else from the fields incremental mining stream mining temporal mining and change detection Since this very wide field concentrate the second challenge the understanding change and organize research contributions this context 
6097 en Ecml Pkdd 2008 Opening and Awards Ceremony
6098 en Data Clustering Years Beyond means The practice classifying objects according perceived similarities the basis for much science Organizing data into sensible groupings one the most fundamental modes understanding and learning example common scheme scientific classification puts organisms taxonomic ranks domain kingdom phylum class etc Cluster analysis the formal study algorithms and methods for grouping objects according measured perceived intrinsic characteristics Cluster analysis does not use category labels that tag objects with prior identifiers class labels The absence category information distinguishes cluster analysis unsupervised learning from discriminant analysis supervised learning The objective cluster analysis simply find convenient and valid organization the data not establish rules for separating future data into categories The development clustering methodology has been truly interdisciplinary endeavor Taxonomists social scientists psychologists biologists statisticians engineers computer scientists medical researchers and others who collect and process real data have all contributed clustering methodology According JSTOR data clustering first appeared the title 1954 article dealing with anthropological data One the most well known simplest and popular clustering algorithms means was independently discovered Steinhaus 1955 Lloyd 1957 Ball and Hall 1965 and McQueen 1967 search via Google Scholar found 000 entries with the word clustering and 560 entries with the words data clustering 2007 alone Among all the papers presented CVPR ECML ICDM ICML NIPS and SDM 2006 and 2007 150 dealt with clustering This vast literature speaks the importance clustering machine learning data mining and pattern recognition cluster comprised number similar objects grouped together While easy give functional definition cluster very difficult give operational definition cluster This because objects can grouped into clusters with different purposes mind Data can reveal clusters different shapes and sizes Thus the crucial problem identifying clusters data specify learn similarity measure spite thousands clustering algorithms that have been published user still faces dilemma regarding the choice algorithm distance metric data normalization number clusters and validation criteria familiarity with the application domain and clustering goals will certainly help making intelligent choice This talk will provide background discuss major challenges and key issues designing clustering algorithms summarize well known clustering methods and point out some the emerging research directions including semi supervised clustering that exploits pairwise constraints ensemble clustering that combines results multiple clusterings learning distance metrics from side information and simultaneous feature selection and clustering 
6099 en Learning language from its perceptual context Current systems that learn process natural language require laboriously constructed human annotated training data Ideally computer would able acquire language like child being exposed linguistic input the context relevant but ambiguous perceptual environment step this direction present system that learns sportscast simulated robot soccer games example The training data consists textual human commentaries Robocup simulation games set possible alternative meanings for each comment automatically constructed from game event traces Our previously developed systems for learning parse and generate natural language KRISP and WASP were augmented learn from this data and then commentate novel games The system evaluated based its ability parse sentences into correct meanings and generate accurate descriptions game events Human evaluation was also conducted the overall quality the generated sportscasts and compared human generated commentaries 
6100 en Improving Classification with Pairwise Constraints Margin based Approach this paper address the semi supervised learning problem when there small amount labeled data augmented with pairwise constraints indicating whether pair examples belongs same class different classes introduce discriminative learning approach that incorporates pairwise constraints into the conventional margin based learning framework also present efficient algorithm PCSVM solve the pairwise constraint learning problem Experiments with data sets show that pairwise constraint information significantly increases the performance classification 
6101 en Exact and Approximate Inference for Annotating Graphs with Structural SVMs Training processes structured prediction models such structural SVMs involve frequent computations the maximum posteriori MAP prediction given parameterized model For specific output structures such sequences trees MAP estimates can computed efficiently dynamic programming algorithms such the Viterbi algorithm and the CKY parser However when the output structures can arbitrary graphs exact calculation the MAP estimate complete problem this paper compare exact inference and approximate inference for labeling graphs study the exact junction tree and the approximate loopy belief propagation and sampling algorithms terms performance and ressource requirements 
6102 en  Fast Method for Training Linear SVM the Primal propose new algorithm for training linear Support Vector Machine the primal The algorithm mixes ideas from non smooth optimization subgradient methods and cutting planes methods This yields fast algorithm that compares well state the art algorithms proved require lambdaepsilon iterations converge solution with accuracy epsilon Additionally provide exact shrinking method the primal that allows reducing the complexity iteration much less than where the number training samples 
6103 en Cascade RSVM Peer Peer Networks The goal distributed learning P2P networks achieve results close possible those from centralized approaches Learning models classification P2P network faces several challenges like scalability peer dynamism asynchronism and data privacy preservation this paper study the feasibility building SVM classifiers P2P network show how cascading SVM can mapped P2P network data propagation Our proposed P2P SVM provides method for constructing classifiers P2P networks with classification accuracy comparable centralized classifiers and better than other distributed classifiers The proposed algorithm also satisfies the characteristics P2P computing and has upper bound the communication overhead Extensive experimental results confirm the feasibility and attractiveness this approach 
6104 en Sequence Labelling SVMs Trained One Pass This paper proposes online solver the dual formulation support vector machines for structured output spaces apply sequence labelling using the exact and greedy inference schemes both cases the per sequence training time the same perceptron based the same inference procedure small multiplicative constant Comparing the two inference schemes the greedy version much faster also amenable higher order Markov assumptions and performs similarly test comparison existing algorithms both versions match the accuracies batch solvers that use exact inference after single pass over the training examples 
6105 en The Boolean Column and Column Row Matrix Decompositions Matrix decompositions are used for many data mining purposes One these purposes find concise but interpretable representation given data matrix Different decomposition formulations have been proposed for this task many which assume certain property the input data nonnegativity and aim preserving that property the decomposition this paper propose new decomposition formulations for binary matrices namely the Boolean and CUR decompositions They are natural combinations two previously presented decomposition formulations consider also two subproblems these decompositions and present rigorous theoretical study the subproblems give algorithms for the decompositions and for the subproblems and study their performance via extensive experimental evaluation show that even simple algorithms can give accurate and intuitive decompositions real data thus demonstrating the power and usefulness the proposed decompositions 
6106 en  Unified View Matrix Factorization Models present unified view matrix factorization that frames the differences among popular methods such NMF Weighted SVD PCA MMMF pLSI pLSI pHITS Bregman clustering and many others terms small number modeling choices Many these approaches can viewed minimizing generalized Bregman divergence and show that straightforward alternating projection algorithm can applied almost any model our unified view the Hessian for each projection has special structure that makes Newton projection feasible even when there are equality constraints the factors which allows for matrix clustering and iii alternating projections can generalized simultaneously factor set matrices that share dimensions These observations immediately yield new optimization algorithms for the above factorization methods and suggest novel generalizations these methods such incorporating row column biases and adding relaxing clustering constraints 
6107 en Improving Maximum Margin Matrix Factorization Collaborative filtering popular method for personalizing product recommendations Maximum Margin Matrix Factorization MMMF has been proposed one successful learning approach this task and has been recently extended structured ranking losses this paper discuss number extensions MMMF introducing offset terms item dependent regularization and graph kernel the recommender graph show equivalence between graph kernels and the recent MMMF extensions Mnih and Salakhutdinov Experimental evaluation the introduced extensions showimproved performance over the original MMMF formulation 
6108 en Learning Bidirectional Similarity for Collaborative Filtering Memory based collaborative filtering aims predicting the utility certain item for particular user based the previous ratings from similar users and similar items Previous studies finding similar users and items are based user defined similarity metrics such Pearson Correlation Coefficient Vector Space Similarity which are not adaptive and optimized for different applications and datasets Moreover previous studies have treated the similarity function calculation between users and items separately this paper propose novel adaptive bidirectional similarity metric for collaborative filtering automatically learn similarities between users and items simultaneously through matrix factorization show that our model naturally extends the memory based approaches Theoretical analysis shows our model novel generalization the SVD model evaluate our method using three benchmark datasets including MovieLens EachMovie and Netflix through which show that our methods outperform many previous baselines 
6109 en Mining Edge Weighted Call Graphs Localise Software Bugs important problem software engineering the automated discovery noncrashing occasional bugs this work address this problem and show that mining weighted call graphs program executions promising technique mine weighted graphs with combination structural and numerical techniques More specifically propose novel reduction technique for call graphs which introduces edge weights Then present analysis technique for such weighted call graphs based graph mining and traditional feature selection schemes The technique generalises previous graph mining approaches allows for analysis weights Our evaluation shows that our approach finds bugs which previous approaches cannot detect far Our technique also doubles the precision finding bugs which existing techniques can already localise principle 
6110 en Exceptional Model Mining most databases possible identify small partitions the data where the observed distribution notably different from that the database whole classical subgroup discovery one considers the distribution single nominal attribute and exceptional subgroups show surprising increase the occurrence one its values this paper introduce Exceptional Model Mining EMM framework that allows for more complicated target concepts Rather than finding subgroups based the distribution single target attribute EMM finds subgroups where model fitted that subgroup somehow exceptional discuss regression well classification models and define quality measures that determine how exceptional given model subgroup Our framework general enough applied many types models even from other paradigms such association analysis and graphical modeling 
6111 en Tight Optimistic Estimates for Fast Subgroup Discovery Subgroup discovery the task finding subgroups population which exhibit both distributional unusualness and high generality Due the non monotonicity the corresponding evaluation functions standard pruning techniques cannot used for subgroup discovery requiring the use optimistic estimate techniques instead far however optimistic estimate pruning has only been considered for the extremely simple case binary target attribute and now attempt was made move beyond suboptimal heuristic optimistic estimates this paper show that optimistic estimate pruning can developed into sound and highly effective pruning approach for subgroup discovery Based precise definition optimality show that previous estimates have been tight only special cases Thereafter present tight optimistic estimates for the most popular binary and multi class quality functions and present family increasingly efficient approximations these optimal functions show empirical experiments the use our newly proposed optimistic estimates can lead speed order magnitude compared previous approaches 
6112 en Multiple Manifold Learning Framework based Hierarchical Mixture Density Model Several manifold learning techniques have been developed learn given data single lower dimensional manifold providing compact representation the original data However for complex data sets containing multiple manifolds possibly different dimensionalities unlikely that the existing manifold learning approaches can discover all the interesting lower dimensional structures therefore introduce hierarchical manifolds learning framework discover variety the underlying low dimensional structures The framework based hierarchical mixture latent variable model which each submodel latent variable model capturing single manifold propose novel multiple manifold approximation strategy used for the initialization our hierarchical model The technique first verified artificial data with mixed and dimensional structures then used automatically detect lower dimensional structures disrupted satellite galaxies 
6113 en Industrial data mining Challenges and perspectives Business Intelligence very active sector all industrial domains Classical techniques reporting and Olap mainly concerned with presenting data are already widely deployed Meanwhile Data Mining has long been used companies niche technique reserved for experts only and for very specific problems credit scoring fraud detection for example But with the increasing availability large data volumes particular but not only from the Web companies are more and more turning data mining provide them with high added value predictive analytics However producing models large numbers making use large data volumes industrial context can only happen solutions challenges both theoretic and operational are found need algorithms which can used produce models when datasets have thousands variables and millions observations need learn how run and control the correct execution hundreds models need ways automate the data mining process will present these constraints industrial contexts and show how KXEN has exploited theoretical results coming from Vladimir Vapnik work provide answers the above mentioned challenges will give few examples real life applications and will conclude with some remarks the future data mining the industrial domain 
6114 en Fraud Risk Management Practice ATOS Worldline performs Fraud Risk Management wide range products like Debit and Credit Cards for Issuers Acquirers and Petrol Companies accross all fraud types like Theft Counterfeit and Internet Fraud During our talk will highlight the different components needed for efficient Fraud Risk Management like creation awareness efficient and flexible infrastructure the right skills the right support etc will particularly focus the role and position data mining this process and the relation between expert and data driven fraud detection All will amply illustrated with real fraud case examples 
6117 en Semantic Unification Real World Data Flow for Delivering Business Intelligence MDC Partners based Belgium and delivers business and market intelligence pharma and medical device companies heterogenous public databases and the internet are our main data sources semantic unification concepts the necessary driving force behind our data gathering data storage platforms this talk discuss number design philosophies and technical challenges building semantic data gathering mining and reporting engine Specifically the semantic unification side will discuss alternative schemes for semantisizing text fragments based bootstrapped probabilistic grammars reference ontologies and factual semantic data The impact the total semantic engine from incoming data reported queries alternative approaches will discussed 
6118 en Learning Decision Trees for Unbalanced Data Learning from unbalanced datasets presents convoluted problem which traditional learning algorithms may perform poorly The objective functions used for learning the classifiers typically tend favor the larger less important classes such problems This paper compares the performance several popular decision tree splitting criteria information gain Gini measure and DKM and identifies new skew insensitive measure Hellinger distance outline the strengths Hellinger distance class imbalance proposes its application forming decision trees and performs comprehensive comparative analysis between each decision tree construction method addition consider the performance each tree within powerful sampling wrapper framework capture the interaction the splitting metric and sampling evaluate over this wide range datasets and determine which operate best under class imbalance 
6119 en One class Classification Combining Density and Class Probability Estimation One class classification has important applications such outlier and novelty detection commonly tackled using density estimation techniques adapting standard classification algorithm the problem carving out decision boundary that describes the location the target data this paper investigate simple method for one class classification that combines the application density estimator used form reference distribution with the induction standard model for class probability estimation this method the reference distribution used generate artificial data that employed form second artificial class conjunction with the target class this artificial class the basis for standard two class learning problem explain how the density function the reference distribution can combined with the class probability estimates obtained this way form adjusted estimate the density function the target class Using UCI datasets and data from typist recognition problem show that the combined model consisting both density estimator and class probability estimator can improve using either component technique alone when used for one class classification also compare the method one class classification using support vector machines 
6120 en Ranking the Uniformity Interval Pairs study the problem finding the most uniform partition label distribution interval This problem occurs discretization continuous features where evaluation heuristics need find the location the best place split the current feature The weighted average empirical entropies the interval label distributions often used for this task observe that this rule sub optimal because prefers short intervals too much Therefore proceed study alternative approaches solution that based compression turns out the best our empirical experiments also study how these alternative methods affect the performance classification algorithms 
6121 en The role hierarchies exploratory data mining broad range data mining tasks the fundamental challenge efficiently explore very large space alternatives The difficulty two fold first the size the space raises computational challenges and second can introduce data sparsity issues even the presence very large datasets this talk consider how the use hierarchies taxonomies the OLAP multi dimensional model can help mitigate the problem 
6122 en  Genetic Algorithm for Text Classification Rule Induction This paper presents Genetic Algorithm called Olex for the induction rule based text classifiers the form classify document under category and not holds where each term Olex relies efficient emph several rules per individual binary representation and uses the measure the fitness function nnThe proposed approach tested over the standard test sets Reuters and Ohsumed and compared against several classification algorithms namely Naive Bayes Ripper SVM Experimental results demonstrate that achieves very good performance both data collections showing competitive with and indeed outperforming some cases the evaluated classifiers Note prototype the ruleninduction system Olex described that paper available the addressn http www mat unical Olex 
6123 en  Joint Topic and Perspective Model for Ideological Discourse Polarizing discussions political and social issues are common mass and user generated media However computer based understanding ideological discourse has been considered too difficult undertake this paper propose statistical model for ideology discourse ideology mean set general beliefs socially shared group people For example Democratic and Republican are two major political ideologies the United States The proposed model captures lexical variations due ideological text topic and due author speaker ideological perspective cope with the non conjugacy the logistic normal prior derived variational inference algorithm for the model evaluate the proposed model synthetic data well written and spoken political discourse Experimental results strongly support that ideological perspectives are reflected lexical variations 
6124 en Towards Machine Learning Grammars and Compilers Programming Languages Polarizing discussions political and social issues are common mass and user generated media However computer based understanding ideological discourse has been considered too difficult undertake this paper propose statistical model for ideology discourse ideology mean set general beliefs socially shared group people For example Democratic and Republican are two major political ideologies the United States The proposed model captures lexical variations due ideological text topic and due author speaker ideological perspective cope with the non conjugacy the logistic normal prior derived variational inference algorithm for the model evaluate the proposed model synthetic data well written and spoken political discourse Experimental results strongly support that ideological perspectives are reflected lexical variations 
6125 en  Joint Segmenting and Labeling Approach for Chinese Lexical Analysis This paper introduces approach which jointly performs cascade segmentation and labeling subtasks for Chinese lexical analysis including word segmentation named entity recognition and part speech tagging Unlike the traditional pipeline manner the cascaded subtasks are conducted single step simultaneously therefore error propagation could avoided and the information could shared among multi level subtasks this approach Weighted Finite State Transducers WFSTs are adopted Within the unified framework WFSTs the models for each subtask are represented and then combined into single one Thereby through one pass decoding the joint optimal outputs for multi level processes will reached The experimental results show the effectiveness the presented joint processing approach which significantly outperforms the traditional method pipeline style 
6126 en Bootstrapping Information Extraction from Semi structured Web Pages consider the problem extracting structured records from semi structured web pages with human supervision required for each target web site Previous work this problem has either required significant human effort for each target site used brittle heuristics identify semantic data types Our method only requires annotation for few pages from few sites the target domain Thus after tiny investment human effort our method allows automatic extraction from potentially thousands other sites within the same domain Our approach extends previous methods for detecting data fields semi structured web pages matching those fields domain schema columns using robust models data values and contexts Annotating pages for web sites yields extraction accuracy job offer sites and vacation rental sites These results significantly outperform baseline approach 
6127 en Large Scale Clustering through Functional Embedding present new framework for large scale data clustering The main idea modify functional dimensionality reduction techniques directly optimize over discrete labels using stochastic gradient descent Compared methods like spectral clustering our approach solves single optimization problem rather than hoc two stage optimization approach does not require matrix inversion can easily encode prior knowledge the set implementable functions and does not have out sample problem Experimental results both artificial and real world datasets show the usefulness our approach 
6128 en Mixed Bregman Clustering with Approximation Guarantees Two recent breakthroughs have dramatically improved the scope and performance means clustering squared Euclidean seeding for the initialization step and Bregman clustering for the iterative step this paper first unite the two frameworks generalizing the former improvement Bregman seeding biased randomized seeding technique using Bregman divergences while generalizing its important theoretical approximation guarantees well end with complete Bregman hard clustering algorithm integrating the distortion hand both the initialization and iterative steps Our second contribution further generalize this algorithm handle mixed Bregman distortions which smooth out the asymetricity Bregman divergences contrast some other symmetrization approaches our approach keeps the algorithm simple and allows generalize theoretical guarantees from regular Bregman clustering 
6129 en Clustering Distributed Sensor Data Streams this work study the problem continuously maintain cluster structure over the data points generated sensor network propose DGClust new distributed algorithm which reduces both the dimensionality and the communication burdens allowing each local sensor keep online discretization its data stream Each new data point triggers cell this univariate grid reflecting the current state the data stream the local site Whenever local site changes its state notifies the central server about the new state The central site keeps small list counters the most frequent global states simple adaptive partitional clustering algorithm applied the frequent states central points providing anytime definition the clusters centers The approach evaluated the context distributed sensor networks presenting empirical and theoretical evidence its advantages 
6130 en Data Streaming with Affinity Propagation This paper proposed StrAP Streaming extending Affinity Propagation data steaming new clustering algorithm extracts the data items exemplars that best represent the dataset using message passing method Several steps are made build StrAP The first one Weighted extends weighted items with loss generality The second one Hierarchical WAP concerned with reducing the quadratic complexity applying data subsets and further applying Weighted the exemplars extracted from all subsets Finally StrAP extends Hierarchical WAP deal with changes the data distribution Experiments artificial datasets the Intrusion Detection benchmark KDD99 and real world problem clustering the stream jobs submitted the EGEE grid system provide comparative validation the approach 
6131 en Parameter Learning Probabilistic Databases Least Squares Approach introduce the problem learning the parameters the probabilistic database ProbLog Given the observed success probabilities set queries compute the probabilities attached facts that have low approximation error the training examples well unseen examples Assuming Gaussian error terms the observed success probabilities this naturally leads least squares optimization problem Our approach called LeProbLog able learn both from queries and from proofs and even from both simultaneously This makes flexible and allows faster training domains where the proofs are available Experiments real world data show the usefulness and effectiveness this least squares calibration probabilistic databases 
6132 en  Simple Model for Sequences Relational State Descriptions Artificial intelligence aims developing agents that learn and act complex environments Realistic environments typically feature variable number objects relations amongst them and non deterministic transition behavior Standard probabilistic sequence models provide efficient inference and learning techniques but typically cannot fully capture the relational complexity the other hand statistical relational learning techniques are often too inefficient this paper present simple model that occupies intermediate position this expressiveness efficiency trade off based logic expressive probabilistic logic for modeling causality However specializing logic represent probability distribution over sequences relational state descriptions and employing Markov assumption inference and learning become more tractable and effective show that the resulting model able handle probabilistic relational domains with substantial number objects and relations 
6133 en Extracting Semantic Networks from Text via Relational Clustering Extracting knowledge from text has long been goal Initial approaches were purely logical and brittle More recently the availability large quantities text the Web has led the development machine learning approaches However date these have mainly extracted ground facts opposed general knowledge Other learning approaches can extract logical forms but require supervision and not scale this paper present unsupervised approach extracting semantic networks from large volumes text use the TextRunner system extract tuples from text and then induce general concepts and relations from them jointly clustering the objects and relational strings the tuples Our approach defined Markov logic using four simple rules Experiments dataset two million tuples show that outperforms three other relational clustering approaches and extracts meaningful semantic networks 
6134 en Data Mining for Anomaly Detection Anomaly detection corresponds discovery events that typically not conform expected normal behavior Such events are often referred anomalies outliers exceptions deviations aberrations surprise peculiarities contaminants different application domains Detection anomalies common problem many domains such detecting fraudulent credit card transactions insurance and tax fraud detection intrusion detection for cyber security failure detection direct marketing and medical diagnostics nAlthough anomalies are definition infrequent many examples their importance quite high compared other events making their detection extremely important nThis tutorial will provide overview the research done the increasingly important field anomaly detection The tutorial will cover the existing literature from variety perspectives such nature input output and the availability supervision nAnomalies will divided into three broad groups Point anomalies Contextual anomalies and iii Structural anomalies and wide variety anomaly detection methods appropriate for each type anomaly will presented Additionally the tutorial will discuss several application domains such intrusion detection fraud detection industrial damage detection healthcare informatics where anomaly detection plays central role 
6135 en The Regularization Frontier Machine Learning Machine Learning algorithms often involve the joint optimization several objective functions for achieving good generalization performance Well known examples are Support Vector Machines for regression classification and novelty detection the Lasso problem where one objective function related the perfect fit the data and the second one concerns particular desirable properties such smoothness sparsity the target model These two goals being antagonist trade off needs achieved Hence the learning process can cast multi objective optimisation problem The aim this tutorial bridge the gap between the multi objective optimization literature and the machine learning community providing insight the Pareto frontier the efficient computation this frontier using regularization path algorithms The connection between these algorithms and parametric optimisation problems will highlighted well issues related sparsity model selection and numerical implementation 
6136 en Nature not human activity rules the climate The science settled Evidence clearly demonstrates that Carbon dioxidencontributes insignificantly Global Warming and therefore not pollutant nnThis fact has not yet been widely recognized and irrationalnGlobal Warming fears continue distort energy policies and economic policy Allnefforts curtail emissions whether global the state level arenpointless and any case ineffective and very costly nnOn the whole warmer climate beneficial 
6138 en The Schelling model urban segregation The later economics Nobel laureate Schelling published 1971 model for the spontaneous segregation people two different groups ethnic religious Recent simulations the Ising type model are reviewed 
6139 en Facilitation competition and vegetation patchiness From scale free distribution patterns new technique for the modeling perennial vegetation patchiness the arid semiarid climatic zone suggested Incorporating the stochasticity that affects life history seedlings and the deterministic dynamics soil moisture and biomass this model flexible enough yield qualitatively different forms spatial organization the facilitation dominated regime scale free distribution patch sizes observed correspondence with recent field studies the competition controlled case the other hand power law statistics valid cutoff and intrinsic length scale appears 
6140 en Nowak Vallacher Mouse Paradigm tool for measuring the dynamics thought Traditional approaches social psychology attribute attitude change external factors disregarding the intrinsic dynamics information processing the brain Vallacher and Nowak proposed method for measuring momentary changes the stream thought the Mouse Paradigm this approach momentary state one feelings about object corresponds the perceived distance from this object tracking the computer mouse movements produced subjects thinking about the object possible find temporal patterns attitude change the presentation will argued that the Mouse Paradigm can valuable tool for measuring social judgment and self esteem 
6141 en Association between genetic polymorphisms for vasopressin and oxytocin receptors and pro social behavior economic decision tasks Human altruism widespread phenomenon that has puzzled evolutionary biologists since Darwin Economic games illustrate human altruism demonstrating that behavior deviates from economic predictions selfish utility maximization game that most plainly demonstrates this altruistic tendency the Dictator Game hypothesized that human pro social behavior some extent hardwired and that two likely candidate genes that may contribute individual differences altruistic behavior are the arginine vasopressin receptor AVPR1a and the oxytocin receptor OXTR nnGenes that some mammals such the vole have been shown have profound impact affiliative behaviors Multiple studies have shown how the two closely related neuropeptides facilitate social communication and cognition across mammals the current investigation demonstrate that AVPR1a and OXTR polymorphisms predict pro social allocation funds two economic games that measure altruistic and pro social behavior the Dictator Game and Social Value Orientations SVO 203 college students participated both one time online version the Dictator game and SVO Subjects and their parents were also genotyped for the AVPR1a and OXTR Using family based method observed preferential transmission individual alleles for the Dictator game and the SVO 
6142 en Fluctuation scaling complex systems Taylor law and beyond Complex systems consist many interacting elements which participate some dynamical process The activity various elements often different and the fluctuation the activity element grows monotonically with the average activity This relationship generically the form fluctuations ≈ const times average where the exponent predominantly the range This power law has been observed very wide range disciplines ranging from population dynamics through the Internet the stock market and often treated under the names Taylor law fluctuation scaling attempt show how general the above scaling relationship surveying the literature well reporting some new empirical data and model calculations also show some basic principles that can underlie the generality the phenomenon 
6143 en Energy policy complex Energy generation comparatively simple energy policy not Can complex systems science help understand the national and international policies past and present Can contribute sensible resolution the problems caused our low cost energy economies and resulting carbon emissions how not why not 
6144 en Stabilization metapopulation cycles Toward classification scheme The stability population oscillations ecological systems considered Experiments suggest that many cases the single patch dynamics predator prey host parasite systems extinction prone and stability achieved only when the spatial structure the population expressed via desynchronization between patches few mechanisms have been suggested far explain the inability dispersal synchronize the system suggest classification scheme that allows for either priori based the system parameters posteriori based local measurements identification the dominant process that yields desynchronization 
6145 en Linking pattern formation and biodiversity Dryland Vegetation Ecological processes generally involve different levels organization starting with singlenspecies individual through population many individuals given species and andiverse community consisting large populations many different species interacting among themselves and with their physical environment Upscaling low level attributes such species traits and biomass resource feedbacks community level properties such vegetation patterns and species diversity highly challenging goal for theorists this talk will describe recentnprogress our group has made towards achieving this goal the context dryland plant communities 
6146 en Principal Component Analysis and Clustering Reveal Human Maternal Ancestry from Complete Mitochondrial Sequences develop simple direct method infer the phylogenetic tree for the maternal lineage all humans usingnprincipal component analysis and consensus ensemble clustering Unlike standard methods such parsimony and maximum likelihood our method fast gives unique tree makes priori assumptions uses all polymorphisms the data and has high internal branch consensus confirms that modern humans came from Africa least two migrations and that the common maternal ancestor humans mitochondrial Eve lived Africa 200 000 years ago also suggests that the called Clade usually defined polymorphism locus 12705 too heterogeneous have derived from single common ancestor and places haplogroups the Asian branch the Clade agreement with their current location 
6147 en The Markovian Patch Occupancy MPO framework Community Ecology Ecological research over the years has pointed the existence wide spectrum semi universal patterns species diversity found over very different life forms and ecosystems the species area relationship the productivity diversity relationship the local regional diversity relationship etc present the Markovian Patch Occupancy MPO framework powerful platform for analyzing the mechanisms underlying these patterns The MPO framework uses stochastic individual based model ecological community based the theory Markov processes The analytically tractable model both general and highly flexible and can easily incorporate wide spectrum ecological factors including the effects area geographical isolation habitat loss habitat heterogeneity life history characteristics and trade offs density dependence community level carrying capacity competition for space various forms dispersal random dispersal preference for unoccupied sites preference for suitable habitats and complete flexibility the demographic rates individual species The MPO framework can used formulate and solve modern models the neutral theory and capable explaining surprisingly wide spectrum the semi universal patterns species diversity The generality high flexibility and analytic tractability the MPO framework make powerful platform for other research fields well 
6148 en Global Features Species Network simple model for competition induced speciation presented and analyzed Logistic growth with nonlocal interaction studied regular and random networks and the large scale structure the emerging genomic frequencies examined The neutrality assumption violated the network random and the competition nonlocal Instead Hubs the sequence space are suppressed the competition more than nodes lower degree Thus speciation unavoidable for large scale free networks The emerging genetic mixture depends strongly the initial conditions The frequency hubs much larger when the population evolves from single nucleation event comparison with populations that recover from catastrophe 
6149 en Dynamic networks the edge chaos network coupled phase oscillators considered Interactions between the oscillators are characterized phase shifts effectively taking into account interaction delays show that this simple model coherent collective dynamics can emerge Alternatively chaos can develop when interaction phase shifts are large enough Introducing global feedback chaotic behavior can suppressed giving rise localized structures the network with complex dynamical behavior This transition scenario analyzed and special attention paid the dynamical properties self organized structures 
6150 en Dynamical properties evolving networks Networks are usually studied static objects through the properties single snapshot the network The network generating mechanism are then deduced from the statistical properties this snapshot propose methodology directly study the network evolution from dynamic data This method joint with appropriate Markov model for edge and node addition provides direct insight the network generation mechanism The Markov model permits the quantitative comparison the contribution each generation mechanism specific network properties 
6151 en Excess covariance financial discuss the properties correlations between returns financial assets both static and dynamic and the challenges they pose understanding the dynamics financial markets Next will discuss how these questions can addressed theoretical models showing how these features are related traders behavior 
6152 en Lévy stable distribution economics this lecture will provide assessment the role played the class Lévy stable distributions modern macroeconomics and econometrics Some emphasis will put the distributional features sectoral level productivity growth rates and their implications for macroeconomic theory 
6153 en The alphabet model for rare events social dynamics most social sciences prediction based extrapolation central tendencies reality almost everything that important the consequence rare event The alphabet model describes how seemingly unimportant rare events may govern social dynamics 
6154 en Community structure graphs Identifying communities networks open challenge fundamental importance several disciplines Here discuss the main aspects the problem from the definition community the problem hierarchy including the crucial issue testing methods community detection 
6155 en Leibniz Complexity and Incompleteness will discuss Leibniz ideas complexity Discours metaphysique 1686 leading modern work program size complexity the halting probability and incompleteness Leibniz principle sufficient reason asserts that anything true true for reason But the bits the numerical value the halting probability are mathematical truths that are true for reason More precisely will explain they are irreducible mathematical truths that true for reason simpler than themselves 
6156 en The broken symmetries financial markets Various types irregularities financial markets will discussed together with the methods needed characterise them and the models that reproduce them particular emphasis will put time reversal asymmetry 
6157 en Information feedback mechanism and market dominance percolation model eco innovation diffusion New technologies often enter the market competitive disadvantage While they may seem promise future advantages such lower costs environmental friendliness higher performance initially they may significantly more expensive than incumbent technologies face teething problems The adoption new technology may also affected consumers’ uncertainty its performance such environment information feedbacks are likely arise and could allow certain technology the dominant one the market Drawing recent percolation models diffusion that combine the contagion aspect agents distributed network with the heterogeneity agent characteristics develop complex dynamics model new technology diffusion using multinomial decision mechanism model each adopter’ choice portfolio new available technologies show the effect information feedbacks market dominance Using agent based simulations explore when limited subsidy policy combined with power law learning curve for the price function the cumulative number adopters can trigger self sustained diffusion certain technology 
6158 en Common Welfare Strong Currencies and the Globalization Process The called “globalization” process the inexorable integration markets currencies nation states technologies andthe intensification consciousness the world whole has behavior exactly equivalent system that tending maximum entropy state This globalization process obeys collective welfare principle where the maximum payoff given the equilibrium the system and its stability the maximization the welfare the collective besides the individual welfare This let predict the apparition big common markets and strong common currencies They will reach the “equilibrium” decreasing its number until they reach state characterized only one common currency and only one big common community around the world 
6159 en The coupling strain evolution and disease dynamics Influenza characterized seasonal outbreaks and gradual genetic yet discontinuous antigenic evolution antigenic cluster jumps occuring every years with large seasonal epidemic result lacking immunity among the population The interplay between viral mutations and age group specific human immune response modelled here trying account for the observed phenomena and predict next season epidemic strain from the dynamics the previous year 
6160 en Self Organization Sound Systems the framework Complex Networks The sound inventories the world languages show considerable extent symmetry has been postulated that this symmetry reflection the human physiological cognitive and societal factors Although the organization the vowel systems has been satisfactorily explained for smaller inventories the structure the consonant inventories open problem since 1939 reformulate the problem the light statistical physics more precisely complex networks and observe that the distribution the occurrence and occurrence the phonemes consonants and vowels over languages are scale free The occurrence network exhibits strong community structures where the driving forces behind the community formation are the human articulatory and perceptual factors order validate the above principle introduce information theoretic definition these factors feature entropy and feature distance and show that the natural language inventories are significantly different these terms from the randomly generated ones preferential attachment based growth model can lead the emergence similar topologies that the real networks Furthermore separate study observe that spectral analysis the occurrence network consonants helps the induction linguistic typologies 
6161 en Random trees and genealogies The talk will review some the statistical properties the trees which represent the ancestry evolving populations both for neutral models asexual and sexual reproduction will particular show how the ages the first common ancestors depend the population size 
6162 en Statistical physics and complex networks Statistical physics approaches are developed and applied successfully recent years understand the topology robustness and function complex networks will show how ideas and tools from percolation theory lead novel results the robustness immunization strategies optimal paths and minimum spanning trees These results are relevant many real world systems ranging from the Internet social systems and climate 
6163 en Complexity What are talking about This field physics was originally identified Solid state Physics then Anderson coined the term Condensed Matter Physics and more recently has merged with Statistical Physics lead the Physics Complex Systems nThe study complex systems refers the emergency collective properties systems with large number parts interaction among them These elements can atoms macromolecules physical biological context but also people machines companies socio economic context The science complexity tries discover the nature the emerging behavior complex systems often invisible the traditional approach focusing the structure the interconnections and the general architecture systems rather than the individual components nIt change perspective the forma mentis scientists rather than new scientific discipline Traditional science based reductionistic reasoning for which one knows the basic elements system possible predict its behavior and properties easy realize however that for cell for the socio economic dynamics one faces new situation which the knowledge the individual parts not sufficient describe the global behavior the structure can represent this situation the study the architecture matter and nature depends some way from the individual elements bricks but then shows fundamental laws and properties which cannot derived from these elements Starting from the simplest physical systems like critical phenomena which order and disorder compete these emergent behaviors can identified many other systems from ecology the immunitary system the social behavior and economics The science complexity has the objective understand the properties these systems Which rules govern their behavior How they adapt changing conditions How they learn efficiently and how they optimize their behavior nThe development the science complexity cannot reduced single theoretical technological innovation but implies novel scientific approach with enormous potentialities influence deeply the scientific activities social economic and technological 
6164 en Emergence complexity biological networks from selection tinkering Recent work has been searching for general principles organization and evolution natural and artificial systems changing through local rules based reuse previously existing substructures Such process tinkering makes big difference least principle when comparing biological structures and man made artifacts pointed out the French biologist François Jacob the engineer able foresee the future use the artifact acts designer whereas evolution does not The first can ignore previous designs whereas the second based changes taking place using available structures nIn spite its apparent drawbacks tinkering has been able generate most complex structures observable the real world including some the technological world Very often the resulting structures share common principles organization suggesting that convergent evolution towards limited number basic plans inevitable How innovations emerge through evolution one the key problems complexity Recent work evolved complex networks suggests that tinkering main driving force shaping complex systems and that several desirable properties including modularity might emerge for free under tinkered evolution 
6165 en Adaptation and organization the economy living matter Metabolic networks guarantee the supply energy and building blocks necessary for the maintenance life Using genomic information mathematical models and optimality criteria one can learn about their evolutionary history and organization principles 
6166 en Agent Based Models Economics and Complexity crucial aspect the complexity approach how interacting elements produce aggregate patterns that those elements turn react This leads the emergence aggregate properties and structures that cannot guessed looking only individual behaviour Explicitly considering how heterogeneous elements dynamically develop their behaviour through interaction hard task analytically the equilibrium analysis mainstream neoclassical economics being not neutral shortcut the other hand explicitly considering the dynamics the process started feasible alternative only when computer power became widely accessible The computational study heterogeneous interaction agents called agent based modelling ABM Interestingly among its first applications prominent role was given economic models although was quickly found value other disciplines too Goal this lecture motivate the use the complexity approach and agent based modelling economics discussing the weaknesses the traditional paradigm mainstream economics and then explain what ABM and which research and policy questions can help analyse 
6167 en Systems Modelling Approaches for making and exploring decisions Previous systems based analyses predictions and decisions include conflict environmental pollution disease organisational changes issues and the mathematical methods involved The big questions for system modellers working with decision makers are how define and focus key issues optimal combination micro and macro modelling
6168 en Complexity science the 21st century Keeping purpose random world
6179 en Hard and easy science Using examples the application quantitative ideas social science hard sciences and recalling some approaches complex problems natural science easy sciences suggest path developing fundamental foundation for the analysis social problems roadmap suggested strategies over few decades with agreed metrics successful activities would give guidance tonquantitative approaches these hard scientific problems 
6180 en Financial crises and risk management The scientific study complex systems has transformed wide range disciplines recent years enabling researchers both the natural and social sciences model and predict phenomena diverse the failure materials earthquakes global warming demographic patterns and financial crises this talk Didier Sornette describes simple powerful and general theory how why and when stock markets crash nMost attempts explain market failures seek pinpoint triggering mechanisms that occur hours days weeks before the collapse nSornette proposes radically different view the underlying cause can sought months and even years before the abrupt catastrophic event the build cooperative speculation into accelerating rise the market price otherwise known bubble This view implies the possibility predicting such events and Sornette will describe the current status predictions that and his collaborators have made for events various markets 
6182 en Creativity and radical breakthroughs Science
6185 en Welcome and Opening Address main sponsors
6186 en Applications Statistical Physics Understanding Complex Systems
6188 en Social science Social science often concerned with the emergence collective behavior out the interactions large numbers individuals but this regard has long suffered from severe measurement problem—namely that interactions between people are hard measure especially scale over time and the same time observing behavior this talk will argue that the technological revolution the Internet beginning lift this constraint illustrate will describe three examples research that would have been extremely difficult even impossible perform just decade ago using email exchange track social networks evolving time using web based experiment study the collective consequences social influence decision making and using social networking site study the difference between perceived and actual homogeneity attitudes among friends Although internet based research still faces serious methodological and procedural obstacles propose that the ability study truly “social” dynamics individual level resolution will have dramatic consequences for social science 
6189 en Genealogies models evolution with selection Simples mean field models evolution presence selection will discussed nThe effect selection modify the statistical properties genealogical trees while absence selection the trees are randomly distributed Kingman coalescent theirnstatistics presence selection are very reminisecent Parisi theory mean field spin glasses 
6190 en Minimal agent based model for the origin and self organization financial markets introduce minimal Agent Based Model which includes the following elements first considered Lux and Marchesi Fundamentalists stabilizing tendency Chartists destabilizing tendency Herding effect tendency follow the others Price behavior analysis the price time series according criteria nThe novelty our model substantial simplification and corresponding reduction the number parameters This leads detailed understanding the origin the Stylized Facts like the fat tails and volatility clustering The are shown correspond finite size effects with respect time and the number agents which however can active different time scales This implies that universality cannot expected describing these properties terms effective critical exponents basic question then the self organization why the system chooses stay this narrow range parameters corresponding also finite value nWe show that the introduction threshold the agents’ action small price fluctuations lead action triggers the self organization towards the quasi critical state and finite average value which depends the other parameters Non stationarity the number active agents and their action plays fundamental role The interpretation the number effective independent agents non trivial and deserves further studies The model can easily generalized more realistic variants systematic way 
6191 en Systemic Mechanism Detection Tumor Formation
6192 en Scale free topologies emerging from dynamical entrainment complex network show that the topology and dynamics network unsynchronized Kuramoto oscillators can simultaneously controlled means forcing mechanism which yields phase locking the oscillators that external pacemaker connection with the reshaping the network degree distribution The entrainment mechanism based the addition regular time intervals unidirectional links from oscillators that follow the dynamics pacemaker oscillators the pristine graph whose phases hold prescribed phase relationship Such dynamically based rule the attachment process leads the emergence power law shape the final degree distribution the graph whenever the network entrained the dynamics the pacemaker show that the arousal scale free distribution connection with the success the entrainment process robust feature characterizing different network initial configurations and parameters 
6193 en Towards physics society Statistical physics has proven invaluable tool describe and understand the properties systems formed large number elementary units big challenge whether the tools and techniquesnof statistical physics are suitable explore large scale social phenomena Most attempts ofnthe literature focus simple microscopic models with little contact real social dynamics validation this approach still lacking and must rely quantitative evidence about real social systems Finding regularities real data crucial step this direction will show that voting and citing behaviors are both characterized scaling and universality The statistical distribution the number votes cites suitably normalized independent the particular system considered This opens the way simple modeling the observed phenomenology 
6194 en Demography Who pays pension Simple computer simulations indicate many European countries serious problems for old age pensions around 2030 later Many more old peoplenand much less young people Possible remedies are immigration and increase retirement ages Algeria the present situation seems betternbalanced the Palestinian Territories the opposite for the nextnfew decades 
6195 en Complex networks theory and applications Complex systems which are composed many interacting entities can represented analyzed and better understood using network representation where the entities are represented nodes and the interactions links recent years was realized that the topology many real networks very different from that the classical graph theory particular while classical graphs were assumed homogeneous with every node having typical number links degree real networks are usually heterogeneous the Internet with nodes having very different degrees Thus many properties networks were not understood and many open questions were asked The finding the new topology led recent years the emergence active field complex networks where new suitable theories and approaches are developed will discuss these developments well many recent applications such robustness effective immunization strategies and optimal transport real world networks nReferences Transport weighted networks partition into superhighways and roads Braunstein Havlin Stanley Phys Rev Lett 148702 2006 Limited path percolation complex networks Lopez Parshani Cohen Carmi Havlin Phys Rev Lett 188701 2007 model Internet topology using shell decomposition Carmi Havlin Kirkpatrick Shavitt Shir PNAS 104 11150 2007 Climate networks around the globe are significantly affected Nino Yamasaki Gozolchiani Havlin Phys Rev Lett 100 228501 2008 Finding Better Immunization Strategy Chen Paul Havlin Liljeros and Stanley Phys Rev Lett 101 058701 2008 
6196 en Changing the world web search Heavy tailed distributions have been observed many phenomena involving consumer behavior especially the internet consider the problem assembling search engine the future examine the impact such heavy tailed consumer behavior the design choice for such engine and the process highlight our poor understanding and the need for much further research into many concrete aspects economically viable search engine operation 
6197 en Can nature solve hard problems Nature certainly poses lot hard problems the physicist the chemist But can natural systems nature inspired artifacts used solve hard problems This general question can made bit more precise focusing combinatorial optimization problems Simple attempts solving problems like Hamiltonian path Steiner tree seem far from the goal and many case seems that the occurence glassy transition which freezes the relaxation metastable states the major obstacle nRecently some the hardest constraint satisfaction problems have been addressed successfully through message passing methods with algorithms which partly get around the freezing transition The talk will review this approach and discuss its limitations Message passing which purely local strategy based the exchange simple probabilistic messages along graph constraints not only very powerful but also appealing since its basic ingredients share some similarity with neural networks This points alternative natural ways solving hard problems through artifacts which get around the basic physical limitations usual thermal systems 
6198 en Computational and mathematical challenges involved estimating Phylogenetic inference presents enormous computational and mathematical challenges but these are particularly exacerbated when dealing with very large datasets containing thousands sequences when sequences evolve under complex evolutionary processes ranging from simple indel models horizontal gene transfer genome rearrangement events this talk will describe some the recent progress evolutionary history reconstructing under complex evolutionary processes focusing particular multiple sequence alignment and its implications for large scale phylogenetics nRelated Link http www phylo org CIPRES project webpage 
6199 en Human Mobility Patterns Despite their importance for urban planning traffic forecasting and the spread biological and mobile viruses our understanding the basic laws governing human motion remains limited owing the lack tools monitor the time resolved location individuals study the trajectory anonymized mobile phone users finding that contrast with the random trajectories predicted the prevailing ´ flight and random walk models human trajectories show high degree temporal and spatial regularity each individual being characterized time independent characteristic travel distance and significant probability return few highly frequented locations Afterncorrecting for differences travel distances and the inherent anisotropy each trajectory the individual travel patterns collapse into single spatial probability distribution indicating that ndespite the diversity their travel history humans follow simple reproducible patterns This inherent similarity travel patterns could impact all phenomena driven human mobility from epidemic prevention emergency response urban planning and agent based modeling 
6200 en Modeling social networks large scale Recent development information and communication technology has enabled study networks social interactions unprecedented size Such systems include email phone networks and communities contrast the traditional questionnaire based investigations these cases natural quantitative measure the strength the interactions present like the frequency duration calls leading weighted network representations One important observationnis that this strength the interactions varies over many orders magnitude natural conclusion that the weights play important roles both the evolution the networks and the dynamics the processes them Based simple rules borrowed from sociology wenconstruct model where the emergence the community structure consequence the interplay between topology and weights show that the model reflects well the observations made huge call network nReferences Kumpula Onnela Saramäki Kaski Kertész Emergence communities weighted networks Phys Rev Lett 228701 2007 Onnela Saramäki Hyvonen Szabó Lazer Kaski Kertész Barabási Structure and tie strengths mobile communication networks PNAS 104 7332 7336 2007 Onnela Saramäki Hyvonen Szabó Argollo Menezes Kaski Barabási Kertész Analysis large scale weighted network one one human communication New Phys 179 2007 
6201 en Prefrontal cortex and decision making The prefrontal cortex has been known participate working memory processes Tonic sustained activation observed during the delay period delay period activity has been considered neural correlate the mechanism for active maintenance information Neurophysiological studies revealed that delay period activity represents retrospective information sensory events well prospective information forthcoming motor information This suggests that delay period activity participates decision processes regarding motor performances based the sensory information examine how delay period activity participates the decision motor behavior analyzed prefrontal activity while monkeys performed two tasks ODR and ODR tasks the ODR task monkeys were required make memory guided saccade the cue location after delay the ODR task four identical visual cues were presented simultaneously during the cue period and monkeys were required make saccade any one direction after the delay Delay period activity was observed both tasks the same neuron with similar directional preferences Neurons with delay period activity were classified into several groups based the temporal pattern the activity itself and the strength the directional selectivity Among these neurons with increasing type delay period activity with persistent directional selectivity throughout the delay period the ODR task also showed directional delay period activity the ODR task These results indicate that increasing type delay period activity which thought represent motor information plays important role generating and enhancing directional bias the ODR task and therefore contributes significantly the decision process the saccade direction the ODR task 
6202 en The case the altruist meme Altruism elicits humans very powerful and diverse feelings Its paradoxical nature makes mysterious and challenging understand difficult understand why rational being would sacrifice its own interests for somebody else especially one reproduction fitness depends them also difficult believe that such trait would survive natural selection fact was shown rigorous theorems wide range conditions that the Nash stable strategy selfish and not share show that the resources sharing phenotype highly favored and wins natural selection dramatically instead incurring fixed gain and losses the players gain loose fixed fractions their current resources Thus the solution the sharing paradox resides recognizing the random multiplicative rather then the usual game theory additive character the real life society economic and cultural games this talk will present analytical and numerical results for different variations the model along with results from intensive computer simulations that support and clarify these results
6203 en Dynamic Decisions Multiple Equilibria and Complexity Agent based models represent the interaction between multiplicity agents through dynamic systems often giving rise intricate and complex dynamics can extend this type economic analysis emphasizing that economic agents have memories form expectations and are guided intentional behavior within the context certain decision horizon However important note that the agents decisions and actions change the economic environment and affect the system dynamics The interaction agents often stylized predator prey competitive and cooperative interactions the context Lotka Volterra systems start with these types systems and show that economic agents decisions can understood perturbation term the general system dynamics The dynamics model with zero time horizon which has small effects the system dynamics can often studied analytically and taken starting point for numerical analysis with longer time horizon Since due nonlinearities multiple equilibria frequently arise this generates path dependency and complex dynamics solve these types models using dynamic programming with flexible grid size that can capture multiple equilibria and threshold and bifurcation behavior Heterogeneity agents and multiple attractors predict bimodal distribution outcomes which can empirically verified using Markov transition matrices give number examples from resource economics development economics investment theory industrial organization imperfect capital markets growth distribution and climate change give prototype examples and illustrate economic mechanisms wherein such complicated dynamics those with threshold and bifurcation behavior can occur These types models can not only empirically tested but have strong policy implications the sense that policy can tilt the dynamics toward superior equilibria and increase the domain attraction for preferable equilibria 
6204 en Strong random correlations complex systems Complex systems living organisms the brain society the economy etc seem depend huge number details which makes them nearly irreducible that they cannot described terms small number variables This poses fundamental difficulties for the modeling such systems and the parametrization calibration any model that may propose describe them Furthermore this irreducibility also implies the existence strong random correlations between large number the components the system that are not necessarily close neighbours geometric sense not necessarily linked strong direct interactions This makes the system sensitive changes the external control parameters boundary conditions etc and poses serious challenge computer simulations These ideas are illustrated some toy models spin glass random cellular automaton and game theoretical model 
6205 en  Paradigmatic Complex System The Immune System The immune system provides accessible data about the evolution the organizational operation and the end function complex system immunology exemplifies the evolution the organizational sociology and the end function complex systems’ research shall discuss select issues related both the system and the science that studies the system nThe system Evolution from innate adaptive immunity Organization degeneracy recognitions and interactions pleiotropic and redundant agents End function body protection body maintenance The science Evolution from clonal selection systems biology the quest for optimums Organization molecular biology versus physiology End function prevention and cure disease 
6206 en Rule Rationality Act Rationality
6207 en  Century Controversy over the Foundations Mathematics tell the dramatic story the recent disputes over the foundations mathematics start with the problems Cantor theory infinite sets and then discuss the work Bertrand Russell David Hilbert Kurt Godel and Alan Turing and finally own work using complexity nThis complexity based analysis the foundations mathematics suggests that perhaps mathematics more similar physics and biology than commonly believed and should sometimes carried out quasi empirically that more the spirit experimental science 
6208 en The Architecture Ecological Interactions Patterns and Principles Descriptions complex feeding relationships among species ecosystems first appeared more than century ago and the quantitative analysis the network structure “food webs” dates back several decades Improvements food web data collection analysis and modeling coupled with resurgence interdisciplinary research the topology many kinds “real world” networks have resulted renewed interest ecological network structure Recent research suggests that food webs display universal scale dependent patterns how trophic links and roles are distributed among species ecological communities The fundamental ways which feeding interactions are organized appears have become established very early the history multicellular life earth Understanding the principles that underlie robust food web patterns represents important frontier ecological research 
6209 en Artifacts and Organization Complexity Perspective Innovation and Social Change Human sociocultural life impossible conceive without two fundamental ingredients artifacts and organizations Just about everything involves interactions with artifacts from the clothes wear and the buildings inhabit the devices through which communicate with one another and the tools and technologies use make ever more artifacts And almost all our interactions depend for their setting purpose and rules organizations whether they churches businesses government agencies political parties law courts police forces armies social clubs – even friendship networks internet nWe human beings didn’ invent either artifacts organizations biological evolution did Both fashioning artifacts and deploying collective action are evolutionary strategies that have been around long time But even didn’ invent them nothing biology remotely compares with the use that human beings have made these two strategies The number and complexity the artifacts have developed over the millennia and particular over the past few centuries and the variety activities have organized around these artifacts has counterpart the pre human world three million years ago our ancestors had essentially one kind artifact and fifty thousand years ago maybe several hundred today’ inhabitant New York City can choose among 1010 different bar coded items not mention host other material informational performative artifacts currently produced human beings for the use human beings Even more unprecedented are the diversity forms and the scale the organizations have created through which collectively carry out political economic social and cultural functions that seem far removed from the overriding biological functional imperatives survival and reproduction nOver the past several years colleagues and have been working out complexity based theory innovation that intended explain how human beings have managed generate the explosion artifacts and the new functionalities they make possible The theory starts from the premise that all artifacts have history the modes interaction among people which artifacts figure The aim the theory describe and analyze the processes through which artifact histories are realized • How new artifact types come into being • How their tokens proliferate and become incorporated into patterns human interaction • And how are new patterns interaction among human beings and artifacts generated nAs will argue the talk cannot begin answer these questions without developing simultaneously theory sociocultural organizations what they are how they come into being how they transform themselves nThe main conclusion the talk that our species has developed new modality innovation which artifacts and organization are inextricably linked human beings generate new artifacts that they embed new collective activities which are turn supported new organizations and sustained new values Over time this new innovation modality gave rise positive feedback dynamic which call exaptive bootstrapping Exaptive bootstrapping explains how have generated many transformations our selves our societies our culture and our environment 
6210 en nformation processing cortical neural networks with dynamic synaptic connections Synaptic transmission the cortex characterized the activity dependent short term plasticity STP which can broadly classified synaptic depression and synaptic facilitation recent experiments indicate different cortical areas exhibit variable mixes facilitation and depression which are also specific for connections between different types neurons the first half presentation will describe the basics dynamic synaptic transmission its biophysical underpinnings and the ways can captured biophysically motivated phenomenological models will also discuss some immediate implications STP information transmission between ensembles neocortical neurons the second half the presentation will focus the effects STP the dynamics recurrent networks and resulting neural computation will introduce the population spikes PSs which are brief epochs highly ynchronized activity that emerge recurrent networks with dominating synaptic depression between excitatory neurons PSs can underlie some the response properties neurons the auditory cortex will then describe the recently introduced idea that synaptic facilitation could utilized order maintain information about the incoming stimuli the facilitation level recurrent connections between the targeted neurons thus providing effective mechanism for short term memory for period several seconds after the termination the stimulus 
6211 en Predicting Climate Change will review the different components the climate system and try demonstrate why its behavior very hard predict will then continue discussing the relative roles anthropogenic and solar climate driving and its implications future climate change which not bleak most often promoted 
6212 en Marked Market Leverage with Zero Intelligent Agents liquid markets real time mark market portfolio valuations may not expected impact prices However during illiquid periods with leveraged trading such settlement can have significant impact price volatility and trading choices While the assumption efficient markets confers speculative traders with stabilizing attributes liquidity settlement trades can have destabilizing properties the short run traders buy when prices rise and sell when prices fall meet collateral requirements there are lot traders the market this situation can become cumulative producing positive autocorrelation returns and volatility clustering Such price dynamics and corresponding drying market liquidity can occur even when traders are zero intelligent that their price expectations risk aversion does not change response price changes 
6213 en Decoding mental states from human brain activity possible predict what person thinking even what they are planning based alone their current brain activity Recent advances have made possible decode and predict person thoughts from functional magnetic resonance imaging fMRI data The key that each thought associated with unique brain activation pattern that can used signature for that specific thought possible train pattern classifiers recognize these characteristic signatures and thus read out person thoughts from their brain activity alone This research can reveal how neural representations mental contents are stored and transformed the brain also gives rise many potential applications for example the control computers and artificial prostheses brain activity the detection concealed mental states 
6214 en Dynamics Information and Evaluation Social Networks The lecture will concern dynamics two different processes occurring social networks the flow information and the process evaluation Similarities and differences how networks structure shapes the spread information and governs social influence the process evaluation will discussed Research social psychology suggests that information not only acquired but also evaluated and interpreted the process interaction individuals construct common social representation Both simulation and empirical data show that transmission information and evaluations operate very different ways Empirical data concerning the structure selected social networks and dynamics information the networks will presented 
6215 en Complex Patterns Reactive Wetting Interface Dynamics Reactive wetting interface dynamics exhibits complex spatio temporal patterns during the kinetic roughening process the triple line This could seemingly described scaling growth and roughness exponents However show that the non linear interface dynamics much more complex Using extreme value statistics particular the persistence measure demonstrate the difficulties associate given universality class this complex system Our reactive wetting system which the only known system room temperature consists small mercury droplets 150m diameter spreading thin silver films 2000 – 4000 The process monitored using optical microscope nnnIn this talk discuss the growth and roughness exponents the propagating interface the temporal interface width fluctuations during single growth process and the lateral correlation length along the triple line – all function the silver substrate roughness and the temperature the system then introduce the persistence measure order demonstrate the complexity the system and suggest several numerical models obtain better insights regarding the microscopic physical mechanisms that play role the process 
6216 en Non Genetic Individuality Predator Prey system Isogenic bacteria can exhibit range phenotypes even homogeneous environmental conditions Such non genetic individuality has been observed wide range biological processes including differentiation and stress response striking example the heterogeneous response bacteria antibiotics whereby small fraction drug sensitive bacteria can persist under extensive antibiotic treatments Recently renewed interest the persistence phenomenon has revealed that non genetic heterogeneity might one the main reasons for the failure antibiotic treatment infections such tuberculosis where single persistent bacterium can start infection Persistence typically observed through the monitoring the survival fraction bacterial population exposed antibiotics The initially rapid killing the bacteria followed significantly reduced killing rate which indicates the presence persistent sub population When cells grown from this persistent sub population are subjected again antibiotics the same phasic killing curve obtained suggesting that the persistent sub population not genetically different from the original population have previously shown that persistent bacteria enter phenotypic state identified slow growth dormancy which protects them from the lethal action antibiotics Here studied the effect persistence the interaction between Escherichia coli and phage lambda focused two different variations this well studied predator prey system phage that present the genome each bacterium and can cause bacterial death process called prophage induction and lytic phage that attacks bacteria from the outside infects them and them kills them The effect the persistent phenotype was studied those systems and the experimental results obtained were then implemented mathematical description these interactions nWe used long term time lapse microscopy follow the expression GFP under the phage lytic promoter well cellular fate single infected bacteria found that dormancy that protects bacteria under antibiotic treatments also protects them against prophage induction competition experiment run between low persistence population and high persistence one demonstrated clear advantage the latter This suggests that persistence might have evolved under the evolutionary pressure prophage stress Intriguingly found that while persistent bacteria are protected from prophage induction they are not protected from lytic infection Quantitative analysis gene expression revealed that the expression lytic genes suppressed persistent bacteria However when persistent bacteria switch normal growth the infecting phage resumes the process gene expression ultimately causing cell lysis nDespite its mild effect the short term survival the population the delayed cell lysis persistent bacteria needs taken account Using mathematical model for this predator prey interaction found that the bacteria non genetic individuality can significantly affect the population dynamics and might relevant for understanding the evolution bacterial hosts and phages nReferencesn1 Rando Verstrepen 2007 Timescales genetic and epigenetic inheritance Cell 128 655 668 Stewart Robertson Young 2003 Tuberculosis problem with persistence Nature Reviews Microbiology 105 Balaban Merrin Chait Kowalik Leibler 2004 Bacterial persistence phenotypic switch Science 305 1622 1625 Pearl Gabay Kishony Oppenheim Balaban 2008 Nongenetic individuality the host phage interaction PLoS Biol e120 
6217 en Epigenomics and Morphodynamics The substrate for heredity DNA chemically rather inert However bears one the elements information that specify the form the organism How can form specified starting from DNA Recent observations indicate that the dynamics transcription — the process that decodes the hereditary information — can imprint forms certain topological class onto DNA This topology allows both optimize transcription and facilitate the concerted change the transcriptional status response environmental modifications the best our knowledge this morphogenetic event first the path from DNA organism 
6219 en Neural mechanisms working memory the prefrontal cortex Working memory mechanism for short term active maintenance information well for processing maintained information The dorsolateral prefrontal cortex DLPFC has been known participate working memory The analysis task related DLPFC activity while monkeys performed variety working memory tasks revealed that delay period activity neural correlate mechanism for temporary active maintenance information because this activity persisted throughout the delay period showed selectivity particular visual feature and was related correct behavioral performances the other hand information processing can considered change the information represented population neurons during the progress the trial Using population vectors calculated population task related DLPFC activities demonstrated the temporal change information represented population DLPFC neurons during performances spatial working memory tasks Cross correlation analysis using spike firings simultaneously isolated pairs neurons reveals widespread functional interactions among neighboring neurons especially neurons having delay period activity and their dynamic modulation depending the context the trial Functional interactions among neurons and their dynamic modulation could mechanism information processing the working memory processes 
6220 en Can attractor network models account for the statistics firing during persistent activity prefrontal cortex Persistent activity observed neurophysiological experiments monkeys thought the neuronal correlate working memory Over the last decade network modelers have strived reproduce the main features these experiments particular attractor network models have been proposed which there coexistence between non selective attractor state with low background activity with selective attractor states which sub groups neurons fire rates which are higher but not much higher than background rates recent detailed statistical analysis the data seems however challenge such attractor models the data indicates that firing during persistent activity highly irregular with average larger than while models predict more regular firing process smaller than will discuss how this feature can reproduced network excitatory leakly integrate and fire neurons 
6221 en The computational limitations balanced networks Computation neural networks relies crucially non linearity neural networks the balanced state the non linearity the neuronal transfer function becomes functionally unimportant The disappearance this non linearity strongly limits the computational power balanced networks will show examples balanced networks for associative memory how one can try circumvent this limitation balanced networks and discuss the problems with these solutions 
6222 en Balanced spatial working memory Neural activity persisting for several seconds thought the neural correlate working memory cortex was found recently that during persistent activity spike trains are highly irregular even more irregular than spontaneous activity show that this apparently innocuous feature raises fundamental difficulty one holds that neuronal nonlinearities combined with recurrent excitation underly activity persistence usually assumed Instead argue that the key nonlinearities involved are synaptic and not neuronal assess this proposal the framework network model representing circuit prefrontal cortex involved spatial working memory This lead suggest that short term plasticity recently discovered synapses made pyramidal cells prefrontal cortex crucial spatial working memory 
6223 en Active memory maintenance with short term synaptic facilitatio Current theoretical framework holds that information actively maintained working memory through enhanced firing rates delay activity This would achieved either via persistent activity reverberation within selective neural populations result intrinsic single cell properties stability Electrophysiological studies show however that delay activity increase can modest sometimes completely disappearing during part the delay period therefore propose new theoretical framework whereby working memory sustained calcium mediated synaptic facilitation the recurrent connections neocortical networks this account the presynaptic residual calcium used buffer which loaded refreshed and read out spiking activity Due the long time constants calcium kinetics the refresh rate can very low which results mechanism that metabolically efficient and resistant external interferences The duration and stability working memory can effectively regulated modulating the spontaneous activity the network Joint work with Omri Barak and Misha Tsodyks
6224 en Working memory for saccadic eye movements the parietal cortex Area LIP the parietal cortex related saccades visual attention and additional related cognitive processes and contains neurons that show persistent activity memory guided saccades The talk will focus comparisons the neuronal activity during memory saccades towards versus opposite the target direction prosaccades and antisaccades and during memory saccades comprising unguided choice versus guided choice will consider computational problems and other implications arising from the results 
6225 en The Computational Principles and Neural Mechanism Underlying Contraction Bias well established that the estimated magnitude memorized stimuli biased small magnitudes are overestimated and large magnitudes are underestimated phenomenon known contraction bias previous study monkeys were trained memorize the frequency vibrotactile stimulus Base and compare with the frequency second stimulus Comparison while single unit activity was recorded their prefrontal cortex Romo 1999 Nature 399 470 473 identified that the pattern errors made the monkeys consistent with the contraction bias providing opportunity study this phenomenon both the level behavior and the level neural activity Here address two questions What are the computational principles and the neural mechanisms underlying the contraction bias show that contraction bias consistent with Bayesian inference which noisy measurement combined with priori knowledge about the distribution Base magnitudes order improve performance According the Bayesian hypothesis increasing the level uncertainty the magnitude the memorized stimulus enhances the bias This uncertainty function the delay between the Base and Comparison frequencies the performance level the monkey decreases with the duration the delay Indeed expected from the Bayesian hypothesis the longer the delay between the Base and Comparison frequencies the greater the bias According the Bayesian hypothesis monkeys utilize the prior distribution Base frequencies their decision making process order study how the monkeys estimate this prior distribution analyzed the dependence the monkeys decisions the recent history stimuli presented them the experiment show that the estimated prior distribution depends mostly the recent history several previous trials The firing rate many prefrontal cortex neurons during the delay period monotonic function the Base stimulus frequency has been suggested that decisions the discrimination task are made comparing this activity with the neural representation the Comparison frequency Thus the contraction the memorized frequencies should reflected the activity the prefrontal cortex neurons resulting the biased decisions studying how past trials affect neural activity the prefrontal cortex seek identify the neural correlate the contraction bias 
6226 en Mechanisms mGluR mediated plateau potentials entorhinal cortex neurons well established that the estimated magnitude memorized stimuli biased small magnitudes are overestimated and large magnitudes are underestimated phenomenon known contraction bias previous study monkeys were trained memorize the frequency vibrotactile stimulus Base and compare with the frequency second stimulus Comparison while single unit activity was recorded their prefrontal cortex Romo 1999 Nature 399 470 473 identified that the pattern errors made the monkeys consistent with the contraction bias providing opportunity study this phenomenon both the level behavior and the level neural activity Here address two questions What are the computational principles and the neural mechanisms underlying the contraction bias show that contraction bias consistent with Bayesian inference which noisy measurement combined with priori knowledge about the distribution Base magnitudes order improve performance According the Bayesian hypothesis increasing the level uncertainty the magnitude the memorized stimulus enhances the bias This uncertainty function the delay between the Base and Comparison frequencies the performance level the monkey decreases with the duration the delay Indeed expected from the Bayesian hypothesis the longer the delay between the Base and Comparison frequencies the greater the bias According the Bayesian hypothesis monkeys utilize the prior distribution Base frequencies their decision making process order study how the monkeys estimate this prior distribution analyzed the dependence the monkeys decisions the recent history stimuli presented them the experiment show that the estimated prior distribution depends mostly the recent history several previous trials The firing rate many prefrontal cortex neurons during the delay period monotonic function the Base stimulus frequency has been suggested that decisions the discrimination task are made comparing this activity with the neural representation the Comparison frequency Thus the contraction the memorized frequencies should reflected the activity the prefrontal cortex neurons resulting the biased decisions studying how past trials affect neural activity the prefrontal cortex seek identify the neural correlate the contraction bias 
6227 en Low dimensional network models for data from the prefrontal cortex During short term memory maintenance different neurons prefrontal cortex PFC recorded under identical conditions show wide variety temporal dynamics and response properties These data are specific example the more general finding that neural recordings from frontal cortices often reveal that different neurons have very different response characteristics Modeling this complexity responses has been difficult Most commonly some features the responses are focused and models that fit those reduced features are built But can the full complexity responses easily captured Here attack the problem fitting simple recurrent neural network models the data nFollowing the traditional approach first group neurons into different classes When selecting neurons from single class the estimation procedure yields connectivity matrix with two populations neurons coupled mutual inhibition and self excitation The connectivity matrix has rank one and approximately agrees with model proposed earlier When selecting neurons from two classes connectivity matrix similar that the ring attractor network emerges with rank two The full complexity and richness the observed neural dynamics however can only captured when estimating network architecture from the full set neurons this case the resulting connectivity matrix has rank five and its structure dominated randomness Simulations the resulting network reproduce the full data set show that several the eigenvalues the connectivity matrix are close zero that the network dynamics has either constant integrating flow along the respective dimensions Finally discuss the consistency the estimated connectivity matrices with the measured noise correlations Timing and Neural Encoding Somatosensory Parametric Working Memory Macaque Prefrontal Cortex Brody Hernandez Zainos and Romo Cereb Cortex 1196 1207 2003 Flexible control mutual inhibition neural model two interval discrimination Machens Romo and Brody Science 307 1121 1124 2005 
6228 en Mechanism for Top down Control Working Memory Capacity Working memory relies the activation both prefrontal and parietal cortex possibly with prefrontal cortex exerting top down control However there still mechanistic description either capacity limitations top down control maintenance information working memory Here propose that lateral inhibition parietal cortex limits mnemonic capacity However high loads this inhibition can counteracted excitatory input from prefrontal cortex thus boosting parietal capacity formulate this computationally biophysical cortical microcircuit model and conceptualize mathematical equation Predictions from the model were confirmed fMRI study The model provides mechanistic framework for understanding top down control working memory and specifies two different contributions prefrontal and parietal cortex working memory capacity 
6230 en Memory blends How perceptual memories interact will describe results from psychophysical experiments using sequences visual stimuli showing that similarity between subsequent stimuli has critical impact the generated memory 
6231 en Short term memory effects visual perception Memory traces stored the form attractors appearing the result recent perceptual experience can actively shape processing and categorization visual stimuli Electrophysiology monkey cortex and computational modeling indicate the existence categorical boundaries the dynamics cortical networks Our psychophysical experiments humans show that these boundaries can shifted following recent visual experience adaptation and priming paradigms 
6232 en Short term memory traces neural networks Critical cognitive phenomena such planning and decision making rely the ability the brain hold information working memory Many proposals exist for the maintenance such memories persistent activity that arises from stable fixed point attractors the dynamics recurrent neural networks However such fixed points are incapable storing temporal sequences recent events alternate and relatively less explored paradigm the storage arbitrary temporal input sequences the transient responses recurrent neural network Such paradigm raises host important questions Are there any fundamental limits the duration such transient memory traces How these limits depend the size the network What patterns synaptic connections yield good performance generic working memory tasks what extent these traces degrade the presence noise use the theory Fisher information construct novel measure memory traces neural networks combining Fisher information with dynamical systems theory find precise answers the above questions for general linear neural networks prove that the temporal duration memory trace any network most proportional the number neurons the network However memory traces generic recurrent networks have short duration even when the number neurons the network large Networks that exhibit good working memory performance must have possibly hidden feedforward architecture such that the signal entering the first layer amplified propagates from one layer the next prove that networks subject saturating nonlinearity can achieve memory traces whose duration proportional the square root the number neurons These networks have feedforward architecture with divergent connectivity spreading excitation across many neurons each layer such networks achieve signal amplification without saturating single neurons 
6233 en The costs visual working memory The capacity visual working memory has been extensively characterized but little work has investigated how occupying visual memory influences other aspects cognition and perception Here show novel effect maintaining item visual working memory slows processing similar visual stimuli during the maintenance period Subjects judged the gender computer rendered faces the naturalness body postures while maintaining different visual memory loads found that when stimuli the same class faces bodies were maintained memory perceptual judgments were slowed Our results suggest there interference between visual working memory and perception caused visual similarity between new perceptual input and items already encoded memory 
6234 en Mixed neuronal selectivity important recurrent neural networks implementing context dependent tasks Higher order animals show the remarkable ability flexibly adapt their behavior according the context The execution complex cognitive tasks can modeled series event driven transitions between mental states each encoding certain disposition behavior specific sensori motor decision this work hypothesize that these mental states are instantiated neuronally recurrent circuit dynamics the form stable attractors the neural activity show that the mathematical conditions for the attractors and the event driven transitions can satisfied only neurons are selective combinations internal mental states and sensory stimuli One possible way generate such mixed selectivity introduce neurons whose afferent connections have random synaptic strengths This approach has least three highly desirable features First spite the combinatorial explosion possible neurons with mixed selectivity the number needed randomly connected neurons grows only linearly with the number relevant task events and contexts which makes reasonably sized network able execute extremely complex cognitive tasks Second the firing patterns neurons the simulated proposed network capture several aspects the activity recorded prefrontal cortex and other brain areas involved complex cognitive processes The activity self sustaining the absence events rule selective and highly heterogeneous Third the introduction randomly connected neurons accelerates the convergence learning algorithms and can exploited rapidly learn complex behavioral tasks conclusion think that mixed selectivity widely observed the living brain can important and general functional principle for executing complex cognitive tasks 
6235 en Unconscious determinants free decisions the human brain There has been long debate whether subjectively free decisions are determined brain activity ahead time Previous claims that subjective decisions are preceded brain activity have been highly criticized inaccuracies the participants subjective reports Also has remained unclear whether intention act initiated motor related brain regions high level brain areas are involved Here use combination statistical pattern recognition and fMRI show that the outcome decisions can decoded from brain activity prefrontal and parietal cortex even ten seconds before they enter awareness This delay too long accounted for inaccuracies measuring the onset conscious intentions Instead presumably reflects the operation network high level control areas that operate slow timescale and begin prepare upcoming decision long before enters awareness This suggests that our free choices can determined brain activity much earlier than commonly appreciated 
6258 en Learning Patterns the Brain Machine Learning Challenges fMRI Analysis Functional Magnetic Resonance Imaging fMRI has given neuroscientists and cognitive psychologists incredible power analyze the deep mysteries the human brain With this powerful imaging technology however many new challenges have arisen for the statistics and machine learning communities this talk will present overview fMRI and some the current machine learning challenges will discuss recent work hierarchical Bayesian methods for dealing with high dimensional sparse data will also discuss the application classical order statistics the problem feature selection Finally will show some our latest results combining large text corpus with fMRI produce generative model neuro activation for arbitrary words the English language 
6259 en Feature Selection via Block Regularized Regression Identifying varying causal elements very high dimensional feature space with internal structures space with many millions linearly ordered features one typically encounters problems such whole genome association WGA mapping remains open problem statistical learning propose block regularized regression model for sparse variable selection high dimensional space where the covariates are linearly ordered and are possibly subject local statistical linkages block structures due spacial temporal proximity the features nnOur goal identify small subset relevant covariates that are not merely from random positions the ordering but grouped contiguous blocks from large number ordered covariates Following typical linear regression framework between the features and the response our proposed model employs sparsity enforcing Laplacian prior for the regression coefficients augmented 1st order Markovian process along the feature sequence that activates the regression coefficients coupled fashion describe sampling based learning algorithm and demonstrate the performance our method simulated and biological data for marker identification under WGA 
6260 en Exploiting document structure and feature hierarchy for semi supervised domain adaptation this work try bridge the gap often encountered researchers who find themselves with few labeled examples from their desired target domain yet still have access large amounts labeled data from other related but distinct source domains and seemingly way transfer knowledge from one the other nnExperimentally focus the problem extracting protein mentions from academic publications the field biology where the source domain data are abstracts labeled with protein mentions and the target domain data are wholly unlabeled captions mine the large number such full text articles freely available the Internet order supplement the limited amount annotated data available nnBy exploiting the explicit and implicit common structure the different subsections these documents including the unlabeled full text are able generate robust features that are insensitive changes marginal and conditional distributions classes and data across domains supplement these domain insensitive features with automatically obtained high confidence positive and negative predictions the target domain learn extractors that generalize well from one section document another Similarly develop novel hierarchical prior structure over the features motivated the common structure feature spaces for this task across natural language data sets Finally lacking labeled target testing data employ comparative user preference studies evaluate the relative performance the proposed methods with respect existing baselines 
6261 en  Agent based Model Employment Production and Consumption
6262 en Breakdown the mean field approximation wealth distribution model
6263 en Dissecting the Canon Visual Subject Popularity Networks Art Research
6264 en Triplet Extraction from Sentences this paper present machine learning approach tonextract subject predicate object triplets from Englishnsentences nnSVM used train model humannannotated triplets and the features are computed fromnthree parsers 
6265 en Semantic Graphs Derived from Triplets with Application Document Summarization Information nowadays has become more and morenaccessible much give birth informationnoverload issue Yet important decisions have benmade depending the available information nAs impossible read all the relevant content thatnhelps one stay informed possible solution would bencondensing data and obtaining the kernel text bynautomatically summarizing nnWe present approach analyzing text andnretrieving valuable information the form ansemantic graph based subject verb object tripletsnextracted from sentences Once triplets have beenngenerated apply several techniques order tonobtain the semantic graph the document coreferencenand anaphora resolution named entitiesnand semantic normalization triplets Finally wendescribe the automatic document summarizationnprocess starting from the semantic representation ofnthe text nnThe experimental evaluation carried out step stepnon several Reuters newswire articles shows ancomparable performance the proposed approachnwith other existing methodologies For the assessmentnof the document summaries utilize automaticnsummarization evaluation package show anranking various summarizers 
6266 en Stochastic Subgradient Approach for Solving Linear Support Vector Machines This paper overview recent approach fornsolving linear support vector machines SVMs thenPEGASOS algorithm The algorithm based antechnique called the stochastic subgradient descent andnemploys for solving the optimization problem posednby the soft margin SVM very popular classifier nnWe briefly introduce the SVM problem and one thenwidely used solvers SVM light then describe thenPEGASOS algorithm and present some experiments nnWe conclude that the algorithm efficiently discoversnsuboptimal solutions large scale problems within anmatter seconds 
6267 en Fuzzy Clustering Documents This paper presents short overview methods for fuzzy clustering and states desired properties for optimal fuzzy document clustering algorithm Based these criteria chose one the fuzzy clustering most prominent methods – the means more precisely probabilistic means nnThis algorithm presented more detail along with some empirical results the clustering dimensional points and documents For the needs documents clustering implemented fuzzy means the TextGarden environment show few difficulties with the implementation and their possible solutions nnAs conclusion also propose further work that would needed order fully exploit the power fuzzy document clustering TextGarden 
6268 en  Functional Programming Approach Distance based Machine Learning Distance based algorithms for both clustering andnprediction are popular within the machine learningncommunity These algorithms typically deal with attributevaluen single table data The distance functions used arentypically hard coded nnWe are concerned here with generic distance basednlearning algorithms that work arbitrary types ofnstructured data our approach distance functions are notnhard coded but are rather first class citizens that can benstored retrieved and manipulated particular cannassemble the fly distance functions for complexnstructured data types from pre existing components nnTo implement the proposed approach use thenstrongly typed functional language Haskell Haskell allowsnus explicitly manipulate distance functions havenproduced library application with structured data typesnand distance functions and used evaluate the potential ofnHaskell basis for future work the field distancebasednmachine learning 
6269 en Improving Morphosyntactic Tagging Slovene Tagger Combination Part speech PoS better morphosyntactic tagging the process assigning morphosyntacticncategories words text important pre processing step for most human language technologynapplications PoS tagging Slovene texts challenging task since the size the tagset over onenthousand tags opposed English where the size typically around sixty and the state the artntagging accuracy still below levels desired The paper describes experiment aimed improvingntagging accuracy for Slovene combining the outputs two taggers – proprietary rule basedntagger developed the Amebis HLT company and TnT tri gram HMM tagger trained handannotatedncorpus Slovene The two taggers have comparable accuracy but there are many casesnwhere the predictions the two taggers differ one the two does assign the correct tag Weninvestigate training classifier top the outputs both taggers that predicts which the twontaggers correct experiment with selecting different classification algorithms and constructingndifferent feature sets for training and show that some cases yield meta tagger with significantnincrease accuracy compared that either tagger isolation 
6270 en Extending Ontologies for Annotating Business News Ontologies are commonly used for annotating textual datanmainly based human language technologies Thisnresearch focuses manual extensions ontologies tonsupport the annotation business news Experiments werenconducted well known Cyc ontology and using Cycnannotator two business news datasets show that thenproposed extensions ontology results annotation withnbetter coverage terms that are relevant for the businessndomain nnThe results identifying financial terms innbusiness news using the original Cyc ontology show thenaverage precision and recall case ofnReuters news and the average precision and thenrecall case Yahoo financial news Using thenproposed extension results with increased performance thenaverage precision and average recall fornYahoo financial news and average precision andnaverage recall for Reuters news 
6271 en Semantic Modeling Translation and Matching QoS The variety access and transport technologiesnavailable modern computer networks pose significantnchallenges related compatibility and quality servicen QoS related issues Applications and services can havenmany different and unique requirements towards thentransportation services TSs they use interconnect nnTraditionally applications are required specify theirnQoS requirements the language which the TSsnunderstand This results reformulation intuitivenparameters desired video resolution parametersnunderstood the TSs required bandwidth nnpaper presents techniques for automaticnmatchmaking application requirements the offersnby TSs providers and automatic translation ofnapplication requirements into the TSs QoSnrequirements this end semantic technologies nnamely OpenCyc are used for ontological modeling ntranslation and matchmaking present relevantnexamples how semantic technologies can used innthe context communication networks 
6272 en Hierarchical Annotation Medical Images this paper describe approach for the automatic medical annotation task the 2008 CLEF cross language image retrieval campaign ImageCLEF The data comprise 12076 fully annotated images according the IRMA code This work focused the process feature extraction from images and hierarchical multi label classification extract features from the images used technique called local distribution edges nnWith this techniques each image was described with variables The goal the classification task was classify image according the IRMA code The IRMA code organized hierarchically Hence classifer selected extension the predictive clustering trees PCTs that able handle this type data nnFurther more constructed ensembles Bagging and Random Forests that use PCTs base classifiers 
6273 en The Statistical Interpretation Simulated Emergency Breaking Event Time Series Data Over three hundred four second 40hz time series datasetsn from simulated emergency braking manoeuvres Englishnfatal accident sites and field trials werenclassified using key characteristics the braking sequencesnextracted for each event nnThese characteristics were thenntested for significant difference between road surface typesnand braking system types One key marker averagendeceleration was also compared against existingnbenchmark ‘typical’ values for acceptable performance asnfound the literature 
6274 en Churn Prediction Model Retail Banking Using Fuzzy Means Clustering The paper presents model based fuzzy methods for churn prediction retail banking The study was done the real anonymised data 5000 clients retail bank Real data are great strength the study lot studies often use old irrelevant artificial data Canonical discriminant analysis was applied reveal variables that provide maximal separation between clusters churners and non churners Combination standard deviation canonical discriminant analysis and means clustering results were used for outliers detection nnDue the fuzzy nature practical customer relationship management problems was expected and shown that fuzzy methods performed better than the classical ones According the results the preliminary data exploration and fuzzy clustering with different values the input parameters for fuzzy means algorithm the best parameter combination was chosen and applied training data set Four different prediction models called prediction engines have been developed The definitions clients the fuzzy transitional conditions and the distance instances fuzzy sums were introduced nnThe prediction engine using these sums performed best churn prediction applied both balanced and non balanced test sets 
6275 en Text Mining Information and Fact Extraction TMIFE communities medical informatics security blog and news analysis business information analysis legal informatics etc Still today somewhat fragmented subfield human language technologies and information retrieval where the themes often forgotten old style pattern based and more recent machine learning techniques applied medical informatics opinion mining and blog extraction are scattered various conferences and sessions computational linguistics artificial intelligence machine learning Web technologies semantic computing nThe aim this tutorial explain important technologies from handcrafted patterns learning and especially focus how they blend together order suit the needs current information systems that retrieve mine information that make decisions and solve problems based the extracted information This unified perspective also entails valuable insights into the role traditional pipelined system architectures and more recent probabilistic inference techniques nProbabilistic extraction which text translated into variety semantic labels slides rfectly integrates with probabilistic retrieval models that naturally combine surface text features and semantic labels ranking computations among which are the popular language retrieval models Finally information extraction alleviates the knowledge acquisition bottleneck expert and question answering systems technology that operate more restricted subject domains nWe conclude with some pointers new challenges among which are the recognition complex semantic concepts narrative scripts issues such medical malpractice competitiveness texts nBecause the reconciling aspects the many techniques and application domains the tutorial will attract students and researchers with different backgrounds 
6276 en Content Based Image Retrieval CBIR This course will give overview the main tasks and methods the content based image retrieval CBIR field nFirstly will address question image retrieval methods application real life what are the real world problems that can solved using these methods where can used human nThen will consider the traditional architecture CBIR systems and the main problems which should solved the developers such system This includes the discussion image preprocessing and feature extraction multidimensional indexing design user interface and data visualization Special attention will given low level feature processing color texture and shape and construction feature vectors The classification known feature vectors will presented and results experimental comparison will discussed for some them nIn the final part the course will briefly review some the existing CBIR systems both commercial and research ones and will analyze and discuss their advantages and disadvantages 
6277 en  Social Media IRSM define Social Media user generated content Web Social Media includes but not limited blogs usenet forums The first part tutorial pretty technical and hands will show specifics data acquisition from blogs microblogs usenet will present our existing data sets and show how use them the second part will talk about specifics using obtained data will cover keyword extraction and other data mining techniques nSpam has become major problem for Internet users and covers web search well most aspects communication including email discussion forums The recent popularity blogging has spurned surge blog spam with many flavors including splogs comment spam trackback spam and ping spam this talk will discuss the differences and commonalities combating spam the blog medium other types spam The exposition will supported results and examples based real data 
6278 en Data Structures DSIR The course presents overview theoretical and practical approaches implementation information retrieval systems mainly focused classic big and large scale search problems but also includes brief description structures applicable for other tasks The course covers wide range questions from high level theoretical view data structures design particular questions implementation includes such important practical problems which are poorly presented available educational literature parallelization lossy compressions techniques and relevant modern hardware features nThe course contains discussion known open source and commercial systems implementations Some considered examples are based lecturer’ practical experience from his participation systems development projects nThe course can interesting for students who want know details system implementation tailoring existing systems for specific data scale task was presented internal seminars for employees Ask com 2007 and 2008 
6279 en Hands Natural Language Processing for Information Access Applications NLPIAA This course focus the development practical applications which involve the use natural language technology The course will introduce NLP concepts which will reinforced the development testing and evaluation technology demonstration sessions Applications studied the course include Information Extraction Question Answering and Text Summarization None the applications will studied detail the main objective the course promote the use NLP and facilitate access available technology which can adapted specific application domains that students can home motivated develop their own tools systems nDetailed content – Overview Natural Language Processing technologies including parts speech tagging named entity recognition parsing semantic interpretation and coreference resolution – Natural Language Technology for Information access existent systems and projects combining advanced NLP will presented Cubreporter project – Information Extraction named entity recognition relation extraction event extraction rule based and machine learning approaches evaluation MUC – Question Answering architecture questions and answers passage selection answer identification evaluation TREC – Text Summarization sentence extraction superficial features for sentence extraction feature combination multi document summarization evaluation Document Understanding Conference 
6284 en PhD Thesis Defense Dynamics large networks basic premise behind the study large networks that interaction leads complexncollective behavior our work found very interesting and counterintuitive patterns forntime evolving networks which change some the basic assumptions that were made thenpast then develop models that explain processes which govern the network evolution nfit such models real networks and use them generate realistic graphs give formalnexplanations about their properties addition our work has wide range applications nit can help spot anomalous graphs and outliers forecast future graph structure and runnsimulations network evolution nnAnother important aspect our research the study “local” patterns and structuresnof propagation networks aim identify building blocks the networks and findnthe patterns influence that these blocks have information virus propagation over thennetwork Our recent work included the study the spread influence large personto nperson product recommendation network and its effect purchases also model thenpropagation information the blogosphere and propose algorithms efficiently findninfluential nodes the network nnA central topic our thesis also the analysis large datasets certain network propertiesnonly emerge and thus become visible when dealing with lots data analyze thenworld’ social and communication network Microsoft Instant Messenger with 240 millionnpeople and 255 billion conversations also made interesting and counterintuitive observationsnabout network community structure that suggest that only small network clusters exist nand that they merge and vanish they grow 
6291 en Polarity with Respect Circle Configurations Euclidean Plane Affine Plane Projective Plane
6462 en Atmospheric Science the human dominated era the Anthropocene Profesor Paul Crutzen tituta Max Planck Nem iji ukvarja raziskavami vpliva stratosferske troposferske kemije biogeokemijsko kro enje elementov spojin ter njene vloge pri klimatskih spremembah Razlo katalitsko vlogo ikovih oksidov pri reakciji ozonom tako pojasnil prvo nizu stratosferskih fotokemijskih reakcij povzro ajo tanj anje ozonskega pla odkritju pomena klorofluoroogljikovih spojin CFC pri pojavu ozonske luknje prof Crutzen teorijo heterogenih reakcij povr ini trdnih delcev polarnih stratosferskih oblakih razlo zakaj tanj anje ozonskega pla najbolj izrazito etku polarnega poletja nad Antarktiko nnPoleg tega ukvarjal tudi problematiko ozona troposferi kjer prihaja zaradi onesna evanja ozra povi anih koncentracij Tudi tem podro bil prof Crutzen razlagami reakcijskih mehanizmov meritvami koncentracij ozona vodilni znanstvenik svetovnem merilu Njegovo delo nagrajeno tevilnimi uglednimi mednarodnimi priznanji nnZa pionirske dose podro nastanka razgradnje ozona atmosferi leta 1995 skupaj Mariom Molino Sherwoodom Rowlandom prejel Nobelovo nagrado kemijo Professor Crutzen starts his talk the time the video 
6467 en Reflections looking back years airplane designer
6468 en  remember you but not your name The brain and proper name retreival Spomnim vem kako kli gani priklic lastnih imen Proper names are important every day life Forgetting them very common source embarrassment increasingly more frequent with aging Their difference with common names has been matter philosophical speculations and linguistic theories Until two decades ago the mechanisms underlying their production were largely unknown and undistinguished from those underlying the production common names nnIn this talk proper name retrieval compared common name retrieval The following questions are addressed Are proper names and common names processed separately Can processing located the brain processing more difficult than processing Does processing change with age differently with respect common names Can neuropsychology used for clinical purposes nnThe answer these questions sought via the methods cognitive neuropsychology Findings selected clinical cases are shown consistent with both philosophical and linguistic theories the difference between and theoretical information processing model proper name retrieval derived from neuropsychological findings proposed The psychological reality some linguistic theories demonstrated nLastna imena pomembna vsakdanjem ivljenju Pozabljenje lastnih imen zelo pogost vir zadrege starostjo postaja vse pogostej Razlike med lastnimi imi imeni predmet tevilnih filozofskih pekulacij jezikoslovnih teorij vse pred dobrima dvema desetletjema bili mehanizmi njihove produkcije prete nepoznani ena eni tistimi uravnavajo produkcijo imen nnV tem predavanju primerja priklic lastnih imen priklicem imen sku alo odgovoriti naslednja vpra anja Ali lastna imena ganih procesirana eno imen Ali lahko znotraj gan lociramo predel ukvarja procesiranjem lastnih imen Ali procesiranje lastnih imen zahtevnej procesiranja imen Ali procesiranje lastnih imen starostjo spreminja druga kot procesiranje imen Ali nevropsihologija lastnih imen uporabna tudi klini namene nnNa vpra anja bomo odgovorili metodami kognitivne nevropsihologije Ugotovitve nekaj klini nih tudij konsistentne tako filozofskimi kot jezikoslovnimi teorijami razliki med lastnimi imi imeni Predstavljen informacijsko procesni model priklica lastnih imen izpeljan nevropsiholo kih ugotovitev tem dokazana psiholo realnost nekaterih jezikoslovnih teorij Professor Semenza starts his talk English the time within video 
6471 en  journey the International Space Station space radiation and light flashes Pot Mednarodno vesoljsko postajo kozmi sevanje svetlobni bliski Christer Fuglesang was born March 1957 Stockholm Sweden studied the University Stockholm where obtained his doctorate Experimental Particle Physics 1987 continued his career experimental high energy physicist and chiefly worked CERN European Organization for Nuclear Research Geneva CERN worked the UA5 experiment which studied proton antiproton collisions the energy 540 GeV nnIn 1980s became Fellow the CPLEAR through which also collaborated with Slovene scientists presently working University Nova Gorica The aforementioned international group scientists studied the violation most basic symmetries nature The group’ most remarkable achievement was the discovery the arrow time the microcosm continued his career working the project regarding the construction the world largest hadron collider LHC nnIn 1990 Fuglesang returned Sweden and obtained position the Manne Siegbahn Institute Physics Stockholm Two years later however decided continue his career astronaut and joined the Astronaut Corps the European Space Agency ESA May 1992 1995 was selected member the backup crew for the Euromir mission Besides obtaining licence for qualified astronaut the American agency NASA 1998 was also awarded the Russian Soyuz Return Commander certificate the meantime Fuglesang continued with his research and was involved the SilEye experiment which investigated light flashes astronauts’ eyes the international space station MIR The same type research being continued the International Space Station ISS nnDr Fuglesang has also initiated the DESIRE project simulate and estimate the radiation environment inside the ISS nnEven prior the accident the space shuttle Columbia was selected crew member the STS 116 which was with the expected delay launched toward the ISS December 2006 Fuglesang’ assigned duties within the STS 116 mission are mainly scientific and technical nature nnDuring his successful career Christer Fuglesang has been presented numerous international awards Moreover Honorary Doctorate from Umeå University Sweden was conferred upon him 1999 nDr Christer Fuglesang tudiral Univerzi Stockholmu kjer leta 1987 doktoriral fizike Svojo kariero nadaljeval kot eksperimentalni fizik visokih energij ino asa delal Evropskem laboratoriju fiziko delcev CERN enevi vrnitvi vedsko kmalu odlo svojo strokovno pot nadaljuje kot astronavt Maja 1992 pridru astronavtom Evropske vesoljske agencije ESA Leta 1995 postal lan rezervne posadke misijo Euromir Leta 1998 dobil licenco astronavta ameri agencije NASA licenco poveljnika ruskega programa Soyuz tem asu nadaljeval raziskovalnim delom nnDelal eksperimentu Sil Eye kjer preu eval svetlobne bliske astronavtovih mednarodni postaji MIR tem delom nadaljuje tudi mednarodni vesoljski postaji ISS pred nesre raketoplana Columbia postal lan posadke STS 116 pri akovanih zamudah poletela proti ISS decembra 2006 Njegove naloge misiji STS 116 bile predvsem znanstvene tehni narave Fuglesang starts his talk English the time 
6474 en What emerging language can tell about language evolution Kaj nam nastajajo jezik lahko pove razvoju jezika Sayyid Bedouin Sign Language ABSL the sign language small insular endogamous community the Negev desert with high incidence genetically recessive profound neurosensory deafness The first deaf individuals were born about years ago and the number deaf members the community now numbers over 100 population about 3500 ABSL appears have developed with little influence from either neighboring sign languages the surrounding spoken languages widely used the community with least many hearing deaf users and neither the language nor the deaf signers are stigmatized the community For several years team linguists from Israel and the United States has been analyzing the structure ABSL Prof Aronoff will review their work date discuss the linguistic structure ABSL and the implications their findings for current theories the nature and evolution human language nZnakovni jezik Sayyid beduinov nastal okviru majhne zaprte skupnosti avi Negev velikim odstotkom genetsko pogojene gluhosti Tekom zadnjih let skupnost razvila samosvoj znakovni jezik skoraj brez vpliva drugih znakovnih jezikov ali sosednjih govorjenih jezikov zaradi esar jezik pomemben razumevanje nastanka razvoja love kega jezika ter narave lovek ega uma 
6477 en Cloning and embryonic stem cells for regenerative medicine Kloniranje embrionalne mati celice regenerativno medicino Parkinsons Alzheimers diabetes and other degenerative diseases could treated with cell transplantation new and healthy cells During the past years the field regenerative medicine has been focusing development therapeutically useful cells from embryonic stem cells While these cells hold great potential their ethicaly controversial derivation has revived research using adult stem cells Recently novel technologies have been developed that allow derivation pluripotent cells from adult somatic tissues This would allow for derivation patient specific autologous cells for cell therapy This presentation will discuss the possibilities for the future development strategies for regenerative medicine nPodro regenerativne medicine prou uje nost zdravljenja Parkinsonove Alzheimerjeve sladkorne ter drugih degenerativnih bolezni presaditvijo novih zdravih celic zadnjih letih osredoto ilo razvoj celi nih terapij embrionalnih mati nih celic Kljub potencialu jih zaradi eti spornega izvora nadome amo mati nimi celicami odraslih tkiv zadnjem asu smo razvili nove tehnologije omogo ajo pridobivanje terapevtskih celic odraslih somatskih virov nam omogo ilo razvoj celi nih terapij bodo razvite presajene istega pacienta Predavanje predstavilo nosti prihodnost celi terapije 
6488 en General introduction the Tyrosafe project
6489 en Warm presentation policies skid resistance
6490 en Question starting presentation policies skid resistance
6491 en Policies noise emissions and rolling resistance presentation
6492 en Debate about policies noise emissions and rolling resistance
6493 en Presentation policy aspects measurement harmonisation
6494 en Debate about presentation policy aspects measurement harmonisation
6495 en Concluding remarks 1st TYROSAFE Workshop
6496 en The handling dangerous goods Switzerland
6497 en GOOD ROUTE The aim the approach and the outcomes
6500 en TraSer Open Source solution for Tracking and Tracing
6502 en Panel discussion Towards intelligent cargo Panelists Evangelos Bekiaris CERTH HIT GOOD ROUTEn Paolo Paganelli Insiel EURIDICEn Jan Tore Pedersen BMT Ltd FREIGHTWISEn Hans Westerheim SINTEF SMARTFREIGHTn Hans Wortmann University Groningen TRASER
6503 en Tracking Tracing the Basis for new Logistic Services
6504 en Current European research ICT Freight and Logistics and prospects for the rest the 7th 
6505 en  service based approach ICT for logistics
6506 en Outlook the usage Active and passive RFID Logistics
6507 en M2M connectivity applications for the Logistics sector
6508 en The integration freight transport ICT
6509 en Smart Freight – past and current research
6510 en INTERSYS – Using RFID for identification and control shipments load units wagons intermodal transport system
6511 en Using Multi Agent Systems for Sustainable Logistics Results from the Dutch Transumo Research Project
6512 en ICT Support for Regional logistics platforms
6517 en  thinking scientific teams competition conflict and collaboration this talk Gadlin will discuss the organizational barriers and breakdown collaboration the scientific community while focusing recurring themes collaborative disputes then presents means for resolving and responding conflict confidentially through dispute resolution programs and pre nuptial agreements between collaborators 
6518 en Nanotechnology Innovation Two Aspects this talk Kesan will discuss the challenges and issues posed nanotechnology innovation for patent policy and for granting patent rights commensurate with innovation Second will discuss how the insights from value sensitive design can applied vindicate societal choices and preferences emerging nanotechnologies 
6519 en Question and Answers for session 
6520 en Investment and interpretation nanotechnology financial journalism and practical epistemology Studies the ways which the media report nanotechnologies and particularly the ways which they frame their interpretation are crucial understanding the formation public perceptions what are highly technical areas scientific endeavour This talk reports research project which whilst broadly located within this area concern looked the related question the financial understanding science how field characterised high levels commercialisation potential investors get information and make judgments about particular applications and the significance the roles played journalists and other mediators this process nnThe focus here the practical epistemological strategies that scientific and financial journalists employ make sense nanotechnologies Drawing interview data the paper considers the way that these journalists assess claims made about scientific validity and investment potential and how they negotiate such narrative dilemmas balancing the need for scepticism rhetorically inflated context with the professional requirement produce interesting story argued that this analytic focus – journalists active interpreters and actors for whom the understanding nanotechnologies pressing practical problem – provides important complement both studies the framing effects journalistic copy and studies public understandings what remains for most the public relatively arcane field Moreover focusing where the action currently may inform our knowledge not just the commercial development nanotechnologies but also the formation and development public opinion 
6521 en Predicting the Future How Ordinary People Make Sense Emerging Nanotechnologies This presentation will briefly review quantitative and qualitative data that suggest the general tenor the current public opinion climate for nanotechnologies and then identify the key factors that can expected affect how people cope with information about any new technology These include their own underlying values their levels trust key social actors and the connections they identify with technologies previously encountered well information from media accounts Public conceptions potential risks are often broader than those commonly identified formal risk assessments encompassing social risks such disruption displacement privacy distribution regulation and well risks human health and environmental integrity While media are only one influence among many they are regularly accused exaggerating some risks while ignoring others Progress toward developing theory that might predict when and explain why this occurs will reviewed 
6522 en Question and Answers for session 
6523 en Perceiving Nanoscale Phenomena Interpreting and Disseminating Nanoscale Images Scientific imaging techniques have played increasingly significant role nanoscale research But how should the resulting images interpreted What kind information they offer about their targets the objects and relations they are about And how should that information understood and disseminated particular how reliable should the information Given the plurality images found nanoscale research unlikely that single unified account can articulated that accommodates all the images question However this doesn’ mean that general framework that helps address central issues the interpretation nanoscale imaging cannot provided nnIn this paper offer such framework provides new conceptualization nanoscale images and their content highlighting the following aspects order understand nanoscale image ’ crucial determine which kind image are dealing with How was the image obtained And which sort information intended convey should then examine the sources bias that the images may contain What kind artifacts may included the image Finally nanoscale images are often used exemplars the domain from which they emerged How can such images used inferential devices that allow researchers generalize the information provided particular image other samples whether the same domain related ones nnAfter motivating and articulating such framework provide some case studies illustrating how the proposal works considering variety nanoscale images from microscopy including probe and electron microscopy 
6524 en Nanotechnology development and public policy this talk Armstrong will discuss five points think about regards Nanotechnology when dealing with development and public policy issues Armstrong focuses the vagueness the term nanotechnology the abstract nature which conceptualized and what level abstraction would appropriate when conceptualizing 
6525 en The Culture the American University the Age Neoliberalism Universities the United States and across the globe are changing What the nature this change For nearly twenty years much the scholarship and work journalists the United States has highlighted increases conflict interest secrecy proprietary research loss unbiased public interest analysts and distortion research agendas associated with university industry research relationships While these concerns are not entirely misplaced argue that the focus what are egregious violations academic norms— dramatic cases—fails capture deeper and more difficult police transformation the university Instead believe fundamental transformation the culture university life and academic science especially underway this paper explore the claims some the most high profile recent work the commercialization the American university and point set examples and indicators that suggest are seeing deep transformation academic culture the United States 
6526 en Why Managing Research Not Managing Science this talk Rjeski will discuss the increase and penetration new nano products into the market and how this measure its success will then address the need for responsibility and education address the public’ desire for full disclosure pre market testing and third party testing and research Finally will discuss the nanotechnology concerns for the future 
6527 en Question and Answers for session 
6528 en Welcome from PIARC Slovenia first delegate
6531 en Introduction the symposium from the technical committee
6532 en Slovenia roads and its expertise
6533 en Research sustainable paving surfacing for low volume rural roads Vietnam
6534 en Macrotexture and drainability friction courses modeling and experiments
6535 en Feasibility using Deflectograph data review drainage network the 
6536 en Surface characteristics asphalt pavements with synthetic lightweight aggregate
6537 en Low dry friction Measurement and imaging
6538 en Samples singular detailed texture and skid resisance analysis
6539 en Evaluation the effect grooving the coeficient friction wet runways
6541 en Tire Road noise relationshipwith viscoelastic properties paving materials
6542 en Thin asphalts surface layers for highways optimised for low tyre road noise
6543 en Statistical properties road traffic noise emission measurements
6544 en The new Austrian skid resistance evaluation background based the correlation skid resistance values roadstar and braking deceleration passenger cars
6545 en Model for assessing risks road infrastructure
6549 en Pavement surface defects Classification and quantification over road network
6550 en Modeling the ups and downs the grip resistance road surface
6551 en The weighted longitudinal profile WLP technical specification and experiences Austria and Germany
6552 en Development Half Car based rutting index
6553 en Developing the automatic measurement surface condition local roads
6554 en Development new transverse laser profiling system for the automatic measurement road cracks
6555 en Routine measurements pavement surface cracks
6556 en Debate about assement the pavement cracking measurement 
6557 en Protocol Applications the Automated Distress Analyzer ADA 
6558 en From theoretical acoustics studies implementation worksite major step towards rolling noise reduction
6559 en Evaluation expérimentale des regles conception des virages par analyse des interactions véhicule chaussée
6561 en Prediction Deterioration Asphalt Pavements Empirical Mechanistic Model
6562 en Relationship between surface skid resistance and rate accidents major intersections Dar Salaam
6563 en The possibilities utilising data gathered from laser measurements pavement surface texture
6564 en Advanced analysis for singular longitudinal profiles
6566 en Quantifying the Impact Jointed Concrete Pavement Curling and Warping Pavement Unevenness
6568 en Application the Cross Correlation Technique Evaluate Profile Data
6569 en Implementation Grinding Simulation Tool the Profile Viewing and Analysis ProVAL Software Tool
6570 en Debate about data analysis tools 
6572 en The long term skid resistance performance three artificial aggregates used chipseal surfaces New Zealand
6573 en Roadex III Health issues related poorly maintained road networks
6574 en May new road less safe for while Initial skid resistance wet and dry asphalt pavements the Netherlands
6577 en Characteristics today concrete surfaces
6578 en Maintenance practices and standards pavements Mexican airports
6580 en Measuring Pavement Condition Developing Countries The World Bank Experience
6581 en Debate about assessment the pavements
6582 en Debate about assessment the pavements friction 
6589 en NSPARQL Navigational Language for RDF Navigational features have been largely recognized fundamental for graph database query languages This fact has motivated several authors propose RDF query languages with navigational capabilities particular have argued previous paper that nested regular expressions are appropriate navigate RDF data and have proposed the nSPARQL query language for RDF that uses nested regular expressions building blocks this paper study some the fundamental properties nSPARQL concerning expressiveness and complexity evaluation Regarding expressiveness show that nSPARQL expressive enough answer queries considering the semantics the RDFS vocabulary directly traversing the input graph also show thatnnesting necessary obtain this last result and study the expressiveness the combination nested regular expressions and SPARQL operators Regarding complexity evaluation prove that the evaluation nested regular expression over RDF graph can computed time · 
6590 en  Experimental Comparison RDF Data Management Approaches SPARQL Benchmark Scenario Efficient RDF data management one the cornerstones realizing the Semantic Web vision the past different RDF storage strategies have been proposed ranging from simple triple stores morenadvanced techniques like clustering vertical partitioning the predicates present experimental comparison existing storage strategies top the SP2Bench SPARQL performance benchmark suite and put the results into context comparing them purely relational model the benchmark scenario observe that terms performance and scalability simple triple store built top column store DBMS competitive the vertically partitioned approach when choosing physical predicate subject object sort order our scenario with real world queries none the approaches scales documents containing tens millions RDF triples and none the approaches can compete with purely relational model conclude that future research necessary further bring forward RDF data management 
6591 en Anytime Query Answering RDF through Evolutionary Algorithms present technique for answering queries over RDF data through evolutionary search algorithm using fingerprinting and Bloom filters for rapid approximate evaluation generated solutions Our evolutionary approach has several advantages compared traditional database nstyle query answering First the result quality increases monotonically and converges with each evolution offering “anytime” behaviour with arbitrary trade off between computation time and query results addition the level approximation can tuned varying the size the Bloom filters Secondly through Bloom filter compression can fit large graphs main memory reducing the need for disk during query evaluation Finally since the individuals evolve independently parallel execution straightforward present our prototype that evaluates basic SPARQL queries over arbitrary RDF graphs and show initial results over large datasets 
6592 en The Expressive Power SPARQL This paper studies the expressive power SPARQL The main result that SPARQL and non recursive safe Datalog with negation have equivalent expressive power and hence classical results SPARQL equivalent from expressive point view Relational Algebra present explicit generic rules the transformations both directions Among other findings the paper are the proof that negationncan simulated SPARQL that non safe filters are superfluous and that current SPARQL W3C semantics can simplified standard compositional one 
6593 en  OWL Far The definition OWL the ontology language underlying the Semantic Web based formal representation methods This provides benefits that tools have firm definition what they are supposed but can have problems due difficulty expense building tools mismatch with needs The panel will discuss whether the general idea designing standard Semantic Web languages with steadily increasing power the progression from RDF RDFS OWL OWL … all based formal methods the right way support the Semantic Web What level expressive power does the Semantic Web need How should standard Semantic Web languages designed Does the Semantic Web even need formality 
6594 en Comparing ontology distances preliminary results There are many reasons for measuring distance between ontologies particular useful know quickly two ontologies are close remote before deciding match them that extent distance between ontologies must quickly computable present constraints applying such measuresnand several possible ontology distances Then evaluate experimentally some them order assess their accuracy and speed 
6595 en Folksonomy based collabulary learning The growing popularity social tagging systems promises alleviate the knowledge bottleneck that slows the full materialization the Semantic Web these systems are cheap extendable scalable and respond quickly user needs However for the sake knowledge workflow one needs find compromise between the ungoverned nature folksonomies and the controlled vocabulary domain experts this paper address this concern first devising method that automatically combines folksonomies with domain expert ontologies resulting enriched folksonomy then introduce new algorithm based frequent itemsets mining that efficiently learns ontology over the concepts present the enriched folksonomy Moreover propose new benchmark for ontology evaluation which used the context information finding since this one the leading motivations for using ontologies social tagging systems quantitatively assess our method conduct experiments real data and empirically show the effectiveness our approach 
6596 en Learning Concept Mappings from Instance Similarity Finding mappings between compatible ontologies important but difficult open problem Instance based methods for solving this problem have the advantage focusing the most active parts the ontologies and reflect concept semantics they are actually being used However such methods have not present been widely investigated ontology mapping compared linguistic and structural techniques Furthermore previous instance based mapping techniques were only applicable cases where substantial set instances was available that was doubly annotated with both vocabularies this paper approach the mapping problem classification problem based the similarity between instances concepts This has the advantage that doubly annotated instances are required that the method can applied any two corpora annotated with their own vocabularies evaluate the resulting classifiers two real world use cases one with homogeneous and one with heterogeneous instances The results illustrate the efficiency and generality this method 
6597 en Instanced based mapping between thesauri and folksonomies The emergence web based systems which users can annotate items raises the question the semantic interoperability between vocabularies originating from collaborative annotation processes often called folksonomies and keywords assigned more traditional way collections are annotated according two systems with tags and keywords the annotated data can used for instance based mapping between the vocabularies The basis for this kind matching appropriate similarity measure between concepts based their distribution annotations this paper propose new similarity measure that can take advantage some special properties user generated metadata have evaluated this measure with set articles from Wikipedia which are both classified according the topic structure Wikipedia and annotated users the bookmarking service del icio The results using the new measure are significantly better than those obtained using standard similarity measures proposed for this task the literature correlates better with human judgments argue that the measure also has benefits for instance based mapping more traditionally developed vocabularies 
6598 en Collecting Community Based Mappings Ontology Repository Several ontology repositories provide access the growing collection ontologies the Semantic Web Some repositories collect ontologies automatically crawling the Web other repositories users submit ontologies themselves addition providing search across multiple ontologies the added value ontology repositories lies the metadata that they may contain This metadata may include information provided ontology authors such ontologies’ scope and intended use feedback provided users such their experiences using the ontologies reviews the content and mapping metadata that relates concepts from different ontologies this paper focus the ontology mapping metadata and community based method collect ontology mappings More specifically develop model for representing mappings collected from the user community and the metadata associated with the mapping use the model bring together more than 000 mappings from sources also validate the model extending BioPortal– repository biomedical ontologies that have developed— enable users create single concept concept mappings its graphical user interface upload and download mappings created with other tools comment the mappings and discuss them and visualize the mappings and the corresponding metadata 
6599 en Algebras ontology alignment relations Correspondences ontology alignments relate two ontology entities with relation Typical relations are equivalence subsumption However different systems may need different kinds relations propose use the concepts algebra relations order express the relations between ontology entities general way show the benefits doing expressing disjunctive relations merging alignments different ways amalgamating alignments with relations different granularity and composing alignments 
6600 en RDF123 from Spreadsheets RDF describe RDF123 highly flexible open source tool for translating spreadsheet data RDF Existing spreadsheet rdf tools typically map only star shaped RDF graphs each spreadsheet row instance with each column representing property RDF123 the other hand allows users define mappings arbitrary graphs thus allowing much richer spreadsheet semantics expressed Further each row the spreadsheet can mapped with fairly different RDF scheme Two interfaces are available The first graphical application that allows users create their mapping intuitive manner The second Web service that takes input URL Google spreadsheet CSV file and RDF123 map and provides RDF output 
6601 en Evaluating long term use the Gnowsis Semantic Desktop for PIM The Semantic Desktop means support users Personal Information Management PIM Using the open source software prototype Gnowsis evaluated the approach two month case study 2006 with eight participants Two participants continued using the prototype and were interviewed after two years 2008 show their long term usage patterns This allows analyse how the system was used for PIM Contextual interviews gave insights behaviour while questionnaires and event logging did not discovered that the personal environment simple has Part and related relations are sufficient for users file and find information and that the personal semantic wiki was used creatively note information 
6602 en Bringing the IPTC News Architecture into the Semantic Web For easing the exchange news the International Press Telecommunication Council IPTC has developed the NewsML Architecture NAR XML based model that specialized into number languages such NewsML and EventsML part this architecture specific controlled vocabularies such the IPTC News Codes are used categorize news items together with other industry standard thesauri While news still mainly the form text based stories these are often illustrated with graphics images and videos Media specific metadata formats such EXIF DIG35 and XMP are used describe the media The use different metadata formats single production process leads interoperability problems within the news production chain itself also excludes linking existing web knowledge resources and impedes the construction uniform end user interfaces for searching and browsing news content nIn order allow these different metadata standards interoperate within single information environment design OWL ontology for the IPTC News Architecture linked with other multimedia metadata standards convert the IPTC NewsCodes into SKOS thesaurus and demonstrate how the news metadata can then enriched using natural language processing and multimedia analysis and integrated with existing knowledge already formalized the Semantic Web discuss the method used for developing the ontology and give rationale for our design decisions provide guidelines for engineering schemas into ontologies and formalize their implicit semantics order demonstrate the appropriateness our ontology infrastructure present exploratory environment for searching and browsing news items 
6603 en Semantic Web Service Choreography Contracting and Enactment The emerging paradigm service oriented computing requires novel techniques for various service related tasks Along with automated support for service discovery selection negotiation and composition support for automated service contracting and enactment crucial for any large scale service environment where large numbers clients and service providers interact Many problems this area involve reasoning and number logic based methods handle these problems have emerged the field Semantic Web Services this paper build upon our previous work where used Concurrent Transaction Logic CTR model and reason about service contracts significantly extend the modeling power the previous work allowing iterative processes the specification service contracts and extend the proof theory CTR enable reasoning about such contracts With this extension our logic based approach capable modeling general services represented using languages such BPEL 
6604 en Formal Model for Semantic Driven Service Execution Integration heterogeneous services often hard wired service workflow implementations this paper define execution model operating semantic descriptions services allowing flexible integration services with solving data and process conflicts where necessary implement the model using our WSMO technology and case scenario from the B2B domain the SWS Challenge 
6605 en Efficient Semantic Web Service Discovery Centralized and P2P Environments Efficient and scalable discovery mechanisms are critical for enabling service oriented architectures the Semantic Web The majority currently existing approaches focuses centralized architectures and deals with efficiency typically pre computing and storing the results the semantic matcher for all possible query concepts Such approaches however fail scale with respect the number service advertisements and the size the ontologies involved the other hand this paper presents efficient and scalable index based method for Semantic Web service discovery that allows for fast selection services query time and suitable for both centralized and P2P environments employ novel encoding the service descriptions allowing the match between request and advertisement evaluated constant time and index these representations prune the search space reducing the number comparisons required Given desired ranking function the search algorithm can retrieve the top matches progressively better matches are computed and returned first thereby further reducing the search engine’ response time also show how this search can performed efficiently suitable structured P2P overlay network The benefits the proposed method are demonstrated through experimental evaluation both real and synthetic data 
6606 en ELP Tractable Rules for OWL introduce ELP decidable fragment the SemanticnWeb Rule Language SWRL that admits reasoning polynomialntime ELP based the tractable description logicnEL and encompasses extended notion the recentlynproposed rules for that logic Thus ELP extends nwith number features introduced the forthcomingnOWL such disjoint roles local reflexivity certain rangenrestrictions and the universal role present reasoning algorithmnbased translation ELP Datalog and thisntranslation also enables the seamless integration safenrules into ELP While reasoning with safe rules such isnalready highly intractable show that safe rules basednon the Description Logic Programming DLP fragment ofnOWL can admitted ELP without losing tractability 
6607 en Term Dependence the Semantic Web large amount terms classes and properties have been published the Semantic Web various parties shared for describing resources Terms are defined based other terms and thus directed dependence relation formed The study term dependence foundation work and important for many other tasks such ontology maintenance integration and distributed reasoning the Web scale this paper analyze the complex network characteristics the term dependence graph and the induced vocabulary dependence graph The graphs analyzed the experiments are constructed from large data set that contains 278 233 terms 039 vocabularies The results characterize the current status schemas the Semantic Web many aspects including degree distributions reachability and connectivity 
6608 en Semantic Relatedness Measure Using Object Properties Ontology This paper presents new semantic relatedness measure ontologies which considers especially the object properties between the concepts Our approach relies two hypotheses Firstly using only concept hierarchy and object properties only few paths can considered “semantically corrects” and these paths obey given set rules Secondly following given edge path has cost represented weight which depends its type mbox part mbox etc its context the ontology and its position this path propose evaluation our measure the lexical base WordNet using part mbox relation with two different benchmarks show that this context our measure outperforms the classical semantic measures 
6609 en  Process Catalog for Workflow Generation developers increasingly look workﬂow technologies perform complex integrations individual software components there growing need for the workﬂow systems have expressive descriptions those components They must know more than just the types component’ inputs and outputs instead they need detailed characterizations that allow them makenﬁne grained distinctions between candidate components and between candidate workﬂows This paper describes PROCAT implemented ontology based cata log for components conceptualized processes that captures and communicates this detailed information PROCAT built layered representation that allows reasoning about processes varying levels abstraction from qualitative con straints reﬂecting preconditions and effects quantitative predictions about output data and performance PROCAT employs Semantic Web technologies RDF OWL and SPARQL and builds SemanticWeb services research describe PROCAT’ approach representing and answering queries about processes discuss some early experiments evaluating the quantitative predictions and report our experience using PROCAT system producing workﬂows for intelligencenanalysis 
6610 en Inference Web Action Lightweight Use the Proof Markup Language The Inference Web infrastructure for web explanations together with its underlying Proof Markup Language PML for encoding justification and provenance information has been used multiple projects varying from explaining the behavior cognitive agents explaining how knowledge extracted from multiple sources information natural language The PML specification has increased significantly since its inception 2002 order accommodate rich set requirements derived from multiple projects including the ones mentioned above this paper have very different goal than the other PML documents demonstrate that PML may effectively used simple systems well complex systems and describe lightweight use language and its associated Inference Web tools show how exemplar scientific application can use lightweight PML descriptions within the context NSF funded cyberinfrastructure project The scientific application used throughout the paper use case for the lightweight use PML and the Inference Web and meant operational prototype for class cyberinfrastructure applications 
6611 en Supporting Ontology based Dynamic Property and Classification WebSphere Metadata Server Metadata management important aspect today’ enterprise information systems Metadata management systems are growing from toolspecific repositories enterprise wide metadata repositories this context one challenge the management the evolving metadata whose schema meta model itself may evolve dynamically added properties which are often hard predict upfront the initial meta model design time another challenge organize the metadata semantically rich classification schemes this paper present practical system which provides support for users dynamically manage semantically rich properties and classifications the IBM WebSphere Metadata Server MDS integrating OWL ontology repository enable the smooth acceptance Semantic Web technologies for developers commercial software which must run hours day days week the system designed consist integrated modeling paradigms with integrated query language and runtime repository Specifically propose the modeling dynamic properties structured metadata OWL properties and the modeling classification schemes OWL ontologies for metadata classification present natural extension OQL Object Query Language like query language embrace dynamic properties and metadata classification also observe that hybrid storage horizontal tables for structured metadata and vertical triple tables for dynamic properties and classification suitable for the storage and query processing existing structured metadata and semantic metadata believe that our study and experience are not specific MDS but are valuable for the community trying apply Semantic Web technologies the structured data management area 
6612 en Towards Multimedia Content Marketplace Implementation Based Triplespaces Multimedia Content Marketplace can support innovative business models the telecommunication sector This marketplace has strong need for semantics ordination and service oriented architecture Triple Space Computing emerging semantic ordination paradigm for Web services for which the marketplace ideal implementation scenario This paper introduces the developed Triple Space platform and our planned evaluation its value our telecommunication scenario 
6613 en Requirements Analysis Tool Tool for Automatically Analyzing Software Requirements Documents present tool called the Requirements Analysis Tool that performs wide range best practice analyses software requirements documents The novelty our approach the use user defined glossaries extract structured content and thus support broad range syntactic and semantic analyses while allowing users write requirements the stylized natural language advocated expert requirements writers Semantic Web technologies are then leveraged for deeper semantic analysis the extracted structured content find various kinds problems requirements documents 
6614 en OntoNaviERP Ontology supported Navigation ERP Software Documentation The documentation Enterprise Research Planning ERP systems usually extremely large and combines various views from the business and the technical implementation perspective Also very specific vocabulary has evolved particular the SAP domain SAP Solution Maps SAP software module names This vocabulary not clearly mapped business management terminology and concepts well known problem practice that searching SAP ERP documentation difficult because requires depth knowledge large and proprietary terminology propose use ontologies and automatic annotation such large HTML software documentation order improve the usability and accessibility namely ERP help files order achieve that have developed ontology and prototype for SAP ERP Our approach integrates concepts and lexical resources from business management terminology SAP business terminology SAP system terminology and Wordnet synsets use standard GATE KIM technology annotate SAP help documentation with respective references our ontology Eventually our approach consolidates the knowledge contained the SAP help functionality conceptual level This allows users express their queries using terminology they are familiar with referring general management terms Despite widely automated ontology construction process and simplistic annotation strategy with minimal human intervention experienced convincing results For average query linked action and topic our technology returns more than relevant resources while naïve term based search returns average only about relevant resources 
6615 en Market Blended Insight modeling propensity buy with the Semantic Web Market Blended Insight MBI project with clear objective making significant performance improvement business business B2B marketing activities the year timeframe The web has created rapid expansion content that can harnessed recent advances Semantic Web technologies and applied both Media industry provision and company utilization exploitable business data and content The project plans aggregate broad range business information providing unparalleled insight into business activity and develop rich semantic search and navigation tools allow any business ’place their sales proposition front prospective buyer’ confident the fact that the recipient has propensity buy 
6616 en DogOnt – Ontology Modeling for Intelligent Domotic Environments Home automation has recently gained new momentum thanks the ever increasing commercial availability domotic components this context researchers are working provide interoperation mechanisms and add intelligence top them For supporting intelligent behaviors house modeling essential requirement understand current and future house states and possibly drive more complex actions this paper propose new house modeling ontology designed fit real world domotic system capabilities and support interoperation between currently available and future solutions Taking advantage technologies developed the context the Semantic Web the DogOnt ontology supports device network independent description houses including both “controllable” and architectural elements States and functionalities are automatically associated the modeled elements through proper inheritance mechanisms and means properly defined SWRL auto completion rules which ease the modeling process while automatic device recognition achieved through classification reasoning 
6618 en  Semantic Data Grid for Satellite Mission Quality Analysis The combination Semantic Web and Grid technologies and architectures eases the development applications that share heterogeneous resources data and computing elements that belong several organisations The Aerospace domain has extensive and heterogeneous network facilities and institutions with strong need share both data and computational resources for complex processing tasks One such task monitoring and data analysis for Satellite Missions This paper presents Semantic Data Grid for satellite missions where flexibility scalability interoperability extensibility and efficient development have been considered the key issues addressed 
6619 en Semantic Wikis Fusing the two strands the Semantic Web
6622 en Data Intelligence Fourth set industry talks ISWC “Data Intelligence” Today lots research inhibited because data that cannot made available the research community this has been one gripes for while great hearing from Big issue course data privacy Goldcorp challenge Goldmining company Provided all their survey data the public online let challenge participants register and seek gold offer prizes Very successful identifying good mining targets our field innovation inhibited inability diseminate info due privacy concerns Many newsworthy privacy violations cracking anonymized search logs anonymized health records anonymized video ratings discourage data release She proposes framework for specifying how data can used that scientists can sign licenses the data they are getting ’ still favor instead focusing ways let users release some subset information about themselves unconditionally— think that for most users deciding what subset unconditionally save much easier job than deciding the restricted conditions under arbitrary unimaginable circumstances under which all their data safe 
6623 en Semantic Web Asia Example Use Cases Tony Lee the President and CEO Saltlux Inc one the global leader semantic web technology headquartered Seoul Korea will deliver speech the ISWC 2008 being held Karlsruhe Germany under the title “Semantic Web Asia Example use cases”nTony will introduce about the current status and the developmental possibilities the Asian semantic web technology market reviewing the commercialization use example cases that Saltlux carried out recently including Artificial Intelligence Mobile Service for KTF City for Samsung SDS Semantic search system for Korea National Archives and other significant cases nSome the invited speakers are from Yahoo Microsoft and SAP nSaltlux participating the ISWC 2008 one the Silver Sponsors 
6626 en Thesaurus based search large heterogeneous collections cultural heritage large virtual collections are coming into existence Such collections contain heterogeneous sets metadata and vocabulary concepts originating from multiple sources the context the Culture demonstrator have shown earlier that such virtual collections can effectively explored with keyword search and semantic clustering this paper describe the design rationale ClioPatria open source system which provides APIs for scalable semantic graph search The use ClioPatria’ search strategies illustrated with realistic use case searching for ”Picasso” discuss details scalable graph search the required OWL reasoning functionalities and show why SPARQL queries are insufficient for solving the search problem 
6628 en Creating and Using Organisational Semantic Webs Large Networked Organisations Modern knowledge management based the orchestration dynamic communities that acquire and share knowledge according customized schemas However while independence ontological views favoured these communities must also able share their knowledge with the rest the organization this paper introduce Forms and Search suite Semantic Web tools for supporting distributed and networked knowledge acquisition capturing retrieval and sharing They enable communities users define their own domain views intuitive way automatically translated into formal ontologies and capture and share knowledge according them The tools favour reuse existing ontologies reuse creates side effect network partially interconnected ontologies that form the basis for knowledge exchange among communities The suite under release support knowledge capture retrieval and sharing large jet engine company 
6629 en  architecture for semantic navigation and reasoning with patient data experiences the Health Child project Medical ontologies have become the standard means recording and accessing conceptualized biological and medical knowledge The expressivity these ontologies goes from simple concept lists through taxonomies formal logical theories the context patient information their application primarily annotation medical instance data exploit higher expressivity propose architecture which allows for reasoning patient data using OWL ontologies The implementation carried out part the Health Child platform prototype discuss the use case where ontologies establish hierarchical classification patients which turn used aid the visualization patient data briefly discuss the treemap based patient viewer which has been evaluated the Health Child project 
6630 en Involving Domain Experts Authoring OWL Ontologies This demonstration presents ROO tool that facilitates domain experts definition ontologies OWL allowing them author the ontology controlled natural language called Rabbit ROO guides users through the ontology construction process following methodology geared towards domain experts’ involvement ontology authoring and exploiting intelligent user interfaces techniques experimental study with ROO was conducted examine the usability and usefulness the tool and the quality the resultant ontologies The findings the study will presented full paper the ISWC08 research track 
6631 en Supporting Collaborative Ontology Development Protege Ontologies are becoming large their coverage that single person small group people can develop them effectively and ontology development becomes community based enterprise present Collaborative Protégé— extension the Protégé ontology editor that have designed specifically support the collaboration process for community users During the ontology development process Collaborative Protégé allows users hold discussions about the ontology components and changes using typed annotations tracks the change history the ontology entities provides chat and search functionality Users edit simultaneously ontology stored common repository All changes made user are seen immediately other users Collaborative Protégé open source and distributed with the full installation Protégé 
6632 en Identfying Potentiallcy Important Conepts and Relations Ontology More and more ontologies have been published and used widely the web order make good use ontology especially new and complex ontology need methods help understand first Identifying potentially important concepts and relations ontology intuitive but challenging method this paper first define four features for potentially important concepts and relation from the ontological structural point view Then simple yet effective Concept And Relation Ranking CARRank algorithm proposed simultaneously rank the importance concepts and relations Different from the traditional ranking methods the importance concepts and the weights relations reinforce one another CARRank iterative manner Such iterative process proved convergent both principle and experiments Our experimental results show that CARRank has similar convergent speed the PageRank like algorithms but more reasonable ranking result 
6633 en RoundTrip Ontology Authoring Controlled Language for Ontology Editing tools offer attractive alternative for naive users wishing create ontologies but they are still required spend time learning the correct syntactic structures and vocabulary order use the Controlled Language properly This paper extends previous work CLOnE which uses standard NLP tools process the language and manipulate ontology Here also generate text the from existing ontology using template based shallow Natural Language Generation NLG The text generator and the CLOnE authoring process combine form RoundTrip Ontology Authoring environment one can start with existing imported ontology one originally produced using CLOnE produce the Controlled Language modify edit the text required and then turn the text back into the ontology the CLOnE environment Building previous methodology undertook evaluation comparing the RoundTrip Ontology Authoring process with well known ontology editor where previous work required reference manual with several examples order use the controlled language the use NLG reduces this learning curve for users and improves existing results for basic ontology editing tasks 
6634 en Integrating Object Oriented and Ontological Representations Case Study Java and OWL The Web Ontology Language OWL provides modelling paradigm that especially well suited for developing models large structurally complex domains such those found Health Care and the Life Sciences OWL’ declarative nature combined with powerful reasoning tools has effectively supported the development very large and complex anatomy disease and clinical ontologies OWL however not programming language using these models applications necessitates both technical means integrating OWL models with programs and considerable methodological sophistication knowing how integrate them this paper present analytical framework for evaluating various OWL Java combination approaches have developed software framework for what call hybrid modelling that building models which part the model exists and developed directly Java and part the model exists and developed directly OWL analyse the advantages and disadvantages hybrid modelling both comparison other approaches and means case study large medical records system 
6635 en Extracting Semantic Constraint from Description Text for Semantic Web Service Discovery Various semantic web service discovery techniques have been proposed many which perform the profile based service signature matching However the service concepts are not sufficient discover web services accurately This paper presents new method enhance the semantic description semantic web service using the semantic constraints service concepts specific context The semantic constraints described constraint graph are extracted automatically from the parsing results the service description text set heuristic rules The corresponding semantic web service matchmaker performs not only the profile’ semantic matching but also the matching their semantic constraints with the help constraint graph based matchmaking algorithm The experiment results are encouraging when applying the semantic constraint discover semantic web services the service retrieval test collection OWLS 
6636 en Enhancing Semantic Web Services with Inheritance Currently proposed Semantic Web Services technologies allow the creation ontology based semantic annotations Web services that software agents are able discover invoke compose and monitor these services with high degree automation The OWL Services OWL ontology upper ontology OWL language providing essential vocabularies semantically describe Web services Currently OWL services can only developed independently one service unavailable then finding suitable alternative would require expensive and difficult global search match desirable have new OWL construct that can systematically support substitution tracing well incremental development and reuse services Introducing inheritance relationship into OWL natural solution However OWL well most the other currently discussed formalisms for Semantic Web Services such WSMO SAWSDL has yet define concrete and self contained mechanism establishing inheritance relationships among services which believe very important for the automated annotation and discovery Web services well human organization services into taxonomy like structure this paper extend OWL with the ability define and maintain inheritance relationships between services Through the definition additional “inheritance profile” inheritance relationships can stated and reasoned about Two types IRs are allowed grant service developers the choice respect the “contract” between services not The proposed inheritance framework has also been implemented and the prototype will briefly evaluated well 
6637 en Using Semantic Distances for Reasoning with Inconsistent Ontologies using and combining multiple ontologies the Web bound lead inconsistencies between the combined vocabularies Even many the ontologies that are use today turn out inconsistent once some their implicit knowledge made explicit However robust and efficient methods deal with inconsistencies are lacking from current Semantic Web reasoning systems which are typically based classical logic earlier papers have proposed the use syntactic relevance functions method for reasoning with inconsistent ontologies this paper extend that work the use semantic distances show how Google distances can used develop semantic relevance functions reason with inconsistent ontologies essence are using the implicit knowledge hidden the Web for explicit reasoning purposes have implemented this approach part the PION reasoning system report experiments with several realistic ontologies The test results show that mixed syntactic semantic approach can significantly improve reasoning performance over the purely syntactic approach Furthermore our methods allow trade off computational cost for inferential completeness Our experiment shows that only have give little quality obtain high performance gain 
6638 en Statistical Learning for Inductive Query Answering OWL Ontologies novel family parametric language independent kernel functions defined for individuals within ontologies presented They are easily integrated with efficient statistical learning methods for inducing linear classifiers that offer alternative way perform classification deductive reasoning method for adapting the parameters the kernel the knowledge base through stochastic optimization also proposed This enables the exploitation statistical learning variety tasks where inductive approach may bridge the gaps the standard methods due the inherent incompleteness the knowledge bases this work system integrating the kernels has been tested experiments approximate query answering with real ontologies collected from standard repositories 
6639 en Optimization and Evaluation Reasoning Probabilistic Description Logic Towards Systematic Approach This paper describes the first steps towards developing methodology for testing and evaluating the performance reasoners for the probabilistic description logic ensuremath mathcal SHIQ Since new formalism for handling uncertainty ontologies such methodology has been proposed There are sufficiently large probabilistic ontologies used test suites addition since the reasoning services ensuremath mathcal SHIQ are mostly query oriented there single problem like classification realization classical that could obvious candidate for benchmarking All these issues make hard evaluate the performance reasoners reveal the complexity bottlenecks and assess the value optimization strategies This paper addresses these important problems making the following contributions First describes probabilistic ontology that has been developed for the real life domain breast cancer which poses significant challenges for the state art ensuremath mathcal SHIQ reasoners Second explains systematic approach generating series probabilistic reasoning problems that enable evaluation the reasoning performance and shed light what makes reasoning ensuremath mathcal SHIQ hard practice Finally the paper presents optimized algorithm for the non monotonic entailment Its positive impact performance demonstrated using our evaluation methodology 
6640 en Combining Reasoner and Rule Engine for Improving Entailment Based OWL Reasoning introduce the notion the mixed and entailment based DLE OWL reasoning defining framework inspired from the hybrid and homogeneous paradigms for integration rules and ontologies The idea combine the TBox inferencing capabilities the algorithms and the scalability the rule paradigm over large ABoxes Towards this end define framework that uses reasoner reason over the TBox the ontology hybrid like and rule engine apply domain specific version ABox related entailments homogeneous like that are generated TBox queries the reasoner The DLE framework enhances the entailment based OWL reasoning paradigm two directions Firstly disengages the manipulation the TBox semantics from any incomplete entailment based approach using the efficient algorithms Secondly achieves faster application the ABox related entailments and efficient memory usage comparing the conventional entailment based approaches due the low complexity and the domain specific nature the entailments 
6641 en Improving RCC Derived Geospatial Approximation OWL Axioms approach improve RCC derived geospatial approximation presented which makes use concept inclusion axioms OWL The algorithm used control the approximation combines hypothesis testing with consistency checking provided knowledge representation system based description logics Propositions about the consistency the refined ABox the associated TBox when compared baseline ABox and TBox are made Formal proves the divergent consistency results when checking either both are provided The application the approach geospatial setting results roughly tenfold improved approximation when using the refined ABox and TBox Ways further improve the approximation and automate the detection falsely calculated relations are discussed 
6642 en OWL Datatypes Design and Implementation analyze the datatype system OWL and OWL and discuss certain nontrivial consequences its definition such the extensibility the set supported datatypes and complexity reasoning also argue that certain datatypes from the list normative datatypes the current OWL Working Draft are inappropriate and should replaced with different ones Finally present algorithm for datatype reasoning Our algorithm modular the sense that can handle any datatype that supports certain basic operations show how implement these operations for number and string datatypes 
6643 en Laconic and Precise Justifications OWL justification for entailment OWL ontology minimal subset the ontology that sufficient for that entailment hold Since justifications respect the syntactic form axioms ontology they are usually neither syntactically nor semantically minimal This paper presents two new subclasses justifications—laconic justifications and precise justifications Laconic justifications only consist axioms that not contain any superfluous “parts” Precise justifications can derived from laconic justifications and are characterised the fact that they consist flat small axioms which facilitate the generation semantically minimal repairs Formal definitions for both types justification are presented contrast previous work this area these definitions make clear what exactly “parts axioms” are order demonstrate the practicability computing laconic and hence precise justifications algorithm provided and results from empirical evaluation carried out several published ontologies are presented The evaluation showed that laconic precise justifications can computed reasonable time for entailments range ontologies that vary size and complexity was found that half the ontologies sampled there were entailments that had more laconic precise justifications than regular justifications More surprisingly was observed that for some ontologies there were fewer laconic justifications than regular justifications 
6644 en Scalable Grounded Conjunctive Query Evaluation over Large and Expressive Knowledge Bases Grounded conjunctive query answering over OWL ontologies intractable the worst case but present novel techniques which allow for efficient querying large expressive knowledge bases secondary storage particular show that can effectively answer grounded conjunctive queries without building full completion forest for large Abox unlike state the art tableau reasoners Instead rely the completion forest dramatically reduced summary the Abox demonstrate the effectiveness this approach Aboxes with million assertions 
6645 en  Kernel Revision Operator for Terminologies Algorithms and Evaluation Revision description logic based ontology deals with the problem incorporating newly received information consistently this paper propose general operator for revising terminologies description logic based ontologies Our revision operator relies reformulation the kernel contraction operator belief revision first define our revision operator for terminologies and show that satisfies some desirable logical properties Second two algorithms are developed instantiate the revision operator Since general these two algorithms are computationally too hard propose third algorithm more efficient alternative implemented the algorithms and provide evaluation results their efficiency effectiveness and meaningfulness the context two application scenarios Incremental ontology learning and mapping revision 
6646 en Description Logic Reasoning with Decision Diagrams Compiling SHIQ Disjunctive Datalog propose novel method for reasoning the description logic mathcal SHIQ After satisfiability preserving transformation from mathcal SHIQ the description logic mathcal ALCI the obtained mathcal ALCI Tbox mathcal converted into ordered binary decision diagram OBDD which represents canonical model for mathcal This OBDD turned into disjunctive datalog program that can used for Abox reasoning The algorithm worst case optimal data complexity and admits easy extensions with safe rules and ground conjunctive queries nSupported the European Commission under contracts 027595 NeOn and 215040 ACTIVE and the Deutsche Forschungsgemeinschaft DFG under the ReaSem project 
6648 en  Interface Based Ontology Modularization Framework for Knowledge Encapsulation this paper present framework for developing ontologies modular manner which based the notions interfaces and knowledge encapsulation Within the context this framework ontology can defined and developed set ontology modules that can access the knowledge bases the others through their well defined interfaces important implication the proposed framework that ontology modules can developed completely independent each others’ signature and language Such modules are free only utilize the required knowledge segments the others describe the interface based modular ontology formalism which theoretically supports this framework and present its distinctive features compared the exiting modular ontology formalisms also describe the real world design and implementation the framework for creating modular ontologies extending OWL and modifying the Swoop interfaces and reasoners 
6649 en  the Semantics Trust and Caching the Semantic Web The Semantic Web distributed environment for knowledge representation and reasoning The distributed nature brings with failing data sources and inconsistencies between autonomous knowledge bases reduce problems resulting from unavailable sources and improve performance caching can used Caches however raise new problems imprecise outdated information propose distinguish between certain and cached information when reasoning the semantic web extending the well known mathcal FOUR bilattice truth and knowledge orders mathcal FOUR taking into account cached information discuss how users can offered additional information about the reliability inferred information based the availability the corresponding information sources then extend the framework towards mathcal FOUR allowing for multiple levels trust data sources this extended setting knowledge about trust information sources can used compute how well inferred statement can trusted and resolve inconsistencies arising from connecting multiple data sources redefine the stable model and well founded semantics the basis mathcal FOUR and reformalize the Web Ontology Language OWL2 based logical bilattices augment OWL knowledge bases with trust based reasoning 
6650 en Exploring Semantic Social Networks using Virtual Reality present Redgraph the first generic virtual reality visualization program for Semantic Web data Redgraph capable handling large data sets demonstrate social network data from the Patent Trade Office develop Semantic Web vocabulary virtual reality terms compatible with GraphXML map graph visualization into the Semantic Web itself Our approach visualizing Semantic Web data takes advantage user interaction immersive environment bypass number difficult issues dimensional graph visualization layout relying users themselves interactively extrude the nodes and links dimensional graph into the third dimension When users touch nodes the virtual reality environment they retrieve data formatted according the data’ schema ontology applied Redgraph social network data constructed from patents inventors and institutions from the United States Patent and Trademark Office order explore networks innovation computing Using this data set results user study comparing extrusion extrusion are presented The study showed the use interface subjects led significant improvement answering fine grained questions about the data set but significant difference was found for broad questions about the overall structure the data Furthermore inference can used improve the visualization demonstrated with data set biotechnology patents and researchers 
6651 en Semantic Grounding Tag Relatedness Social Bookmarking Systems Collaborative tagging systems have nowadays become important data sources for populating semantic web applications For tasks like synonym detection and discovery concept hierarchies many researchers introduced measures tag similarity Even though most these measures appear very natural their design often seems rather hoc and the underlying assumptions the notion similarity are not made explicit more systematic characterization and validation tag similarity terms formal representations knowledge still lacking Here address this issue and analyze several measures tag similarity Each measure computed data from the social bookmarking system del icio and semantic grounding provided mapping pairs similar tags the folksonomy pairs synsets Wordnet where use validated measures semantic distance characterize the semantic relation between the mapped tags This exposes important features the investigated similarity measures and indicates which ones are better suited the context given semantic application 
6652 en Semantic Modelling User Interests Based Cross Folksonomy Analysis The continued increase Web usage particular participation folksonomies reveals trend towards more dynamic and interactive Web where individuals can organise and share resources Tagging has emerged the facto standard for the organisation such resources providing versatile and reactive knowledge management mechanism that users find easy use and understand common nowadays for users have multiple profiles various folksonomies thus distributing their tagging activities this paper present method for the automatic consolidation user profiles across two popular social networking sites and subsequent semantic modelling their interests utilising Wikipedia multi domain model evaluate how much can learned from such sites and which domains the knowledge acquired focussed Results show that far richer interest profiles can generated for users when multiple tag clouds are combined 
6654 en  Semantic Multimedia Web Create Annotate Present and Share your Media The success content centered social Web services contributes ever growing amount digital multimedia content available the Web Video advertisement becoming more and more popular and films music and videoclips are largely consumed from legacy commercial databases using such multimedia material however still hard problem Why difficult find appropriate multimedia content reuse and repurpose content previously published and adapt interfaces these content according different user needs nnThis tutorial proposes cover these questions Based established media workflow practices describe small number fundamental processes media production explain how multimedia metadata can represented attached the content describes and benefits from the web that contains more and more formalized knowledge the Web linked data show how web applications can benefit from semantic metadata for creating searching and presenting multimedia content 
6655 en RDFa Bridging the Web Documents and the Web Data RDFa the bridge between the Web Documents targeting human users and the Web Data focusing machines Not only due the recent uptake RDFa Digg Yahoo etc learning how and where use RDFa essential This tutorial will introduce the usage RDFa real world use cases and will enable the attendees work with RDFa both the client the server side will create publish and consume RDFa marked data the course the tutorial and discuss advanced aspects such dynamic content handling There are pre requisites for participation the tutorial other than familiarity with the basics the Semantic Web such URIs RDF XHTML and SPARQL 
6656 en Knowledge Representation and Extraction for Business Intelligence Business Intelligence requires the acquisition and aggregation key pieces knowledge from multiple sources order provide business analysts with valuable information feed statistical models and tools The massive amount textual and multimedia information available business analysts makes information extraction and semantic based digital tools key enablers for the acquisition and management semantic information The role Ontologies important here since they promote interoperability and uniform and standardized access heterogeneous sources and software components addition they encode rules for deduction new knowledge from extracted data nnThe tutorial will give overview approaches identify extract and consolidate semantic information for business intelligence also stressing the role temporal information The tutorial will take practical hands approach which theoretical concepts and approaches are presented together with case studies semantic based tools the context the 6th Framework Programme Musing Integrated Project which targeting three different vertical domains Financial Risk Management Internationalisation and Operational Risk Management 
6657 en Reasoning for Ontology Engineering and Usage will provide brief introduction OWL fact OWL2 and the underlying Description Logic clarifying the semantics and providing examples help the understanding this admittedly complex formalism particular will discuss common misunderstandings around OWL and OWL2 explain the open world assumption inferences and the functionality reasoners will use the RacerPro reasoner demonstrate the benefit using reasoning for query answering over ontologies Scalability issues with respect expressive ontologies well huge assertional knowledge bases are discussed 
6658 en Realizing Semantic Web Application You are aware the Semantic Web but you haven’ got time develop Semantic Web application yourself During this tutorial challenge the Semantic Web technologies the Web ground realizing mash that reuses transforms and combines existing data taken from the open Web nnRSWA tutorial explains how develop step step Semantic Web application that expects music style input retrieves data from online music archives and event databases merges them and let the users explore events related artists that practice the required style The result Semantic Web Application named Music Event Explorer shortly meex try out http swa cefriel meex 
6659 en How Publish Linked Data the Web The Web increasingly understood global information space consisting not just linked documents but also Linked Data The Linked Data principles provide basis for realizing this Web Data Semantic Web Since early 2007 numerous data sets have been published the Web according these principles domains broad music books geographical information films people events reviews and photos combination these data sets consist over billion RDF triples interlinked more than million triples that cross data sets this Web Linked Data continues grow and increasing number applications are developed that exploit these data sets there growing need for data publishers researchers developers and Web practitioners understand Linked Data principles and practice Run some the leading members the Linked Data community this tutorial will address those needs and provide participants with solid foundation from which begin publishing Linked Data the Web well implement applications that consume Linked Data from the Web 
6660 en Semantic Web for Health Care and Life Sciences The W3C Semantic Web Health Care and Life Sciences Interest Group HCLSIG has used RDF tools integrate several large biological and clinical databases This has simplified access relational and hierarchical data and enabled third party additions the database HCLSIG demonstrates the use Semantic Web technologies access data web scale taking advantage OWL and rules allow queries purpose data without the need coordinate with the data custodian nnThis tutorial will introduce OWL and rule mappings databases well introduce good practices for data modeling and publication The use SKOS for terminologies will also described Attendees will learn possible applications Semantic Web tools share data between and within organizations and solve large scale data integration problems nnThis tutorial will discuss how publishers biological and clinical data can use OWL and rules model their data and how users Semantic Web tools can access this more diverse data Attendees should familiar with the Semantic Web languages RDF Turtle SPARQL and introduced OWL These materials will covered the earlier RSWA tutorial 
6661 en Free Semantic Content Using OpenCyc Semantic Web Applications OpenCyc will more accessible and Semantic Web interoperability will enhanced users are able access just the parts OpenCyc they need The tutorial will describe how Semantic Web researchers and practitioners can benefit from integrating their representations with the extensive upper and middle level ontological content the free and unrestricted OpenCyc knowledge base and other integrative vocabularies like Okkam The syntax OpenCyc will described both raw form and mapped onto Semantic Web standard languages and the content the knowledge base will described overview Based that ’ show how extend the OpenCyc for user applications and how make use web services environment support knowledge integration and simple machine learning applications Finally ’ demonstrate the use the OpenCyc vocabulary support broad applicability knowledge capture application illustrative the transition from Web2 Web3 Hands exercises will used illustrate knowledge use and construction use OpenCyc with inference and use for semantic search over text web services environment 
6663 en Multimedia Semantic Web The Capture Storage Sharing Organizing Retrieval and Use knowledge dominate most socio economic activities our society Most the knowledge the world initially captured and stays the form experiences different sensing modalities Current technology can address knowledge text because text the experiential data converted symbols humans Converting sensory data symbols computer systems has been difficult primarily due our inability formally represent and effectively model the appropriate context within which the multimedia sensory data should interpreted This problem integrating continuous multimedia and symbolic data becomes more urgent multimedia data becoming common and the resulting social applications the Web are required deal with semantics multimedia data Clearly the collection searchable multimedia experiences will facilitate progress sciences and the quality human life every part the world across all economies and cultures this paper will present challenges offered semantics multimedia data review emerging semantic web approaches towards addressing these challenges and present some example applications that are being developed address these emerging challenges 
6664 en Freebase Open Writable Database the World’ Information Freebase open database the world’ information built global community and free for anyone query contribute and build applications Drawing from large open data sets like Wikipedia MusicBrainz GNIS EDGAR etc Freebase curated passionate community users and contains structured information millions topics such people places music film food science historical events and more nnPart what makes this open database unique that spans domains but requires that particular topic exist only once Freebase Thus freebase identity database with user contributed schema which spans multiple domains For example Arnold Schwarzenegger may appear movie database actor political database governor and bodybuilder database Universe Freebase however there only one topic for Arnold Schwarzenegger that brings all these facets together The unified topic single reconciled identity which makes easier find and contribute information about the linked world live 
6665 en Message Bottle How can the Semantic Web Community more convincing Enormous resources are poured into projects like the Large Hadron Collider the Hubble space telescope the Iter fusion reactor Computer science resources pale comparison – the European Semantic Web effort tiny compared those projects Why this the case Does the Semantic Web computer science general promise less impact relevance than those Physics projects talk will argue that the Physicists are much better formulating engaging mission and message Especially the Semantic Web community has not been very good coming with convincing mission directed the public need and can better will formulate requirements and starting point for such message and investigate ongoing seemingly unrelated research areas and trends the Semantic Web like Semantic Sensor Networks Social Semantic Desktop and Semantic Publishing and how they contributes better conveyable mission 
6666 en Semantic Web Challenge Billion Triple Challenge The central idea the Semantic Web extend the current human readable web encoding some the semantics resources machine processable form Moving beyond syntax opens the door more advanced applications and functionality the Web Computers will better able search process integrate and present the content these resources meaningful intelligent manner nnThe core technological building blocks are now place and widely available ontology languages flexible storage and querying facilities reasoning engines etc Standards and guidelines for best practice are being formulated and disseminated the W3C nnThe Semantic Web Challenge offers participants the chance show the best the Semantic Web The Challenge thus serves several purposes Helps illustrate society what the Semantic Web can providen Gives researchers opportunity showcase their work and compare othersn Stimulates current research higher final goal showing the state the art every yearn
6667 en Lightning Talks This year ISWC will include session “Lightning Talks” The session provides opportunity for participants present ideas comments calls for collaboration scathing polemic criticisms … controversy and discussion are positively encouraged would particularly welcome observations comments arising from material presented during the conference 
6668 en Closing Ceremony and Best Paper Awards Outlook ISWC2009
6669 en Assesment surface ravelling using traffic speed survey techniques
6670 en  method for developing preliminary friction deterioration model runway
6671 en Evaluation the international friction index coefficients for various devices
6672 en Seasonal variationsof pavement surface frictional properties
6673 en How assess payment adjustment when both surface and mechanical defects are involved sinergy study theory and experiments
6726 en  SUSY first steps after LHC discovery missing energy discovery possible the LHC the first year running The origin such signal could any huge number models supersymmetry non supersymmetric models with extra dimensions little Higgs Recently have developed realistic strategy rapidly narrow the list candidate theories close the moment discovery The strategy based robust ratios inclusive counts simple physics objects studied specific cases showing discrimination look alike models simulated data sets that are least 100 times smaller than used previous studies discriminate supersymmetry models from non supersymmetric look alikes with only 100 simulated data using combinations observables that trace back differences spin 
6729 en Detection Symmetries and Repeated Patterns Point Cloud Data Digital models physical shapes are becoming ubiquitous our economy and life Such models are sometimes designed initio using CAD tools but more and more often they are based existing real objects whose shape acquired using various scanning technologies most instances the original scanner data just set but very large set points sampled from the surface the object are interested tools for understanding the local and global structure such large scale scanned geometry for variety tasks including model completion reverse engineering shape comparison and retrieval shape editing inclusion virtual worlds and simulations etc This talk will present number point based techniques for discovering global structure data sets including partial and approximate symmetries shared parts repeated patterns etc also interest perform such structure discovery across multiple data sets distributed network without actually ever bring them all the same host 
6730 en Discrete Curvature Flow for Surfaces and Manifolds This talk introduce the concepts theories and algorithms for discrete curvature flows for surfaces with arbitrary topologies Discrete curvature flow for hyperbolic manifolds with geodesic boundaries are also explained Curvature flow method can used design Riemannian metrics prescribed curvatures and applied for parameterization graphics shape registration and comparison vision and brain mapping medical imaging spline construction computer aided geometric design and many other engineering fields 
6731 en Certified Mesh Generation Given domain the problem mesh generation construct simplicial complex that approximates both topological and geometrical sense and whose elements satisfy various constraints such size aspect ratio anisotropy The talk will cover some recent results triangulating surfaces and volumes Delaunay refinement anisotropic mesh generation and surface reconstruction Applications medical images computer vision and geology will discussed 
6732 en Information Theoretic Algorithms for Diffusion Tensor Imaging Concepts from Information Theory have been used quite widely Image Processing Computer Vision and Medical Image Analysis for several decades now Most widely used concepts are that divergence minimum description length MDL etc These concepts have been popularly employed for image registration segmentation classification etc this chapter review several methods mostly developed our group the Center for Vision Graphics Medical Imaging the University Florida that glean concepts from Information Theory and apply them achieve analysis Diffusion Weighted Magnetic Resonance MRI data This relatively new MRI modality allows one non invasively infer axonal connectivity patterns the central nervous system The focus this chapter review automated image analysis techniques that allow automatically segment the region interest the DWMRI image wherein one might want track the axonal pathways and also methods reconstruct complex local tissue geometries containing axonal fiber crossings Implementation results illustrating the algorithm application real MRI data sets are depicted demonstrate the effectiveness the methods reviewed 
6733 en Statistical Computing Manifolds for Computational Anatomy Computational anatomy emerging discipline that aims analyzing and modeling the individual anatomy organs and their biological variability across population The goal not only model the normal variations among population but also discover morphological diferences between normal and pathological populations and possibly detect model and classify the pathologies from structural abnormalities Applications are very important both neuroscience minimize the uence the anatomical variability functional group analysis and medical imaging better drive the adaptation generic models the anatomy atlas into patient speci data nnHowever understanding and modeling the shape organs made  cult the absence physical models for comparing diferent subjects the complexity shapes and the high number degrees freedom implied Moreover the geometric nature the anatomical features usually extracted raises the need for statistics and computational methods objects like curves surfaces and deformations that not belong standard Euclidean spaces investigate this chapter the Riemannian metric basis for developing generic algorithms compute manifolds nnWe show that few computational tools derive this structure can used practice the basic atoms build more complex generic algorithms such mean computation Mahalanobis distance interpolation ltering and anisotropic difusion elds geometric features This computational framework illustrated with the analysis the shape the scoliotic spine and the modeling the brain variability from sulcal lines where the results suggest new anatomical ndings 
6734 en Large Scale Object Recognition Systems This paper introduces recent methods for large scale image search State the art methods build the bag features image representation first analyze bag features the framework approximate nearest neighbor search This shows the sub optimality such representation for matching descriptors and leads derive more precise representation based onn Hamming embedding andn weak geometric consistency constraints WGC nHE provides binary signatures that refine the matching based visual words WGC filters matching descriptors that are not consistent terms angle and scale and WGC are integrated within the inverted file and are efficiently exploited for all images even the case very large datasets nnExperiments performed dataset one million images show significant improvement due the binary signature and the weak geometric consistency constraints well their efficiency Estimation the full geometric transformation ranking step short list images complementary our weak geometric consistency constraints and allows further improve the accuracy 
6735 en Recovering Shape and Motion from Video Sequences recent years because cameras have become inexpensive and ever more prevalent there has been increasing interest video based modeling shape and motion This has many potential applications areas such electronic publishing entertainment sports medicine and athletic training however inherently difficult task because the image data often incomplete noisy and ambiguous our work focus the recovery deformable and articulated motion from single video sequences nnIn this talk will present the models have developed for this purpose and demonstrate the applicability our technology for Augmented Reality and human body tracking purposes Finally will present some open research issues and discuss our plans for future developments 
6736 en Computational Geometry from the Viewpoint Affine Differential Geometry Incidence relations configurations vertexes edges etc are important computational geometry Incidence relations are invariant under the group affine transformations the other hand affine differential geometry study hypersurfaces affine space that are invariant under the group affine transformation Therefore affine differential geometry gives new sight computational geometry nnFrom the viewpoint affine differential geometry algorithms geometric transformation and dual transformation are discussed The Euclidean distance function generalized divergence function affine differential geometry divergence function asymmetric distance like function manifold and important object information geometry For divergence functions the upper envelope type theorems statistical manifolds are given Voronoi diagrams determined from divergence functions are also discussed 
6737 en Unifying Subspace and Distance Metric Learning with Bhattacharyya Coefficient for Image Classification this talk propose unified scheme subspace and distance metric learning under the Bayesian framework for image classification According the local distribution data divide the nearest neighbors each sample into the intra class set and the inter class set and aim learn distance metric the embedding subspace which can make the distances between the sample and its intra class set smaller than the distances between and its inter class set reach this goal consider the intra class distances and the inter class distances from two different probability distributions respectively and model the goal with minimizing the overlap between two distributions nnInspired the Bayesian classification error estimation formulate the objective function minimizing the Bhattachyrra coefficient between two distributions further extend with the kernel trick learn nonlinear distance metric The power and generality the proposed approach are demonstrated series experiments the CMU PIE face database the extended YALE face database and the COREL 5000 nature image database 
6738 en Non standard Geometries and Data Analysis Traditional data mining starts with the mapping from entities points Euclidean space The search for patterns and structure then framed geometric search this space Concepts like principal component analysis regression clustering and centrality estimation have natural geometric formulations and now understand great deal about manipulating such typically high dimensional spaces For many domains interest however the most natural space embed data not Euclidean nnData might lie curved manifolds even inhabit spaces endowed with different distance structures than spaces How does one data analysis such domains this talk discuss two specific domains interest that pose challenges for traditional data mining and geometric methods One space consists collections distributions and the other the space shapes both cases present ongoing work that attempts interpret and understand clustering such spaces driven different applications 
6760 en From spinwaves Giant Magnetoresistance and beyond Peter Grünberg joint winner the 2007 Nobel Prize Physics The talk based his Nobel lecture 2007 
6761 en PS10 First attempt commercial solar energy the world The field solar energy research has reached level maturity where truly commercial applications can envisaged nThe fascinating story one the first prototypes will presented 
6762 en Prospect Particle Physics China The Beijing Electron Positron Collider BEPC finished its running July 2005 with great success both the Tau Charm physics experiment and the synchrotron radiation light source The latest Charm physics results from BEPC are reviewed including the observation the new resonance X1835 with possible explanation the PPbar bound state The major upgrade BEPC into double ring collider called BEPCII will increase its luminosity two orders magnitude nnThe physics window BEPCII mainly the precision measurements the Charm physics and the search for new phenomena The construction BEPCII finished The tuning the storage ring goes smoothly The synchrotron radiation facility BEPCII opened users with high performance since the end 2006 nnThe new detector BESIII has been moved into the interaction region June and the joint commissioning started The non accelerator experiments China are promoted with great efforts including the neutrino physics experiments the cosmic ray measurements and the particle astrophysics experiments Space nnThe reactor neutrino experiment Daya Bay could reach the sensitivity the measurement the neutrino mixing parameter sin22 The medium and long term plan the Chinese particle physics experiments also discussed 
6763 en  rays from comets surprising discovery Comets are kilometre size aggregates ice and dust which remained from the formation the solar system was not obvious expect ray emission from such objects Nevertheless when comet Hyakutake 1996 was observed with the ROSAT ray satellite during its close approach Earth March 1996 bright ray emission from this comet was discovered This finding triggered search archival ROSAT data for comets which might have accidentally crossed the field view during observations unrelated targets increase the surprise even more ray emission was detected from four additional comets which were optically 300 000 times fainter than Hyakutake nnFor one them comet Arai 1991 ray emission was even found data which were taken six weeks before the comet was optically discovered These findings showed that comets represent new class celestial ray sources The subsequent detection ray emission from several other comets dedicated observations confirmed this conclusion nnThe talk will summarise the highlights the series discoveries and provide explanation for this unexpected phenomenon 
6765 en Accelerators for Hadrontherapy Hadrontherapy was born 1938 when neutron beams were used cancer therapy but has become accepted therapeutical modality only the last fifteen years Fast neutrons are still use even their limitations are now apparent Charged hadron beams are more favourable since the largest specific energy deposition occurs the end their range matter The most used hadrons are present protons and carbon ions which allow dose deposition which conforms the tumour target nnRadiobiological experiments and the results the first clinical trials indicate that carbon ions have besides this macroscopic property different way interacting with cell the microscopic level There are thus solid hopes use carbon beams about 4500 MeV control tumours which are radioresistant both rays and protons nnAfter discussing these macroscopic and microscopic properties and presenting the work carried out CERN the framework the Proton Ion Medical Machine Study PIMMS the hospital based facilities the world running under construction will reviewed 
6782 en Status the LHC detectors design construction commissioning
6783 en Planning Learn with Knowledge Discovery Ontology Assembly optimized knowledge discovery workfows requires awareness and extensive knowledge about the principles and mutual relations between diverse data processing and mining algorithms aim alleviating this burden automatically proposing workfows for the given type inputs and required outputs the discovery process The methodology adopted this study define formal conceptualization knowledge types and data mining algorithms and design planning algorithm which extracts constraints from this conceptualization for the given user input output requirements demonstrate our approach two use cases one from scientific discovery genomics and another from advanced engineering 
6785 en Information Geometry and Its Applications Information geometry emerged from studies invariant properties manifold probability distributions includes convex analysis and its duality special but important part Here begin with convex function and construct dually flat manifold The manifold possesses Riemannian metric two types geodesics and divergence function The generalized Pythagorean theorem and dual projections theorem are derived therefrom construct alpha geometry extending this convex analysis this review geometry manifold probability distributions then given and plenty applications are touched upon Appendix presents easily understable introduction differential geometry and its duality 
6786 en Information Geometry Duality Convexity and Divergences this talk explore the mathematical relationships between duality information geometry convex analysis and divergence functions nFirst from the fundamental inequality convex function family divergence measures can constructed which specializes the familiar Bregman divergence Jenson difference beta divergence and alpha divergence etc nnSecond the mixture parameter turns out correspond the alpha alpha duality information geometry which call referential duality since related the choice reference point for computing divergence nnThird convex conjugate operation induces another kind duality information geometry namely that biorthogonal coordinates and their transformation which call representational duality since related the expression geometric quantities such metric affine connection curvature etc the underlying manifold Under this analysis what traditionally called duality and duality information geometry reflect two very different meanings duality that are nevertheless intimately interwined for dually flat spaces 
6787 en Computational Photography Epsilon Coded Imaging Computational photography combines plentiful computing digital sensors modern optics actuators and smart lights escape the limitations traditional cameras enables novel imaging applications and simplifies many computer vision tasks However majority current Computational Photography methods involve taking multiple sequential photos changing scene parameters and fusing the photos create richer representation The goal Coded Computational Photography modify the optics illumination sensors the time capture that the scene properties are encoded single few photographs describe several applications coding exposure aperture illumination and sensing and describe emerging techniques recover scene parameters from coded photographs 
6788 en The Intrinsic Geometries Learning seminal paper Amari 1998 proved that learning can made more efcient when one uses the intrinsic Riemannian structure the algorithms spaces parameters point the gradient towards better solutions this paper show that many learning algorithms including various boosting algorithms for linear separators the most popular top down decision tree induction algorithms and some line learning algorithms are spawns generalization Amari natural gradient some particular non Riemannian spaces nnThese algorithms exploit intrinsic dual geometric structure the space parameters relationship with particular integral losses that are minimized unite some them such AdaBoost additive regression with the square loss the logistic loss the top down induction performed CART and single algorithm which show general convergence the optimum and explicit convergence rates under very weak assumptions consequence many the classi cation calibrated surrogates Bartlett 2006 admit efficient minimization algorithms 
6789 en Applications Information Geometry Radar Signal Processing Main issue High Resolution Doppler Imagery related robust statistical estimation Toeplitz Hermitian positive definite covariance matrices sensor data time series Doppler Echography Underwater acoustic Electromagnetic Radar Pulsed Lidar consider this problem jointly the framework Riemannian symmetric spaces and the framework Information Geometry Both approaches lead the same metric that has been initially considered other mathematical domains study Bruhat Tits complete metric Space Upper half Siegel Space Symplectic Geometry Based Frechet Karcher barycenter definition geodesics Bruhat Tits space address problem Covariance matrices Mean estimation Our main contribution lies the development this theory for Complex Autoregressive models maximum entropy solution Doppler Spectral Analysis nnSpecific Blocks structure the Toeplitz Hermitian covariance matrix used define iterative parallel algorithm for Siegel metric computation Based Affine Information Geometry theory introduce for Complex Autoregressive Model Kohler metric reflection coefficients based Kohler potential function given Doppler signal Entropy The metric closely related Kohler Einstein manifold and complex Monge Ampere Equation Finally study geodesics space Kohler potentials and action Calabi Kohler Ricci Geometric Flows for this Complex Autoregressive Metric nnWe conclude with different results obtained real Doppler Radar Data bands band radar monitoring wake vortex turbulences detection for Coastal band Surface Wave Radars 
6790 en Constant Working Space Algorithms for Image Processing This talk surveys recent progress constant working space algorithms for problems related image processing extreme case when input image given read only memory which reading array element allowed but writing any value any array element prohibited and also the number working storage cells available for algorithms most some constant This chapter shows how number important fundamental problems can solved such highly constrained situation 
6791 en Sparse Geometric Super Resolution What the maximum signal resolution that can recovered from partial noisy degraded data This inverse problem central issue from medical satellite imaging from geophysical seismic HDTV visualization Internet videos Increasing image resolution possible taking advantage geometric regularities whatever means Super resolution can indeed achieved for signals having sparse representation which incoherent relatively the measurement system nnFor images and videos requires construct sparse representations redundant dictionaries waveforms which are adapted geometric image structures Signal recovery redundant dictionaries discussed and applications are shown dictionaries bandlets for image super resolution 
6792 en Sparse Sampling Variations Theme Shannon Sampling not only beautiful topic harmonic analysis with interesting history but also subject with high practical impact the heart signal processing and communications and their applications The question very simple when there one one relationship between continuous time function and adequately acquired samples this function cornerstone result course Shannon sampling theorem which gives sufficient condition for reconstructing the projection signal onto the subspace bandlimited functions and this taking inner products with sinc function and its shifts Many variations this basic framework exist and they are all related subspace structure the classes objects that can sampled Recently this framework has been extended classes non bandlimited sparse signals which not have subspace structure Perfect reconstruction possible based suitable projection measurement This gives sharp result the sampling and reconstruction sparse continuous time signals namely that measurements are necessary and sufficient perfectly reconstruct sparse continuous time signal accordance with the principle parsimony call this sampling Occam rate nnWe first review this result and show that relies structured Vandermonde measurement matrices which the Fourier matrix particular case also uses separation into location and value estimation the first being non linear while the second linear Because this structure fast methods exist and are related classic algorithms used spectral estimation and error correction coding then generalize these results number cases where sparsity present including piecewise polynomial signals well broad classes sampling measurement kernels including Gaussians and splines course real cases always involve noise and thus retrieval sparse signals noise considered That there stable recovery mechanism and robust practical algorithms achieve Lower bounds Cramer Rao are given which can also used derive uncertainty relations with respect position and value sparse signal estimation Then concrete estimation method given using iterative algorithm due Cadzow and shown perform close optimal over wide range signal noise ratios This indicates the robustness such methods well their practicality nnNext consider the connection compressed sensing and compressive sampling recent approach involving random measurement matrices discrete set and retrieval based convex optimization These methods have the advantage unstructured measurement matrices actually typically random ones and therefore certain universality the cost some redundancy compare the two approaches highlighting differences similarities and respective advantages Finally move applications these results which cover wideband communications noise removal and superresolution imaging name few conclude indicating that sampling alive and well with new perspectives and many interesting recent results and developments nnJoint work with Thierry Blu CUHK Lionel Coulot Ali Hormati EPFL Pier Luigi Dragotti ICL and Pina Marziliano NTU 
6793 en Image Retrieval via Kullback Divergence Patches Wavelets Coefficients the Framework This talk presents framework define objective measure the similarity dissimilarity between two images for image processing The problem twofold define set features that capture the information contained the image relevant for the given task andn define similarity measure this feature space nnIn this paper propose feature space well statistical measure this space Our feature space based global description the image multiscale transformed domain After decomposition into Laplacian pyramid the coefficients are arranged intrascale interscale interchannel patches which reflect the dependencies neighboring coefficients presence specific structures textures each scale the probability density function pdf these patches used description the relevant information Because the sparsity the multiscale transform the most significant patches called Sparse Multiscale Patches SMP describe efficiently these pdfs nnWe propose statistical measure the Kullback Leibler divergence based the comparison these probability density function Interestingly this measure estimated via the nonparametric nearest neighbor framework without explicitly building the pdfs This framework applied query example image retrieval method Experiments two publicly available databases showed the potential our SMP approach for this task particular performed comparably SIFT based retrieval method and two versions fuzzy segmentation based method the UFM and CLUE methods and exhibited some robustness different geometric and radiometric deformations the images 
6794 en Machine learning and kernel methods for computer vision Kernel methods are new theoretical and algorithmic framework for machine learning representing data through well defined dot products referred kernels they allow use classical linear supervised machine learning algorithms non linear settings and non vectorial data major issue when applying these methods image processing computer vision the choice the kernel will present recent advances the design kernels for images that take into account the natural structure images 
6795 en  Visibility and Lines Space Computing visibility information environment crucial many applications such computer graphics vision and robotics Typical visibility problems include computing the view from given point determining whether two objects partially see each other and computing the umbra and penumbra cast light source given scene two points are visible the segment joining them does not properly intersect any obstacle the scene The study visibility thus intimately related the study the set free line segments scene this talk will review some recent combinatorial and algorithmic results related non occluded segments tangent four objects three dimensional scenes 
6796 en Procedural Modeling Architectures Towards Large Scale Visual Reconstruction Three dimensional content novel modality used numerous domains like navigation post production cinematography architectural modeling and urban planning These domains have benefited from the enormous progress has been made reconstruction from images Such problem consists building geometric models the observed environment State the art methods can deliver excellent results small scale but suffer from being local and cannot considered large scale reconstruction process since the assumption recovering images from multiple views for important number buildings rather unrealistic nnOn the other hand several efforts have been made the graphics community towards content creation with city engines Such models are purely graphics based and given set rules grammars well dictionary architectures buildings can produce virtual cities Such engines could become far more realistic through the use actual city models well knowledge building architectures Developing models rules grammars that are image based and coupling these models with actual observations the greatest challenge urban modeling nnSolving the large scale geometric modeling problem from minimal content could create novel means world representation well novel markets and applications this talk will present some preliminary results large scale modeling and reconstruction through architectural grammars 
6797 en  Video Fusion Graphics and Vision recent years dimensional video has received significant attention both research and industry Applications range from special effects feature films the analysis sports events video concerned with the computation virtual camera positions and fly throughs scene given multiple conventional video streams The high quality synthesis such view independent video representations poses variety technical challenges including acquisition reconstruction processing compression and rendering nnIn this talk will outline the research this area carried out ETH over the past years will discuss various concepts for passive and active acquisition video using combinations multiple cameras and projectors Furthermore will address topics related the representation and processing the massive amount data arising from such multiple video streams nnI will highlight the underlying technical concepts and algorithms that draw upon knowledge both from graphics and from vision Finally will demonstrate some commercial applications targeting virtual replays for sports broadcasts 
6798 en Semantic Technologies for Enterprise Adding Value RTD Better marketing innovative ICT solutions the world business requires links forged between researchers ICT industry players and corporate users and greater understanding the market reached This session will bring together actors involved developing and marketing ‘Semantic Technologies for the Enterprise’ STE implementing semantics their productive processes and applied research These participants will presented with market research the conditions for uptake STE key economic sectors along with real life experiences turning RTD output into profitable products and services Opportunity will given discuss these results particularly focusing ways identify and fill gaps the market 
6800 en From the Lab the Market
6801 en Ovum’ Approach and Interim Analysis
6802 en Semantic Technologies for Enterprise Semantic Open Innovation Success Story 
6804 en Semantics digital content From multimedia emerging Media This session aims solicit discussions exchange ideas and establish new partnerships the area semantic media technologies and semantic based modelling and processing general but will focus content particular according the missions the SMaRT society and the Coordination Action FOCUS K3D which address the “Intelligent Content and Semantics” strategic objective the FP7 ICT theme nIn this session will invite experts representatives projects and institutions dealing with the topic semantics Multimedia analysis and retrieval order discuss challenges this field and how address them 
6806 en  Space Bridging the semantic gap
6809 en Semantics digital content Open discussion 
6810 en FOster the Comprehension and USe Knowledge intensive technologies for coding and sharing media content
6811 en AWG CAD CAE and Virtual Product Modeling
6814 en Archaeology Cultural Heritage AWG
6815 en Semantics digital content Open discussion 
6816 en The Expanding Information Universe New Trends New Forms New Usages
6817 en Filling the pipes – the brave new visual world
6818 en The Information Universe the Near Future
6819 en The Expanding Information Universe Open Discussion
6820 en  Introduction Collective Intelligence
6822 en Mining the Web Improve Search
6823 en Social Network Analysis and Collective Intelligence 
6825 en User Interfaces and Interaction for 
6830 en ICT services for goods mobility Scenario and vision
6831 en TraSer Identity Based Tracking and Web Services for SMEs
6833 en ICT Services for Sustainable Freight Transport Open Discussion
6834 en Complex Metallic Alloys Concept Properties and Perspective The conference will focus few examples the atypical behavior ofncomplex metallic alloys including quasicrystals the ultimate state ofnstructural complexity crystal made metals The main issue thisntopic understand why Nature selects complex compounds whereas mostnconstituent metals embody simple versions the densest possible packing ofnhard spheres turn complexity entails atypical physical properties that significantlyndepart from the ones known for simple metals and their alloys Examples arentransport properties surface electronic structure surface energy wettingnand friction The view the author that complex metallic alloys help revisitnancient and probably also well established problems metal physics thusnimproving our understanding the basic properties condensed matter nwhile parallel potential applications may sorted out Examples will bengiven 
6835 en Developments high performance type carbon nanotube field effect transistors scaling down with Moore law the modern silicon complementary metal oxide semiconductor CMOS technology facing great challenges and people are looking for alternatives Carbon nanotube CNT due its novel structure and properties has been regarded one the most promising building blocks for the future integrated circuits Since the first CNT field effect transistor CNTFET was designed 1998 device performance hasbeen continually improved using palladium electrodes and high materials which are less prone current leakage gate dielectrics type CNTFETs have now surpassed the capabilities ofnstate the art silicon MOSFETs nnHowever the development type CNTFETs has lagged behind This mainly due the difficulty fabricating Schottky barrier free contact between metal electrodes and the conduction band the CNT The slow progress producing CNTFETs hasngreatly hindered the development CNT based integrated circuits Recently discovered that scandium can used generate ohmic contact with thenconduction band CNT and high performance type CNTFETs can easily fabricated nnBased this discovery proposed CNT based doping free CMOS technology and pushed the limits ntype CNTFETs also demonstrated design whole carbon nanotube circuits integrating Multi Walled CNTs with the Single Walled CNTFETs which serve interconnects All our results show prospective future CNT based integrated circuits 
6837 en Incorporating optical techniques electron microscopy for comprehensive characterization individual nanostructures The purpose this informal talk introduce briefly some new additions the research group Peking University and seek more future collaborations with JSI nnOptical techniques luminescence and Raman spectroscopy can provide rich information semiconductor properties band structure phonon structure confinements etc which are complementary electron microscopy techniques Initial efforts have been carried out combine submicron optical techniques and situ nanoprobe technique electron microscopy carry out comprehensive characterization individual semiconductor nanostructures nnIn the first approach attach individual suspended semiconductor nanowires nanorods nanometer sized metal tips which are compatible for different instruments such scanning electronnmicroscope SEM transmission electron microscope TEM and microphotoluminescence nThus optical microstructural SEM and TEM and electrical nanoprobe technique inside SEM characterization can carried out the same nanostructure Our results situ annealed ZnO nanowires show conclusive correlations among defect related green emission redshift the nearnband edge emission carrier density and oxygen deficiency This highly flexible technique also enables angular dependent microphotoluminescence measurements individual suspended ZnO nanorods nIn the second approach combine optical fiber probe with the nanoprobe technique SEM achieve comprehensive characterization optoelectronic nanotructures inside single chamber nnThe nanoprobe technique employing sharp metal tips used for nanostructure manipulation and electrical measurement The fiber probe coupled spectrometer laser and controlled nanomanipulator allows local optical detection excitation Using situ light emitter and photodetector based individual nanostructures demonstrate that above technique with high flexibility and efficiency can play important role building prototype optoelectronic devices and selectingsuitable nanostructures for device purposes 
6839 en Neural control – Layers Loops Learning
6851 en  overview the United States government space and science policy making process brief overview the basic elements the space and science policy making apparatus will presented focussing insights into the interactions among the principal organizations policy making bodies and individual participants and their respective impact policy outcomes Several specific examples will provided illustrate the points made and the conclusion there will some observations current events the that may shape the outcome for the near term future space and science policy several areas 
6861 en Variable selection nonparametric additive models consider nonparametric additive model conditional mean function nin which the number variables and additive components may much nlarger than the sample size but the number non zero additive compo nnents small relative the sample size The statistical problem ndetermine which additive components are non zero The additive compo nnents are approximated truncated series expansions with spline bases nThe adaptive group LASSO used select non zero components ngive conditions under which this procedure selects the non zero components ncorrectly with probability approaching one the sample size increases Fol nlowing model selection oracle cient asymptotically normal estimators nthe non zero components can obtained using existing methods The nresults Monte Carlo experiments show that the adaptive group LASSO nprocedure works well with samples moderate size 
6862 en The prediction error functional regression The talk considers functional linear regression where scalar responses nare modeled dependence random functions propose smoothing nsplines estimator for the functional slope parameter based slight modi nﬁcation the usual penalty Theoretical analysis concentrates the error nin out sample prediction the response for new random function nIt shown that rates convergence the prediction error depend the nsmoothness the slope function and the structure the predictors nthen prove that these rates are optimal the sense that they are minimax nover large classes possible slope functions and distributions the predic ntive curves For the case models with errors variables the smoothing nspline estimator modiﬁed using denoising correction the covari nance matrix discretized curves The methodology then applied real ncase study where the aim predict the maximum the concentration nozone using the curve this concentration measured the preceding day 
6863 en Inverse problems empirical risk attitudes Supported several recent investigations the empirical pricing kernel nparadox might considered stylized fact Chabi Garcia nRenault 2008 simulation studies have been presented which suggest that nthis paradox might caused regime switching stock prices ﬁnan ncial markets Alternatively want emphasize microeconomic view nBased economic model with state dependent utilities for the ﬁnan ncial investors succeed explaining the paradox changes the risk nattitudes Theoretically the change behaviour compressed the pric ning kernels starting point for empirical insights shall develop and ninvestigate inverse problem terms data ﬁts for estimated basic val nues the pricing kernel Also numerical solutions this problem will npresented 
6864 en Variational Inference and Experimental Design for Sparse Linear Models Sparsity fundamental concept modern statistics and often the nonly general principle available the moment address novel learning nplications with many more variables than observations Despite the recent nadvances the theoretical understanding and the algorithmics sparse npoint estimation higher order problems such covariance estimation noptimal data acquisition are seldomly addressed for sparsity favouring mod nels and there are virtually scalable algorithms nWe provide approximate Bayesian inference algorithm for sparse lin near models that can used with hundred thousands variables Our nmethod employs convex relaxation variational inference and settles nopen question continuous Bayesian inference The Gaussian lower bound nrelaxation convex for class super Gaussian potentials including the nLaplace and Bernoulli potentials nOur algorithm reduces the same computational primitives used for nsparse estimation methods but requires Gaussian marginal variance esti nmation well show how the Lanczos algorithm from numerical math nematics can employed compute the latter nWe are interested Bayesian experimental design powerful framework nfor optimizing measurement architectures have applied our framework nto problems magnetic resonance imaging design and reconstruction 
6865 en Groupwise sparsity enforcing estimators for solving the EEG MEG inverse problem Cerebral current ﬂows are directly related information transfer the nbrain and thus excellent means for studying the mechanisms cogni ntive processing Electro and Magneto encephalography EEG and MEG nare noninvasive measures these electric currents EEG their respec ntive accompanying magnetic ﬁelds MEG The reconstruction the cere nbral current density from EEG MEG measurements ill posed inverse nproblem the forward mapping from the current sources the external nsensors linear the inverse problem may formulated highly nder determined linear system equations which has unique solution nThe common strategy deal with this ambiguity regularization ﬁt nting the data with additional penalization the sources Both norm nand norm based penalties have been proposed based the neurophys niologically motivated assumptions smoothness and sparsity respectively 
6866 en Nonparametric estimation the error distribution software testing introduce estimation procedure for the error distribution based non additive relations nonparametric setting with application software ntesting Therein face nonlinear statistical inverse problem which can nbe solved Fourier methods derive exact conﬁdence intervals and nprove rate optimality for the derived method 
6867 en Kernel Representations and Kernel Density Estimation There has been great deal attention recent times particularly nmachine learning representation multivariate data points · nwhere positive and symmetric and thus induces reproducing kernel nHilbert space The idea then use the matrix substitute for the empirical covariance matrix sample for PCA nand other inference Jordan and Fukumizu 2006 for instance Nadler nal 2006 connected this approach one based random walks and diffusion limits and indicated connection kernel density estimation nmaking least formal connection multiplication operator function space make further connection and show how clustering results nBeylkin Shih and 2008 which apparently from Nadler can nbe explained 
6868 en Consistency random forests and other averaging classiﬁers the last years his life Leo Breiman promoted random forests for nuse classiﬁcation suggested using averaging means obtaining ngood discrimination rules The base classiﬁers used for averaging are simple nand randomized often based random samples from the data left nfew questions unanswered regarding the consistency such rules this ntalk give number theorems that establish the universal consistency nof averaging rules 
6869 en Nonnegative garrote additive models using splines The nonnegative garrote method was proposed variable selection nmethod Breiman 1995 this talk consider additive modeling and napply the nonnegative garrote method for selecting among the independent nvariables For initial estimation the unknown univariate functions nuse splines estimation Eilers Marx 1996 and backﬁtting applied nto deal with the additive modeling compare the pro posed method ninvolving splines with some other methods for additive models The ﬁnite sample performance the procedure investigated via simulation study nand illustration with real data provided 
6870 en Statistical performances SVM Regularization Classiﬁcation
6871 en Approximation Random Fields High Dimension consider the approximation term partial sums the Karhunen nLo eve expansion parametric random ﬁelds tensor product type the naverage case setting investigate the behavior ∞ the informa ntion complexity approximation with error not exceeding given level nIt was recently shown that for this problem one observes the curse dimen nsionality intractability phenomenon aim give the exact asymptotic nexpression for the information complexity 
6872 en Some methods sparse recovery suggest some new methods sparse recovery deterministic and nstatistical models Examples include problems with missing data con nstrained minimization and other prove sparsity oracle inequalities both nfor the case exact sparse model and for approximately sparse solutions 
6873 en Stability Selection for High Dimensional Data Despite remarkable progress over the past years estimation high ndimensional structure such graphical modeling cluster analysis nvariable selection generalized regression remains cult Among the nmain problems are the choice appropriate amount regularization potential lack stability solution and quantiﬁcation evidence nor signiﬁcance selected structure set selected variables nWe introduce the new method stability selection which addresses these ntwo jor problems for high dimensional structure estimation both from npractical and theoretical point view Stability selection based sub nsampling combination with high dimensional selection algorithms nsuch the method extremely general and has very wide range nplicability Stability selection provides ﬁnite sample control for some error nrates false discoveries and hence transparent principle choose proper namount regularization for structure estimation model selection Maybe neven more importantly results are typically remarkably insensitive the nchosen amount regularization Another property stability selection nthe empirical and theoretical improvement over pre speciﬁed selection meth nods prove for randomized Lasso that stability selection will model nselection consistent even the necessary conditions needed for consistency nthe original Lasso method are violated demonstrate stability selection nfor variable selection Gaussian graphical modeling and clustering using real nand simulated data nThis joint work with Nicolai Meinshausen 
6874 en The incoherence condition additive models extend the idea regularization using the Lasso the case nadditive model with components being larger than the sample size nOur method has group Lasso type structure and penalizes non smoothness nof the components the additive model arrive sparsity oracle nequality need incoherence condition which generalizes the incoherence nconditions used for the Lasso Bickel 2008 impose the “restricted neigenvalue assumption” which closely related the “compatibility con ndition” van Geer 2007 which simply call “Condition ” will nformulate version such “Condition ” for additive models verify nit discuss the case random design prove new results for weighted nempirical processes which make the transition from random ﬁxed design npossible and which only requires population version “Condition ” nconsequence that the sparsity oracle property our procedure holds when nthe variables are independent andthatalsovariousdependencystructuresare allowed 
6875 en Sparse Canonical Correlation Analysis present novel method for solving Canonical Correlation Analy nsis CCA sparse convex framework using least squares approach nThe presented method focuses the scenario when one interested nlimited primal representation for the ﬁrst view while having dual rep nresentation for the second view Sparse CCA SCCA minimises the number nof features used both the primal and dual pro jections while maximising nthe correlation between the two views The method demonstrated two npaired corpuses English French and English Spanish for mate retrieval nWe are able observe the mate retreival that when the number the noriginal features large SCCA outperforms Kernel CCA KCCA learning nthe common semantic space from sparse set features 
6876 en Matching pursuit algorithms machine learning will describe generic matching pursuit algorithm that can used nmachine learning for regression subspace methods kernel PCA and kernel nCCA and classiﬁcation given time will also describe some generalisa ntion error bounds upper bounding their loss Some these bounds will nbe formed using standard sample compression bounds whilst others will namalgamations traditional learning theory techniques such theory nand Rademacher complexities This joint work with John Shawe Taylor 
6878 en The purpose Academic Freedom Today Lecture the President the Republic Danilo Türk delivered the ceremony marking the 20th anniversary the Magna Charta Universitatum 
6879 en The European Union and Its Global Role The Partnerships That Are Needed Preisdent the Republic Danilo Türk delivered lecture entitled The European Union and Its Global Role The Partnerships That Are Needed Columbia University part the World Leaders Forum 
6880 en Europe and Islam Coexistence Integration The President the Republic Slovenia Danilo Türk visited the Oxford Centre for Islamic Studies where delivered lecture entitled Europe and Islam Coexistence Integration ”
6885 en  Customer Relationship Management CRM 
6886 en  Quality Control Management QCM 
6887 en  Project management Add new timesheet task
6888 en  Project management Create incident
6889 en  Project management Reply the incident
6890 en  Project management Tasks
6891 en  Project management Create expense
6892 en  Project management Send forum notifications
6893 en  Project management Receive timesheet task
6894 en  Project management Add new component
6895 en  Project management Company user setup
6896 en  CKM Advanced search
6897 en  QCM Using Best Network
6909 en Opening the conference SAMT´ 
6910 en Tracking the Progress Multimedia Semantics from MPEG Web This paper will describe the next generation hybrid scalable classification systems that combine social tagging machine learning and traditional library classification approaches will also discuss approaches the related challenge aggregating light weight community generated tags with complex MPEG descriptions and discipline specific ontologies through common extensible upper ontologies enhance discovery and use multimedia content across disciplines and communities 
6911 en Automatic Summarization Rushes Video using Bipartite Graphs this paper present new approach for automatic summarization rushes unstructured video Our approach composed three major steps First based shot and sub shot segmentations filter sub shots with low information content not likely useful summary Second method using maximal matching bipartite graph adapted measure similarity between the remaining shots and minimize inter shot redundancy removing repetitive retake shots common rushes video Finally the presence faces and motion intensity are characterised each sub shot measure how representative the sub shot the context the overall video then proposed Video summaries composed keyframe slideshows are then generated order evaluate the effectiveness this approach run the evaluation carried out TREC using the same dataset and evaluation metrics used the TRECVID video summarization task 2007 but with our own assessors Results show that our approach leads significant improvement terms the fraction the TRECVID summary ground truth included and competitive with other approaches TRECVID 2007 
6912 en Performing Content based Retrieval Humans using Gait Biometrics order analyse surveillance video need efficiently explore large datasets containing videos walking humans this resolution the human walk their gait can determined automatically more readily than other features such the face Analysis can rely retrieval video data which has been enriched using semantic annotations manual annotation process time consuming and prone error due subject bias explore the content based retrieval videos containing walking subjects using semantic queries evaluate current biometric research using gait unique their effectiveness recognising people distance introduce set semantic traits discernible humans distance outlining their psychological validity Working under the premise that similarity the chosen gait signature implies similarity certain semantic traits perform set semantic retrieval experiments using popular latent semantic analysis techniques from the information retrieval community 
6913 en  Video Abstraction Systems Architectures and Modelling Abstract Nowadays the huge amount video material stored multimedia repositories makes the search and retrieval such content very slow and usually difficult task The existing video abstraction systems aim ease the multimedia access problem providing short versions the original content which ease the search and navigation process reducing the time spent content browsing There are many video abstraction system variations providing different kinds output video skims keyframe based summaries etc This paper presents generic video abstraction architecture which aims characterize the stages required for generic abstraction process well the definition the theoretical aspects and requirements for the modelling video abstraction systems which first step before building abstraction systems with specific characteristics 
6915 en Context non ontological determinant semantics This paper theoretical analysis formal annotation and ontology for the expression the semantics document They are found wanting this respect not only for technical reasons but because they embody fundamentally misunderstood model the process signification propose alternative model which the interpretation context plays fundamental rôle the definition activity game that includes all actions performed document including accessing external data briefly discuss and its current technical embodiment 
6916 en Meta Metadata extensible semantic architecture for multimedia metadata definition extraction and presentation This paper introduces new extensible architecture for defining the metadata multimedia from different sources extracting this metadata from documents and representing users introduce meta metadata semantic data structures that guide the extraction and manipulation strongly typed metadata including visual representations from diverse documents Meta metadata declarations are automatically translated into metadata class definitions Both are defined using the ecologylab xml information binding framework Extensions the framework support manipulation instances the generated metadata classes with generic field accessor objects enabling information extraction information visualization contextual metadata presentation editing and interaction show how meta metadata and the metadata generates are used the mixed initiative information composition information discovery support tool combinFormation 
6917 en  System Ontologies and Services for Hypermedia Authoring the Web Manual authoring hypermedia from collections media and metadata hardly manageable task for non professional users The use semantic annotation and intelligent authoring systems allows the automatic generation stereotyped hypermedia presentations with effective communication power entrusting the intelligent system the management constraints content structuring and design decisions this work present software platform supporting the development hypermedia authoring applications The platform composed several web services based combination logic programming and semantic web technologies Every services share common underlying semantic layer describing media assets concepts representations and attributes the authoring process Two sample applications illustrate the usage the platform the Semantic Image Gallery service which allows semantically search and virtually organize collections images and the Hyper Atlas service which realizes the automatic generation hypermedia presentations navigable according hierarchy concepts 
6918 en  Semantic Model for the Authorisation Context Aware Content Adaptation Nowadays users want able access their computing resources and all kind content using different types devices from wireless portable devices stationary devices connected local area networks way that context based content adaptation has become essential for Universal Multimedia Access UMA scenarios This content adaptation represents the modification object possibly subjected the Intellectual Property law and the original author rights holder should able retain the possibility vetoing restricting the operation Whereas MPEG addresses the adaptation the part the standard DIA Digital Item Adaptation and the Rights Expressions Language REL the part still lacks integrated approach them nThis paper considers the authorisation context aware content adaptation generic multimedia scenario based the integration two new standard based ontologies providing bridge between them semantic level First presented the Context Aware Ontology CAO which models the Universal Environment Descriptor UED tool contained the MPEG DIA standard Then introduced the Adaptation Authoriser based the RRDOnto Represent Rights Data ontology which grants that rights will respected along the Value Chain while supporting the MPEG License model Finally the integration both described providing joint model that allows the adaptation controlled Content Creators and Content Distributors 
6920 en Tag Suggestr Automatic Photo Tag Expansion using Visual Information for Photo Sharing Websites this paper propose automatic photo tag expansion system for the community photo collections such Flickr Our aim suggest relevant tags for target photograph uploaded the system user incorporating the visual and textual cues from other related photographs the first step the system requires the user add only few initial tags for each uploaded photo These initial tags are used retrieve related photos including the same tags their tag lists The set candidate tags collected from large pool photos weighted according the similarity the target photo the retrieved photo including the tag Finally the tags the highest rankings are used automatically expand the tags the target photo The experimental results Flickr photos show that the use visual similarity semantically relevant photos recommend tags improves the quality suggested tags compared other techniques that use only text information 
6921 en WhoAmI Web2 Platform for Faceted Identity Management through Aggregation Social Media this paper describe methods and implementation for the aggregation and visualization personal social media consider important offer non proprietary software that capable raise awareness for diverse aspects mediated identity nThis issue has become important especially over the course the past five years where the role users changed more and more from consumers towards prosumers giving away facets their daily life commodity nIntelligent aggregation such social media may lead coarse descriptions digital identities observed over long enough time periods Our tool offers such possibilities users who are concerned about the way they deal with their life and its digital representation the public nThis paper also outlines number reasons why one should concerned about this which are confirmed small user study that conducted 
6923 en Clustering Visual Data using Ant inspired Methods
6925 en Eliminating the Back Tracking Step the Longest Common Subsequence LCSS Algorithm for Video Sequence Matching
6926 en Research Networks and Media the Framework Programme Results Trends and Prospects
6927 en PLATO for Information Mining Satellite Imagery Satellite images are numerous and weakly exploited urgent develop efficient and fast indexing retrieval system easy their access Content based image retrieval systems CBIR are known provide efficient framework thus propose associate CBIR approach with text based queries adapt these big 12000 times 12000 pixels and semantically rich images The presented system relies multimedia data mining system called PLATO able adapt any kind multimedia data Moreover state the art relevance feedback strategy introduced provide interactive learning and auto annotation 
6928 en Semantic driven multimedia retrieval with the MPEG Query Format The MPEG Query Format MPQF new standard from the MPEG standardization committee which provides standardized interface multimedia document repositories The purpose this paper describing the necessary modifications which will allow MPQF manage metadata modelled with Semantic Web languages like RDF and OWL and query constructs based SPARQL The suggested modifications include the definition new MPQF query type and generalization the MPQF metadata processing model far know this the first work apply the MPEG Query Format semantic driven search and retrieval multimedia contents 
6929 en Enriching Thesaurus Improve Retrieval Audiovisual Documents many archives audiovisual documents annotation and retrieval are done using metadata from structured vocabulary thesaurus practice many these thesauri have limited structure The objective this paper find out whether retrieval audiovisual resources from collection indexed with house thesaurus can improved anchoring the thesaurus external semantically richer thesaurus propose method enrich the structure thesaurus and investigate its added value for retrieval purposes nWe first anchor the thesaurus external resource WordNet From this anchoring infer relations between pairs terms the thesaurus that were previously unrelated employ the enriched thesaurus retrieval experiment TRECVID 2007 data set The results are promising with simple techniques are able enrich thesaurus such way that adds retrieval performance 
6930 en Validating the Detection Everyday Concepts Visual Lifelogs The Microsoft SenseCam small lightweight wearable camera used passively capture photos and other sensor readings from user day day activities can capture 000 images per day equating almost million images per year used aid memory creating personal multimedia lifelog visual recording the wearer life However the sheer volume image data captured within visual lifelog creates number challenges particularly for locating relevant content Within this work explore the applicability semantic concept detection method often used within video retrieval the novel domain visual lifelogs concept detector models the correspondence between low level visual features and high level semantic concepts such indoors outdoors people buildings etc using supervised machine learning doing determines the probability concept presence apply detection everyday semantic concepts lifelog collection composed 257 518 SenseCam images from users The results were then evaluated subset 907 images determine the precision for detection each semantic concept and draw some interesting inferences the lifestyles those users additionally present future applications concept detection within the domain lifelogging 
6931 en Using Fuzzy DLs Enhance Semantic Image Analysis Research image analysis has reached point where detectors can learned generic fashion for significant number conceptual entities The obtained performance however exhibits versatile behaviour reflecting implications over the training set selection similarities visual manifestations distinct conceptual entities and appearance variations the conceptual entities factor partially accountable for these limitations relates the fact that machine learning techniques realise the transition from visual features conceptual entities based solely information regarding perceptual features Hence significant part knowledge missed this paper investigate the use formal semantics order benefit from the logical associations between the conceptual entities and thereby alleviate part the challenges involved extracting semantic descriptions More specifically fuzzy based reasoning framework proposed for the extraction enhanced image descriptions based initial set graded annotations generated through generic image analysis techniques Under the proposed reasoning framework the initial descriptions are integrated semantic level resolving inconsistencies emanating from conflicting descriptions Furthermore the descriptions are enriched means entailment resulting more complete image descriptions Experimentation the domain outdoor images has shown very promising results demonstrating the added value terms accuracy and completeness 
6932 en Labelling Image Regions Using Wavelet Features and Spatial Prototypes this paper present approach for image region classification that combines low level processing with high level scene understanding For the low level training predefined image concepts are statistically modeled using wavelet features extracted directly from image pixels For classification features given test region compared with these statistical models provide probabilistic evaluations for all possible image concepts Maximizing these values themselves already leads classification result label However our paper they are used input for the high level approach exploiting explicitly represented spatial arrangements labels called spatial prototypes formalize the problem using Fuzzy Constraint Satisfaction Problems and Linear Programming They provide model with explicit knowledge that suitable aid the task region labeling Results experiments performed for more than 6000 test image regions show that using the combination low level and high level image analysis increases the labeling accuracy significantly 
6933 en Data the people for the people What can learn from social media and community contributed collections information the web The most salient attribute social media the creation environment that promotes user contributions the form authoring curation discussion and use content This activity generates large volumes data including some types data that were not previously available Even more importantly design decisions these applications can directly influence the users motivations participate and hugely affect the resultant data will discuss the cycle social media and argue that holistic approach social media systems which includes design applications and user research can advance data mining and information retrieval systems Using Flickr example will describe study which examine what motivates users add tags and geotags their photos The new data enables extraction meaningful not say semantic information from the Flickr collection use the extracted information for example produce summaries and visualizations the Flickr collection making the repository more accessible and easier search browse and understand scales the process the user input helps alleviate previously intractable problems multimedia content analysis 
6935 en The Sample Complexity Learning the Kernel The success kernel based learning algorithms depends upon the suitability the kernel the learning ntask Ideally the choice kernel should based prior information the learner about the task hand nHowever practice kernel parameters are being tuned based available training data will discuss the nsample complexity overhead associated with such ”learning the kernel” scenarios will address the setting nin which the training data for the kernel selection target labeled examples well settings which this ntraining based erent types data such unlabeled examples and examples labeled erent but related tasks Part this work joint with Nati Srebro 
6936 en Second Order Optimization Kernel Parameters investigate the use second order optimization approaches for solving the multiple kernel learning MKL nproblem show that the hessian the MKL can computed ciently and this information can used nto compute better descent direction than the gradient used the state the art SimpleMKL algorithm nWe then empirically show that our new approaches outperforms SimpleMKL terms computational ciency 
6937 en Multi Kernel Learning for Biology One the primary tasks facing biologists today integrate the erent views molecular biology that nare provided various types experimental data yeast for example for given gene typically know nthe protein encodes that protein’ similarity other proteins the mRNA expression levels associated with nthe given gene under hundreds experimental conditions the occurrences known inferred transcription nfactor binding sites the upstream region that gene and the identities many the proteins that interact nwith the given gene’ protein product Each these distinct data types provides one view the molecular nmachinery the cell nKernel methods allow represent these heterogeneous data types normal form and use kernel nalgebra reason about more than one type data simultaneously Consequently multi kernel learningnmethods have been applied variety biology applications this talk will describe several these napplications outline the lessons have learned from applying multi kernel learning methods real data nand suggest several avenues for future research this area 
6940 en Multi Task Learning via Matrix Regularization
6941 en Feature Selection From Correlation Causality Variable and feature selection have become the focus much research areas application for which ndatasets with tens hundreds thousands variables are available These areas include text processing ofninternet documents gene expression array analysis and combinatorial chemistry The jective variable nselection three fold improving the prediction performance the predictors providing faster and more ncost ective predictors and providing better understanding the underlying process that generated the ndata This tutorial will cover wide range aspects such problems providing better deﬁnition nthe jective function feature construction feature ranking multivariate feature selection cient search nmethods and feature validity assessment methods Most feature selection methods not attempt nuncover causal relationships between feature and target and focus instead making best predictions nwill examine situations which the knowledge causal relationships beneﬁts feature selection Such beneﬁts nmay include explaining relevance terms causal mechanisms distinguishing between actual features and nexperimental artifacts predicting the consequences actions performed external agents and making npredictions non stationary environments 
6942 en Learning Bounds for Support Vector Machines with Learned Kernels
6943 en Mixed Norm Kernels Hyperkernels and Other Variants
6945 en Infinite Kernel Learning this paper build upon the Multiple Kernel Learning MKL framework rewrite the problem nin the standard MKL formulation which leads Semi Inﬁnite Program devise new algorithm nsolve Inﬁnite Kernel Learning IKL The IKL algorithm applicable both the ﬁnite and inﬁnite case nand ﬁnd faster and more stable than SimpleMKL Furthermore present the ﬁrst large scale ncomparison SVMs MKL variety benchmark datasets also comparing IKL The results show ntwo things for many datasets there beneﬁt using MKL IKL instead the SVM classiﬁer thus nthe ﬂexibility using more than one kernel seems use some datasets IKL yields massive nincreases accuracy over SVM MKL due the possibility using largely increased kernel set For those ncases parameter selection through Cross Validation MKL not applicable 
6946 en Kernel Learning for Novelty Detection consider kernel learning for one class Support Vector Machines consider mix and norms nof the individual weight vector norms allowing control the sparsity the resulting kernel combination nThe resulting optimisation can solved ciently using coordinate gradient method consider napplication automatically detecting the appropriate metric for guided image search task 
6947 en Optimization Machine Learning Recent Developments and Current Challenges The use optimization framework for formulating machine learning problems has become much more widespread recent years some cases the demands the machine learning problems beyond the scope traditional optimization paradigms While existing optimization formulations and algorithms serve good starting point for the solution strategies important work must carried out the interface optimization and machine learning devise strategies that exploit the special features the application and that perform well very large data sets This talk reviews recent developments from optimization perspective focusing activity during the past three years and looking particular problems where the machine learning application has motivated novel algorithms analysis the optimization domain also discuss some current challenges highlighting several recent developments optimization that may useful machine learning applications 
6948 en Online and Batch Learning Using Forward Looking Subgradients
6949 en Robustness and Regularization Support Vector Machines consider robust classiﬁcation problem and show that standard regularized nSVM special case our formulation providing explicit link between reg nularization and robustness the same time the physical connection noise and nrobustness suggests the potential for broad new family robust classiﬁcation nalgorithms Finally show that robustness fundamental property classi nﬁcation algorithms proving consistency support vector machines using nonly robustness arguments instead dimension stability 
6950 en Training Binary Classifier with the Quantum Adiabatic Algorithm This paper describes how make the problem binary classiﬁcation amenable nquantum computing formulation employed which the binary classiﬁer nconstructed thresholded linear superposition set weak classiﬁers The nweights the superposition are optimized learning process that strives min nimize the training error well the number weak classiﬁers used efﬁcient nsolution this problem known bring into format that allows the applica ntion adiabatic quantum computing AQC ﬁrst show that the bit precision nwith which the weights need represented only grows logarithmically with the nratio the number training examples the number weak classiﬁers This nallows effectively formulate the training process binary optimization prob nlem Solving with heuristic solvers such tabu search ﬁnd that the resulting nclassiﬁer outperforms widely used state the art method AdaBoost nriety benchmark problems Moreover discovered the interesting fact that nbit constrained learning machines often exhibit lower generalization error rates nChanging the loss function that measures the training error from loss least nsquares maps the training quadratic unconstrained binary optimization This ncorresponds the format required Wave’ implementation AQC Simu nlations with heuristic solvers again yield results better than those obtained with nboosting approaches Since the resulting quadratic binary program hard nadditional gains can expected from applying the actual quantum processor 
6951 en Polyhedral Approximations Convex Optimization propose unifying framework for solution convex programs polyhedral approximation includes classical methods such cutting plane Dantzig Wolfe decomposition bundle and simplicial composition but also includes refinements these methods well new methods that are well suited for important large scale types problems arising for example network optimization 
6952 en Large scale Machine Learning and Stochastic Algorithms The presentation stresses important differences between machine learning and conventional optimisation approaches and proposes some solutions The first part discusses the the interaction two kind asympotic properties those the statistics and those optimization algorithm Unlikely optimization algorithm such stochastic gradient show amazing performance for large scale machine learning problems The second part shows how the deeper causes this performance suggests the theoretical possibility learn large scale problems with single pass over the data Practical algorithms will discussed various second order stochastic gradients averaging methods dual methods with data reprocessing 
6953 en  Improved Branch and Bound Method for Maximum Monomial Agreement The hard maximum monomial agreement MMA problem consists ﬁnd ning single logical conjunction that best ﬁts weighted dataset “positive” and “negative” binary vectors Computing classiﬁers using boosting methods involves maximum agreement subproblem each iteration although such subproblems nare typically solved heuristic methods Here describe exact branch nand bound method for maximum agreement over Boolean monomials improv ning the earlier work Goldberg and Shan particular develop ntighter upper bounding function and improved branching procedure that nploits knowledge the bound and the dataset while having lower branching nfactor Experimental results show that the new method able solve larger nproblem instances and runs faster within linear programming boosting proce ndure applied medium sized datasets from the UCI repository 
6954 en Tuning Optimizers for Time Constrained Problems using Reinforcement Learning Many popular optimization algorithms like the Levenberg Marquardt algorithm LMA use heuristic based “controllers” that modulate the behavior the ntimizer during the optimization process For example the LMA damping nparameter dynamically modiﬁed based set rules that were developed nusing various heuristic arguments Here show that modern reinforcement nlearning technique utilizing very simple state space can dramatically improve nthe performance general purpose optimizers like the LMA problems where nthe number function evaluations allowed constrained budget Results nare given both classical non linear optimization problems well difﬁcult ncomputer vision task Interestingly the controllers learned for particular opti nmization domain work well other optimization domains Thus the controller nappeared have extracted optimization rules that were not just domain speciﬁc nbut generalized across range optimization domains 
6956 en Welcome and program presentation short overview over the posters Machine learning has traditionally been focused prediction Given observations that have been generatednby unknown stochastic dependency the goal infer law that will able correctly predict futurenobservations generated the same dependency Statistics contrast has traditionally focused datanmodeling the estimation probability law that has generated the data During recent years thenboundaries between the two disciplines have become blurred and both communities have adopted methodsnfrom the other however probably fair say that neither them has yet fully embraced the ﬁeldnof causal modeling the detection causal structure underlying the data Since the Eighties there hasnbeen community researchers mostly from statistics and philosophy who have developed methods aimingnat inferring causal relationships from observational data While this community has remained relativelynsmall has recently been complemented number researchers from machine learning The goal ofnthis workshop discuss new approaches causal discovery from empirical data their applications andnmethods evaluate their success Emphasis will put the deﬁnition objectives reached andnassessment methods evaluate proposed solutions The participants are encouraged participate ancompetition pot luck which datasets and problems will exchanged and solutions proposed 
6959 en Benchmarks wikis and open source causal discovery
6960 en Causal Structure Search Philosophical Foundations and Future Problems
6961 en Distinguishing Causes from Effects using Nonlinear Acyclic Causal Models
6962 en Causal models conditional density models
6963 en Analysis the binary instrumental variable model
6965 en Introduction and overwiew believe that the wide spread adoption open source software policies will have tremendous ipactnon the ﬁeld machine learning The goal this workshop further support the current dvelopmentsnin this area and give new impulses Following the success the inaugural NIPS MLOSS workshopnheld NIPS 2006 the Journal Machine Learning Research JMLR has started new track for machinenlearning open source software initiated the workshop’ organizers Many prominent machine learningnresearchers have authored position paper advocating the need for open source software machinenlearning Furthermore the workshop’ organizers have set community website mloss org where peoplencan register their software projects rate existing projects and initiate discussions about projects and relatedntopics This website currently lists 156 such projects including many prominent projects the area ofnmachine learning The main goal this workshop bring the main practitioners the area machinenlearning open source software together order initiate processes which will help further improve thendevelopment this area particular have move beyond mere collection more less unrelatednsoftware projects and provide common foundation stimulate cooperation and interoperability betweenndi erent projects important step this direction will common data exchange format such thatndi erent methods can exchange their results more easily 
6966 en Octave GNU Octave high level language primarily intended for numerical computations provides con nvenient command line interface for solving linear and nonlinear problems numerically and for performingnother numerical experiments using language that mostly compatible with Matlab may also usednas batch oriented language 
6967 en Torch Torch provides Matlab like environment for state the art machine learning algorithms easy usenand very cient thanks simple yet powerful fast scripting language Lua and underlying nimplementation Torch easily extensible and has been shown scale very large applications 
6968 en Shark Shark machine learning library Tutorials and html documentation make Shark easy learn nThe installation Shark straightforward does not depend any third party software and compilesnunder Linux Solaris MacOS and Windows Various example programs serve starting points for ownnprojects Shark provides methods for linear and nonlinear optimization particular evolutionary andngradient based algorithms comes with erent types artiﬁcial neural networks ranging from standard
6969 en Kernlab kernlab package providing kernel based machine learning functionality designed providentools for kernel algorithm development but also includes range popular machine learning methods fornclassiﬁcation regression clustering novelty detection quantile regression and dimensionality reduction nAmong other algorithms included the package are Support Vector Machines Spectral Clustering KernelnPCA solver and range kernels Gaussian Laplacian string kernels etc 
6970 en Machine Learning mlpy introduce mlpy high performance Python package for predictive modeling makes extensive use ofnNumPy provide fast dimensional array manipulation and easy integration code Mlpy provides highnlevel procedures that support with few lines code the design rich Data Analysis Protocols DAPs fornpredictive classiﬁcation and feature selection Methods are available for feature weighting and ranking datanresampling error evaluation and experiment landscaping The package includes tools measure stabilitynin sets ranked feature lists special interest bioinformatics for functional genomics for which largenscale experiments with 106 classiﬁers have been run Linux clusters and the Grid 
6971 en MDP – Modular toolkit for Data Processing Modular toolkit for Data Processing MDP Python data processing framework From the user’ per nspective MDP collection supervised and unsupervised learning algorithms and other data processingnunits that can combined into data processing sequences and more complex feed forward network archi ntectures From the scientiﬁc developer’ perspective MDP modular framework which can easily benexpanded nnThe implementation new algorithms easy and intuitive The new implemented units arenthen automatically integrated with the rest the library The base available algorithms steadily ncreasing and includes name but the most common Principal Component Analysis PCA and NIPALS nseveral Independent Component Analysis algorithms CuBICA FastICA TDSEP and JADE Slow FeaturenAnalysis Gaussian Classiﬁers Restricted Boltzmann Machine and Locally Linear Embedding 
6972 en What good mloss project
6973 en Matplotlib matplotlib python plotting library which produces publication quality ﬁgures variety hardcopynformats and interactive environments across platforms matplotlib can used python scripts the pythonnand ipython shell ala matlab mathematica web application servers and works with six graphical userninterface toolkits matplotlib tries make easy things easy and hard things possible You can generatenplots histograms power spectra bar charts error charts scatter plots etc with just few lines code nFor the power user you have full control line styles font properties axes properties etc via objectnoriented interface via handle graphics interface familiar matlab users 
6974 en Disco Disco open source implementation the Map Reduce framework for distributed computing thenoriginal framework Disco supports parallel computations over large data sets unreliable cluster com nputers You don’ need cluster use Disco – script provided that installs Disco automatically thenAmazon’ EC2 computing cloud where you get computing resources demand basis 
6975 en Nieme Nieme machine learning library for large scale classiﬁcation regression and ranking relies the framework energy based models which uniﬁes several learning algorithms ranging from simple perceptronsnto recent models such the Pegasos support vector machine regularized maximum entropy models nThis framework also uniﬁes batch and stochastic learning which are both seen energy minimizationnproblems Nieme can hence used wide range situations but particularly interesting for very nlarge scale learning tasks where both the examples and the features are processed incrementally Being ablento deal with new incoming features any time within the learning process another key feature thenNieme toolbox Nieme released under the GPL license ciently implemented and worksnon Linux MacOS and Windows Interfaces are available for Java and Python 
6976 en libDAI libDAI free and open source library licensed under GPL that provides implementations ofnvarious approximate inference methods for discrete graphical models libDAI supports arbitrary factorngraphs with discrete variables this includes discrete Markov Random Fields and Bayesian Networks Thenlibrary targeted researchers able use the library good understanding graphical modelsnis needed Currently libDAI supports the following approximate inference methods exact inference bynbrute force enumeration exact inference junction tree methods Mean Field Loopy Belief Propagation nTree Expectation Propagation Generalized Belief Propagation Double loop GBP and various variants ofnLoop Corrected Belief Propagation Planned extensions are Gibbs sampling and IJGP well variousnmethods for obtaining bounds the partition sum and marginals Bound Propagation Box Propagation nTree based Reparameterization 
6977 en BCPy2000 BCPy2000nJeremy Hill Max Planck Institute for Biological Cybernetics ¨ ubingen GermanynBCPy2000 provides platform for rapid ﬂexible development experimental Brain Computer Interfacensystems based the BCI2000 org project From the developer’ point view the implementation isncarried out Python taking advantage various high level packages VisionEgg for stimulus presentation nNumPy and SciPy for signal processing and classiﬁcation and IPython for interactive debugging BCPy2000nimplements lot infrastructure allowing you get new experiments and running quickly alsoncontains set optional tools which are still work progress but which are rapidly turning into ankind “standard library” object oriented signal processing and stimulus widgets These features makenit ﬂexible platform for developers new NumPy SciPy based machine learning algorithms the ﬁeld ofnrealtime biosignal analysis 
6978 en Model Monitor Common practice Machine Learning often implicitly assumes stationary distribution meaning that thendistribution particular feature does not change over time practice however this assumption oftennviolated and real world models have retrained result would helpful then able tonanticipate and plan for changes distribution order avoid this retraining Model Monitor Javantoolkit that addresses this problem provides methods for detecting distribution shifts data comparingnthe performance multiple classiﬁers under shifts distribution and evaluating the robustness individualnclassiﬁers distribution change such allows users determine the best model models for theirndata under number potential scenarios Additionally Model Monitor fully integrated with the WEKAnmachine learning environment that variety commodity classiﬁers can used desired 
6979 en  Glue and Codecs Glue Glue protocol and software implementation for evaluating reinforcement learning algorithms Ournsystem facilitates the comparison alternative algorithms and can greatly accelerate research progress asnthe UCI database has accelerated progress supervised machine learning Creating comparable bench nmarking resource for reinforcement learning challenging because the temporal nature reinforcementnlearning Reinforcement learning agents interact with dynamic process the environment which gener nates observations and rewards The observations and rewards received the learning agent depend the actions training data cannot simply stored ﬁle they are supervised learning Instead the rein nforcement learning agent and environment must interacting programs Glue agents and environmentsncan written Java Matlab Python and Lisp and can all run one machine can connectnacross the Internet this seminar will introduce the design principles that helped shape Gluenand demonstrate some the interesting extensions that have been created the reinforcement learningncommunity 
6980 en Experiment Databases for Machine Learning Experiment Databases for Machine Learning large public repository machine learning experiments asnwell framework for producing similar databases for speciﬁc goals This projects aims bring the infor nmation contained many machine learning experiments together and organize way that allows everyonento investigate how learning algorithms have performed previous studies share such information withnthe world common language proposed dubbed ExpML capturing the basic structure large rangenof machine learning experiments while remaining open for future extensions This language also enforcesnreproducibility requiring links the used datasets and algorithms and storing all details the nperiment setup All stored information can then accessed querying the database creating powerfulnway collect and reorganize the data thus warranting very thorough examination the stored results nThe current publicly available database contains over 500 000 classiﬁcation and regression experiments andnhas both online interface http expdb kuleuven well stand alone explorer tool eringnvarious visualization techniques This framework can also integrated machine learning toolboxes tonautomatically stream results global local experiment database download experiments thatnhave been run before 
6983 en Recent Advances Learning Sparse Structured Input Output Model Models Algorithms and Applications
6984 en Integrating Ontological Prior Knowledge into Relational Learning
6985 en Relation Prediction Multi Relational Domains using Matrix Factorization
6987 en Joint Learning Multiple Structured Output Prediction Tasks
6989 en Joint Kernel Support Estimation for Structured Prediction
6990 en Learning Optimal Subsets with Implicit User Preferences
6991 en Learning Structural Support Vector Machines with Latent Variables
6992 en Algebraic statistics for random graph models Markov bases and their uses use algebraic geometry study statistical model for the analysis networks represented graphs with directed edges due Holland and Leinhardt known which allows for differential attraction popularity and expansiveness well additional effect due reciprocation particular attempt derive Markov bases for and link these the results Markov bases for working with log linear models for contingency tables Because the contingency table representation for expect some form congruence Markov bases and related algebraic geometry notions are useful for least two statistical problems determining condition for the existence maximum likelihood estimates and using them traverse conditional given minimal sufficient statistics sample spaces and thus generating exact distributions useful for assessing goodness fit outline some these potential uses for the algebraic representation 
6993 en Algebraic statistics and contingency tables this talk will give overview the role algebraic statistics the statistical analysis contingency tables will survey major areas which algebraic methods proved crucial and provided fertile ground for novel research directions computation sharp integer bounds for cell entries existence maximum likelihood estimates simulation from probability distributions spaces tables Markov bases high dimensional sparse tables with structural zeros log linear model selection will give examples that illustrate this methodology and talk about open problems 
6994 en Toric Modification Mixture Models the Bayes estimation was pointed out that resolution singularity provides algorithm elucidate the generalization performance learning machines However there effective procedure find the resolution map This presentation proposes new method find based the toric modification using Newton diagram the proposed method learning curves several hierarchical models are clarified 
6995 en Learning Parameters Discrete Naive Bayes Models Computing Fibers the Parametrization map Discrete Naive Bayes models are usually defined parametrically with map from parameter space probability distribution space First present two families algorithms that compute the set parameters mapped given discrete Naive Bayes distribution satisfying certain technical assumptions Using these results then present two families parameter learning algorithms that operate projecting the distribution observed relative frequencies dataset onto the discrete Naive Bayes model considered They have nice convergence properties but their computational complexity grows very quickly with the number hidden classes the model 
6996 en Stationary Subspace Analysis Non stationarities are ubiquitous phenomenon real world data yet they challenge standard Machine Learning methods training and test distributions differ cannot principle gen eralise from the observed training sample the test distribution This affects both supervised and unsupervised learning algorithms classification problem for instance may infer spurious dependen cies between data and label from the the training sample that are mere artefacts the non stationarities Conversely identifying the sources non stationary behaviour order better understand the analyzed system often lies the heart scientific question this end propose novel unsupervised paradigm Stationary Subspace Analysis SSA SSA decomposes multi variate time series into stationary and non stationary subspace derive efficient algorithm that hinges optimization procedure the Special Orthogonal Group exploiting the Lie group structure the optimization manifold can explicitly factor out the inherent symmetries the problem and thereby reduce the number parameters the exact degrees freedom The practical utility our approach demonstrated application Brain Computer Interfacing BCI 
6997 en Alternatives the Discrete Fourier Transform well known that the discrete Fourier transform DFT finite length discrete time signal samples the discrete time Fourier transform the same signal equidistant points the unit circle Hence the signal length goes infinity the DFT approaches the DTFT Associated with the DFT are circular convolution and periodic signal extension this paper identify large class alternatives the DFT using the theory polynomial algebras Each these Fourier transforms approaches the DTFT just the DFT does but has its own signal extension and notion convolution which therefore are not periodic Furthermore these Fourier transforms have Vandermonde structure which enables their computation via fast log algorithms 
6998 en Graph Helmholtzian and rank learning The graph Helmholtzian the graph theoretic analogue the Helmholtz operator vector Laplacian much the same way the graph Laplacian the analogue the Laplace operator scalar Laplacian will see that decomposition associated with the graph Helmholtzian provides way learn ranking information from incomplete imbalanced and cardinal score based data this framework edge flow representing pairwise ranking orthogonally resolved into gradient flow acyclic that represents the optimal global ranking and divergence free flow cyclic that quantifies the inconsistencies the latter large then the data does not admit statistically meaningful global ranking further decomposition the inconsistent component into curl flow locally cyclic and harmonic flow locally acyclic provides information the validity small and large scale comparisons alternatives This joint work with Xiaoye Jiang Yuan Yao and Yinyu 
6999 en Identity Management Homogeneous spaces consider the identity management problem where the identities are classified into two classes red and blue The purpose here make predictions the two class identities when confusions arise among identities this work propose principle maintain probability distributions over homogeneous space which provides mechanism valid for taking into account any desired degree approximation Markov models are used formulate the two class identity management problem which tries compactly summarize distributions homogeneous spaces Projecting down and lifting information different order statistics can achieved using Radon transformations The commutative property Markov updating with Radon transform enable maintain exact information over different order statistics Thus accurate classification predictions can made based the low order statistics maintained evaluate the performance our algorithms real camera network data and show effectiveness our scheme 
7000 en Adaptive Fourier Domain Inference the Symmetric Group
7001 en Consistent Structured Estimation for Weighted Bipartite Matching Given weighted bipartite graph the assignment problem consists finding the heaviest perfect match This classical problem combinatorial optimization which solvable exactly and efficiently standard methods such the Hungarian algorithm and widely applicable real world scenarios give exponential family model for the assignment problem Edge weights are obtained from suitable composition edge features and parameter vector which learned maximize the likelihood sample consisting training graphs and their labeled matches The resulting consistent estimator contrasts with existing max margin structured estimators which are inconsistent for this problem 
7002 en Beyond Search Computational Intelligence for the Web Introduction
7003 en Collective Wisdom Information Growth Wikis and Blogs Wikis and blogs have become enormously successful media for collaborative information creation Articles and posts accrue information through the asynchronous editing users who arrive both seeking information and possibly able contribute information Most articles stabilize high quality trusted sources information representing the collective wisdom all the users who edited the article propose model for information growth which relies two main observations article quality improves attracts visitors faster rate rich get richer phenomenon and simultaneously the chances that new visitor will improve the article drops there only much that can said about particular topic Our model able reproduce many features the edit dynamics observed Wikipedia and blogs collected from LiveJournal particular captures the observed rise the edit rate followed decay 
7005 en Beyond the Semantic Web There are multiple sources power available for forming and propelling automobiles analogously there are several sources power for forming and propelling thoughts Besides the neural ones you most familiar with and the Semantic Web ones that have received the lion share hype recent years there are some additional ones that are tapping into with some success These deep semantic representations and operations are able produce useful and cases even novel conclusions requiring induction abduction and analogy well deductive reasoning will illustrate this with case examples from recent Cyc applications including terrorism scenario generation for intelligence analysts and hoc clinical trial question answering for medical researchers 
7006 en Knowledge Representation and Reasoning Discussion
7007 en Scalable Collaborative Filtering Algorithms for Mining Social Networks Social networking sites such Orkut MySpace Hi5 and Facebook attract billions visits day surpassing the page views Web Search These social networking sites provide applications for individuals establish communities upload and share documents photos videos and interact with other users Take Orkut example Orkut hosts millions communities with hundreds communities created and tens thousands blogs photos uploaded each hour assist users find relevant information essential provide effective collaborative filtering tools perform recommendations such friend community and ads matching this talk will first describe both computational and storage challenges traditional collaborative filtering algorithms brought aforementioned information explosion deal with huge social graphs that expand continuously effective algorithm should designed run thousands parallel machines for sharing storage and speeding computation perform incremental retraining and updates for attaining online performance and fuse information multiple sources for alleviating information sparseness the second part the talk will present algorithms recently developed including parallel Spectral Clustering parallel Growth parallel combinational collaborative filtering parallel LDA parallel spectral clustering and parallel Support Vector Machines 
7009 en Interactively Optimizing Information Systems Dueling Bandits Problem present online learning framework tailored towards real time learning from observed user behavior search engines and other information access systems particular only require pairwise comparisons which were shown reliably inferred from implicit feedback will present algorithm with theoretical guarantees well simulation results 
7011 en Online Search and Advertising Future and Present Search engine companies are gathering treasure troves user generated data has already been shown that such data can used directly improve the user online experience will discuss some ideas what online search and advertising might look like few years hence light the algorithms and data have now Moving from future present will outline some recent work done researchers the Text Mining Search and Navigation team Microsoft Research the work TMSN touches many aspects online search and advertising 
7012 en Machine Learning for the Web Unified View Machine learning and the Web are technology and application area made for each other The Web provides machine learning with ever growing stream challenging problems and massive data with them search ranking hypertext classification information extraction collaborative filtering link prediction targeting social network modeling etc Conversely seemingly just about every conceivable machine learning technique has been applied the Web Can make sense this vast jungle techniques and applications Instead attempting impossible exhaustive survey will instead try distill unified view the field from our experience date using the language Markov logic networks which has most the statistical models used the Web special cases and the state the art learning and inference algorithms for will able cover lot ground short time understand the fundamental structure the problems and solutions and see how combine them into larger systems 
7013 en Search Query Disambiguation from Short Sessions Web searches tend short and ambiguous therefore not surprising that Web query disambiguation actively researched topic However most existing work relies the existence search engine log data which each user search activities are recorded over long periods time Such approaches may raise privacy concerns and may difficult implement for pragmatic reasons this work present approach Web query disambiguation that bases its predictions only short glimpse user search activity captured brief session about previous searches average Our method exploits the relations the current search session which the ambiguous query issued previous sessions order predict the user intentions and based Markov logic present empirical results that demonstrate the effectiveness our proposed approach data collected form commercial general purpose search engine 
7014 en Machine Learning Market Design and Advertising Given the complexity preferences markets such key word advertising hard believe that the facto standard decentralized local greedy algorithmn advertisers bid for clicks keywords any where close being optimal for any reasonable objective welfare profit etc this talk consider the market design problem from global perspective make connections between machine learning theory and market design theory where machine learning design problems closely mirror game theoretic design problems reduce general theoretical market design problem natural machine learning optimization problem These theoretical results lead number practical answers advertising market design questions 
7015 en Internet Advertising and Optimal Auction Design This talk describes the optimal revenue maximizing auction for sponsored search advertising show that search engine optimal reserve price independent the number bidders Using simulations consider the changes that result from search engine choice reserve price and from changes the number participating advertisers 
7016 en Learning optimally from self interested data sources line auctions the analysis current online auctions essential parameters such click through rates are often assumed known The disregard the uncertainty that present reality leads several serious problems the talk will highlight two there principled exploration new ads and there incentive for advertisers only subscribe well targeted key words fact there interesting opportunity for very poorly targeting advertisers exploit this fact present new auction that solves both problems The key trick for this auction that advertisers are not only requested submit bid but also belief over their own click through rate 
7018 en Multiview Clustering via Canonical Correlation Analysis Clustering algorithms such means perform poorly when the data highdimensional number efficient clustering algorithms developed recent years address this problem projecting the data into lower dimensional subspace via principal components analysis PCA random projections before clustering Such techniques typically require stringent requirements the separation between the cluster means Here present ongoing work projection based clustering that addresses this using multiple views the data use canonical correlation analysis CCA nto project the data each view lower dimensional subspace Under the assumption that the correlated dimensions capture the information about the cluster identities the separation conditions required for the algorithm successful are significantly weaker than those prior results the literature describe experiments two domains speech audio and images the speakers’ faces and text and links Wikipedia articles discuss several issues that arise when clustering these domains particular the existence multiple possible “cluster variables” and hierarchical cluster structure 
7019 en Multi View Dimensionality Reduction via Canonical Correlation Analysis analyze the multi view regression problem where have two views the input data and real target variable interest semi supervised learning setting consider two separate assumptions one based redundancy and the other based correlation and show how under either assumption alone dimensionality reduction based CCA could reduce the labeled sample complexity The basic semi supervised algorithm follows with unlabeledndata perform CCA with the labeled data project the inputs onto certain CCA subspace perform dimensionality reduction and then least squares regression this lower dimensional space show how under either assumption the number labeled samples could significantly reduced comparison the single view setting particular show how this dimensionality reduction only introduces little bias but could drastically reduce the variance The two assumptions consider are redundancy assumption and uncorrelated assumption Under the redundancy assumption have that the best predictor from each view roughly good the best predictor using both views Under the uncorrelated assumption have that conditioned the views X1nand are uncorrelated show that under either these assumptions CCA appropriate dimensionality reduction technique are also the process large scale experiments word disambiguation using theWikipedia with the disambiguation pages helping provide labels nThis work presents extensions ideas Ando and Zhang 2007 and Kakade and Foster 2007 
7020 en The Double Barrelled LASSO Sparse Canonical Correlation Analysis present new method which solves double barelled LASSO convex least squares approach the presented method focus the scenario where one interested limited primal feature representation for the first view while having dual kernel representation for the second view LASSO minimises the number features used both the primal and dual projectionsnwhile minimising the error maximising the correlation between the two views 
7021 en Learning Shared and Separate Features Two Related Data Sets using GPLVMs Dual source learning problems can formulated learning joint representation the datansources where the shared information represented terms shared underlying process However there may situations which the shared information not the only useful information nand interesting aspects the data are not common both data sets Some useful features withinnone data set may not present the other and vice versa this complementary property motivatesnthe use multiple data sources over single data sources which capture only one type useful information nnFor instance having two eyes and two streams visual data allows gain Dnimpression the world This ability stereo vision combines both shared features and featuresnprivate each data stream form coherent representation the world common shifted featuresncan used disparity estimation infer depths objects while some features which may benseen one view but not the other due occlusions can provide additional information aboutnthe scene this work present probabilistic generative framework for analysing two sets data where the structure each data set represented terms shared and private latent space nnExplicitly modeling private component for each data set avoids oversimplified representation the within set variation such that the between set variation can modeled more accurately well giving insight into potentially interesting features particular data set Since two data sets may have complex possibly nonlinear relationship use nonparametric Bayesian techniques define Gaussian process priors over the functions from latent data spaces such that each data set modelled Gaussian Process Latent Variable Model GPLVM where the dependency structure captured terms shared and private kernels 
7022 en Multiview Fisher Discriminant Analysis CCA can seen multiview extension PCA which information from two sources used for learning finding subspace which the two views are most correlated However PCA and extension CCA does not use label information Fisher Discriminant Analysis uses label information find informative projections which can more informative supervised learning settings show that FDA and its dual can both formulated generalized eigenproblems enabling kernel formulation derive regularised two view equivalent Fisher Discriminant Analysis and its corresponding dual both which can also formulated generalized eigenproblems then show that these can cast equivalent disciplined convex optimisation problems and subsequently extended multiple views show experimental results EEG dataset and part the PASCAL 2007 VOC challenge dataset 
7023 en Selective Multitask Learning Coupling Common and Private Representations this contribution address the problem selective transfer knowledge multitask learningnfor classification consider selective transfer interesting framework since when tasks are notntruly closely related traditional multitask approaches become suboptimal study two multitask learning frameworks where develop the aforementioned selective transfer paradigm The two scenarios correspond two ways constructing the mapping from examples output space the first naive scenario the hypothesis direct mapping from the input space onto the output space the second one the overall hypothesis space constructed more sophisticate way through cascade mappings into intermediate representation spaces Examples learning methods under the first scenario are Support Vector Machines SVM with linear kernel and Single Layer Perceptrons SLP Learning methods under the second type are Multi Layer Perceptrons MLP and non linear SVMs 
7024 en Regression Canonical Correlation Analysis this paper present Regression Canonical Correlation Analysis extension Canonical Correlation Analysis where one the dimensions fixed and demonstrate how can solved efficiently applied the extension the task query translation the context Cross Lingual Information Retrieval 
7025 en Multiple kernel learning for multiple sources this talk will consider the problem learning predictor from multiple sources information situation common many domains such computer vision bioinformatics will focus primarily the multiple kernel learning framework which amounts consider one positive definite kernel for each source information Natural unanswered questions arise this context namely Can one learn from infinitely many sources Should one prefer closely related sources very different sources worth considering large kernel induced feature space multiple sources 
7026 en  LVM for Data Consolidation Manymachine learning task are involvedwith the transfer information fromone representation corresponding representation tasks where several different observations represent the same underlying phenomenon classical algorithm for feature selection using information from multiple sources representations Canonical Correlation Analysis CCA CCA the objective select features each observation space that are maximally correlated compared dimensionality reduction where the objective represent the data more efficient form suggest dimensionality reduction technique that builds CCA extending the latent space with two additional spaces each specific partition the data the model capable representing the full variance the data this paper suggest generative model for shared dimensionality reduction analogous that CCA 
7027 en Two level infinite mixture for multi domain data The combined unsupervised analysis coupled data sources open problem machine learning particularly important example from the biological domain the analysis mRNA and protein profiles derived from the same set genes either over time under different conditions Such analysis has the potential provide far more comprehensive picture the mechanisms transcription and translation than the individual analysis the separate data sets The problem similar that attacked with traditional Canonical Correlation Analysis CCA but many application areas the CCA assumptions are too restrictive Probabilistic CCA and kernel CCA have both been recently proposed but the former still limited linear relationships and the latter compromises the interpretability the original space this work preset nonparametric model for coupled data that provides interpretable description the shared variability the data well that that isn’ shared whilst being free restrictive assumptions such those found CCA nThe hierarchical model built from two marginal mixtures one for each representation generalisation three more straightforward Each object will assigned one component each marginal and the contingency table describing these joint assignments assumed have been generated mixture tables with independent margins This top level mixture captures the sharednvariability whilst the marginal models are free capture variation specific the respective data sources The number components all three mixtures inferred from the data using novel Dirichlet Process formulation 
7028 en Probabilistic Models for Data Combination Recommender Systems propose method for jointly learning multiple related matrices and show that sharing information between the two matrices such approach allows improve predictive performances for items where one the matrices contains very sparse information While the above justification has focused recommender systems the approach described applicable any two datasets that relate common set items and can represented matrix form Examples such problems could include image data where each image associated with set words for example captioned tagged images sets scientific papers that can represented either using bag words representation terms their citation links and from other papers corpora documents that exist two languages 
7030 en Semi Supervised Learning and Learning via Similarity Functions two key settings for Data dependent Concept Spaces
7031 en Theory Matching Pursuit Kernel Defined Feature Spaces analyse matching pursuit for kernel principal components analysis KPCA proving that the sparse subspace produces sample compression scheme show that this bound tighter than the KPCA bound Shawe Taylor and highly predictive the size the subspace needed capture most the variance the data analyse second matching pursuit algorithm called kernel matching pursuit KMP which does not correspond sample compression scheme However give novel bound that views the choice subspace the KMP algorithm compression scheme and hence provide bound upper bound its future loss Finally describe how the same bound can applied other matching pursuit related algorithms 
7032 en Chromatic PAC Bayes Bounds for Non IID Data Pac Bayes bounds are among the most accurate generalization bounds for classifiers learned with iid data and particularly for margin classifiers However there are many practical cases where the training data show some dependencies and where the traditional iid assumption does not apply Stating generalization bound for such frameworks therefore the utmost interest this work propose the first the best our knowledge pac Bayes generalization bounds for classifiers trained data exhibiting dependencies The approach based the decomposition called dependency graph the data sets independent data through the tool fractional covers Our bounds are very general since being able find upper bound the chromatic number the dependency graph sufficient for get new bounds for specific settings show how our results can used derive bounds for bipartite ranking and windowed prediction 
7034 en Exploiting Cluster Structure Predict The Labeling Graph The nearest neighbor and the perceptron algorithms are intuitively motivated the aims exploit the cluster and linear separation structure the data classified respectively develop new online perceptron like algorithm Pounce exploit both types structure refine the usual margin based analysis perceptron like algorithm now additionally reflect the cluster structure the input space apply our methods study the problem predicting the labeling graph find that when both the quantity and extent the clusters are small may improve arbitrarily over purely margin based analysis 
7035 en Online Prediction Large Diameter Graphs continue our study online prediction the labelling graph show fundamental limitation Laplacian based algorithms the graph has large diameter then the number mistakes made such algorithms may proportional the square root the number vertices even when tackling simple problems overcome this drawback means efficient algorithm which achieves logarithmic mistake bound based the notion spine path graph which provides linear embedding the original graph practice graphs may exhibit cluster structure thus the last part present modified algorithm which achieves the “best both worlds” performs well locally the presencenof cluster structure and globally large diameter graphs 
7036 en Online Graph Prediction with Random Trees
7037 en Representation Prior Knowledge from Bias Meta Bias 
7038 en Generalization Bounds for Indefinite Kernel Machines
7039 en From line Algorithms Data Dependent Generalization
7040 en Study Classification Algorithms using Moment Analysis
7041 en The use Unlabeled Data Supervised Learning the Manifold Dossier
7043 en Learning Temporal Sequence Biological Networks
7044 en Switching Regulatory Models Cellular Stress Response
7045 en Detecting the Presence and Absence Causal Relationships Between Expression Yeast Genes with Very Few Samples
7046 en KIRMES Kernel based Identification Regulatory Modules Euchromatic Sequences
7047 en Approximate Substructure Matching for Biological Sequence Classification
7048 en Predicting Binding Affinities MHC Class Epitopes Across Alleles
7050 en Full Bayesian Survival Models for Analyzing Human Breast Tumors
7051 en Probabilistic assignment formulas mass peaks metabolomics experiments
7052 en Learning “graph mer” motifs that predict gene expression trajectories development
7053 en  the relationship between DNA periodicity and local chromatin structure
7054 en The American Denial Global Warming Polls show that between one third and one half Americans still believe that there solid evidence global warming that warming happening can attributed natural variability Others believe that scientists are still debating the point nJoin scientist and renowned historian Naomi Oreskes she describes her investigation into the reasons for such widespread mistrust and misunderstanding scientific consensus and probes the history organized campaigns designed create public doubt and confusion about science 
7055 en  Antarctica The Global Warning Antarctica environment today microcosm the world environment future endangered creatures such the chinstrap penguins humpback whales and albatrosses continue face extinction research scientists have concluded that this icy ecosystem serves final warning impending environmental deterioration nnIn Antarctica The Global Warning Sebastian Copeland photographs have captured both the incredible beauty the continent and the devastation that climate changes have wreaked His data photographs and conclusions — along with contributions from Will Steger David Rothschild Stephen Schneider Zac Goldsmith Mikhail Gorbachev and Leonardo DiCaprio — bring readers with insight and urgency the momentous reality the not distant future with insight and urgency 
7056 en Global Warming Nation Under Siege The rapid depletion fossil fuels and the rising sea level from the warming the earth atmosphere are converging dramatically alter our future nnEdward Mazria founder Architecture 2030 unveils new study sea level rise showing fly over images depicting potentially calamitous coastal and national impacts 
7057 en Conversations with History Noam Chomsky this edition Conversations with History Berkeley Harry Kreisler joined linguist and political activist Noam Chomsky discuss activism anarchism and the role the United States plays the world today 
7058 en The Time Paradox The New Psychology Time That Will Change Your Life Your every significant choice every important decision you make determined force operating deep inside your mind your perspective time your internal personal time zone This the most influential force your life yet you are virtually unaware Once you become aware your personal time zone you can begin see and manage your life exciting new ways nnIn The Time Paradox Drs Zimbardo and Boyd draw thirty years pioneering research reveal for the first time how your individual time perspective shapes your life and shaped the world around you Further they demonstrate that your and every other individual time zones interact create national cultures economics and personal destinies 
7059 en Copyright laws todays digital world
7061 en When causality matters for prediction Investigating the practical tradeoffs
7071 en Lecture Molecular Biology 
7072 en Lecture Molecular Biology 
7073 en Lecture Molecular Biology 
7076 en Lecture Recombinant DNA 
7077 en Lecture Recombinant DNA 
7078 en Lecture Recombinant DNA 
7079 en Lecture Recombinant DNA 
7080 en Lecture Cell Cycle Signaling
7082 en Lecture Virology Tumor Viruses
7087 en Lecture Nervous System 
7088 en Lecture Nervous System 
7089 en Lecture Nervous System 
7090 en Lecture Stem Cells Cloning 
7091 en Lecture Stem Cells Cloning 
7092 en Lecture Molecular Medicine 
7094 en Lecture Molecular Medicine 
7095 en Lecture Human Polymorphisms and Cancer Classification
7096 en Lecture Future Biology
7098 en ITER Promises unkept 
7099 en Activized Learning Transforming Passive Active with Improved Label Complexity active learning learning algorithm given access large pool unlabeled examples and allowed request the labels any particular examples that pool interactively empirically driven research one the most common techniques for designing new active learning algorithms use existing passive learning algorithm subroutine and actively construct training set for that method carefully choosing informative examples label The resulting active learning algorithms are thus able inherit the tried and true learning bias the underlying passive algorithm while often requiring significantly fewer labels achieve given accuracy compared random sampling nnThis naturally raises the theoretical question whether every passive learning algorithm can activized transformed into active learning algorithm that uses smaller number labels achieve given accuracy this talk will address precisely this question particular will explain how use any passive learning algorithm subroutine construct active learning algorithm that provably achieves strictly superior asymptotic label complexity Along the way will also describe many the recent advances the formal study the potential benefits active learning general 
7100 en Probabilistic Decision Making Under Model Uncertainty Partially Observable Markov Decision Processes offer rich mathematical framework for decision making under uncertainty recent years number methods have been developed optimize the choice action given parametric model the domain many applications however this model must learned using finite set trajectories When this data proves difficult expensive collect often the case that the resulting model poorly imprecisely defined nnIn this talk will present two recent results the topic decision making under model uncertainty the first half will describe method for estimating the bias and variance the value function terms the statistics the empirical transition and observation model Such error terms can used meaningfully compare the value different policies the second half will present bayesian approach designed simultaneously improve the model and select good actions Performance the two methods will illustrated using problems drawn from the fields robotics and medical treatment design 
7101 en Object Recognition and Segmentation Association Many object recognition systems train different classifier for each object category and use the sliding window approach classify image regions this talk pose the object recognition problem data association where novel object explained solely terms small set exemplar objects which visually similar learn different distance function for each exemplar such that the returned distances can interpreted detect the presence object Our exemplars are represented image regions and the learned distances capture the relative importance shape color texture and position features for that region use the distance functions detect and segment objects novel images associating the bottom segments obtained from multiple image segmentations with the exemplar regions evaluate the detection and segmentation performance our algorithm real world outdoor scenes from the LabelMe dataset and also show some qualitative image parsing results 
7102 en Local Minima Free Parameterized Appearance Models Parameterized Appearance Models PAMs Eigen tracking Active Appearance Models Morphable Models are commonly used model the appearance and shape variation objects images While PAMs have numerous advantages relative alternate approaches they have least two drawbacks First they are especially prone local minima the fitting process Second often few any the local minima the cost function correspond acceptable solutions solve these problems this paper proposes method learn cost function explicitly optimizing that the local minima occur and only the places corresponding the correct fitting parameters the best our knowledge this the first paper address the problem learning cost function explicitly model local properties the error surface fit PAMs Synthetic and real examples show improvement alignment performance comparison with traditional approaches 
7103 en Inference Complexity Learning Bias Graphical models are usually learned without regard the cost doing inference with them result even good model learned may perform poorly prediction because requires approximate inference propose alternative learning models with score function that directly penalizes the cost inference Specifically learn arithmetic circuits with penalty the number edges the circuit which the cost inference linear Our algorithm equivalent learning Bayesian network with context specific independence greedily splitting conditional distributions each step scoring the candidates compiling the resulting network into arithmetic circuit and using its size the penalty show how this can done efficiently without compiling circuit from scratch for each candidate Experiments several real world domains show that our algorithm able learn tractable models with very large treewidth and yields more accurate predictions than standard context specific Bayesian network learner far less time Joint work with Daniel Lowd 
7104 en Differentiable Sparse Coding Prior work has shown that features which appear biologically plausible well empirically useful can found sparse coding with prior such Laplacian that promotes sparsity show how smoother priors can preserve the benefits these sparse priors while adding stability the Maximum Posteriori MAP estimate that makes more useful for prediction problems Additionally show how calculate the derivative the MAP estimate efficiently with implicit differentiation One prior that can differentiated this way regularization demonstrate its effectiveness wide variety applications and find that online optimization the parameters the regularized model can significantly improve prediction performance 
7105 en Partially Observed Maximum Entropy Discrimination Markov Networks Learning graphical models with hidden variables can offer semantic insights complex data and lead salient structured predictors without relying expensive sometime unattainable fully annotated training data While likelihood based methods have been extensively explored our knowledge learning structured prediction models with latent variables based the max margin principle remains largely open problem this paper present partially observed Maximum Entropy Discrimination Markov Network PoMEN model that attempts combine the advantages Bayesian and margin based paradigms for learning Markov networks from partially labeled data PoMEN leads averaging prediction rule that resembles Bayes predictor that more robust overfitting but also built the desirable discriminative laws resemble those the develop style algorithm utilizing existing convex optimization algorithms for subroutine demonstrate competent performance PoMEN over existing methods real world web data extraction task 
7106 en Rare Category Detection for Spatial Data Given unlabeled unbalanced data set the goal rare category detection discover examples from the minority classes with few label requests Rare category detection open challenge machine learning and has lot applications such financial fraud detection network intrusion detection astronomy spam image detection etc this talk will introduce two methods for rare category detection with spatial data The first one essentially performs local density differential sampling and requires the prior information about the data set input The second one based specially designed exponential families and prior free Experimental results demonstrate the effectiveness these methods different real data sets 
7107 en Some Challenging Machine Learning Problems Computational Biology Time Varying Networks Inference and Sparse Structured Input Out Learning Recent advances high throughput technologies such microarrays and genome wide sequencing have led avalanche new biological data that are dynamic noisy heterogeneous and high dimensional They have raised unprecedented challenges machine learning and high dimensional statistical analysis and their close relevance human health and social welfare has often created unique demands performance metric different from standard data mining pattern recognition problems this talk will discuss two such problems First will present new statistical formalism for modeling network evolution over time and several new algorithms based temporal extensions the sparse graphical logistic regression for parsimonious reverse engineering the latent time varying networks will show some promising results recovering the latent sequence temporally rewiring gene networks over more than 4000 genes during the life cycle Drosophila melanogaster from microarray time course time resolution only limited sample frequency Second will present family sparse structured regression models the context uncovering true associations between linked genetic variations inputs the genome and networks human traits outputs the phenome time allows will also present another class new models known the maximum entropy discrimination Markov networks which address the same problem the maximum margin paradigm but using entropic regularizer that lead distribution structured prediction functions that are simultaneously primal and dual sparse with few support vectors and low effective feature dimension nnJoint work with Amr Ahmed Seyoung Kim Mladen Kolar Song and Jun Zhu 
7108 en New methods for digital generation and postprocesing true random numbers
7110 en Lecture Introducing the StarFestival curriculum
7111 en Lecture Next Big Thing Video Internet
7112 en Lecture Media Education and Technology
7113 en Lecture Educational Uses Technology
7114 en Lecture Media Literacy Strategy for Combatting Moral Panic
7115 en Lecture Educational Technology Initiatives Business Education the Sloan School Management MIT
7116 en Lecture Discussion StarFestival
7117 en Lecture Maria Itria Fifth grade Harvard Kent School Boston USA
7118 en Lecture Mary Rudder Kindergarten Harvard Kent School Boston USA
7230 en Welcome and Opening remarks Opening OECD
7231 en Slovenia Corporate Governance and OECD
7232 en The Role OECD Global Corporate Governance
7233 en Panel discussion Panelists Bojan Dremelj CEO Telekom Slovenia mag iga Debeljak CEO Mercator Juan Carlos Fernandez Zara International Finance Corporation mag Mirjana Dimc Perko CFO Gorenje Marko Simoneti CEO Ljubljana Stock Exchange
7234 en OECD guidelines for State owned Enterprises case Norway
7236 en Panel discussion Panelists Ale Hauc CEO Slovene Post mag Borut Jamnik President the Slovene Supervisory Board Association mag Tadej Tufek CEO Adria Airways Peter Tev Vicepresident Association Employers Slovenia Marko Kry anowski CEO Petrol
7242 en TAO the way semantic SOA methodology and tools
7243 en Vigitermes Project pharmaceutical knowledge base grounded semantic technologies
7244 en VideoLectures net case study The task the VideoLectures case study develop software component that will aid the VideoLectures editors categorizing recorded lectures ontology population This functionality required due the rapid growth the number hosted lectures well due the fact that the categorization taxonomy rather fine grained 200 categories and growing addition aiding the categorization new lectures the software will also used for categorization and additional categorization lectures already categorized nnWe will show that were successful our task the categorizer highly accurate – achieves accuracies that stretch – above the baseline – and highly robust terms missing data The latter means that lecture might missing textual annotations such the description and slide titles but still categorized correctly Furthermore the categorizer has been successfully integrated into the VideoLectures Web site Categorization suggestions termed quick links are provided the author the categorization panel 
7245 en Linked Life Data for annotation MEDLINE Semantic data integration and search the life science domain
7246 en Fundamental Constants Physics and their Time Dependence the Standard Model Particle Physics are dealing with fundamental constants the experiments these constants can measured but theoretically they are not understood will discuss these constants which are mostly mass parameters Astrophysical measurements indicate that the finestructure constant not real constant but depends time Grand unification then implies also time variation the QCD scale Thus the masses the atomic nuclei and the magnetic moments the nuclei will depend time proposed experiment which currently done Prof Haensch Munich and his group The first results indicate time dependence the QCD scale will discuss the theoretical implications 
7250 en  Passion for Discovery The human side doing theoretical physics explored through stories about the interactions between physicists and about the effects world events can have scientists behavior and even their interests and style These stories cluster nicely around certain bigger themes create overarching whole This happens both account some interesting narrative structures intrinsic the science physics itself and account the way physics integrates into the general culture The stories concern Einstein Schrödinger Pauli Heisenberg Stueckelberg Jordan and Fock and also involve some mathematicians like Emmy Noether Teichmüller and Bers and even the psychologist Jung 
7251 en The Historical Origins and Economic Logic Open Science Modern big science projects such the LHC experiments physics that are being prepared run CERN embody the distinctive ethos cooperation and mechanisms coordination among distributed groups researchers that are characteristic open science Much has been written about the institutions open science their supporting social norms and their effectiveness generating additions the stock reliable knowledge But from where have these institutions and their supporting ethos come How robust can assume them the face the recent trends for universities and research institutes some domains science seek appropriate the benefits new discoveries and inventions asserting intellectual property claims search for the historical origins the institutions open science throws some new light these issues and the answers may offer some lessons for contemporary science and technology policy making 
7253 en Hanbury Brown and Twiss and Other Atom atom Correlations Advances Quantum Atom Optics Fifty years ago two astronomers Hanbury Brown and Twiss invented new method measure the angular diameter stars spite the atmospheric fluctuations Their proposal prompted hot debate among physicists how might two particles photons emitted independently opposite extremities star behave correlated way when detected was only after the development Glauber full quantum analysis that the effect was understood two particle quantum interference effect From modern perspective can viewed early example the amazing properties pairs entangled particles The effect has now been observed with bosonic and fermionic atoms stressing its fully quantum character After putting these experiments historical perspective will present recent results and comment their significance will also show how our single atom detection scheme has allowed demonstrate the creation atom pairs non linear mixing matter waves This result paves the way experiments aiming probing entanglement atom pairs 
7254 en The genesis WiFi and its applications 1985 changes regulations caused paradigm shift permitting the use radio spectrum for devices that did not need have end user license After few years products appeared the market and group developed standard for broadband wireless communications among computers The presentation will explain how the standard developed and was adopted the Alliance well the global harmonization and expansion the available radio spectrum over half GHz nnThe success and user innovation and initiatives makes vehicle bring broadband internet rural areas both developing well developed countries Vic Hayes Senior Research Fellow the Delft University Technology and writing book titled The genesis and the road toward global success nnHe holds BSEE and joined NCR the Netherlands 1974 established and chaired the IEEE 802 Standards Working Group for Wireless Local Area Networks and became known the Father After chairing the successfully mobilized the computer industry support the agenda item for 455 MHz spectrum primary allocation the agenda the World Radio Conference 2003 October 2003 Vic retired from Agere Systems nnFor his pioneering work Vic the recipient the Innovation Award 2004 The Economist the Dutch Vosko Trophy Alliance Leadership Awards The IEEE Standards Medallion the IEEE Leadership Award the IEEE Hans Karlsson Award and the IEEE Steinmetz Award 
7255 en Worrying About the LHC Lesson from Astrophysics worry about the LHC popular sport shall share own worries hopefully original and via parable for this method can quote earlier authors The parable concerns topic astrophysics gamma ray bursts which happens simple exercise but quite interesting one elementary particle physics and beam dynamics topics not unrelated the LHC Though most the talk will dedicated the physics and particular its recent developments the allegory will allow detect what shall argue may dangerous viruses invading science not have the decisive antidotes but shall discuss some possible ones 
7256 en Energy Sustainability and Development huge increase energy use expected the coming decades – see the IEA’ ‘business usual’ reference scenario below While developed countries could use less energy large increase needed lift billions out poverty including over the world’ population who still lack electricity Meeting demand environmentally responsible manner will huge challenge The World Bank estimates that coal pollution leads 300 000 deaths China each year while smoke from cooking and heating with biomass kills million world wide – more than malaria The IEA’ alternative scenario requires smaller increase energy use than the reference scenario and also less carbon intensive but still implies that CO2 emissions will increase 2030 compared the reference scenario Frighteningly implementing the alternative scenario faces “formidable hurdles” according the IEA despite the fact that would yield financial savings for consumers that far exceed the initial additional investment cost shall give overview the energy outlook and the portfolio technological and economic measures that are need meet the energy challenge and better than the alternative scenario 
7257 en Fermilab Plan with High Intensity Proton Source Fermilab the ’ primary laboratory for particle physics proposes plan maintain leadership for the laboratory and particle physics the quest discover the fundamental nature the physical universe the decades ahead Discoveries the physics the Quantum Universe would come from powerful next generation particle accelerators Fermilab’ Tevatron currently the world’ most powerful particle accelerator will shut down the end this decade after the LHC CERN begins operations the LHC physicists will join scientists from around the world the exploration the physics the Terascale follow the LHC physicists propose the International Linear Collider globally funded and operated accelerator build LHC results and illuminate Terascale science Fermilab will work host the proposed ILC the soon possible maintaining the nation’ historic leadership frontier particle physics Should events postpone the start the ILC Fermilab would build intensity frontier accelerator one percent the ILC’ length and combine with existing accelerators create Project Project ’ intense beams would give Fermilab’ scientific users new way into the world neutrinos and precision physics With its ILC technology Project would spur industrialization and reduce costs ILC components while advancing accelerator science for future applications particle physics and beyond addition Project would drive forward the technology for still higher energy accelerators the future such muon collider Fermilab’ plan would maintain the nation’ leadership particle physics keeping the laboratory and particle physics the pathway discovery both the Terascale with the ILC and beyond and the domain neutrinos and precision physics the intensity frontier 
7258 en  LHCb Search for New Physics Hadron factory Many essential features the quark sector the Standard Model have first been probed and quark decays indirect manner notable examples include the doublet structure the existence three generations and the masses the charm and top quarks Recent progress made the experiments factories and Tevatron the study hadron decays now put serious constraints the characteristics possible physics beyond the Standard Model through measurements related the Flavour Changing Neutral Current When the LHC becomes operational will the most powerful source hadrons The LHCb experiment will then able study such processes the system with similar accuracy that achieved the factories the system allowing improve further the stringent tests the Standard Model The experiment will also improve the measurements the system well may observe sign new physics first and combination with the ATLAS and CMS results will probe the flavour structure the new physics this presentation review the evolution the LHCb experiment conjunction with the development physics the current status the experiment and its prospects 
7259 en The Bill and Melinda Gates Foundation pushing the boundaries what possible public health perspectives and challenges the global community Introduction July 2008 Bill Gates will transition out day day role Microsoft spend more time his philanthropic work with the Bill and Melinda Gates Foundation the world’ largest philanthropic organization the Gates Foundation has set ambitious goals tackle some the world’ worst diseases this talk Julie Jacobson will outline some the objectives the Gates Foundation and how impacting public health and challenging the global community Speaker Bio Senior Programme Officer the Bill and Melinda Gates Foundation Julie Jacobson currently supports grants working toward the control neglected tropical diseases and works with the development and implementation new vaccines the infectious disease group Global Health Previously Jacobson was Scientific Director Immunization Solutions and Director Japanese encephalitis project PATH international non profit organization director the project she managed million grant accelerate the control endemic countries improving data the distribution accelerating the development improved vaccine and diagnostic tests for and helping countries integrate vaccine into immunization programs her role scientific director she defined the direction and growth immunization solutions work increasing the availability vaccines the world’ most vulnerable populations This ranged from work clinical trials for specific vaccines directly working with ministries health and partners decision making vaccine introduction and planning Before that Jacobson was responsible for prioritizing and designing field activities for PATH’ Children’ Vaccine Project the areas including yellow fever and rotavirus Prior joining PATH Jacobson worked the Centers for Disease Control and Prevention Epidemic Intelligence Officer this capacity she worked disaster epidemiology and conducted needs assessments for disaster victims evaluated national surveillance systems and evaluated the health impact earthquakes displaced persons Jacobson physician with training clinical tropical medicine and applied epidemiology 
7260 en TOTEM different LHC experiment TOTEM will pursue physics program complementary that the other LHC detectors spanning wide range from total cross section and elastic scattering measurements the study diffractive and forward phenomena The TOTEM program will lead better understanding the fundamental aspects strong interactions For the first time hadron colliders the very forward rapidity range containing the energy flow and explored high energy cosmic ray experiments covered allowing the search for unusual phenomena hinted cosmic ray experiments The technical implementation all TOTEM detectors described Silicon sensors housed called Roman pots allow measurements elastic and diffractive protons distances small from the beam centre scheme tag events from Double Pomeron Exchange diffractive protons both sides transforms the LHC into almost clean “gluon” collider where the centre mass energy determined the momentum losses the forward protons thus offering interesting way search for new particles later stage the combination CMS and TOTEM will provide unprecedented almost complete rapidity coverage allowing variety new studies including hard diffraction 
7261 en Summary Summary Strings 2008 which was held CERN the year during which the LHC started This conference the largest and most important one String Theory runs annually and usually draws several hundred participants mostly active researchers the field The main purpose the conference review the latest developments for experts but there were also free talks for the general public 
7262 en Remodeling the Topological String Perturbatively and Nonperturbatively Lecture held Strings 2008 – August 2008 CERN hosted the 2008 edition Strings the annual conference that focuses superstring theory and related matters 
7263 en Tadpole Cancellation the Topological String Lecture held Strings 2008 – August 2008 CERN hosted the 2008 edition Strings the annual conference that focuses superstring theory and related matters 
7264 en Cosmological Unification String Theories Lecture held Strings 2008 – August 2008 CERN hosted the 2008 edition Strings the annual conference that focuses superstring theory and related matters 
7265 en  duality and Boundary Conditions SYM Lecture held Strings 2008 – August 2008 CERN hosted the 2008 edition Strings the annual conference that focuses superstring theory and related matters 
7266 en Developments BPS Wall crossing Lecture held Strings 2008 – August 2008 CERN hosted the 2008 edition Strings the annual conference that focuses superstring theory and related matters 
7267 en Extremal Black Holes and AdS2 CFT1 Correspondence Lecture held Strings 2008 – August 2008 CERN hosted the 2008 edition Strings the annual conference that focuses superstring theory and related matters 
7268 en BPS Black Holes and Topological Strings Review Lecture held Strings 2008 – August 2008 CERN hosted the 2008 edition Strings the annual conference that focuses superstring theory and related matters 
7270 en  loop Perturbative Konishi from AdS5xS5 String Sigma Model Lecture held Strings 2008 – August 2008 CERN hosted the 2008 edition Strings the annual conference that focuses superstring theory and related matters 
7271 en General Gauge Mediation Lecture held Strings 2008 – August 2008 CERN hosted the 2008 edition Strings the annual conference that focuses superstring theory and related matters 
7272 en Holographic Gauge Mediation Lecture held Strings 2008 – August 2008 CERN hosted the 2008 edition Strings the annual conference that focuses superstring theory and related matters 
7274 en Holographic Recipes Finite Density and Low Temperature Lecture held Strings 2008 – August 2008 CERN hosted the 2008 edition Strings the annual conference that focuses superstring theory and related matters 
7275 en Scattering Amplitudes via AdS CFT Lecture held Strings 2008 – August 2008 CERN hosted the 2008 edition Strings the annual conference that focuses superstring theory and related matters 
7276 en Nonlinear Fluid Dynamics from Gravity Lecture held Strings 2008 – August 2008 CERN hosted the 2008 edition Strings the annual conference that focuses superstring theory and related matters 
7277 en Integrability the AdS CFT System Lecture held Strings 2008 – August 2008 CERN hosted the 2008 edition Strings the annual conference that focuses superstring theory and related matters 
7278 en The Search for New Physics the LHC Lecture held Strings 2008 – August 2008 CERN hosted the 2008 edition Strings the annual conference that focuses superstring theory and related matters 
7279 en String Phenomenology the Eve the LHC Lecture held Strings 2008 – August 2008 CERN hosted the 2008 edition Strings the annual conference that focuses superstring theory and related matters 
7280 en  theory GUTs and the Weak Scale Lecture held Strings 2008 – August 2008 CERN hosted the 2008 edition Strings the annual conference that focuses superstring theory and related matters 
7281 en  New Infinite Class Anti Sitter Flux Vacua Lecture held Strings 2008 – August 2008 CERN hosted the 2008 edition Strings the annual conference that focuses superstring theory and related matters 
7282 en  brane Instantons Type Orientifolds Lecture held Strings 2008 – August 2008 CERN hosted the 2008 edition Strings the annual conference that focuses superstring theory and related matters 
7283 en  Chern Simons Matter Theories Branes and Supergravity Lecture held Strings 2008 – August 2008 CERN hosted the 2008 edition Strings the annual conference that focuses superstring theory and related matters 
7284 en Unveiling the Structure Amplitudes Gauge Theory and Gravity Lecture held Strings 2008 – August 2008 CERN hosted the 2008 edition Strings the annual conference that focuses superstring theory and related matters 
7285 en What the Simplest Quantum Field Theory Lecture held Strings 2008 – August 2008 CERN hosted the 2008 edition Strings the annual conference that focuses superstring theory and related matters 
7286 en Fermionic duality Lecture held Strings 2008 – August 2008 CERN hosted the 2008 edition Strings the annual conference that focuses superstring theory and related matters 
7287 en Dual Superconformal Symmetry Scattering Amplitudes SYM Lecture held Strings 2008 – August 2008 CERN hosted the 2008 edition Strings the annual conference that focuses superstring theory and related matters 
7288 en The Gauge string Duality and QCD Finite Temperature Lecture held Strings 2008 – August 2008 CERN hosted the 2008 edition Strings the annual conference that focuses superstring theory and related matters 
7289 en Who afraid blue red and green Speaking about our populistically acting mass media environment and its influence aspects mediation general the Austrian artist will present examples his documentarynphotographic work and his interactive media projects within mass media systems nThe meta world public representation where basic aspects democracy economy are transmitted setting ideological standards seems irresistibly shifting over balanced commercial contents surveillance and propaganda especially moments crisis which does challenge the media systems most important for the development western democracies principal way since its beginnings nQuestions media observation and the public media space and its ownership and political implications will linked artistic concepts which try research the “abstract”ntechnological aspects and strategies media society and which suggest also that formal abstract work not necessarily contradiction political aspects artistic practices 
7290 en Who speaking ”The multitude voices into which Regina Maria Moeller splits her artistic work corresponds the various positions she adopts with regard that which she confronts Similar the way which overlapping circles form intersections that shift previously peripheral material into new center Moeller shifts attention and reshuffles the cards speak secondary characters become protagonists coherencies become contents opposites are robbed their oppositions Moeller uses the strategies inherent her media overwriting and adapting them for her own purposes and shows that there are always number different versions underneath and alongside the official interpretation ” Matthias Herrmann Regina Moeller embodiment – dress plot exhibition catalogue Secession Vienna 2004 nRegina Maria Moeller lives Berlin She studied art education art history and history middle ages the Ludwig Maximilians University Munich Germany She the founding editor the magazine regina and the creator the label embodiment Regina Moeller visiting professor for the fall term MIT’ Visual Arts Program nRegina Maria Moeller situates her works the border realm art fashion and comics She takes various formats contemporary cultural communication and reflects their identity forming economic and functional connotations nFor example her magazine regina with which she has reached broad readership since the late 1990s she adapts the language women’ magazines Through subtle shifts she under mines the common constructions female identity Parallel this Regina Moeller has designed clothing carpets furniture and inner decor under her own label embodiment since 1993 
7291 en Forty Years High Energy String Collisions Lecture held Strings 2008 – August 2008 CERN hosted the 2008 edition Strings the annual conference that focuses superstring theory and related matters 
7292 en Projections and instrumentations With the aid especially designed bodilynequipment Wodiczko’ recent projectionsn“animate ” real time the facades publicnedifices Much smaller their scale thenwearable instrumentations share with thesenmonumental projections similar psychologicalnand political objectives The aim both projectsnis inspire and assist the users animators inndeveloping perfecting and “projecting” theirnvoice and gestures public space nBoth projections and instrumentations require anpreparatory video recording and recording nprocess that psychologically and politicallynengages participants and aids constructingntheir testimonies Through this process nparticipants gradually recover and developnthe mastery and artistry public speaking nStep step they recall articulate and conveynoverwhelming life experiences Armed withnnew psycho cultural prosthetic equipment andnempowered with the prestige and monumentalnscale civic edifices they become prominentnfearless speakers nThe main objective the use media thesenprojections and instrumentations create antransitional psychological space that encouragesna gradual passage from participants’ traumaticnsilence traumatized speech toward confidentnarticulate voice this way their psycho politicalndevelopment which Wodiczko’ projects seeknto contribute may help participants becomennot only frank transmitters truth but alsoncritical and passionate animators public space 
7293 en Maximal Supersymmetry Duality and Scattering Amplitudes Lecture held Strings 2008 – August 2008 CERN hosted the 2008 edition Strings the annual conference that focuses superstring theory and related matters 
7294 en Multiple Membrane Dynamics Lecture held Strings 2008 – August 2008 CERN hosted the 2008 edition Strings the annual conference that focuses superstring theory and related matters 
7295 en Game risk disaster “Are here play serious Andnin all seriousness what playing gamesnfor that matter For the past four years nGustavo Artigas who based Mexico City nbut coordinates the majority his projectsnin other international cities has developed anstunning complex language surrounding thensocial tensions group organization and thenconsequences and risks involved game andndisaster situations More specifically Artigas’nwork engages universe limits for thengame the limit between what and what isnnot game more difficult specify than itnseems first glance The disaster the othernhand – Artigas’ experience – limit confinednby fear and inevitability Acting Masternof Ceremonies has developed three ringncircus scheme juxtaposing games performativengestures and political critiques into episodicalnchapters ” – Jennifer Teets
7296 en Lagrangians for Multiple branes Lecture held Strings 2008 – August 2008 CERN hosted the 2008 edition Strings the annual conference that focuses superstring theory and related matters 
7297 en Heterotic Standard Models Lecture held Strings 2008 – August 2008 CERN hosted the 2008 edition Strings the annual conference that focuses superstring theory and related matters 
7299 en Superstring Amplitudes Formal Progress and Implications for LHC Lecture held Strings 2008 – August 2008 CERN hosted the 2008 edition Strings the annual conference that focuses superstring theory and related matters 
7300 en Outlook Outlook for Strings 2008 – August 2008 CERN hosted the 2008 edition Strings the annual conference that focuses superstring theory and related matters 
7301 en Archive The MIT Museum has recently received the archives Mary Otis Stevens SBArch one the most important female architects the Northeast during the 1960s and 1970s nnInitially protégé Walter Gropius Stevens partnered with her husband Thomas McNulty MArch from 1956 1969 One their most important projects was the 1965 Lincoln House designed for themselves and their three small sons Lincoln nnPerhaps the first house the built glass and exposed concrete was instant sensation the international architectural press the cover Architectural Forum and Deutsche Bauzeitung and widely featured the large circulation press well But rocked the little town Lincoln the same way the Gropius House had the late 1930s Neighbors speculated since there were windows facing the street the occupants must have been nudists nnFor Lincoln House Stevens and McNulty enlisted movement and hesitation their basic design concepts The originality the house stemmed from the architects rejection preset notions what house was freeing them transfer their own ideas about movement and hesitation the scale the city the scale the house nnTo maximize freedom and movement the house for instance the architects eliminated most interior doors fostering movement not only between the different areas the interior but also between the inside and the outside “ wanted make the house into kind miniature city” says Stevens “ was very urban The idea was bring people together not isolate them boxes different floors You had choices all the time ”nnApart from the unique space created using urban concepts movement the setting single family house the Lincoln House was also one the first with curvilinear geometry giving the building sculptural quality Life called sculpture for living The Lincoln House also served sundial sited that its longitudinal axis was exactly each cloudless day noon streak light would shoot down the stairs and extend its length the afternoon wore along the pathway leading the children area nnIn the 1960s Stevens and McNulty founded iPress Inc which Stevens directed from 1968 1978 making major contribution architectural and urban theory with books focusing the social context architecture such The Ideal Communist City Alexei Gutnov and Towards Non Oppressive Environment Alexander Tzonis nnIn 1970 she and McNulty published their own classic work World Variation looking the city social realm identifying then current problems and possible design solutions They also collaborated with Gyorgy Kepes founder MIT’ Center for Advanced Studies the design the City Night exhibit the 1968 Triennale where they used moving lines light each line programmed with different time sequence turn 100 foot corridor into place celebrating human movement nnIn 1975 Stevens founded the Design Guild collaborative architectural practice focused non profit clients historic preservation and adaptive use the Guild disbanded 1991 nnLast fall the new museum collection was inventoried and catalogued KatharinanMaria Tanzberger 2006 graduate the University Applied Arts Vienna who was introduced Stevens’ work her professor Liane Lefaivre Intrigued the notion house with doors Tanzberger was raised just such place she was drawn exploring Stevens’ work further writing research paper and eventually coming MIT work the archive nnThe collection consists more than 300 drawings and diagrams well many texts particular interest the large collection the sketches over the years sketches that differ from the architectural drawings the prewar period that they were not renderings facades elevations but rather diagrams charting the flow movement nThe Stevens collection companion the McNulty papers held the MIT Archives McNulty was member MIT architecture faculty from 1949 1956 when went into private practice with Stevens For six years also taught the University Petroleum and Minerals Dhahran Saudi Arabia professor architecture nThis article based part “Living Outside the Box Marty Otis Stevens and Thomas McNulty’ Lincoln House” Professor Liane Lefaivre Chair Architectural History and Theory the University Applied Art Vienna appeared Harvard Design Magazine Number Spring Summer 2006 
7302 en Rachel Harrison talks with Johanna Burton Since the early 1990s American artist Rachel Harrison has been developing brand unwieldy unyielding sculpture sometimes abject and sometimes abrasive its refusal give meaning Objects from the catch all drawer clown nose syringe framed photograph houseplant are deposited built agglomerations polystyrene and cement giving individual works the pugnacious air bad joke sometimes emphasized title like 2006 Nice Rack dolly stool table ladder thickly encrusted good new lends most works strong sense autonomy but never resolution nnUsing elements fundamental sculpture the way object requires walk around the way try make sense out two different things juxtaposed her works lead towards one understanding and then makes question turn the corner They leave you with your interpretive tools blunted even they hint portraiture Sometimes Harrison picks camera 2000 she took series photos window Perth Amboy where vision the Virgin Mary had appeared the glass Pilgrims tended press hand against the pane the sense touch were better equipped pick trace the event These photographs unexpectedly representing unfiltered human desire were part maze like installation corrugated cardboard with objects 
7303 en Let Put Puppet Show Let Put Puppet Show afternoon event revolving around puppetry scheduled for Friday April The Center has invited John Bell artist and founder Great Small Works Linda Norden curator the American Pavilion for the 2005 Venice Biennale and curator Pierre Huyghe 2004 puppet opera featuring puppet Linda Karen Zasloff artist and shadow puppeteer and other special guests for lecture Let Put Puppet Show brings together artists curators and puppeteers explore the ways puppets and puppet theater have functioned within contemporary art and society 
7333 en Course Introduction elective technical elective the graduate program here the Department Material Science and Engineering That say not core requirement that poses some different challenges for the instructor core class you have captive audience The students have take the class because satisfies some degree requirement and they are there whether they like not the students who are taking are taking because they want learn the material because presumably relevance their research you have the luxury teaching group that self selected 
7334 en Lecture Vision Statement Administrative Details Introduction Taxonomy Chemical Species Origins Modern Chemistry Welcome 091 name Donald Sadoway and your lecturer this fall got plenty room here you need sit You can sit the steps and the aisles get things sorted out the next day two What like today introduce myself introduce the subject introduce plans have plans for you have plans for you called plans for learning because that what all about nPeople you coming now you can sit here you even can sit the floor here one big happy family let begin telling you that 091 the most important subject that you will take MIT 
7335 en Lecture Classification Schemes for the Elements Mendeleyev and the Periodic Table Atomic Structure You are allowed use the test the official version the Periodic Table the Elements which most you should have now There was shipment that came partway through the day Thursday you didn get Periodic Table swing the office just down the hall from this lecture theater And you bring the Periodic Table and the Table Constants and calculator and something write with That four items Show sit down and the first question does anybody have pen may not have that many pens those are the four items You not use aid sheet the weekly test 
7336 en Lecture Rutherford Model the Atom Bohr Model Hydrogen time get back learning couple announcements before get started tomorrow there will minute quiz recitation based upon the content homework one Obviously not going question identical something you done but going cover that subject matter please don bring your attorney didn ask question that identical one that you worked Second thing started talking about the periodic table and believe that hallmark any educated person the 21st century who technically literate know the periodic table heart time get back learning couple announcements before get started tomorrow there will minute quiz recitation based upon the content homework one Obviously not going question identical something you done but going cover that subject matter 
7337 en Lecture Atomic Spectra Hydrogen Matter Energy Interactions Involving Atomic Hydrogen You are required only put the one two letter chemical abbreviation the symbol Some people ask want you know the molecular weights and and thought that was bit excessive nnSo think you just know the symbols for the ones that are there that would just dandy Here the lady scarf very hot black See trim lines blue and gold and has elements 
7338 en Lecture The Shell Model Bohr Sommerfeld Model and Multi electron Atoms Quantum Numbers The mnemonics contest deadline week from today Send mail you want win that hot tie that hot scarf come attention that people are moving freely about recitations without arranging through office And some the recitations sections are uncomfortably large which defeats the purpose the recitation part mean want you have access the instructor and you have students there instead that dilutes your access 
7339 en Lecture Broglie Heisenberg and Schrödinger The Aufbau Principle Pauli Exclusion Principle and Hund Rules Photoelectron Spectroscopy Average Valence Electron Energy saw that the Bohr model was able correlate the observations Angstrom which had been formulated Balmer And furthermore the concept energy level quantization was observed mercury during the course the Franck Hertz experiment giving credence the notion that quantization energy levels not the property one electron atoms alone but something that more broadly applicable Bohr was validated very very strong measure but there were also some contrary data And saw those First there was the observation Michelson who back the late 1880s had done very precise interferal metric measurements the hydrogen lines and had observed that the 656 nanometer line associated with the transition equals equals was fact doublet 
7340 en Lecture Octet Stability Electron Transfer Ionic Bonding Properties Ionic Compounds Crystal Lattice Energy Chemical properties let put something hypothesis Let say well maybe has with the energy that takes remove electrons And one other thing that failed point out you take look the energies associated with the outermost electrons this case lithium you see megajoules per mole and then what the That associated with one equals one inner shell There huge difference between the energies the outermost shell and the inner shells which tells you that unlikely that any electrons except those the outermost shell are going active 
7341 en Lecture Born Haber Cycle Octet Stability Electron Sharing Covalent Bonding Lewis Structures Hybridization First thing read the test That comes big shock lot people don read the test They just open and they just start working There going don know four five questions Well just put them down the order that came out head don put them any strategic order don put hardest first easiest first don even think they are chronological order topic think just whatever said well let something don know pick topic What are asking you cannot remember They are all made and ready But pick topic Pick something about the Periodic Table 
7342 en Lecture Electronegativity Partial Charge Polar Bonds and Polar Molecules Ionic Character Covalent Bonds Pauling Calculation Heteronuclear Bond Energies That say guess the answer ahead time strip all the decimal places off Just with powers ten and then see what the answer should And you will within every time And that good thing know because you come out with answer that somewhere near the diameter the universe and supposed the diameter atom then you will know that you probably made mistake 
7343 en Lecture LCAO Energy Level Diagrams for He2 Li2 Hybridization Double Bonds and Triple Bonds Paramagnetism and Diamagetism This 091 and have standards here class average and the standard deviation was you can see where things lie pass Congratulations lot people put the effort and there some learning going 
7344 en Lecture11 The Shapes Molecules Electron Domain Theory Secondary Bonding And beyond that really requires some intensive quantum mechanics going stay with and block And saw that had two atomic orbitals when they blended form the molecular orbital took this sort the ellipsoidal shape called that sigma orbital And the characteristic the sigma orbital that you have continuous electron density from one nucleus the other said holidays constant electronic density could then combine orbital and orbital for example the case hydrogen fluoride the case plus will end with orbital that looks something like this And also termed sigma orbital because again you look from one nucleus the other there continuous electron density holidays 
7345 en Lecture Metallic Bonding Band Theory Solids Heitler and London Band Gaps Metals Semiconductors and Insulators Absorption Edge Semiconductor will three hour extravaganza celebration learning where you all come show you what you have mastered And going just grand grand time And will over the Johnson Athletic Center urge you take look the final exam schedule and make your travel plans soon you know what your last obligation Because things are going get booked and going harder and harder get out here certainly get out decent price Last day looked Electron Domain Theory which allowed predict the shapes molecules And this taken from the book This Table And have highlighted orange worked through some these molecules last day the SF6 BrF5 ICl4 
7346 en Lecture Intrinsic and Extrinsic Semiconductors Doping Compound Semiconductors Molten Semiconductors last day talked about secondary bonding and looked various forms secondary bonding Here the cartoons dipole dipole interactions dipole induced dipole solutions little bit diversion induced dipole induced dipole which was the London dispersion forces van der Waals bonds and also hydrogen bonding And all these helped answer the question what the state aggregation The reason want know the state aggregation that this solid state chemistry And want know when something solid this helps get that conclusion And then came the point where realized that three quarters the periodic table wasn covered either ionic bonding covalent bonding van der Waals bonding primary form bonding 
7347 en Lecture Introduction the Solid State the Crystal Systems the Bravais Lattices Wireless Fantasy Vladimir Ussachevsky one the first pieces computer generated music was done Columbia University 1960 was commissioned group fans Lee Forest and was honor Forest contribution wireless broadcast And one the first broadcasts Forest ever sent over the radio was the piece that you are hearing Parsifal from the Wagner Opera And what Ussachevsky has done the piece process make sound really distanct though coming over shortwave radio And then has Morse Code and there various Morse Code messages going through the piece Wireless Fantasy from 1960 done long hand the way was really done with Morse Code mainframe computer and giant reel reel decks 
7348 en Lecture Properties Cubic Crystals Simple Cubic Face centered Cubic Body centered Cubic Diamond Cubic Crystal Coordinate Systems Miller Indices have nothing special planned today just run the mill lecture you get sense what like sitting one these seats that you paid dearly for hope can convince you that you made smart decision putting your son daughter this campus You will come the quick conclusion not because the facilities Facilities here are nothing special Classrooms labs and the peer group not the faculty Faculty are but think the peer group 
7349 en Lecture Characterization Atomic Structure The Generation rays and Moseley Law Let see couple announcements Tomorrow there will quiz six based homework six just the crystallography There little bit the end homework six rays And will just start talk about rays today think that will leave that out will just based crystallography And have asked the recitation instructors administer the test the end the period you can have some chance ask questions Last day talked about crystallography were introduced the seven crystal systems and the Bravais lattices which are shown the slide taken from the lecture notes And saw that wanted describe the arrangement atoms crystal could combining the notion the Bravais lattice which there are distinct types with basis 
7350 en Lecture ray Spectra Bragg Law Opera that good one That good was opera yes What opera wasn Wagner but that good guess certainly reasonable style way over the top That was Maria Callas singing Mamma Morta from Andrea Chenier which was written 1895 and premiered the spring 1896 exactly the time when the world was going nuts over this mysterious form radiation that can see inside the human body thought that was good match The thing best class That Maria Callas This opera for those you who don like opera This the way some you may recognize you saw the movie Philadelphia This the piece that playing when the Tom Hanks character visits the loft excuse the Denzel Washington character visits the loft the Tom Hanks character And this playing fantastic piece way over the top 
7351 en Lecture ray Diffraction Crystals Diffractometry Debye Scherrer Laue Crystal Symmetry Here have plotted intensity versus wavelength Long wavelength low energy Energy increasing from right left And what see family nested curves each taking different plate voltage nnLow voltage gives low intensity High voltage gives high intensity see this whale shaped background which refer the continuous spectrum bremsstrahlung And then once reach critical voltage beyond which start see this second set lines here which have indicated fuchsia And this the characteristic spectrum and quantized not continuous have discrete values wavelength associated with energy transitions within the target And those transitions are prompted the ejection inner shell electrons 
7352 en Lecture Defects Crystals Point Defects Line Defects Interfacial Defects Voids just going quickly over the comments that give before every test just put everybody the right frame mind The coverage lecture that will start with ionics and through the generation rays but not Bragg law anything like that remember you got bring five things with you your periodic table table constants something write with calculator and your aid sheet And you know going make bold suggestion For some you why don you write your recitation instructor name your aid sheet Because going tell you what going don have recitation instructor name the exam not going grade 
7353 en Lecture Amorphous Solids Glass Formation Inorganic Glasses Silicates have high here had number people the 80s and 90s had number people that were the 50s and 60s the first test who moved the right and had also some people that were here who moved the left Far more moved the left than moved the right talked the TAs and put fair bit care into preparing the test that one felt that was atypically difficult But somehow people didn well have been getting emails from people asking about makeup Yeah there third test the 17th November are not going allow you retry until you get score that you like because there point doing that 
7354 en Lecture Engineered Glasses Network Formers Network Modifiers Intermediates Properties Silicate Glasses Metallic Glass that the subject matter for tomorrow ten minute test And think that all have way introduction Anybody recognize the music Philip Glass yes What else would you play you are teaching amorphous solids You could play something like Glass Onion The Beatles you can stand the Beatles But didn want that yeah there people generation two categories those who think the Beatles are great and those who think they are just ahem and the second category They bore 
7355 en Lecture Chemical Kinetics The Rate Equation Order Reaction Rate Laws for Zeroth First and Second Order Reactions Temperature Dependence Rate Reaction The oxide ions into the network and they break the oxygen bonds process call scission And then lastly certain glasses add compound type called intermediate And these are actually network formers but they form different number bonds than the parent network Typically larger number bonds And doing they create some free volume which enhances certain properties sometimes the mechanical properties sometimes the thermal properties Specifically thermal shock resistance enhanced the addition network formers 
7356 en Lecture Diffusion Fick First Law and Steady state Diffusion Dependence the Diffusion Coefficient Temperature and Atomic Arrangement The specific chemical rate constant the proportionality And can influenced temperature through this Arrhenius type relationship which compares the exponential the activation energy with the available thermal energy And saw that can integrate that rate equation and put the data the test have first order reaction should get semi log dependence And think got that shown here Here the data that showed you last day This just normal decrease concentration with time typical attenuation curve put the first order test according this relationship should get straight line with slope minus 
7357 en Lecture Fick Second Law FSL and Transient state Diffusion Error Function Solutions FSL One announcement There will Quiz the weekly quiz tomorrow based the content Homework which don remember what but you know what made but already thinking about the next glorious event Now remember There chemical kinetics and glasses That right chemical kinetics and amorphous solids That right Last day started talking about diffusion which solid state mass transport random atomic motion And were drawn the paper that the display which was published 1855 Adolf Fick which gave the law that bears his name describing how matter diffuses through matter Fick was very talented individual and want draw attention something else 
7358 en Lecture Solutions Solute Solvent Solution Solubility Rules Solubility Product will start with the material beginning with Bragg law didn talk about diffraction the last test The coverage talked about generation rays but not their use diffraction starting with ray diffraction through the end last day lecture And the reason doing this that tomorrow holiday There are academic exercises tomorrow And didn think made good pedagogical sense teach you something today and have recitation Thursday You don meet again with your recitation instructor until Tuesday and then Wednesday the test being mindful that going start talking about solutions today None that will the test 
7359 en Lecture Acids and Bases Arrhenius Brønsted Lowry and Lewis Definitions Acid Strength and And came know the common ion effect which the presence common ion observed repressed solubility Today want talk about subset some specialized solution chemistry And that takes acids and bases which are pervasive Perhaps you got this morning and washed your hair with balanced shampoo and treated yourself some orange juice with citric and ascorbic acid Maybe you had the radio playing powered zinc alkaline batteries started car thanks lead acid battery And had some appliances running electricity generated coal fired plant which was spewing sulfur dioxide generating acid rain are off good start 
7360 en Lecture Organic Chemistry Basic Concepts Alkanes Alkenes Alkynes Aromatics Functional Groups Alcohols and Ethers Aldehydes and Ketones Esters Amines you should know what are going examining you and the same comments that made before want give you feedback let you know how you doing whether your study methods are effective not not attempt retest your admission MIT anything like that you your work you should very well And you have not done your work you shouldn very well and able tell you just what said the past Please take the time read the whole exam the easy questions for you the ones that you find easiest those first But let honest this isn high school anymore 
7361 en Lecture Organic Glasses Polymers Synthesis Addition Polymerization and Condensation Polymerization lot people improved There were lot rags riches stories but there are still fair number people down here And suggestion you that you are down here and you want Too much talking people you want start your weekend soon will help you inviting you leave You don have stay here you don want but you choose stay please sit silence This 091 you are down here get and see Please talk your recitation instructor come and see and will talk about strategies for studying strategies for success want you pass this class but just doing the same thing over This think Einstein definition insanity doing the same thing over and over again expecting different outcome 
7362 en Lecture Structure property Relationships Polymers Crystalline Polymers last day started talking about polymers macromolecules These are chemicals that have very high molecular weight with repeating chemical structure given example here vinyl chloride the individual molecule And addition polymerization can break the double bond have propagate and end with something which the polyvinyl chloride numbers can very large and can get molecular weights the vicinity 000 000 grams per mole further looked tailoring properties control molecular architecture saw that could look bulk composition and form such things copolymers which are polymers what alloys are metals 
7363 en Lecture Biochemistry The Amino Acids Peptides and Proteins Today want talk about biochemistry are going spend the next three lectures biochemistry This the chemistry living organisms And want make several points way introduction The first one that living organisms are chemical systems And they are governed the same laws that apply inanimate matter don have special chemistry And fact came across this comment that was made the Nobel Laureate Richard Feynman who said that some cataclysm all scientific knowledge were destroyed and only one sentence passed onto the next generations creatures what statement would contain the most information the fewest words believe that the atomic hypothesis the atomic fact whatever you wish call that all things are made atoms 
7366 en Lecture Phase Diagrams Basic Definitions Phase Component Equilibrium One component Phase Diagrams Two component Phase Diagrams Complete Solid Solubility are going the first three lectures the last topic going talk about phase diagrams starting today Monday and wrap Wednesday Phase diagrams related the question stability and sustaining the solid state And talked about the behavior solids and used solids order teach the rudiments chemistry But today want talk about the conditions under which solids are stable And under what conditions solids remain stable when they become unstable This important industry for example 
7367 en Lecture Two component Phase Diagrams Limited Solid Solubility Lever Rule What want today finish the second installment phase diagrams Last day looked unary phase diagrams That say single component That meant all had was worry about pressure versus temperature because everything simple composition And have here the display phase diagram water which looked last day And have redrawn here for convenience And just wanted draw your attention several things are looking how the stability the different phases water varies with pressure and temperature 
7368 en Lecture Wrap Closing Remarks about the Course Student Course Evaluations You think you happy happy very happy What will today wrap phase diagrams make some comments about the final exam and then going get some people that aren associated with class are going come they will pass out paperwork and the course evaluations And get you out here Before any further draw your attention another IAP subject you looking for something during January and this will offered myself and postdoc Patrick Trapa 
7382 en Advanced Topics Programming Languages Series Python Design Patterns
7389 en Categorizing Field – The Use the Nanotechnology Label across Communities Labels are important the emergence organizational fields The construction and use labels enables communication and coordination across communities This paper argues that new and existing communities’ uses labels commence categorization process central the construction meaning and definition boundaries within organizational fields Employing ethnographic observations interviews and 774 articles from five different nanotechnology communities covering primarily the year period from 1984 2005 show the differentiated use the nanotechnology label across communities Scientists and entrepreneurs were not the creators and first adopters the nanotechnology label instead futurists the government and venture capitalists played pivotal roles promoting the nanotechnology label supplying the field with resources and infusing the nanotechnology label with meaning Theoretically this paper adds our understanding field emergence reframing emergence categorization process 
7390 en Nanotechnology Collaboration Information Transfer and Field Structure Nanotechnology unique field encompassing many disciplines and specializations Collaboration between firms important the development the field and collaboration across sub fields may particularly beneficial – stimulating innovation through the exchange information Based survey conducted 242 Massachusetts nanotechnology firms explore the underlying factors that encourage and direct collaboration between firms Firms are often embedded several different networks association – with university collaborators industry wide associations informal networks information transfer and field identity consider whether these loose associations lead more tangible types cooperation between firms and explore what factors push firms create diverse ties across disciplines Finally consider how the resulting structure may impact firms and the industry 
7392 en Local Ecologies Knowledge National Systems Innovation and Nanotech Research the Global South Science and technology studies tend focus the global South and especially Africa mainly when “following the Northern scientist” southwards when seeking sites pathology and data collection novice partners European and American research projects Yet the fields bio nano and information technologies are rapidly converging many regions the world and research proceeding apace several key centers erstwhile developing countries This presentation will examine the features South Africa’ complex local ecology knowledge and its national system innovation suggesting how bio pasts may shaping nano futures there specific ways which may provide important insights and raise provocative questions for the study nano tech societies 
7393 en Bounding Nanotechnology Deconstructing the Drexler Smalley Debate Nanotechnology” has been touted many one the most critical emerging technological fields today – offering promises new treatments for cancer new computing approaches etc However determining what nanotechnology means the nature its benefits and its risks whose research counts nanotechnology and who gets speak behalf those who nanotechnology – essentially the process drawing boundaries around nanotechnology field – has turned out highly political process constant negotiation with significant implications for funding legislation risk management and public support this presentation will focus the construction one the most high profile moments controversy about nanotechnology’ possibilities debate between Eric Drexler and Richard Smalley published “point counterpoint feature” Chemical Engineering News Drawing upon scholarship science studies concerning boundary work well organizational theory the role entrepreneurial actors the emergence institutions seek broaden analysis the debate include important institutional and organizational contexts – particularly the role science journalism and editorial decision making nnSarah Kaplan Assistant Professor Management the Wharton School University Pennsylvania She also author the bestselling business book Creative Destruction Currency Doubleday 2001 which looks the challenges performance dynamic markets She received her from MIT’ Sloan School Management Her research investigates the role interpretive processes shaping technology evolution and firm response technical change the biotechnology telecommunications personal digital assistant and most recently nanotechnology fields Prior her academic career she was management consultant for nearly decade with McKinsey Company where she put innovation tools and techniques work broad range companies many industries such medical devices retailing steel pharmaceuticals and consumer packaged goods 
7394 en Laboratory Engagements Risky Discourse and Research Decisions This presentation describes semi structured interactions between social scientists and nanoscale researchers and around the laboratory that are based approach termed midstream modulation Contrary initial skepticism the part nanoscale scientists the interactions came seen valuable both from the standpoint responsible innovation and also terms the research process itself nnErik Fisher Assistant Research Professor Center for Nanotechnology Society and Consortium for Science Policy and Outcomes Fisher joins CNS ASU from the University Colorado Center for Science and Technology Policy Research the summer 2006 CNS ASU fellowship allowed him spend several weeks the Netherlands comparing international studies nanotechnology society His research included both macro and micro level analysis the integration societal considerations into conducted ethnographic style research nanoscale engineering laboratory investigate the possibility and utility implementing key provisions federal nanotechnology legislation Fisher research has been published Science and Public Policy Technology Society and Philosophy Today holds graduate certificate Science and Technology Policy Classics and Philosophy and Mathematics
7395 en  Mirror Social Development Industry decisions regarding new technologies This study examines how organizations manage risks presented new technologies and the impact the institutional environment has this governance process Micro and nanotechnology research and development presents important case which study the influence institutional environments organizations Our survey addresses the perspectives and actions firms take address the potential importance environmental health and safety public perceptions and regulation their decisions Recent public reports have raised concern about seeming lack attention potential governance and regulatory concerns within the industry Our preliminary survey data collected from Massachusetts based firms supports the view that companies decisions concerning nanotechnology are not usually influenced environmental occupational health and safety concerns consumer and general public perceptions Companies are sensitive federal and state regulations although these are minor concern for companies surveyed 
7396 en Advancing the Science Science and Innovation Policy Current Approach and Next Step The scientific enterprise often cited being critical factor contributing the creation high wage jobs and firm competitiveness Yet our scientific understanding the functioning the scientific enterprise extremely limited which turns limits our understanding the consequences different policy interventions The Science Science Innovation Policy program NSF was established order better empirical and theoretical basis for science and innovation policy The presentation will provide overview the current state the program the research and discussion the future research agenda 
7397 en Inventor Mobility and Knowledge Transmission Nanotechnology Using patent records nanotechnology study the relationship between inventor mobility among firms and knowledge diffusion find evidence consistent with story that one important nanotechnology subfield when inventors move among firms they spread knowledge particular find that consider any two patents and where and are the Chemicals misc subclass and are assigned different firms and where granted after patent more likely cite patent the patent firm employs inventor who earlier worked for the patent firm 
7398 en Nano Social Science Emerging Specialization Our group Georgia Tech Alan Porter Philip Shapiro and Jan Youtie continues analyze expanding compilation nanoscience and nanoengineering “nano” research literature from three databases well nanopatents have recently updated our Science Citation Index nano search through mid year 2008 contains 508 000 article abstracts dating from 1991 have now compiled counterpart nano searches the Social Science Citation Index Arts Humanities Citation Index and Scopus – totaling 307 articles profile this small but rapidly growing literature explore the development social sciences addressing nanotechnology find evidence that social scientists are increasingly drawing their own body literature whereas earlier years they drew relatively more heavily upon the nano science and engineering literatures Bibliometric analyses identify contingent some authors whose work heavily cited the nano social science literature parse them into eight dimensions and explore the literature’ changing emphases Our results support the hypothesis that social studies nano are coalescing into research network their own right 
7399 en Manufacturing Issues and the National Nanomanufacturing Network Without manufacturing there are products Nanomanufacturing involves broad range issues that are addressed with best practices developed from previous manufacturing experiences well new approaches The National Nanomanufacturing Network NNN open network for collaboration and information exchange among the nanomanufacturing research development and education community This network alliance academic government and industry partners that cooperate advance nanomanufacturing strength the The NNN conducts strategic workshops and facilitates other cooperative activities build effective and responsible communities practice nanomanufacturing The NNN hosts InterNano the open source information clearinghouse provide vital information nanomanufacturing community nnMark Tuominen rofessor Physics and Director the Center for Hierarchical Manufacturing CHM and MassNanoTech University Massachusetts Amherst CHM research and education center for the development efficient process platforms and versatile tools for the two and three dimensional integration components and systems across multiple length scales Its mission includes collaboration and cyberinfrastructure activities through National Nanomanufacturing Network internano org and digital library based nanomanufacturing clearinghouse MassNanoTech campus wide initiative for nanoscale science and engineering With more than faculty researchers the Initiative provides single point contact for academic and industrial collaborations Tuominen personal research interests are around nanostructures from self assembling block copolymer templates and nanoscale device physics 
7400 en Question and Answers for Pannel 
7401 en Question and Answers for Pannel 
7402 en Question and Answers for Pannel 
7417 en  Projects CERN The speaker will review and illustrate with examples the different types aspects occurring projects CERN and the current initiatives aiming properly handling these projects 
7418 en Intellectual Property Issues Practice Protection Use and Dissemination Project Results Based practical cases the speaker will first show the good practices regarding issues and framework and then address Rights and their application FP7 projects 
7419 en Patenting CERN The speaker will present why when CERN takes patents highlighting motivations and benefits the patent system for CERN 
7420 en Information from Patents Applications Commercialising Scientific and Industrial Research and Development The speaker will address the role patent information the basis case studies covering pure research applied research innovation and development 
7421 en Organization and Content the Seminar Presentation the Intellectual Property seminar 
7422 en Introduction research General overview the role research CERN 
7435 en Equality Internet Access Broadband Massachusetts public Town Hall Forum with Department Telecommunications and Cable Commissioner Sharon Gillett was held Wednesday April 2008 the University Massachusetts Amherst nnThe Town Hall Forum was designed provide opportunity for researchers citizens advocates and students discuss Governor Deval Patrick broadband initiative and related policy issues concerning telecommunications and cable nnThe Forum was sponsored the Science Technology and Society Initiative the Center for Public Policy and Administration and the National Center for Digital Government 
7438 en Human Rights and Global Issues our Time
7440 en Human Rights and Global Issues our Time
7441 en Human Rights and Global Issues our Time
7442 en Implementing common framework business and human rights Professor John Ruggie Special Representative Business and Human RightnIrene Khan Secretary General Amnesty InternationalnModerated John Morrison Programme Director Business Leaders Initiative Human Rightsn BLIHR 
7443 en Human Rights and Global Issues our Time
7444 en Implementing common framework business and human rights
7445 en Questions Reactions from the audience
7447 en ‘Looking back’ – what have learned from the past years
7448 en ‘Looking back’ – what have learned from the past years
7451 en ‘Looking back’ – what have learned from the past years
7452 en ‘Looking forward’ – what are some the challenges the next years
7453 en Global human rights the age The key lessons the Universal declaration
7454 en European Union Area Globalization
7467 en ‘Looking forward’ – what are some the challenges the next years
7468 en ‘Looking forward’ – what are some the challenges the next years
7469 en ‘Looking forward’ – what are some the challenges the next years
7477 en The responsibility respect human rights due diligence and avoiding complicity
7480 en The value human rights aware approach business key global challenges
7481 en The value human rights aware approach business key global challenges
7482 en The value human rights aware approach business key global challenges
7483 en The value human rights aware approach business key global challenges
7484 en The value human rights aware approach business key global challenges
7491 en Compiling monolingual dictionary for native speakers
7492 en Lexicographer notes related corpus based dictionary
7529 en Lecture Introduction layered view digital communication
7530 en Lecture Discrete source encoding
7531 en Lecture Memory less sources prefix free codes and entropy
7533 en Lecture Entropy and asymptotic equipartition property
7534 en Lecture Markov sources and Lempel Ziv universal codes
7536 en Lecture High rate quantizers and waveform encoding
7537 en Lecture Measure fourier series and fourier transforms
7538 en Lecture Discrete time fourier transforms and sampling theorem
7539 en Lecture Degrees freedom orthonormal expansions and aliasing
7540 en Lecture Signal space projection theorem and modulation
7541 en Lecture Nyquist theory pulse amplitude modulation PAM quadrature amplitude modulation QAM and frequency translation
7543 en Lecture Jointly Gaussian random vectors and processes and white Gaussian noise WGN 
7544 en Graphical models This course covers the basics Probabilistic Graphical Models including the basic theory Bayesian Networks and Markov Random Fields well inference and learning algorithms and applications 
7545 en Reinforcement learning This course covers the theory and application reinforcement learning the task learning make optimal sequential decisions when given delayed reward signal Topics will include planning known and unknown environments and will place equal emphasis theoretical results and practical implementation issues the context various applications 
7546 en Document Analysis will consider various problems document analysis named entity recognition natural language parsing information retrieval and look various probabilistic graphical models and algorithms for addressing the problem This will not extensive coverage information extraction natural language processing but rather look some the theory methods and practice particular cases 
7547 en Group Theory Machine Learning This course covers diverse aspects the role played symmetry pattern analysis and machine learning designed provide background knowledge using examples and touch current research topics without over emphasizing formalizations and technical descriptions 
7548 en Learning Theory This course highlights some relationships between surrogate losses scoring rules divergences Bregman divergences statistical information and ROC curves and their implications for applications such divergence estimation 
7550 en Computer vision pseudo boolean function function from the space boolean vector the real numbers They occur naturally problems computer vision related segmentation where every pixel image should labelled minimize certain cost function Although the minimization such functions general hard many techniques have been develloped minimize certain classes such functions This the topic pseudo boolean optimization which will the subject this talk Useful methods include graph cuts algorithms message passing and linear programming relaxation The extension functions with finite label set will also considered 
7551 en Game Theory Clustering The course will provide overview recent work pairwise data clustering which has lead establish intriguing connections between unsupervised learning and evolutionary game theory The framework centered around the notion dominant set novel graph theoretic concept which generalizes that maximal clique edge weighted graphs Algorithms inspired from evolutionary game theory and applications computer vision and pattern recognition will discussed 
7552 en Unsupervised learning The first part his tutorial will discuss supervised semi supervised and partially supervised learning Convex relaxations will presented for supervised and semi supervised training support vector machines max margin Markov networks log linear models and Bayesian networks The concept partially supervised training will then introduced with convex relaxations developed for training multi layer perceptrons and deep networks Relationships these methods classical training algorithms Viterbi and self supervised training will discussed Limitations convex relaxations will also considered The tutorial will then present methods for scaling such training algorithms Finally some simple approximation bounds will introduced along with rudimentary generalization theory for self supervised training 
7553 en Data Mining The ability distinguish differentiate and contrast between different datasets key objective data mining Such ability can assist domain experts understand their data and can help building classification models This presentation will introduce the principal techniques for contrasting datasets will also focus some important real world application areas that illustrate how mining contrasts advantageous 
7554 en Lecture Linear functionals and filtering random processes
7555 en Fundamentals Metalogic This course provides introduction the metatheory elementary logic Following refresher the basics notation and the use classical logic representation language concentrate the twin notions models and proof axiomatic system first order logic introduced and proved complete for the standard semantics and then give overview the basic concepts proof theory and formal set theory The material this course presupposed other courses the Summer School which why presented first 
7556 en Computability And Incompleteness these lectures cover the following topics Computability and Recursive Functions Proof that exactly the partial recursive functions are computable Gödel’ Incompleteness Theorems Löb Theorem These very deep and very powerful results metalogic from the 1930s were unexpected They arose context which was expected that finitary proof consistency arithmetic would shortly forthcoming This followed the proposal the mathematician David Hilbert 1862 1943 for the complete axiomatisation and formalisation all mathematical knowledge and proofs Although committed formal methods many Hilbert’ proofs were existential nature which ran counter the finitistic constructivist methods mathematics deal with this criticism Hilbert proposed that the formal methods program should establish that all the “Ideal” existential arguments could principle replaced “Real” constructive arguments showing some sort conservation result However the incompleteness results showed that this ‘program’ could not carried out simple way 
7557 en Introduction Modal Logic cover the syntax Kripke semantics correspondence theory and tableaux style proof theory propositional modal and temporal logics These logics have important applications diverse range fields incuding Artificial Intelligence Theoretical Computer Science and Hybrid Systems 
7558 en Lecture Review introduction detection
7559 en Overview Automated Reasoning Course Description many applications expect computers reason logically might naively expect this what computers are good but fact they find extremely difficult this overview course look briefly several varieties mechanical reasoning The first automated deduction whereby conclusions are derived from assumptions purely following algorithm without user intervention Automated deduction procedures are parametrized the logic they are capable reasoning with distinguish between propositional logic and first order logic Development and application propositional logic procedures also called SAT solvers received considerable attention the last ten years for solving constraint satisfaction problems applications hardware design verification and planning and scheduling Regarding automated deduction first order logic discuss applications standard deductive procedures such resolution and basic concepts such unification also examine the dual problem theorem proving viz generating models given theory which has applications finding counterexamples for non theorems third important area covered the course dealing with interactive theorem proving Interactive theorem proving requires certain amount instructions from the user tell the proving program the theorem prover how proceed with proof Such interaction required usually because the use higher order logics whose expressive formalisms allow natural modeling complex systems such operating system various protocols recent trend the development interactive proving improve its automation combining the power automatic provers 
7560 en Overview Automated Reasoning Course Description many applications expect computers reason logically might naively expect this what computers are good but fact they find extremely difficult this overview course look briefly several varieties mechanical reasoning The first automated deduction whereby conclusions are derived from assumptions purely following algorithm without user intervention Automated deduction procedures are parametrized the logic they are capable reasoning with distinguish between propositional logic and first order logic Development and application propositional logic procedures also called SAT solvers received considerable attention the last ten years for solving constraint satisfaction problems applications hardware design verification and planning and scheduling Regarding automated deduction first order logic discuss applications standard deductive procedures such resolution and basic concepts such unification also examine the dual problem theorem proving viz generating models given theory which has applications finding counterexamples for non theorems third important area covered the course dealing with interactive theorem proving Interactive theorem proving requires certain amount instructions from the user tell the proving program the theorem prover how proceed with proof Such interaction required usually because the use higher order logics whose expressive formalisms allow natural modeling complex systems such operating system various protocols recent trend the development interactive proving improve its automation combining the power automatic provers 
7561 en Introduction Statistical Machine Learning This course provides brief overview the methods and practice statistical machine learning which concerned with the development algorithms and techniques that learn from observed data constructing stochastic models that can used for making predictions and decisions The idea the course give mini introduction and background logicians interested the courses and summarize the core concepts covered the machine learning courses during this week 
7562 en Logic Automata Games This course provides the students with fundamental notions temporal logic calculus two player infinite games alternating tree automata and with their relationship answer the model checking and satisfiability problems 
7563 en Dynamical Logic Dynamic Logic was developed the late 1970s David Harel building previous work Pratt modal logic and any modal logic allows reason about the truth statements different states worlds extends classical modal logic however taking explicitly into account the transitions from one state the next state Descriptions actions events programs are part the syntax Dynamic Logic This course will start with introduction into the logical theory propositional and first order dynamic logic with respect very fine grained notion actions the next level Dynamic Logic for abstract programing language will considered will end presenting Dynamic Logic for real programming language and show how this can used software verification including demo working system 
7564 en Lecture Detection for random vectors and processes
7565 en Lecture Theorem irrelevance ary detection and coding
7566 en Lecture Baseband detection and complex Gaussian processes
7567 en Lecture Introduction wireless communication
7568 en Lecture Doppler spread time spread coherence time and coherence frequency
7569 en Lecture Discrete time baseband models for wireless channels
7570 en Lecture Detection for flat rayleigh fading and incoherent channels and rake receivers
7571 en Lecture Case study — code division multiple access CDMA 
7572 en Official welcomes Pozdravni nagovori
7575 en The Centre Everywhere Religion and the Public Space
7576 en Europe Trope Contemporary Muslim Thought
7577 en Maria’ Flag Religion and Public Space Europe
7578 en Turkey and the Consolidation Democracy Turkey
7579 en Turkish “State Islam”– Example The Relationship Between Religion and State
7580 en Accession Turkey the European Union Analysis Historical Political and Economical Processes
7581 en The “Responsibility Protect” Common Approach the and Turkey
7583 en Globalized Governance the Democratic Deficit and the ansnationalization the Public Sphere
7584 en Characteristic “Defects” Pluralistic Media Systems Eastern Europe
7585 en Somaesthetics and Democracy From Theory Practice – Considering Advertising The Equality Based Public Perception The Bodily Differences
7586 en The New “Oriental Despotism” Imagery Democratic Europe through its Others
7587 en The Missing Link Flaws and Democracy Promotion Strategies
7588 en Solidarity and Social Hope The European Case
7589 en Have the ‘Eastward Enlargements’ the European Union Further Extended and Deepened Democratic Scrutiny Accountability Deliberation Participation and Control the New Member States 
7590 en Transition and Europeanisation Central and Eastern Europe – National Post National 
7591 en Democracy Concept Political Responsibility the People
7592 en Democratic Antinomies Freedom and Security Liberty and Equality Individual and Collective Claims
7593 en Interpersonal relationships basis ethics
7596 en Justification Legitimacy and the Authority the European Polity
7598 en The Contingent Encounter Equality and Liberty Contemporary Theories Postdemocracy
7599 en European Citizenship The Roma Issue
7600 en Gender still significant qualifier the labour market structure Gender differentiation and segregation some key professions The Example the Republic Slovenia 
7601 en Measuring Social Capital Multicultural Communities
7602 en Balkan Wars The Past and the Future Europe Historical Perspectives Western and Eastern European Historiographies
7642 en Lecture State system 0th law equation state
7643 en Lecture Work heat first law
7644 en Lecture Internal energy expansion work
7655 en Lecture Entropy and the Clausius inequality
7657 en Lecture Entropy and irreversibility
7658 en Lecture Fundamental equation absolute third law
7660 en Lecture Criteria for spontaneous change
7662 en Lecture Gibbs free energy
7663 en Lecture Multicomponent systems chemical potential
7666 en Lecture Temperature pressure and 
7667 en Lecture Equilibrium application drug design
7668 en Lecture Phase equilibria — one component
7669 en Lecture Clausius Clapeyron equation
7670 en Lecture Phase equilibria — two components
7672 en Lecture Non ideal solutions
7674 en Lecture Introduction statistical mechanics
7675 en Lecture Partition function — large limit
7676 en Lecture Partition function — many particles
7677 en Lecture Statistical mechanics and discrete energy levels
7679 en Lecture Applications chemical and phase equilibria
7680 en Lecture Introduction reaction kinetics
7681 en Lecture Complex reactions and mechanisms
7682 en Lecture Steady state and equilibrium approximations
7684 en Lecture Temperature dependence catalysis
7686 en Lecture Autocatalysis and oscillators
7775 en Online Social Networks Modeling and Mining Online social networks have become major and driving phenomena the web this talk will address key modeling and algorithmic questions related large online social networks From the modeling perspective raise the question whether there generative model for network evolution The availability time stamped data makes possible study this question extremely fine granularity exhibit simple natural model that leads synthetic networks with properties similar the online ones From algorithmic viewpoint focus data mining challenges posed the magnitude data these networks particular examine topics related influence and correlation user activities and compressibility such networks 
7776 en Information Theoretic Comparison Stochastic Graph Models Some Experiments The Modularity measure community structure known falsely ascribe community structure random graphs least when naively applied Although motivated simple kind comparison stochastic graph models has been suggested that more careful comparison information theoretic framework might avoid problems like this one Most earlier papers exploring this idea have ignored the issue skewed degree distributions and have only done experiments few small graphs means large scale experiment over 100 large complex networks have found that modeling the degree distribution essential Once this done the resulting information theoretic clustering measure does indeed avoid ’ bad property seeing cluster structure random graphs 
7777 en Approximating the Number Network Motifs World Wide Web the Internet coupled biological and chemical systems neural networks and social interacting species are only few examples systems composed large number highly interconnected dynamical units These networks contain characteristic patterns termed network motifs which occur far more often than randomized networks with the same degree sequence Several algorithms have been suggested for counting detecting the number induced non induced occurrences network motifs the form trees and bounded treewidth subgraphs size log and size most for some motifs nIn addition counting the number motifs node part was recently suggested method classify nodes the network The promise that the distribution motifs node participate indication its function the network Therefore counting the number network motifs node part provides major challenge However such practical algorithm exists nWe present several algorithms with time complexity log delta epsilon that for the first time approximate for every vertex the number non induced occurrences the motif the vertex part for length cycles length cycles with chord and length paths where log and for all motifs size most four addition show algorithms that approximate the total number non induced occurrences these network motifs when efficient algorithm exists Some our algorithms use the color coding technique 
7778 en Finding dense subgraphs with size bounds
7779 en The giant component random subgraph given graph
7780 en Quantifying the impact information aggregation complex networks temporal perspective
7781 en  Policy Perspective Query Log Privacy Enhancing Techniques popular search engines face the sometimes conflicting interests protecting privacy while retaining query logs for variety uses numerous technical measures have been suggested both enhance privacy and preserve least portion the utility query logs This article seeks assess seven these techniques against three sets criteria how well the technique protects privacy how well the technique preserves the utility the query logs and how well the technique might implemented user control user control defined mechanism that allows individual Internet users choose have the technique applied their own query logs 
7782 en Survey and evaluation query intent detection methods
7783 en Analysis Long Queries Large Scale Search Log
7784 en Comparative Analysis Clicks and Judgments for Evaluation
7785 en Query Suggestions Using Query Flow Graphs
7786 en Intentional Query Suggestion Making User Goals More Explicit During Search
7787 en Search Shortcuts Using Click Through Data from the 2006 RFP Dataset
7845 en Adopt rag doll and save child For the sixth consecutive year now UNICEF Slovenia has been successfully implementing the project Rag doll which under the title Adopt rag doll and save child ensures the vaccination children against six infectious diseases diphtheria measles whooping cough infantile paralysis tuberculosis and tetanus the developing countries Namely every day million children around the world die from the diseases that could prevented nThe project Rag doll has spread throughout the entire country with extreme success among the small and big the young and old men and women makers rag dolls The rag doll toy known all cultures the world and this project UNICEF symbolizes child from developing country who needs our help With the purchase adoption rag doll you enable the vaccination one child against six infectious diseases nThe manufacturing rag dolls based the voluntary work older volunteers pupils primary and secondary schools and children and their teachers kindergartens The purchase rag doll forms bond between those who helped child with their contribution and those who enabled this with their voluntary work For this purpose every rag doll has identification card with her his characteristics and greeting card with which buyer can inform the manufacturer about the doll new home Thus the doll not bought but rather adopted her new family Facts and figures more than million children around the world are not vaccinated due the diseases that could prevented vaccination die over million children every year six children every minute one child every minute solely due measles while the 80s only every fifth child was vaccinated today the number has risen the world children What UNICEF doing UNICEF the main supplier vaccines the developing countries UNICEF vaccinates more than all the children around the world EUR diphtheria measles whooping cough infantile paralysis tuberculosis tetanus nnMake your own unique rag doll and save childnIt not difficult make doll can done anyone child adult all you need little imagination and effort 
7850 en The Secret History Silicon Valley How Stanford the CIA NSA Built the Valley Know TodaynnHow much does average Googler know about the history the placenhe works Silicon Valley nCome and test your knowledge have seen this talk and assure you neven seasoned Silicon Valleynveterans will find this story interesting Silicon Valley entrepreneurnSteve Blank will talk about hownWorld War set the stage for the creation and explosive growth ofnSilicon Valley and the role ofnFrederick Terman and Stanford working with government agenciesn including the CIA and thenNational Security Agency set companies this area thatnsparked the creation hundredsnof other enterprises 
8086 en Machine Learning Pattern Recognition Cross modal analysis and fusion
8089 en Multimedia Ontologies for Reasoning and Analysis
8091 en Flexible Interfaces for Semantically Annotated Multimedia
8092 en Calais the media and the semantic web
8094 en Concerns about Privacy Innovation ICT and Media Industries
8095 en Taling about Networked Journalism Search Privacy Filtering Personalisation
8195 en Authors Google Slavoj Zizek The Authors Google program was pleased welcome Slavoj Google New York office discuss his latest book Violence 
8198 en New materials where chemistry and materials sciences meet Novi materiali kjer sre ata kemija znanost materialih New materials are the basis for new technologies overcome the limits traditional materials new materials concepts are needed example inorganic organic hybrid materials Combination inorganic and organic building blocks molecular scale results properties between that purely organic polymers molecular materials etc and purely inorganic materials glass ceramics etc order obtain the desired “tailor made” property profiles the reactivity and functionality the molecular precursors must carefully tuned This offers the opportunity design chemical strategies for the synthesis materials with pre defined properties nNovi materiali osnova novih tehnologij presegli meje tradicionalnih materialov potrebni konceptualno novi pristopi sintezi Primer teh anorgansko organski hibridni materiali Kombinacija anorganskih organskih gradnikov molekularni ravni vodi lastnosti med lastnostmi istih organskih polimeri molekularni materiali itd istih anorganskih materialov steklo keramika itd nnDa dosegli elene lastnosti novega materiala potrebno skrbno izbrati prilagoditi reaktivnost funkcionalnost molekulskih snovi katerih izhajamo daje nosti rtovanja kemijskih strategij sintezo materialov vnaprej dolo enimi lastnostmi 
8201 en Service oriented architectures Case study
8206 en Web Service Modeling Ontology WSMO 
8207 en Web service modeling language WSML 
8210 en Business Process Management The semantics BPM
8212 en Towards verifying compliance Semantic Web service compositions
8213 en Web services geospatial semantic web
8241 en Non classical Logic Non classical logics are used characterize phenomena with which classical logic has difficulty represent alternative views reasoning Relevant logic for example rejects the rule classical logic that allows add new premises already valid inference produce another valid inference Relevant logic its name suggests demands that all the premises valid argument actually relevant the derivation the conclusion contrast weaker form relevant logic – linear logic – not supposed represent alternative view valid inference but rather describe relationships between different sorts entities than classical relevant logic Traditionally logics are thought represent relationships between propositions but linear logic represents relationships between resources and actions The resulting logic quite different from traditional logics and interestingly related the other logics that will study such relevant logic variant linear logic that will also examine used study the flow information between agents 
8242 en Intelligent Agents agent entity that receives percepts from the environment which operating and applies actions the environment order achieve its goals The notion agent provides unifying conceptual framework for current research artificial intelligence nnIn these three lectures will introduce the basic ideas agents describe some agent architectures and comment briefly relevant philosophical and historical issues 
8243 en Search and Games Search major direction current research and powerful solving technology wide range real life problems This course focuses single agent search techniques Pathfinding games used application domain 
8244 en Artificial Intelligence Planning The course presents the most important approaches state space traversal used planning including techniques based propositional satisfiability testing heuristic state space search and logic based data structures like binary decision diagrams The main applications these techniques classical planning and more complex forms planning discussed 
8245 en Knowledge Representation and Reasoning Research knowledge representation and reasoning has long history artificial intelligence and logic based approaches have played major part the fields development this course will survey logic based KRR from non monotonic logics though description logics and the semantic web 
8246 en Universal Artificial Intelligence The dream creating artificial devices that reach outperform human intelligence many centuries old this course will present elegant parameter free theory optimal reinforcement learning agent embedded arbitrary unknown environment that possesses essentially all aspects rational intelligence The theory reduces all conceptual problems pure computational questions 
8247 en Weighted Graphs and Disconnected Components Patterns and Generator The vast majority earlier work has focused graphs which are both connected typically ignoring all but the giant connected component and unweighted Here study numerous real weighted graphs and report surprising discoveries the way which new nodes join and form links social network The motivating questions were the following How connected components graph form and change over time What happens after new nodes join network– how common are repeated edges study merous diverse real graphs citation networks networks social media internet traffic and others and make the following contributions observe that the non giant connected components seem stabilize size observe the weights the edges follow several power laws with surprising exponents and propose intuitive generative model for graph growth that obeys observed patterns nnJoint work with Leman Akoglu and Christos Faloutsos 
8248 en Large Scale Scene Matching for Graphics and Vision
8249 en Efficient Parallel Learning Linear Dynamical Systems SMPs
8251 en Machine Learning Applications Challenges Natural Language Parsing
8253 en Lattice dynamics studied inelastic neutron scattering and numerical modelling Neutron scattering and lattice dynamics have long history particular with experimental data being used refine inter atomic force constants Nowadays there still strong synergy between experiment and simulation with the difference that initio computational methods are often now used analyse inelastic scattering data from complex systems addition abinitio methods give access electronic and magnetic structure the latter being directly probed neutron scattering techniques 
8368 en Opening LICSB 
8370 en Detecting Evolutionary Inter Gene Heterogeneity Borrelia burgdorferi Borrelia burgdorferi one the bacterial species responsible for the most prevalent vector borne disease the temperate zone the northern hemisphere Lyme borreliosis Phylogenetic analyses burgdorferi are now based concatenation several housekeeping genes that are assumed evolve according one evolutionary pattern nnThis strong assumption and when untrue inferences are compromise between different phylogenetic signals have designed Bayesian mixture model under missing data formulation automatically recover the evolutionary pattern each site DNA alignment Evolutionary consistency among set genes can argued whenever most the sites are allocated the same evolutionary class nnOnly this case will concatenation genes produce valid inferences this study demonstrate consistency the evolution eight housekeeping genes and evolutionary inconsistency between these housekeeping genes and the gene encoding the immunodominant outer surface protein Our method suitable indicator evolutionary agreement disagreement when employing large scale gene concatenations not only burgdorferi but for any phylogenetic analysis Margos 2008 Proceedings the National Academy Sciences the USA 105 8730 8735 
8371 en Role Gene Mutations Predicted from Computational Model the Cochlea the Inner Ear The mutations the GJB2 gene encoding for the connexin Cx26 protein are the most common source nonsyndromic forms deafness Cx26 building block gap junctions establishing electrical intercellular connectivity between cells distinct cochlear compartments Cochlear circulation ions such potassium and metabolites such IP3 essential for normal hearing animal models the Cx26 deficiency the organ Corti one the compartments seem suggest the death sensory cells outer and inner hair cells OHC and IHC respectively due failed homeostasis the underlying problem However this mechanism may not the only one search for alternative mechanisms have used large scale three dimensional model mechano electrical transduction sound the cochlea Mistrik 2009 Indeed careful analysis revealed that reduced conductivity the organ Corti would decrease the receptor potential across the OHC basolateral membrane the OHC electromotility crucial for sound amplification granting the cochlear sensitivity and frequency selectivity conclude that the reduction the OHC somatic electromotility could represent additional pathological mechanism the Cx26 related forms deafness 
8372 en Gaussian process regression bootstrapping Both mechanistic and empirical modelling techniques are employed systems biology The former construct models whose structure explicitly describes components the biological system under investigation while the latter make predictions the strength patterns the data Although empirical models such Gaussian process regression GPR not directly help elucidate the processes that generated given data set they can nevertheless form part strategy for testing and investigating hypotheses and mechanistic models our work exploit the predictive power GPR order generate plausible simulated data sets from experimentally obtained time course data This amounts parametric bootstrap which the parametric model multivariate normal that implicitly takes into account the time dependence the data Having obtained bootstrap samples fit mechanistic models both the original and simulated data The variability amongst these fitted models reveals the sensitivity the fit uncertainty the data use this approach investigate the effects data uncertainty upon parameter estimates model signalling pathway and upon gene network inference 
8373 en Estimation Multiple Transcription Factor Activities using ODEs and Gaussian Processes Recently ordinary differential equations ODEs have been used infer the concentration single transcription factor protein from time series expression data set target genes For instance this has been applied uncover the concentration the p53 protein see Barenco 2006 the present work propose framework estimate multiple TFs from set observed gene expressions that are regulated these TFs assume that the connectivity network that describes which TFs regulate each the genes partially and probabilistically observed For example such side information can available through technique such Chromatine Immunoprecipitation ChIP The objective inference estimate the structure the sub network the concentration the transcription factor proteins continuously time well infer the type regulation each network link activation repression non regulation This multiple framework uses Gaussian process priors model the unobserved activities continuously time considered Lawrence 2007 for the single case The ODE model transcriptional regulation using multiple TFs based the following linear differential equation where denotes the gene expression jth gene time are the kinetic parameters the equation each concentration function are the connectivity weights between the gene and the TFs and sigmoid Michaelis Menten type function Given set observations the gene expression discrete time points the parameters and the protein concentration functions are estimated using full Bayesian methodology that employs Markov chain Monte Carlo algorithm Gaussian process priors are placed the functions while the connectivity weights are given sparse priors that the side prior information about the network connectivity taken into account The whole framework currently applied sub networks yeast cell cycle gene expression data Spellman 1998 and Orlando 2008 using the connectivity ChiP information provided Lee 2002 This joint work with Magnus Rattray and Neil Lawrence 
8374 en Definition Valid Proteomic Biomarkers Bayesian Solutions Currently Unmet Challenge Clinical proteomics suffering from high hopes generated reports apparent biomarkers most which could not later substantiated via validation This has brought into focus the need for improved methods finding panel clearly defined biomarkers examine this problem urinary proteome data was collected from healthy adult males and females and analysed find biomarkers that differentiated between genders believe that models that incorporate sparsity terms variables are desirable for biomarker selection proteomics data typically contains huge number variables peptides and few samples making the selection process potentially unstable nnThis suggested the application the two level hierarchical Bayesian probit regression model that Bae and Mallick 2004 proposed for variable selection which used three different priors for the variance the regression coefficients inverse Gamma exponential and Jeffreys incorporate different levels sparsity their model have also developed alternative method for biomarker selection that combines model based clustering and sparse binary classification nnBy averaging the features within the clusters obtained from model based clustering deﬁne “superfeatures” and use them build sparse probit regression model thereby selecting clusters similarly behaving peptides aiding interpretation 
8375 en Time varying genetic network inference using informative priors
8376 en Moment closure and block updating for parameter inference stochastic biological models This talk will tackle one the key problems the new science systems biology inference for the rate parameters underlying complex stochastic kinetic biochemical network models using partial discrete and noisy time course measurements the system state Although inference for exact stochastic models possible computationally intensive for relatively small networks explore the Bayesian estimation stochastic kinetic rate parameters using approximate models based moment closure analysis the underlying stochastic process assuming Gaussian distribution and using moment closure estimates the first two moments can greatly increase the speed parameter inference The parameter space can efficiently explored embedding this approximation into MCMC procedure impute the missing species using bridge updating scheme where each proposed move bridge length investigate how the choice affects the efficiency the sampling auto regulatory gene network 
8377 en Bayesian model selection mechanistic models Erk MAP kinase phosphorylation dynamics ABC SMC Bayesian parameter inference algorithm which based efficient simulation mechanistic models have adapted for model selection defining extended parameter space theta Model selection ABC SMC algorithm chooses the best model for the system given the set available models balancing the fit the data and the complexity the model Here apply the phosporylation dynamics Erk MAP kinase has been demonstrated that vitro phosphorylation and dephosphorylation MAPK occur though distributive mechanism Burack 1997 Ferrell 1997 Zhao 2001 Recently novel experimental techniques based automated high throughput immunostaining and image processing have allowed for collection data based population individual cells vivo Ozaki preparation are going examine four different hypotheses distributive phosphorylation and dephosphorylation processive phosphorylation and dephosphorylation distributive phosphorylation processive dephosphorylation processive phosphorylation distributive dephosphorylation modeled kinetic ODE models and employ Bayesian model selection tool based ABC SMC algorithm Toni 2009 determine the most likely mechanisms phosphorylation and dephosphorylation occuring Erk signaling pathway vivo 
8378 en Exploring experimental designs for network inference using perturbations and Bayesian sequential learning strategy Modern approaches systems biology call for tightly coupled iterative cycle computational modelling and independent experimental validation model predictions Bayesian formulation model inference should exceptionably amenable this type experimental paradigm Given prior knowledge that has been encoded into model can train the model data from experiment The result posterior distribution over say gene regulatory networks which can act prior for the next model trained data from experiment The Bayesian model each stage can seen distillation the experimental data obtained that point and since probabilistic model can used expert prior for the model trained the next data set Bayesian sequential learning strategy can therefore employed instead waiting for all the data collected before training the first model explore this paradigm using simulated data from realistic silico model network and experimental microarray time series data sets studying stress responses Arabidopsis and coli 
8379 en Hybrid Inference for Stochastic Kinetic Models
8380 en Bayesian Hypotheses Testing Raman Spectroscopy Surface enhanced resonance Raman spectroscopy SERRS can used detect wide range biochemical species employing speciﬁc set nanoparticle probes New data obtained using this technology will signiﬁcantly improve our abilities understand biological systems enabling high throughput measurements protein concentrations Analysis spectra produced SERRS often done manually and solid statistical approach interpreting such results very important draw valid conclusions model data obtained using SERRS using Gaussian Processes This modelling approach enables computing marginal likelihoods over erent covariance functions GPs and therefore consistent hypotheses testing can performed investigate several important problems analytical biochemistry • Whether the spectroscopic response analytes changes time the observed variations can explained measurement errors • possible measure the erences concentrations analyte given practical variability the measurement • What are the most informative frequency bands measure the concentration given protein with high conﬁdence additionally develop calibration procedure based regression the spectroscopic data using Markov Chain Monte Carlo marginalise over the hyper parameters the covariance function 
8381 en Inference probabilistic model dynamic DNA Microsatellites are simple sequence repeats present both coding and non coding regions the genome DNA instability some microsatellites the underlying genetic defect number human diseases including myotonic dystrophy type DM1 New quantitative data collected single molecule analysis repeat length blood cells from 145 DM1 patients reveals the extent and nature the genetic variation within and between patients Morales PhD thesis 2006 This dataset thousands novo mutations provides unique opportunity examine the underlying mechanism mutation which thought universal biological process that simply amplified the disease case are developing discrete mathematical models and stochastic simulation techniques that capture key features the mutation mechanism underlying repeat length evolution derive analytical expressions for the length distribution adapted birth and death process and employ Bayesian techniques calibrate our models against the biological data and test model hypotheses Our work aims improve prognostic information for patients well providing deeper understanding the underlying biological process particular will provide evidence that previous model Kaplan 2007 can improved introducing non zero contraction rate 
8382 en Beyond Molecular Biology – Applying Gene Regulation Network Inference Methods Ecology Reconstructing gene regulation networks from gene expression data important task molecular biology for which various network inference methods have been developed ecology species interaction networks serve similar purpose that they show how different species relate each other have investigated the possibility applying the methods that were developed for gene regulation networks reconstruct species interaction networks from species abundance data used Lotka Volterra style simulation model produce synthetic data based species interaction networks and then tried reconstruct the original network from this data using Bayesian networks LASSO Least Absolute Shrinkage and Selection Operator and SBR Sparse Bayesian Regression also developed extensions these methods for dealing with the problem spatial autocorrelation Our experiments showed that can retrieve many species interactions while keeping the false positive rate low compared the different methods and found that LASSO and Bayesian networks perform best 
8383 en Temporal Development and Collapse Arctic Plant Pollinator Network Topology and linkage rules plant pollinator networks have received much attention lately One aspect that difficult study the temporal dynamics the network requires observation how the network changes over time Here study Arctic plant pollinator network two consecutive years using mathematical models and describe the temporal dynamics daily assembly and disassembly links simple statistical distributions Among other things demonstrate that the dynamics strikingly similar both years despite strong turnover the composition the pollinator community and the day day development the network poorly correlates with available weather parameters 
8385 en Mentoring and Persistence among Lower Income First Generation College Students STEM Increasing the diversity the STEM workforce has been issue national concern for decades African American and Latino students from working class families are significantly underrepresented science and technical fields and this especially the case for female students within computer science and engineering Over half first generation lower income Latinos and African American students use two year colleges trade colleges entry point the four year degree but few actually complete these pathways Thus research warranted better understand the experiences ethnically diverse working class women and men within these complex pathways research guided broadly ecological perspective that highlights the importance macro economic factors and multiple contexts home school and work has focused the mentoring experienced lower income students they strive “get track” and persist toward four year STEM degree Drawing upon longitudinal survey and interview data with high school students trade college students community college and university students have investigated how particular functions mentoring are associated with STEM persistence will describe examples essential instrumental functions mentoring and productive mentoring constellations articulate need for greater organizational infrastructures for mentoring and point implications for designing mentoring interventions governmental aid for students pursuing higher education and transfer program designs that link shorter term certificate and degree programs four year degree programs 
8411 en The state art policies for skid resistance
8412 en Low noise road surfaces current practices Europe
8413 en General discussion the potential value harmonised policies
8414 en Report back the results group discussions
8415 en Conclusions the 2nd Tyrosafe Workshop
8428 en Lecture The Motivation Applications Machine The Motivation Applications Machine Learning The Logistics the Class The Definition Machine Learning The Overview Supervised Learning The Overview Learning Theory The Overview Unsupervised Learning The Overview Reinforcement Learningn
8439 en Sparse Exponential Weighting and Langevin Monte Carlo The performance statistical estimators several scenarios such nadaptive nonparametric estimation aggregation estimators and estima ntion under the sparsity constraint can assessed terms sparsity oracle ninequalities SOI for the prediction risk One the challenges ﬁnd nestimators that attain the sharpest SOI under minimal assumptions the ndictionary Methods estimation adapted the sparsity scenario like the nLasso the Dantzig selector their modiﬁcations can easily realized for nvery large dimensions the problem but their performance conditioned nby severe restrictions the dictionary Such methods fail when the ele nments the dictionary are not approximately non correlated This some nwhat unsatisfactory since known that the BIC method enjoys better nSOI without any assumption the dictionary However the BIC method nNP hard This talk will focus Sparse Exponential Weighting new tech nnique sparse recovery aiming realize compromise between theoretical noptimality and computational ciency The method based aggrega ntion with exponential weights using heavy tailed sparsity favoring prior nThe theoretical performance Sparse Exponential Weighting terms nSOI comparable with that the BIC and even better some aspects nNo assumption the dictionary needed the same time show that nthe method computationally feasible for relatively large dimensions the nproblem prove that Langevin Monte Carlo LMC algorithms can nsuccessfully used for computing Sparse Exponential Weighting estimators nNumerical experiments conﬁrm fast convergence properties the LMC and ndemonstrate nice performance the resulting estimators This joint nwork with Arnak Dalalyan 
8440 en hase transitions phenomenon Compressed Sensing Compressed Sensing reconstruction algorithms typically exhibit zeroth order phase transition phenomenon for large problem sizes where there domain problem sizes for which successful recovery occurs with overwhelming probability and there domain problem sizes for which recovery failure occurs with overwhelming probability nnThe mathematics underlying this phenomenon will outlined for ell1 regularization and non negative feasibility point regions Both instances employ large deviation analysis the associated geometric probability event nnThese results give precise and only conditions the number samples needed Compressed Sensing applications nnLower bounds the phase transitions implied the Restricted Isometry Property for Gaussian random matrices will also presented for the following algorithms ell regularization for CoSaMP Subspace Pursuit and Iterated Hard Thresholding 
8441 en Large Precision Matrix Estimation for Time Series Data with Latent Factor Model Estimating large precision inverse covariance matrix cult due nthe curse dimensionality The sample covariance matrix notoriously bad nfor estimating the covariance matrix when the dimension the multivariate nvector comparable even larger than the number time points observed nIt singular and hence cannot inverted for the precision matrix nWe use the factor model and procedure proposed Pan and Yao 2008 nfor multivariate time series data carry out dimension reduction when ≈ nor even version the unknown factors and the corresponding factor nloadings matrix are obtained show that when each factor shared cross sectional data points the estimated factor loadings matrix well nas the estimated precision matrix for the original data converge weakly nL2 norm the true ones rate independent This striking result ndemonstrates clearly when the “curse” cancelled out the “blessings” ndimensionality particularly useful portfolio allocation ﬁnance when nthe number stocks large Convergence rate norm for the precision nmatrix directly related the goodness the estimated optimal portfolio nwhich converges weakly the true one the average squared norm nrate also independent result nWe also show that the method cannot estimate the covariance matrix nbetter than the sample covariance matrix which coincides with the result nFan 2008 when factors are known Simulations demonstrate variety nof ects the estimators when assumptions are not met set real stock nmarket data analysed 
8442 en Fast methods for sparse recovery alternatives Finding sparse solutions underdetermined inverse problems fundamental challenge encountered wide range signal processing applications from signal acquisition source separation Recent theoretical advances our understanding this problem have further increased interest their application various domains many areas such for example medical imaging geophysical data acquisition necessary find sparse solutions very large underdetermined inverse problems Fast methods therefore have developed this talk will present two classes fast algorithm that are competitive with the more classical minimization Basis Pursuit The first techniques based upon greedy selection approach However each iteration several new elements are selected The selected coefficients are then updated using conjugate update direction This extension the previously suggested Gradient Pursuit framework allow even greedier selection strategy also has the unique property allowing smooth trade off between recovery performance and computational complexity The second technique that discuss extremely simple strategy called Iterative Hard thresholding IHT Despite its simplicity can shown that gives near optimal performance guarantees robust observation noise has low bounded computational complexity per iteration and only requires fixed number iterations depending the signal noise ratio the signal Unfortunately niaive application IHT yields empirical performance substantially below that other state the art recovery algorithms therefore discuss have the algorithm can modified obtain performance that comparable with state the art while retaining its strong theoretical properties 
8443 en Poster Spotlights Comparison Inference Methods for Sparse Factor Analysis Models nOliver Stegle Kevin Sharp Magnus Rattray John Winnnn Generalization Bounds for Learning the Kernel Rademacher Chaos Complexity nYiming Ying Colin Campbellnn Learning Non Sparse Kernel Mixtures nMarius Kloft Ulf Brefeld Soren Sonnenburg Alexander Zien Pavel Laskov Klaus Robert Mullernn regularization path for functional features nManuel Loth Philippe Preuxnn regularised sparse classifiers PAC Bayes analysis nAta Kabannn Robust Regression and Lasso nHuan Constantine Caramanis Shie Mannornn Selection Functional ANOVA Models with Non uniform Data nMarco Signoretto Kristiaan Pelckmans Johan Suykensnn Sparse and Interpretable Principal Components nDoyo Gragn Nickolay Trendafilovnn Sparse multiscale spatial models fMRI irregular graphs nHarrison Woods Green Stagewise Polytope Faces Pursuit for Recovery Sparse Representations nMark Plumbley Marco Bevilacquann Subspectral Algorithms for Sparse Learning nBaback Moghaddam Yair Weiss Shai Avidannn Variable Selection and Sparsity Recovery via Penalty nZongben Hai Zhang Yao Wang Xiangyu Chang
8444 en Multi Task Learning via Matrix Regularization present method for learning representations shared across multiple tasks Multi task learning has become increasingly important recently applications such collaborative filtering object detection integration databases signal processing etc Our method addresses the problem learning low dimensional subspace which task regression vectors lie This non convex problem can relaxed trace nuclear norm regularization problem which solve with alternating minimization algorithm This algorithmic scheme can shown always converge optimal solution Moreover the method can easily extended order use nonlinear feature maps inputs via reproducing kernels This consequence optimality conditions known representer theorems for which show necessary and sufficient condition Finally consider matrix regularization with more general spectral functions such the Schatten norms instead the trace norm show that our algorithm and results apply these cases well 
8445 en Algorithmic Strategies for Non convex Optimization Sparse Learning consider optimization formulations with non convex regularization that are natural for learning sparse linear models There are two approaches this problem Heuristic methods such gradient descent that only find local minimum drawback this approach the lack theoretical guarantee showing that the local minimum gives good solution Convex relaxation such regularization that solves the problem under some conditions but often leads sub optimal sparsity reality nnThis talk tries remedy the above gap between theory and practice presenting two algorithms for direct optimization non convex objectives sparse learning for which performance guarantees can established The first method multi stage convex relaxation scheme that iteratively refines the regularization The second approach greedy procedure for solving non convex sparse regularization show that under appropriate conditions both procedures lead desirable local solutions sparse non convex formulations that are superior the global solution regularization 
8446 en High Dimensional Non Linear Variable Selection through Hierarchical Kernel Learning consider the problem high dimensional non linear variable selection for supervised learning Our approach based performing linear selection among exponentially many well defined groups features positive definite kernels that characterize non linear interactions between the original variables select efficiently from these many kernels use the natural hierarchical structure the kernels extend the multiple kernel learning framework kernels that can embedded directed acyclic graph show that then possible perform kernel selection through graph adapted sparsity inducing norm polynomial time the number selected kernels Moreover study the consistency variable selection high dimensional settings showing that under certain assumptions our regularization framework allows number irrelevant variables which sub exponential the number observations 
8447 en Matching Pursuit Kernel Fisher Discriminant Analysis consider the problem high dimensional non linear variable selection for supervised learning Our approach based performing linear selection among exponentially many well defined groups features positive definite kernels that characterize non linear interactions between the original variables select efficiently from these many kernels use the natural hierarchical structure the kernels extend the multiple kernel learning framework kernels that can embedded directed acyclic graph show that then possible perform kernel selection through graph adapted sparsity inducing norm polynomial time the number selected kernels Moreover study the consistency variable selection high dimensional settings showing that under certain assumptions our regularization framework allows number irrelevant variables which sub exponential the number observations 
8448 en Some results for the adaptive Lasso consider the high dimensional linear regression model with observations and variables The adaptive Lasso uses least squares loss with weighted penalty where the weights are proportional the inverse initial estimator the coefficients show for the case that the initial estimator obtained from the standard Lasso then under the restricted eigenvalue condition given Bickel 2007 with large probability there will false positives and adaptive Lasso will detect all coefficients larger than certain value provided the number coefficients smaller than small assume perhaps stronger version the restricted eigenvalue condition the adaptive Lasso will fact detect even smaller coefficients the limiting case under the irrepresentable condition Zhao and 2006 coefficients order least log will detected These results can obtained from oracle inequality for Lasso with general weights will present the results non asymptotic form 
8450 en Latent Variable Sparse Bayesian Models variety practical approaches have recently been introduced for performing estimation and inference using linear models with sparse priors the unknown coefficients process that can have wide ranging implications diverse areas such model selection and compressive sensing While not always derived marketed such many these methods can viewed arising from Bayesian models capitalizing latent structure expressible via hyperparameters inherent sparse distributions Here focus four such strategies standard MAP estimation hyperparameter MAP estimation also called evidence maximization empirical Bayes iii variational Bayes using factorial posterior and local variational approximation using convex lower bounding All these approaches can used compute tractable posterior approximations the underlying full distribution however the exact nature these approximations frequently unclear and challenging task determine which strategy and sparse prior are appropriate Rather than justifying such selections using the credibility the full Bayesian model sometimes done base evaluations the actual underlying cost functions that emerge from each method this end discuss common unifying objective function that encompasses all the above and then assess its properties with respect representative applications such finding maximally sparse minimal quasi norm representations This objective function can expressed either coefficient space hyperparameter space duality that facilitates direct comparisons between seemingly disparate approaches and naturally leads theoretical insights and useful optimization strategies such reweighted and minimization This perspective also suggests extensions the sparse linear model including alternative likelihood functions for classification and more general sparse priors applicable covariance component estimation group selection and the incorporation explicit coefficient constraints non negativity Several examples related neuroimaging and compressive sensing will considered 
8451 en Poster Spotlights Space Feature Selection Criteria based Multivariate Mutual Information nGavin Brownnn Alternatives modelling sparsity gene expression networks Burroughs Juarez Morrisseynn Average case theory for sparse Bayesian PCA regime nMagnus Rattraynn Inferring genetic regulation using Sparse Bayesian Regression with Penalised Splines nNigel Burroughs Miguel Juraez Morrisseynn Learning Graphical Model Structure with Bayesian Sparse Linear Factor Models nRicardo Henao Ole Winthernn Learning Sparse Classifiers with Applications Biomedical Research nColin Campbell Yiming Yingnn Regularisation with Conditionally Positive Definite Kernels nChristian Walder Jalal Fadili Stephane Canunn Model Selection with Penalised Likelihood Multi Dimensional Contingency Table nSusana Conde Gilbert MacKenzie Peter Eggernn Sparse Algorithms are not Stable free lunch Theorem nHuan Constantine Caramanis Shie Mannor Sparsity Adaptive Control nPhilippe Preux Sertan Girginnn Speech signal modelling with sparse autoregression nMahesan Niranjannn State Extraction Dimensionality Reduction nWendelin Boehmer Steffen Grunewalder Klaus Obermayer 
8452 en Sparsity online multitask multiview learning Multitask and multiview learning interesting case for the study interacting learning systems this talk describe results the multitask multiview domain where regularization achieved imposing sparsity constraints geometrical and spectral nature online learning framework nnJoint work with Giovanni Cavallanti and Claudio Gentile 
8453 en Learning with Many Reproducing Kernel Hilbert Spaces this talk consider the problem learning target function that belongs the linear span large number reproducing kernel Hilbert spaces Such problem arises naturally many practice situations with the ANOVA the additive model and multiple kernel learning the most well known and important examples investigate approaches based type complexity regularization and the nonnegative garrote respectively show that the computation both procedures can done efficiently and the nonnegative garrote could more favorable times also study their theoretical properties from both variable selection and estimation perspective establish several probabilistic inequalities providing bounds the excess risk and error that depend the sparsity the problem Part the talk based joint work with Vladimir Koltchinskii 
8454 en Distilled Sensing Active sensing for sparse recovery The study and use sparse representations data rich applications has garnered signi cantnattention the signal processing statistics and machine learning communities the presentnwork describe novel sensing procedure called Distilled Sensing which sequential andnadaptive approach for recovering sparse signals noise nPassive sensing approaches currently the most widespread data collection methods involve non nadaptive data collection procedures that are completely speci before any data observed Inncontrast collects data sequential and adaptive manner Often such procedures are knownnas active sensing sequential experimental design and allow the use data observed earliernstages guide the collection future data The added nexibility active sensing together with ansparsity assumption has the potential enable extremely effcient and accurate inference 
8455 en Testing and estimation sparse normal means model with connections shape restricted inference Donoho and Jin 2004 following work Ingster 1999 studied the problem testing nfor any signal sparse normal means model and showed that there “detection boundary” nabove which the signal can detected and below which test has any power They showed that nTukey’ “higher criticism” statistic achieves the detection boundary will introduce new family nof test statistics based phi divergences indexed which all achieve the Donoho Jin nIngster detection boundary will also review recent work estimating the proportion non zero nmeans and make some connections shape constrained estimation 
8456 en Robotics and Mechatronics From Space Surgery and the Virtual World After briefly emphasizing the importance mechatronics for our future societies the talk briefly comments the development and evolvement industrial robots over the past years emphasizes the importance mechatronic concepts and sensory feed back for more precision and autonomy the future The progress and perspectives space robotics are addressed next Space technology characterized major driver for new generation power saving ultralightweight arms and articulated hands important prerequisite for the emerging field mobile production assistants and service robotics nnThe technological potentials are demonstrated DLR space robot experiments and the newest light weight arm and four finger hand generation which are fully joint torque controlled and thus are provided with programmable cartesian impedance feature which allows for new programming techniques and human friendly operational modes One the most challenging application fields for these new technologies surgical robotics its state the art and perspectives are briefly outlined nnnHowever mechatronics crucial importance for artificial organs and prostheses too Finally the talk points out the importance intelligent mobility the development rovers and crawlers mars and moon the robotic electric cars the future and the flying robots which are capable modeling the world photorealistically 
8459 en Why study insulators Superconductors are sexier and semiconductors produce billion per year devices why should scientists study insulating materials Firstly most magnets are insulators and second all ferroelectrics which switch charge applied voltage are insulators phenomena that involve magnetism ferroelectricity piezoelectricity and pyroelectricity are generally insulating the past few years the study insulating materials has taken two new directions The study nano devices including sensors actuators and transducers The first thing one discovers that you make insulating material thin enough conducts quite well And what are the conduction mechanisms Poole Frenkel Schottky Fowler Nordheim tunneling space chage limited The second thing one finds that ferroelectrics and ferromagnets have domains and the smaller the object the smaller its domains have developed theory nano domains that works all magnets and ferroelectrics from size six orders magnitude with adjustable parameters also find domains that are round instead rectangular and fractal instead integer dimension Finally will talk about materials that are simultaneously magnetic and ferroelectric Gilbert showed 1600 that electrostatics and magnetism are unrelated but that isn quite true time permits will show some ferroelectric memories including the ones the SONY Playstation 
8465 en Lecture Application Supervised Learning Autonomous Deriving Application Supervised Learning Autonomous Deriving ALVINN Linear Regression Gradient Descent Batch Gradient Descent Stochastic Gradient Descent Incremental Descent Matrix Derivative Notation for Deriving Normal Equations Derivation Normal Equations
8466 en Lecture The Concept Underfitting and Overfitting The Concept Underfitting and Overfitting The Concept Parametric Algorithms and Non parametric Algorithms Locally Weighted Regression The Probabilistic Interpretation Linear Regression The motivation Logistic Regression Logistic Regression Perceptron
8467 en Lecture Newton Method Newton Method Exponential Family Bernoulli Example Gaussian Example General Linear Models GLMs Multinomial Example Softmax Regression
8473 en The World Wide Web and the Wealth Nations Does Matter 
8496 en Lecture Discriminative Algorithms Discriminative Algorithms Generative Algorithms Gaussian Discriminant Analysis GDA GDA and Logistic Regression Naive Bayes Laplace Smoothing
8497 en Lecture Multinomial Event Model Multinomial Event Model Non linear Classifiers Neural Network Applications Neural Network Intuitions about Support Vector Machine SVM Notation for SVM Functional and Geometric Margins
8498 en  Belief and Otherness Slavoj Zizek speaking about belief the other others radical otherness respect for otherness resistance hatred intolerance towards wisdom totalitarian regimes displacement multitude and diversity just action fighting fascism preserving humanity killing the enemy Alain Badiou Judith Butler including references movies like Unbreakable with Bruce Willis and Shrek Public open lecture for the students the European Graduate School EGS Media and Communication Studies department program Saas Fee Switzerland Europe 2006 Slavoj Zizek 
8500 en Lecture Optimal Margin Classifier Optimal Margin Classifier Lagrange Duality Karush Kuhn Tucker KKT Conditions SVM Dual The Concept Kernels
8501 en Lecture Kernels Mercer Theorem Kernels Mercer Theorem Non linear Decision Boundaries and Soft Margin SVM Coordinate Ascent Algorithm The Sequential Minimization Optimization SMO Algorithm Applications SVM
8502 en Lecture Bias variance Tradeoff Bias variance Tradeoff Empirical Risk Minimization ERM The Union Bound Hoeffding Inequality Uniform Convergence The Case Finite Sample Complexity Bound Error Bound Uniform Convergence Theorem Corollary
8503 en Lecture Uniform Convergence The Case Infinite Uniform Convergence The Case Infinite The Concept Shatter and Dimension SVM Example Model Selection Cross Validation Feature Selection
8504 en Lecture Bayesian Statistics and Regularization Bayesian Statistics and Regularization Online Learning Advice for Applying Machine Learning Algorithms Debugging fixing Learning Algorithms Diagnostics for Bias Variance Optimization Algorithm Diagnostics Diagnostic Example Autonomous Helicopter Error Analysis Getting Started Learning Problemn
8505 en Lecture The Concept Unsupervised Learning The Concept Unsupervised Learning means Clustering Algorithm means Algorithm Mixtures Gaussians and the Algorithm Jensen Inequality The Algorithm Summaryn
8506 en Lecture Mixture Gaussian Mixture Gaussian Mixture Naive Bayes Text clustering Application Factor Analysis Restrictions Covariance Matrix The Factor Analysis Model for Factor Analysis
8507 en Lecture The Factor Analysis Model The Factor Analysis Model for Factor Analysis Principal Component Analysis PCA PCA Dimensionality Reduction Algorithm Applications PCA Face Recognition Using PCA
8508 en Lecture Latent Semantic Indexing LSI Latent Semantic Indexing LSI Singular Value Decomposition SVD Implementation Independent Component Analysis ICA The Application ICA Cumulative Distribution Function CDF ICA Algorithm The Applications ICAn
8509 en Lecture Applications Reinforcement Learning Applications Reinforcement Learning Markov Decision Process MDP Defining Value Policy Functions Value Function Optimal Value Function Value Iteration Policy Iteration
8510 en Lecture Generalization Continuous States Generalization Continuous States Discretization Curse Dimensionality Models Simulators Fitted Value Iteration Finding Optimal Policy
8511 en Lecture State action Rewards State action Rewards Finite Horizon MDPs The Concept Dynamical Systems Examples Dynamical Models Linear Quadratic Regulation LQR Linearizing Non Linear Model Computing Rewards Riccati Equation
8512 en Lecture Advice for Applying Machine Learning Advice for Applying Machine Learning Debugging Reinforcement Learning Algorithm Linear Quadratic Regularization LQR Differential Dynamic Programming DDP Kalman Filter Linear Quadratic Gaussian LQG Predict update Steps Kalman Filter Linear Quadratic Gaussian LQG 
8513 en Lecture Partially Observable MDPs POMDPs Partially Observable MDPs POMDPs Policy Search Reinforce Algorithm Pegasus Algorithm Pegasus Policy Search Applications Reinforcement Learning
8526 en SP3 Semantic Web Services
8527 en COIN Service Platform with hands 
8530 en Web 20th Anniversary Panel WWW2009 coincides with the 20th Anniversary the Web conference organisers would like include this panel commemorate The initial idea provide rich overview the past years and well forecast into the future nnChair Wendy Hall 
8531 en Reflecting the last years and looking forward the next 
8533 en The Continuing Metamorphosis the Web The invention HTML and HTTP catalyzed path enormous innovation that was hard foresee the early 1990’ The Web’ continuing metamorphosis has led fantastically increased capabilities and economic value has catalyzed the creation distributed systems orders magnitude larger than any previously built new programming and distribution models for computer applications great advances the fields information retrieval entirely new domains for theoretical computer science and more This greatly enhanced web changing the entire environment and enabling some early research promises become reality for most Internet users this presentation will discuss such examples and particular what happens when speech image processing human language translation and mobility are woven into all will also extrapolate from some current research and advanced web technologies paint picture the web five ten years out This should have implications for the computer science community well the vast community that leveraging the web for ever greater goals 
8534 en The Emergence Web Science Since the term was coined 2005 Web Science has provided rallying call for researchers who are interested the social and organisational behaviour engendered the Web about the underpinning technology Web Science inherently inter disciplinary Web Science research aims provide the means better model the Web’ structure describe the principles that have fuelled its phenomenal growth and discover how online human interactions are driven and can change social conventions Research needed reveal the principles that will ensure that the network continues grow productively Research required implement principles that can settle complex issues such privacy protection and intellectual property rights course cannot predict what this nascent discipline might reveal But Web science has already generated powerful insights how the Web structured how resilient how ideas travel through the tens millions blogs how might include information Web content that its accuracy and origin more transparent the micro scale the Web infrastructure artificial languages and protocols piece engineering However fundamentally about the interaction human beings creating linking and consuming information this interaction that also need research and understand this interaction that generates the Web behavior emergent properties the macro scale These macro properties are often surprising and require analytic methods understand them The Web’ use part wider system human interaction – the Web has had profound effects society with each emerging wave creating both new challenges and new opportunities available wider sectors the population than ever before nnThe Web Science Research Initiative WSRI was launched November 2006 Tim Berners Lee Wendy Hall Nigel Shadbolt and Daniel Weitzner WWW2007 Banff WSRI sponsored reception present the ideas behind Web Science the WWW community WWW2008 WSRI sponsored workshop entitled “Understanding Web Evolution Prerequisite for Web Science” chaired Dave Roure attracted lot excellent papers – see http webscience org events www2008 and was one the largest workshops the conference March 2009 WSRI running its first Web Science conference Athens WebSci’ – see www websci09 org with the aim bringing computer scientists and social scientists together discuss this important topic nnThe aim this panel bring this debate the heart the WWW community WWW2009 Madrid 
8535 en Latent Space Domain Transfer between High Dimensional Overlapping Distributions Transferring knowledge from one domain another challenging due number reasons Since both conditional and marginal distribution the training data and test data are non identical model trained one domain when directly applied diffeerent domain usually low accuracy For many applications with large feature sets such text document sequence data medical data image data different resolutions etc two domains usually not contain exactly the same features thus introducing large numbers missing values when considered over the union features from both domains other words its marginal distributions are most overlapping the same time these problems are usually high dimensional such several thousands features Thus the combination high dimensionality and missing values make the relationship conditional probabilities between two domains hard measure and model address these challenges propose framework that first brings the marginal distributions two domains closer filling those missing values disjoint features Afterwards looks for those comparable sub structures the latent space mapped from the expanded feature vector where both marginal and conditional distribution are similar With these sub structures latent space the proposed approach then find common concepts that are transferable across domains with high probability During prediction unlabeled instances are treated queries the mostly related labeled instances from out domain are retrieved and the classifcation made weighted voting using retrievd out domain examples formally show that importing feature values across domains and latent semantic index can jointly make the distributions two related domains easier measure than original feature space the nearest neighbor method employed retrieve related out domain examples bounded error when predicting domain examples 
8536 en Large Scale Online Bayesian Recommendations present probabilistic model for generating personalised recommendations items users web service The system makes use content information the form user and item meta data combination with collaborative filtering information from previous user behavior order predict the value item for user Users and items are represented feature vectors which are mapped into low dimensional trait space which similarity measured terms inner products The model can trained from different types feedback order learn user item preferences Here present three alternatives direct observation absolute rating each user gives some items observation binary preference like don like and observation set ordinal ratings user specific scale Efficient inference achieved approximate message passing involving combination Expectation Propagation and Variational Message Passing also include dynamics model which allows items popularity user taste user personal rating scale drift over time using Assumed Density Filtering ADF for training the model requires only single pass through the training data This line learning algorithm capable incrementally taking account new data the system can immediately reflect the latest user preferences evaluate the performance the algorithm the MovieLens and Netflix data sets consisting 000 000 and 100 000 000 ratings respectively This demonstrates that training the model using the line ADF approach yields state the art performance with the option improving performance further computational resources are available performing multiple passes over the training data 
8537 en Learning Consensus Opinion Mining Data from Labeling Game this paper consider the challenge how identify the consensus opinion set users how the results for query should ranked Once consensus rankings are identified for set queries these rankings can serve for both evaluation and training retrieval and learning systems present novel approach collecting user preferences over image search results use collaborative game which players are rewarded for agreeing which image result best for query Our approach distinct from other labeling games because are able elicit directly the preferences interest with respect image queries extracted from query logs source relevance judgments this data provides useful complement click data Furthermore free positional biases and does not carry the risk frustrating users with non relevant results associated with proposed mechanisms for debiasing clicks describe data collected over days from deployed version this game that amounts about million expressed preferences between pairs Finally present several approaches modeling this data order extract the consensus rankings from the preferences and better sort the search results for targeted queries 
8538 en Rated Aspect Summarization Short Comments Web technologies have enabled more and more people freely comment different kinds entities sellers products services The large scale information poses the need and challenge automatic summarization many cases each the user generated short comments comes with overall rating this paper study the problem generating rated aspect summarization short comments which decomposed view the overall ratings for the major aspects that user could gain different perspectives towards the target entity formally define the problem and decompose the solution into three steps demonstrate the effectiveness our methods using eBay sellers feedback comments also quantitatively evaluate each step our methods and study how human agree such summarization task The proposed methods are quite general and can used generate rated aspect summary given any collection short comments each associated with overall rating 
8540 en DBpedia Linked Data Hub and Data Source for Web Applications and Enterprises The DBpedia project provides Linked Data identifiers for currently million things and serves large knowledge base structured information DBpedia developed into the central interlinking hub for the Linking Open Data project its URIs are used within named entity recognition services such OpenCalais and annotation services such Faviki and the BBC started using DBpedia their central semantic backbone DBpedia structured data serves background information the process interlinking datasets and provides rich source information for application developers Beside making the DBpedia knowledge base available linked data and RDF dumps offer Lookup Service which can used applications discover URIs for identifying concepts and SPARQL endpoint that can retrieve data from the DBpedia knowledge base used applications This talk will give introduction DBpedia for web developers and overview DBpedia development over the last year will demonstrate how DBpedia URIs are used for document annotation and how Web applications can via DBpedia facilitate Wikipedia source structured knowledge 
8541 en  new tool improve the filtering options advanced searching have developed software application that analyzes detail text English and labels the text with linguistic attributes plus additional information fully automatic way With this new texts search engine able index the information way that provides new filtering possibilities for advanced searches 
8542 en Web infrastructure for the 21st Century The Web success leading the information technology revolution has relied enormous computing infrastructure recent years both cloud computing well social networks are putting even more burden such infrastructure The cloud computing paradigm creating massive shift computing – from based applications cloud based applications Cloud computing frees users from having remember where the data resides gives users access information anywhere and provides fast services through essentially infinite online computing Social networks the other hand emerge the social aspects the Web where the social interactions put demands Web applications and turn further demands the Web infrastructure nThe Internet which was mostly developed for interactive applications between humans and computers has struggled handle the necessities Web designed around content For instance Web content moves from one place another Web pointers are broken and search ranking algorithms Similarly content often not where should when you need and routers waste capacity copying the same content millions times result have seen the emergence Internet systems that were not planned for from the beginning Web Caching Content Distribution Networks P2P networks nIn this talk will discuss the challenges that the Web posing today Internet infrastructure and argue about various solutions cope with them particular will argue how think the Internet networking the content information layer and the underlying architectural system design principles needed guide the efficient engineering new Web infrastructure services 
8543 en Mining the Web for Better Search There are several semantic sources that can found the Web that are either explicit Wikipedia implicit derived from Web usage data Most them are related user generated content UGC what called today the Web this talk show several applications mining the wisdom crowds behind UGC improve search will show live demos find relations the Wikipedia improve image search well our current research the topic Our final goal produce virtuous data feedback circuit leverage the Web itself 
8544 en Mining the Web Facilitate Fast and Accurate Approximate Match Tasks relying recognizing entities have recently received significant attention the literature Many such tasks assume the existence reference entity tables this paper consider the problem determining whether candidate string approximately matches with reference entity This problem important for extracting named entities such products locations from reference entity table matching entity entries across heterogenous sources Prior approaches have relied string based similarity which only compare candidate string and entity matches with this paper observe that considering such evidence across multiple documents significantly improves the accuracy matching develop efficient techniques which exploit web search engines facilitate approximate matching the context our proposed similarity functions extensive experimental evaluation demonstrate the accuracy and efficiency our techniques 
8545 en SmartMiner New Framework for Mining Large Scale Web Usage Data this paper propose novel framework called Smart Miner for web usage mining problem which uses link information for producing accurate user sessions and frequent navigation patterns Unlike the simple session concepts the time and navigation based approaches where sessions are sequences web pages requested from the server viewed the browser Smart Miner sessions are set paths traversed the web graph that corresponds users navigations among web pages have modeled session reconstruction new graph problem and utilized new algorithm Smart SRA solve this problem efficiently For the pattern discovery phase have developed efficient version the Apriori All technique which uses the structure web graph increase the performance From the experiments that have performed both real and simulated data have observed that Smart Miner produces least more accurate web usage patterns than other approaches including previous session construction methods have also studied the effect having the referrer information the web server logs show that different versions Smart SRA produce similar results Another novel work that have implemented distributed version the Smart Miner framework employing Map Reduce paradigm which enables processing huge size web server logs belonging multiple web sites the best our knowledge this paper the first attempt propose such large scale framework forweb usage mining problem conclude that can efficiently process terabytes web server logs belonging multiple web sites employing our scalable framework 
8546 en Releasing Search Queries and Clicks Privately The question how publish anonymized search log was brought the forefront well intentioned but privacy unaware AOL search log release Since then series hoc techniques have been proposed the literature though none are known provably private this paper take major step towards solution show how queries clicks and their associated perturbed counts can published manner that rigorously preserves privacy Our algorithm decidedly simple state but non trivial analyze the opposite side privacy the question whether the data can safely publish any use Our findings offer glimmer hope demonstrate that non negligible fraction queries and clicks can indeed safely published via collection experiments real search log addition select application keyword generation and show that the keyword suggestions generated from the perturbed data resemble those generated from the original data 
8547 en Large Scale Integration Senses for the Semantic Web Nowadays the increasing amount semantic data available the Web leads new stage the potential Semantic Web applications However also introduces new issues due the heterogeneity the available semantic resources One the most remarkable redundancy that the excess different semantic descriptions coming from different sources describe the same intended meaning nIn this paper propose technique perform large scale integration senses expressed ontology terms order cluster the most similar ones when indexing large amounts online semantic information can dramatically reduce the redundancy problem the current Semantic Web order make this objective feasible have studied the adaptability and scalability our previous work sense integration translated the much larger scenario the Semantic Web Our evaluation shows good behaviour these techniques when used large scale experiments then making feasible the proposed approach 
8548 en Triplify Light weight Linked Data Publication from Relational Databases present Triplify simplistic but effective approach publish linked data from relational databases Triplify based mapping HTTP URI requests onto relational database queries Triplify transforms the resulting relations into RDF statements and publishes the data the Web various RDF serializations particular Linked Data The rationale for developing Triplify that the largest part information the Web already stored structured form often data contained relational databases but published Web applications merely HTML mixing structure layout and content order reveal the pure structured information behind the current Web implemented Triplify light weight software component which can easily integrated and deployed with the numerous widely installed Web applications Our approach includes method for publishing update logs enable incremental crawling linked data sources Triplify complemented library configurations for common relational schemata and REST enabled datasource registry Triplify configurations are provided containing mappings for many popular Web applications including Wordpress Drupal Joomla Gallery and phpBB show that despite its light weight architecture Triplify usable publish very large datasets such 160GB geo data from the OpenStreetMap project 
8549 en SOFIE Self Organizing Flexible Information Extraction This paper presents SOFIE system that can extend existing ontology new facts SOFIE provides integrative framework which information extraction word disambiguation and semantic reasoning all become part one unifying model SOFIE processes text Web sources and finds meaningful patterns maps the words the pattern entities the ontology hypothesizes the meaning the pattern and checks the semantic plausibility the hypothesis with the existing ontology Then the new fact added the ontology avoiding inconsistency with the existing facts The logical model that connects existing facts new hypotheses extraction patterns and consistency constraints represented set propositional clauses use approximation algorithm for the Weighted MAX SAT problem compute the most plausible subset hypotheses Thereby the SOFIE framework integrates the paradigms pattern matching entity disambiguation and ontological reasoning into one unified model and enables the automated growth large ontologies Experiments using the YAGO ontology existing knowledge and various text and Web corpora input sources show that our method yields very good precision around percent higher 
8550 en Emergent Semantics Social Tagging Social bookmarking systems are becoming increasingly important data sources for bootstrapping and maintaining Semantic Web applications Their emergent information structures have become known folksonomies key question for harvesting semantics from these systems how extend and adapt traditional notions similarity folksonomies and which measures are best suited for applications such community detection navigation support semantic search user profiling and ontology learning Here build evaluation framework compare various general folksonomy based similarity measures which are derived from several established information theoretic statistical and practical measures Our framework deals generally and symmetrically with users tags and resources For evaluation purposes focus similarity between tags and between resources and consider different methods aggregate annotations across users After comparing the ability several tag similarity measures predict user created tag relations provide external grounding user validated semantic proxies based WordNet and the Open Directory Project also investigate the issue scalability find that mutual information with distributional micro aggregation across users yields the highest accuracy but not scalable per user projection with collaborative aggregation provides the best scalable approach via incremental computations The results are consistent across resource and tag similarity 
8551 en Measuring the Similarity between Implicit Semantic Relations from the Web Measuring the similarity between semantic relations that hold among entities important and necessary step various Web related tasks such relation extraction information retrieval and analogy detection For example consider the case which person knows pair entities Google YouTube between which particular relation holds acquisition The person interested retrieving other such pairs with similar relations Microsoft Powerset Existing keyword based search engines cannot applied directly this case because keyword based search the goal retrieve documents that are relevant the words used query not necessarily the relations implied pair words propose relational similarity measure using Web search engine compute the similarity between semantic relations implied two pairs words Our method has three components representing the various semantic relations that exist between pair words using automatically extracted lexical patterns clustering the extracted lexical patterns identify the different patterns that express particular semantic relation and measuring the similarity between semantic relations using metric learning approach evaluate the proposed method two tasks classifying semantic relations between named entities and solving word analogy questions The proposed method outperforms all baselines relation classification task with statistically significant average precision score Moreover reduces the time take Latent Relational Analysis process 374 word analogy questions from days less than hours with SAT score 
8552 en Extracting Key Terms From Noisy and Multitheme Documents present novel method for key term extraction from text documents our method document modeled graph semantic relationships between terms that document exploit the following remarkable feature the graph the terms related the main topics the document tend bunch into densely interconnected subgraphs communities while non important terms fall into weakly intercon nected communities even become isolated vertices apply graph community detection techniques partition the graph into thematically cohesive groups terms introduce criterion function select groups that contain key terms discarding groups with unimportant terms weight terms and determine semantic relatedness between them exploit information extracted from Wikipedia Using such approach gives the following two advantages First allows effectively processing multi theme documents Second good filtering out noise information the document such for example navigational bars headers web pages Evaluations the method show that outperforms existing methods producing key terms with higher precision and recall Additional experiments web pages prove that our method appears substantially more ective noisy and multi theme documents than existing methods 
8554 en TP1 Leveraging Complex Knowledge
8560 en TechCrunch Dealing with the Media TechCrunch was founded June 2005 weblog dedicated obsessively profiling and reviewing new Internet products and companies addition covering new companies profile existing companies that are making impact commercial and cultural the new web space nnTechCrunch has now grown into network technology focused sites offering wide range content and new media 
8561 en 1st Pre Kick off NGO meeting From the email nnHere would seek synchronize with other similar initiatives thenworld scale terms goals strategies and standards setup meansnfor content sharing and exchange opinions lessons learned and thusnenforcing the sustainability and integrability video lectures thenglobal open education initiatives nnAs you already know are making first steps establishing formalnnon profit organisation with the support European Commission thenframe funded project Pascal2 and would like use thisnopportunity invite interested parties become founding members ofnan NGO nnThe meeting agenda Welcome Mitja Jermoln Introduction – John Shawe Taylorn MIT OpenCourseWare presentation – Cecilia Oliveiran Opencast presentation – Mara Hancockn OpenCourseWare Consortium Meena Hwang Skype OpenCourseWare Consortium presentation – Larry Coopermann VideoLectures Net technology view Peter Universität Osnabrück ETH Zürich Markus Ketterl Skype University Cambridge Global Grid for Learning Steeple presentation Bjoern Hasslern ETH Zürich presentation Olaf Schulten Vision Ideas Finances presentation – Mitja Jermol
8577 en Introduction Semantic Search 2009 recent years have witnessed tremendous interest and substantial economic exploitation search technologies both web and enterprise scale However the representation user queries and resource content existing search appliances still almost exclusively achieved simple syntax based descriptions the resource content and the information need such the predominant keyword centric paradigm keyword queries matched against bag words document representation nnOn the other hand recent advances the field semantic technologies have resulted tools and standards that allow for the articulation domain knowledge formal manner high level expressivity the same time semantic repositories and reasoning engines have only now advanced state where querying and processing this knowledge can scale realistic scenarios nnIn parallel these developments the past years have also seen the emergence important results adapting ideas from the problem search RDF OWL data folksonomies microformat collections semantically tagged natural text Common these scenarios that the search focused not document collection but metadata which may possibly linked embedded textual information Search and ranking metadata stores another key topic addressed the workshop nnAs such semantic technologies are now state provide significant contributions problems nIn this context several challenges arise for Semantic Search systems These include among others How can semantic technologies exploited capture the information need the user How can the information need the user translated expressive formal queries without enforcing the user capable handling the difficult query syntax How can expressive resource descriptions extracted acquired from documents users How can expressive resource descriptions stored and queried efficiently large scale How can vague information needs and incomplete resource descriptions handled How can semantic search systems evaluated and compared with standard systems 
8578 en Correlator things did things should and things don know how Correlator http sandbox yahoo com Correlator demo showcasing work developed Yahoo Research Barcelona the areas information extraction retrieval and visualization will use this and other Yahoo demos during talk discuss some the technologies used evaluate its strengths and weaknesses and pinpoint some the research problems which find most interesting this area 
8579 en Investigating the Demand Side Semantic Search through Query Log Analysis this paper propose method create aggregated representations the information needs Web users when searching for particular types objects suggest this method way investigate the gap between what Web search users are expecting ¯ and the kind information that provided Semantic Web datasets formatted according particular ontology evaluate our method qualitatively measuring its power query completion mechanism Last perform qualitative evaluation comparing the information Web users search for with the information available Dbpedia the structured data representation Wikipedia 
8580 en Semantic Search for Enterprise this paper describe how Enterprise can bene fit from lightweight semantics for information integration enabling better and easier search process for the end users 
8581 en Improving search results with lightweight semantic search discussion paper The goal each search service yield the most relevant results given query Traditional full text search not enough and many approaches improve search rankings are adopted this paper propose method combined search query scoring computation leveraging lightweight semantics represented metadata related searchable content extends state the art approaches both indexing and searching stage discuss two approaches called concept scoring computation order capture different properties available metadata 
8582 en Wanderlust Extracting Semantic Relations from Natural Language Text Using Dependency Grammar Patterns great share applications modern information technology can bene from large coverage machine accessible knowledge bases However the bigger part todays knowledge provided the form unstructured data mostly plain text initial step exploit such data presentnWanderlust algorithm that automatically extracts semantic relations from natural language text The procedure uses deep linguistic patterns that are ned over the dependency grammar sentences Due its linguistic nature the method performs unsupervised fashion and notnrestricted any speci type semantic relation The applicability the proposed approach examined case study which put the task generating semantic wiki from the English Wikipedia corpus present exhaustive discussion about the insights obtained from thisnparticular case study including considerations about the generality the approach 
8583 en Towards ECSSE live Web Data search and integration illustrate the works toward implementing Entity Centric Semantic Search Engine ECSSE ECSSE leverages the Sindice Semantic Web Index find and combine together semantically structured data published the web With respect previous Semantic Web Data integrators ECSSE uses holistic approach which large scale semantic web indexing logic reasoning data aggregation heuristics hoc ontology consolidation external services and user interaction all play together create rich entity descriptions and live embeddable data mash ups 
8584 en Story Link Detection with Entity Resolution News archives present vast base cultural and social knowledge However their size also the cause for difficult navigation through the sequence articles belonging certain topic thread the ideal scenario one could navigate over the whole sequence articles where every article would link other relevant articles discussing the same event Continuing progress entity resolution and extraction has enabled the possibility apply semantic background knowledge the task story link detection SLD adding additional information existing article text and annotations this paper propose method extracted entity resolution measure its effect performance the task topic link detection developed system which extracts additional entities from article text and links them entities from our background knowledge base Current experiments this ongoing work show that although entity resolution via text similarity outperforms using plain text the case story link detection only achieves SLD performance comparable human annotations some cases 
8585 en Retrieval and Ranking Semantic Entities for Enterprise Knowledge Management Tasks describe task sensitive approach retrieval and ranking semantic entities using the domain information available enterprise Our approach utilizes noisy named entity tagging and document classification top enterprise search engine provide input novel ranking metric for each entity retrieved for task Retrieval query centric where the user query the target topic technology needed for proposal Named entities are then extracted from the retrieved documents and ranked according their similarity the target topic evaluate our approach comparing baseline retrieval and ranking technique that based entity occurrence rates and show encouraging results 
8586 en P2P Concept Search Some Preliminary Results Concept Search extends syntactic search search based the computation string similarity between words with semantic search search based the computation semantic relations between complex concepts allows deal with ambiguity natural language P2P Concept Search extends Concept Search allowing distributed semantic search over structured P2P network The key idea exploit distributed background knowledge and indices 
8587 en Question Answering Based Semantic Graphs this paper present question answering system supported semantic graphs Aside from providing answers natural language questions the system offers explanations for these answers via visual representation documents their associated list facts described subject – verb – object triplets and their summaries The triplets automatically extracted from the Penn Treebank parse tree obtained for each sentence the document collection can searched and have implemented question answering system serve natural language interface this search The vocabulary questions general because not limited specific domain however the questions grammatical structure restricted predetermined template because our system can understand only limited number question types The answers are retrieved from the set facts and they are supported sentences and their corresponding document The document overview comprising the semantic representation the document generated the form semantic graph the list facts contains and its automatically derived summary offers explanation each answer The extracted triplets are further refined assigning the corresponding referenced named entity resolving pronominal anaphors well attaching the associated WordNet synset The semantic graph belonging the document developed based the enhanced triplets while the document summary automatically generated from the semantic description the document and the extracted facts 
8588 en Relevance Feedback Between Hypertext and Semantic Search Relevance feedback one method for creating ‘virtuous cycle’ put Baeza Yates between semantics and search Previous approaches search have generally considered the SemanticnWeb and hypertext Web search entirely disparate indexing and searching over different domains While relevance feedback have traditionally improved information retrieval performance relevance feedback normally used improve rankings single data set Our novel approach use relevance feedback from hypertext Web search improve the retrieval Semantic Web data nWe also inspect whether relevance feedback from Semantic Web data can improve hypertext Web search results both cases evaluation based certain kinds informational queries abstractnconcepts people and places selected from query log and human judges show that relevance feedback works relevance feedback from hypertext Web search can improve the retrieval Semantic Web data and vice versa evaluate our work over wide range algorithms and show improves baseline performance these queries for deployed systems well such the semantic Search engine FALCON and the commercial Web search engine Yahoo nsearch 
8589 en Managing Collaboration Projects using Semantic Email
8590 en Using TREC for cross comparison between classic and ontology based search models Web scale The construction standard datasets and benchmarks evaluate ontology based search approaches and compare then against baseline models major open problem the semantic technologiesncommunity this paper propose novel evaluation benchmark for ontology based models based adaptation the well known Cranfield paradigm Cleverdon 1967 traditionally used the community The proposed benchmark comprises text document collection set queries and their corresponding document relevance judgments and set ontologies and Knowledge Bases covering the query topics The document collection and the set queries and judgments are taken from one the most widely used datasets the community nthe TREC Web track use case example apply the proposed benchmark compare real ontology based search model Fernandez 2008 against the best systems TREC and TREC 2001 competitions deep analysis the strengths and weaknesses this benchmark and discussion how can used evaluate other ontology based search systems also included the end the paper 
8591 en Searching and ranking RDF documents and social networks semantic web based applications are gaining popularity nvery large RDF documents are becoming common SPARQLnis the facto standard querying RDF data and researchnon efficient implementations SPARQL interfaces for verynlarge RDF graphs has attracted great deal interest innthe recent years However large datasets the user facesnthe problem that the result set for her queries can large nIn this situation there clear for the user from wherento start looking the results since all them are equallynvalid Moreover given the result SPARQL query thenonly possible order lexicographical which doesn’ help thenuser distinguish which the returned values should shenlook first this sense would desirable have notionnof “relevance” nodes related problem that ofnanalyzing social network data Most social network analysisnconcentrates heavily finding social groups and findingnthe importance individuals social network However nthis work generally considers the social network graphnwith single type connection edges representing the existencenof social communication friendship for example nThere are not many methods developed for social networksnwith many different types semantic connections anresult there very little work querying semanticallynrich social network data 
8593 en Query Log Mining Web Search Engines have stored their logs information about users since they started operate This information often serves many purposes The primary focus this tutorial introduce the discipline query mining showing its foundations and analyzing the basic algorithms and techniques that could used extract and exploit useful knowledge from this potentially infinite source information Furthermore participants this tutorial will given unified view the literature query log analysis 
8597 en  Galactic Arms Race GAR Automatic Content Generation Multiplayer Online Video Game This video showcases new algorithm called cgNEAT thatnautomatically generates content video games demonstrate thisnnew technique created near commercial quality game callednGalactic Arms Race GAR which the weapons systems are entirelyninvented the game itself The cgNEAT method which short forncontent generating NeuroEvolution Augmenting Topologies evolvesnnew weapons which are controlled artificial neural networks bynvarying the most popular weapons the past this way annevolutionary process causes the algorithm explore the space ofnweapons the game played producing never ending supply ofnnovel and functional content The aim show that can bensophisticated enough produce some the content games withoutnthe need for artists programmers observing what players likednin the past The video presents montage actual gameplay thatndemonstrates the surprising variety compelling weapons invented bynthe game itself also explicates the underlying technology morenthrough action than through words For more information GAR whichnwill released this Spring please visit http gar eecs ucf edu 
8598 en  EDGE Enhanced Device for Geospatial Exploration This video presentation robotics simulation project Microsoft Robotics Project was used for the development this project The video shows the robot agent the simulation environment looking for hostages takes pictures the hostage and locates their positions The video shows how the robot scans the area and avoids walls using its laser The video shows the screens the software with nice rock song and brief description the methods and algorithms used the robot 
8599 en  Learning Kinematic Models Articulated Objects Robots operating home environments must able interact with articulated objects such doors drawers Ideally robots are able autonomously infer articulation models observation this video briefly present approach for learning kinematic models inferring the connectivity rigid parts and the articulation models for the corresponding links Our method uses mixture parameterized and parameter free Gaussian process representations and finds low dimensional manifolds that provide the best explanation the given observations Our approach has been implemented and evaluated using real data obtained various realistic home environment settings Corresponding paper http www informatik uni freiburg sturm media sturm09ijcai pdf
8600 en  The Autonomous City Explorer This video presents the Autonomous City Explorer ACE project Its goal was create robot capable navigating unknown urban environments without the use prior map knowledge GPS data The robot had find its way solely interacting with pedestrians and building topological representation its surroundings This video outlines the necessary ingredients for successful low level navigation sidewalks vision processing cluttered outdoor environments and information retrieval from pedestrians More information can found http www ace robot 
8601 en  Applying Case Based Reasoning Texas Hold Poker This video summarizes the use Case Based Reasoning principles the area Texas Hold poker Introductions CBR and Texas Hold are included well description about two poker bots which have developed that make use CBR play poker Results and conclusions our research are briefly presented For more information you can visit our website http www auckland research gameai 
8603 en  Motion Synthesis and Control Learning for Knotting Deformable Linear Objects This research deals with motion planning and control for Deformable Linear Objects DLOs still complex task get robot manipulate rope cloth realise this vision getting robot handle dexterous objects have taken the simplest object DLO for our study purpose The operations performed the DLO are knot tying The DLO thus parameterised Knot and make the DLO tied into various knot types The mathematical branch Knot Theory extensively used here realise the Knots The configuration space that the Knot can move computed the Knot Energy use the Minimum Distance Knot energy here With this create hierarchical graph structure with nodes corresponding optimal knot configurations obtained optimising this Knot energy functional Thus navigating this graph are able tie various knots The study looks into simple and complex knot types Motion control while tying also brought about using the SARSA Ã Â» Reinforcement Learning algorithm The motion planner resilient perturbations well Thus devising Knot Energy together with SARSA Ã Â» have built multi scale reactive knot tying motion planner Results show that our method incrediblynfaster than normal Probabilistic and feedback control methods For more please refer MSc thesis titled Multi scale Reactive Motion Planning with Deformable Linear Objects http www inf publications thesis online IM080596 pdf for the complete version including Motion control http www mediafire com file dozd2zm3mam MSc thesis SARSA and Knot energy version pdf 
8604 en  AIspace Tools for Learning Artificial Intelligence This video summarizes our work set interactive algorithm visualization tools for teaching and learning The tools cover many the topics that would intro course They are freely available online http aispace org They were developed the Laboratory for Computational Intelligence the University British Columbia 
8605 en  The Dinochrome Brigade This video provides short introduction our technology for robot localization and then shows how this technology enables various robotic tasks Brief demonstrations are shown for moving robot formations uniform coverage region chain formations and collaborative pulling The video meant highlight our accomplishments but not tutorial More information can found http www uwyo edu wspears maxelbot and http www uwyo edu wspears pubs html 
8607 en  Multi Camera People Tracking Presented Humanoid humanoid gives talk like human presenter about real time vision system using multiple cameras for people tracking room The humanoid demonstrates few perception control capabilities including visually guided hand arm control briefly describes the algorithm used and shows some people tracking results including each person trajectory and walking direction and reports the number people the room The vision system with two quad core Ghz CPUs runs real time the end the video game application based person tracking presented 
8608 en  Copycat Hand for All Copycat Hand for All robot system that imitates the human motions visually estimating the human hand and arm postures high speed and with high accuracy The system uses only one high speed camera and note But once you stand front the robot and move your hand and arm freely reproduces your behavior without time delay the first stage our system uses coarse screening the proportional information the hand images which roughly correspond forearm rotation bending the thumb four fingers And then the second stage performs detailed search for the selected candidates The estimation error less than one degree the joint angle and the processing time fps more are now enhancing flexibility for those having thick thin long short deeply hooking fingers through using different typical hand images featuring different bone length and thickness and joint movable ranges order permit the system respond accurately people all ages and both sexes including foreign people For more information please see our lab page http www tsukuba hoshino copycat pdf 
8610 en  Toward Interactive Learning Container and Non Container Objects This video highlights our work toward creating robots that interactively learn about container and non container objects demonstrates that robot can distinguish between them dropping block the area above the object and observing the movement patterns while pushing the object Also the video illustrates that the robot can learn perceptual model containers identify novel containers the environment Check out the lab webpage atn http www ece iastate edu alexs lab the first author webpage http www ece iastate edu shaneg research html for more information 
8611 en  Plan Based Machinima Creation System This video describes our plan based machinima creation system and concludes with example film created with 
8612 en  How Cook Perfect Love Story This movie about the Taaable project http taaable Web based CBR Cooking system also participant the Computer Cooking Contest The movie illustrates real situation how CBR system can help human solve cooking problem and how learns case failure The main topics addressed the movie are case based reasoning and interactive learning 
8613 en  CogSketch Open Domain Sketch Understanding for Research and Education This video describes CogSketch sketch understanding system being developed for research and educational purposes CogSketch automatically generates symbolic representations sketches These representations can used the input reasoning systems The video demonstrates two educational applications CogSketch Worksheets which can provide students with automatic feedback comparing their sketches teacher sketches and identifying differences and the Design Buddy which uses qualitative mechanics analyze engineering design sketches 
8614 en  Bodies Motion Dynamic Motion Capture explore the use full body physical simulation for human kinematic tracking from monocular and multi view video sequences within the Bayesian filtering framework Towards greater physical plausibility consider human motion generated feedback control loop where Newtonian physics approximates the rigid body motion dynamics the human and the environment through the application and integration forces The result more faithful modeling human environment interactions such ground contacts resulting from collisions and the human motor control For more information please see http robotics brown edu projects dynamical tracking 
8615 en  Situated Interaction This video provides overview the Situated Interaction project Microsoft Research effort towards developing open world interactive systems that can embed interaction and computation deeply into the natural flow daily tasks activities and collaborations The video highlights project goals and reviews prototype platform which weaves together several component technologies including learning and inference about activities and goals speech recognition and synthesis vision conversational scene analysis and multiparty dialog management support fluid interactions with multiple users open world context The video illustrates several challenges and competencies with applicationnrunning the platform named Receptionist that handles problems the domain building receptionists More information about the project and related research are available http research microsoft com people dbohus research situated interaction html 
8618 en  Reinforcement Learning Example brief introduction reinforcement learning using the task bartending example 
8619 en  Real Live Robot Learning created reinforcement learning demo simple robot navigation task and took the public teach them about and robotics The video shows the system adapting real time various modifications the robot design and provides very gentle introduction the idea model based reinforcement learning 
8620 en  Using Entropy Distinguish Shape versus Text Hand Drawn Diagrams Most sketch recognition systems are accurate recognizing either text shape graphic ink strokes but not both Distinguishing between shape and text strokes therefore critical task recognizing hand drawn digital ink diagrams that contain text labels and annotations have found the entropy rate accurate criterion classification found that the entropy rate significantly higher for text strokes compared shape strokes and can serve distinguishing factor between the two The paper has been accepted for publication the 2009 IJCAI proceedings Thisnvideo shows our system action Please visit our lab here http srlweb tamu edu srlng home 
8621 en  News Seven The Future the Future This video summarizes News Seven automated news system The system able find relevant text process that text and supplement with images video and blogger responses The final output the system online Flash presentation that uses animated avatars with generated speech and modeled after traditional nightly news broadcast Current segments include Movie Review Entertainment Segment and Louis Black style rant segment More information about News Seven can found http newsatseven com News Seven also currently live http www zap2it com news zap news 6717570 htmlstory 
8622 en  Penso BCI System This video reveals how Brain Computer Interfaces work basic terms demonstrating BCI system called Penso providing less formal nutshell view the basic principles BCI system language accessible general audience this minute video has sparked interest and enthusiasm prospective postgraduate students the BCI area For more information please see our team page http www weg usyd edu projects penso 
8623 en  Write Reflect Polish This video introduces writing support too called Glosser that leverages language processing and text analysis techniques analyze and provide feedback students they write essay Although the video was designed welcome engineering students tool they would using their first year also ignited student interest natural language processing and related technologies showing how certain technologies can applied the real world For more information please see our team page http www weg usyd edu projects glosser 
8625 en  Robots the Rescue Mixed initiative human robot teaming for disaster response The humanoid robot Nexi and team robot helicopters are deployed response simulated fire aboard Navy ship Working together with remote human operator the robots search for survivors and guide them safety mixed initiative tasking system allows the human operator specify team goals via tasking interface and also allows goals generated the robots result local observations and interactions with victims The robots autonomously handle the details navigation and task execution and communicate their location task status and important observations the operator via the interface The interface also allows the robots ask for the operator help with difficult recognition problems such confirming the location victim from partial identification 
8626 en  Improving Offensive Performance Through Opponent Modeling Although theory opponent modeling can useful any adversarial domain practice both difficult accurately and use effectively improve game play this video present approach for online opponent modeling and illustrate how can used improve offensive performance the Rush 2008 football game football team behaviors have observable spatio temporal structure defined the relative physical positions team members over time demonstrate that this structure can exploited recognize football plays very early stage the play using supervised learning method Based the teams play history our system evaluates the competitive advantage executing play switch based the potential other plays increase the yardage gained and the similarity the candidate plays the current play this video investigate two types play switches whole team and subgroup Both types play switches improve offensive performance but modifying the behavior only key subgroup offensive players yields greater improvements yardage gained 
8627 en  Playbook new approach tasking interfaces Playbook system developed Smart Information Flow Technologies that allows the delegation complex tasks from humans multiple unmanned systems Through this method operator can declare high level instructions that are understandable unmanned aerial vehicles allowing them automatically calculate most efficient means completing their goal dramatically simplifying the operator workload More information www sift info 
8629 en  Conversational Virtual Role Players This video showcases technology called Virtual Role Players VRP for implementing conversational virtual humans that engage spoken dialog and exhibit culturally appropriate behavior designed for use plug training simulation systems The version displayed integrated with the Virtual Battlespace VBS2 mission rehearsal environment 
8630 en  The Stanford Autonomous Helicopter Stanford Autonomous Helicopter project pushes the limits autonomous flight control teaching computer fly competition class remote controlled helicopter through range aerobatic stunts Our apprenticeship learning approach learns fly the helicopter observing human demonstrations and capable wide variety expert maneuvers many cases can even exceed the performance the human expert from which learned http heli stanford edu 
8631 en  The Intelligent Dynamic Workbook for Learning Written East Asian Languages Our video summarizes one our recent projects regarding sketch recognition for the domain written East Asian languages such Chinese and Japanese Our research focuses developing computer assisted language instruction CALI systems which provide human instructor level assessment students written East Asian writings both for visual structure and written technique That strive provide intelligent dynamic workbook for supplementing current East Asian language programs order alleviate the difficulties learning written East Asian 
8632 en  Little Robot Goes Missing this video demonstrate how robots are able find their location map The video based the project work 4th year students the University Alberta 
8633 en  Robotic Secrets Revealed Episode 001 Using Three Cup Shuffle Magic Trick backdrop present system which performs head body pose and fiducial based object tracking all well hand and head gesture recognition and production The sensor born information and the capabilities are tightly integrated psychologically plausible manner within embodied version the ACT cognitive architecture ACT The Mobile Dextrous Social MDS Robot interprets and uses gestures including deictic and symbolic hand gestures well head nods and shakes The overall approach provides with powerful integrated system facilitating many different avenues research human robot interaction 
8634 en  WiiGesture WiiGesture gesture recognition program for actions that use accelerometer data uses artificial intelligence classify gestures using wiimote from few examples each gesture This was project for Machine Learning class Many algorithms were tried like LCSS Bagged Trees SVMs and Fast Fourier Transforms and the video highlights the one found most useful Cross Correlation This was really fun project that has real world applications the video game industry and hope encourages students consider studying Artificial Intelligence 
8635 en  Real Life Reinforcement Learning lot the research the field reinforcement learning has been focused tested simulation domains Some the characteristics real life domains such the shape their noise function imperfect perception that results violation Markovianness are typically neglected the simulation this video promote performing reinforcement learning research real problems make sure algorithms are more robust these design imperfections 
8650 en  Casey Quest Transfer Learning for Adversarial Environments dramatization Transfer Learning research through the journey bit football player Based research conducted David Aha Matthew Molineaux and Gita Sukthankar for ICCBR More information available http www knexusresearch com projects rush 
8652 en Welcome statements given the representatives
8654 en Regions Drive the New Industrial Revolution
8655 en European Research and Technology Organisations and the Challenges Sustainability and Competitiveness
8656 en Promoting Applied Research Development and Innovation Croatian Perspectives
8657 en Regional Cooperation for Sustainable Knowledge Societies SEE
8658 en Presentation and the Role the “Technology and Business Innovation Center for Mariculture ” the University Dubrovnik the Croatian Aquaculture Industry
8659 en Contribution Intellectual Property Promotion and Technology Innovation Management South East Europe
8661 en STP project Business Plan and Inovation Strategy Development Public Research Institute
8662 en Human Capital Building the Key Enhanced Economic Competitiveness SEE Economies
8663 en Interregional Innovation Policy South East Europe Past Experiences and Prospects for the Future
8664 en Sustainability Cross Border RTD and Innovation Cooperation Projects and Networks
8665 en Technology Parks and Technology Transfer Making Full Use Cross Border Opportunities
8666 en National innovation system BICROs view
8668 en Instruments Promoting Research Cooperation South Eastern Europe
8669 en The Global Crisis Opportunity for New RTD Strategies Environmental and Energy Policies
8670 en Collaboration Developement Solar Cells – Materials and Device
8671 en YEAR Initiating the operation Young Researchers through Training and Networking
8673 en What happened the first decade the 21st century Zizek’ visit organised the Department for Social Critique group social scholars who publish Albanian language magazine called “Critique and Society ”nnAgon Hamza founder the Department for Social Critique rated Zizek one the “most important living philosophers” “ believe his lectures will spark debate and will lead different perspective our existing socio political life ” Hamza told Balkan Insight nnZizek who widely regarded fiery and colourful scholar never reluctant make controversial remarks seen Marxist philosopher and one the “most wanted” contemporary lecturers nnDescribed other scholars the “most formidably brilliant” recent theorist have emerged from Europe Zizek’ work infamously idiosyncratic His work includes striking dialectical reversals received common sense and sheds alternative view social and political events 
8674 en Ideology between Symptom and Fetish Zizek’ visit organised the Department for Social Critique group social scholars who publish Albanian language magazine called “Critique and Society ”nnAgon Hamza founder the Department for Social Critique rated Zizek one the “most important living philosophers” “ believe his lectures will spark debate and will lead different perspective our existing socio political life ” Hamza told Balkan Insight nnZizek who widely regarded fiery and colourful scholar never reluctant make controversial remarks seen Marxist philosopher and one the “most wanted” contemporary lecturers nnDescribed other scholars the “most formidably brilliant” recent theorist have emerged from Europe Zizek’ work infamously idiosyncratic His work includes striking dialectical reversals received common sense and sheds alternative view social and political events 
8678 en Multimedia Search the perspective Future Internet Services
8680 en Chorus the landscape European effort MMSE
8685 en The AMI and AMIDA projects Recognition and Understanding Meetings and Lectures
8686 en Towards Web scale content search the SAPIR approach
8687 en THESEUS – Advanced Services for MMSE
8689 en  review first preliminary results from Quaero
8694 en Introduction and brief overview CHORUS findings and recommendation regarding user centric design
8696 en CHORUS studies outcome use case typology dimensions
8697 en MOVIMOS scalable distributed multimedia search engine for mobile applications
8698 en VideoCLEF evaluation moving image retrieval
8699 en  Chorus Vision Outcome the Think Tank 
8700 en User scenarios and user requirements from media professionals
8701 en Chorus Status and Challenges MMSE Technology
8702 en ImageCLEF VCDT Evaluation multilabel image annotation incorporating domain knowledge and concept subjectivity
8703 en  Scene Structure Analysis for Semantic Annotation and Retrieval Unedited Video 
8706 en Panel closing session Disruptive Technologies and Services the near Future
8824 en Emergence Cooperation Agricultural Production
8825 en Large Events the Stock Market Study High Resolution Data
8826 en How Quantify the Influence Correlations Investment Diversification When assets are correlated benefits investment diversification are reduced measure the influence correlations investment performance new quantity the effective portfolio size proposed and investigated both artificial and real situations show that most cases the effective portfolio size much smaller than the actual number assets the portfolio and that lowers even further during financial crises 
8827 en Assessing the Critical Factors that Determine the Availability Wood Fuel Switzerland with Agent Based Model
8862 en Presentations project results HeavyRoute09
8866 en Panel discussion the requirements the models and data used for the applications order have system that can used European wide
8868 en Driver support warning black spots application
8869 en Driver support warning roll over application
8873 en Panel discussion the applications developed HeavyRoute
8874 en Results from field and simulator tests
8888 en Web and Collaborative Working Environments What can learn Web applications are becoming more and more widespread not only for leisure and entertainment but also for business purposes developers collaborative work environments need ask ourselves consider this wave new ideas and applications hazard that sweeps away can learn surf this wave presentation ’ first distill Web applications and technologies identify the basic concepts Then ’ discuss how these concepts can used for the design and development cooperative work applications 
8889 en Value Proposition for Enterprise Interoperability Manufacturing Value Chains Manufacturing generating wealth and jobs fully exploiting knowledge and resources the fundamental enabler and sustainer Europe’ Competitive and Sustainable Development Manufacturing Europe provides presently the added value over € 535 million and the employment million people with each job the factory floor generating two other jobs services Manufacturing Europe presently under threat and crucial and urgent need add value and decrease costs embedding design and technology compensate for the fierce competition from the emerging economies The need keep manufacturing operations and jobs Europe calls for industry transformation ensure strong cost reductions increased flexibility and smaller response times while keeping high standards product quality with increasing complex novel products But the ability manage increased product complexity spreading subcontracting and outsourcing cannot achieved without building collaborative networks over the complete supply and value chain Enterprise interoperability thus stringent requirement highly competitive manufacturing value chains And also emergent one want able design and deploy competitively sustainable European Production System through the use disruptive technological processes enabled digital production 
8892 en Surface plasmons meet organic optoelectronics Surface plasmons are optical modes the interface metal and dielectric which are important variety fields nanooptics surface enhanced spectroscopy metamaterials and photonic devices Recent years have brought substantial progress controlling surface plasmons with micro and nanostructures forming waveguides mirrors splitters resonators complement this toolbox passive plasmonic elements dynamic active devices organic semiconductor devices have proven efficient one hand norganic light emitting diodes can applied for direct surface plasmon excitation the other hand surface plasmon detection can based integrated organic diodes 
8893 en Tracking primary photoinduced events biomolecules with few optical cycle light pulses Many light induced processes organic molecules such energy relaxation energy charge transfer and conformational changes occur ultrafast timescales ranging from The speed such elementary processes intimately linked their efficiency making ultrafast optical spectroscopy invaluable tool for their investigation Pump probe spectroscopy requires both short pulses order observe fast dynamics and broad frequency tunability excite system resonance and probe optical transitions occurring different frequencies Optical parametric amplifiers OPAs are ideal tools for such experiments because they provide frequency tunability and support broad gain bandwidths enabling the generation very short pulses this talk will describe state the art system based two synchronized OPAs providing sub temporal resolution over very broad spectral range from 400 After reviewing the pulse generation techniques and the system performance will present selected examples applications such energy transfer photosynthetic light harvesting complexes electronic and vibrational dynamics carbon nanotubes isomerization rhodopsin 
8913 en The contributions Presence and Ergonomics the Digital Factory Presence and Ergonomics are key elements the development virtual and augmented reality systems and environments This paper describes the contributions these human factors the digital factory within the DiFac FP6 2005 IST 035079 European Commission funded research project For Presence the main contribution the construction and validation new questionnaire called Flow for Presence Questionnaire This paper presents the concept Presence describes the development the questionnaire and discusses the initial findings For ergonomics the focus placing end users the core the development process Industrial partners have been involved from the beginning DiFac ensure that the final solution meets their requirements This approach should also increase their acceptance the final solutions increasing their sense ownership However recognition the constraints end users time the development process has also included expert evaluations the technologies 
8914 en Approach and development innovative tool for integration immersive devices virtual manufacturing environments Immersive Integrator
8931 en The Norwegian experience The Norwegian Ambassador Guro Vikør spoke about the resolution 1325 Women Peace and Security and the Action Plan based the resolution 1325 before Prof Jelu talked about Slovenian efforts regarding peace building and gender equality She promised the audience that the Republic Slovenia will adopt the Action Plan 1325 into their politics She was very impressed over what Norway and Sweden specific have accomplished both regarding gender equality their home countries and peace building where has been needed 
8932 en Teoreti prakti izhodi podro izgradnje miru medkulturnega dialoga enakosti spolov
8933 en Theoretical and practical views for Peace Building Interreligious Dialogue and Gender Equality The former prime minister Norway Kjell Magne Bondevik who also the founder and president the Oslo Center for Peace and Human Rights elaborated about what and how Norway have and can regarding peace building and gender equality Norway with other Scandinavian countries have been the first take gender equality seriously into politics and they have adopted the Action Plan 1325 
8934 en Woman institution woman role peacemaking and peacebuilding the world
8936 en Obstacles Gender Equality Emerita Prof Maca Jogan held short presentation some her research regarding obstacles gender equality and the Swedish Ambassador Inger Ultvedt shared with the attendants the Swedish experience adopting the Action Plan 1325 The female lieutenant Tonja Delopst ended the round table perfectly telling about her own experience being one the soldiers the ISAF operations Afghanistan 
8937 en Swedish Experience Adopting Action Plan 1325 RES 1325 2000 Women Peace and Security 
8968 en Opening and setting the scene During the workshop innovation and approaches for managing and fostering innovation will revisited and discussed both from individual firm and inter firm perspective Critical reviews the new paradigm from theoretical perspective will complemented discussion empirical findings and case studies Interactive discussions will provide insights into key challenges and barriers creation and innovation Participants are invited exchange experiences during the discussion and define future research 
8971 en Attitudes and behaviours fostering creative deliverables Creative products such books films music and design objects are increasingly significant sector modern advanced economies The processes required develop these new products are often complex they require creative individuals work with businesses that are often seeking commercial return any investment Traditionally research has focussed the processes and review points that could improve the likelihood success new creative products This paper argues that alternative theoretical perspective may benefit participants and researchers understand the process innovation Value exchange theory This theory considers equivalent exchange underpin voluntary transactional interactions between parties Data collected from participants involved four creative innovations two books and two pieces public art are presented This data suggests transactions can reciprocated however that there are also number significant non reciprocated transactions The paper concludes that researchers should consider the possibility the gift they are understand the process innovation the creative industries 
8972 en Open innovation – Opening towards open innovation Open innovation claimed the new breed innovation requiring enterprises look beyond the boundaries their organisation and use external and internal actors and knowledge successfully create value related business management literature shifts from closed open models are argued triggered new technological economic and social trends that many organisations least partially virtualise their members being distributed across different locations and embedded various socio economic and cultural contexts Complementing that line argument the current paper undertakes socio systems theoretical revisits key institutional premises assumed concepts above organisation knowledge collaboration complexity etc examine explore and restate which sense openness may feasible organisational realm and with what respects open innovation may supported accordingly argued that rather than requiring tear down organisational walls outwards which principle not possible open innovation enables and enabled differentiating organisations inwards better turn irritations feared into chances recognised leverage upon 
8973 en The networked SME – What the role openness superior innovation management 
8974 en Cooperation coaching novel Approach empower SMEs innovate
8975 en 2020 Vision SME Challenges for Collaborative Innovation for Product Service Organisation
8976 en Different initiatives and Projects for SMEs clusters target Innovation
8977 en Towards Adaptive Interenterprise Systems Interenterprise operability appears high complexity with regard technology organisation and application poses many challenges supporting ICT solutions frequently resumed under the term interoperability number application issues have been pointed out the Enterprise Interoperability Research Roadmap the European Commission The optimal organisational fit ICT systems becomes basic issue enterprise interoperability always linked with business processes And technological issues the end put forward the question software engineering how address the specifics interenterprise processes appropriate systems engineering approaches This paper reflects these issues and suggests combine the concept component based software engineering and the software product line approach means facilitate the engineering adaptive interenterprise systems argue that such combination offers the potential supporting interenterprise operability reasonable level complexity while keeping resulting systems adaptive and evolutionary 
8978 en Enterprise Interoperability Towards Framework for Enterprise Applications Deployment Emerging Economy SMEs Emerging economies are considered provide the future growth opportunities for the ICT industry With regard enterprise applications the envisaged growth will essentially driven SMEs they represent the largest proportion the untapped market order capture this future growth market suppliers enterprise applications systems have consider deployment strategies that address long tail demand patterns the comparatively small scale emerging economy SMEs present fundamental discrepancy from industrialised economy cases This paper presents theoretical analysis the fundamentals this discrepancy order establish basis for preliminary framework for deploying enterprise applications manner that accommodates long tail demand patterns The proposed framework seeks overcome the reliance commercially successful deployment strategies such COTS ERP formalised business process models 
8979 en The Semantic Enterprise Bringing Meaning Business Processes This lecture presents answer the demand for more interoperability data systems and thus organisations PROCESSUS particular project the German national funded high tech initiative THESEUS has the objective create based corporate system that will allow companies compare products solutions and details business associates well locating the complex and sometimes obscure specialist information needed employees whose work involves high density knowledge bases The research teams are also aiming develop basic semantic platform that will integrate companys internal planning resources with management the digital content agile business processes One specific scenario taken from the domain mechanical engineering will demonstrate the requirements intra and intererenterprise communication and the envisaged solution 
8980 en Ambient Intelligence Technologies for Industrial Working Environments Manufacturing SMEs
8981 en Collaborative Environment for Virtual Collaborative Networks ELV Recycling SMEs
8982 en Intelligent Networked Devices for Enabling Proactive Collaboration with Customers
8983 en Network centric Middleware supporting dynamic Web Service Deployment heterogeneous Embedded Systems
8993 en Scaffolding innovations –Implications regional innovation barriers for platform based innovation management improvement This lecture presents different typical SME innovation profiles found within sample Central Swiss companies For each profile the main barriers innovation are depicted Subsequently innovation management platform depicted which available since 2007 Bringing profiles and the characteristics the platform together some crucial implications for innovation coaches will pointed out This paper bases results the qualitative research project Innovation intense Lucerne School Business The objective the project was integrate complement and expand insights that have been created several previous research projects the Lucerne School Business innovation management Central Swiss SMEs 
8994 en Experiences virtual Enterprise Networking Switzerland
9040 en Prihodnost medijev okrogla miza
9105 en Multi Objective Design Exploration MODE Visualization and Mapping Design Space Multi Objective Design Exploration MODE and its application are presented MODE reveals the structure the design space from the trade off information and visualizes panorama for Decision Maker Self Organizing Map incorporated into MODE visual data mining tool for the design space The resulting MODE was applied the multi disciplinary wing design problem and revealed the design sweet spot and the detailed trade off information about aerodynamic and structural performance successfully 
9106 en Self Organizing Maps Enhance Local Performance Multi Objective Opimization This work focuses new approach enhance the results obtained multi objective ptimization especially tailored for computationally hard CAE models The methodology combines Self Organising Maps and Response Surfaces with evolutionary multi objective optimization algorithms The challenge improve the results spending only few extra computations First optimization with evolutionary algorithm explores the wide range the possible solutions Then Self Organising Maps has been used detect local correlations this way circumscribing the scope the search the design parameter space After the definition new bounds for the input variables new Design Experiment was performed the CFD model and then interpolated with Response Surface Modeling techniques Then virtual optimization has been applied these meta models and the most interesting virtual designs were validated means new CFD simulations Beyond the improvements with regard the initial design the methodology guaranteed reduction the computational resources needed obtain such results compared full direct optimization Self Organizing Maps allowed for selecting the most promising area for the objectives and gained new insights the relations between input and output variables 
9107 en Learning and Prediction Survey This survey considers the design methods for learning mathematical models from data The contemporary toolbox machine learning consists wide set techniques essentially reducing few formal arguments The aim this presentation then give insight some them and argue how they could implemented successfully When doing will touch topics risk based modeling probabilistic inference convex optimization and kernel based learning amongst others will exemplify two application areas namely identification dynamic systems and modeling and prediction reliability data 
9108 en Knowledge Extraction from Aerodynamic Design Data and its Application Turbine Blade Geometries Applying numerical optimisation methods the field aerodynamic design optimisation normally leads huge amount heterogeneous design data While often only the most promising results are investigated and used drive further optimisations general methods for investigating the entire design data set are rare our target extract comprehensive knowledge from the design data concerning the interrelation between the shape and the performance the design The extracted knowledge prepared way that usable for guiding further computational well manual design and optimisation processes For the design complex aerodynamic shapes common use different kinds representations what makes difficult even impossible analyse the entire design data set suggest the transformation the design data into discrete unstructured surface meshes and hence result homogeneous parametrisation the designs This makes possible analyse the design data independent the representation used during the design and optimization process the basis discrete unstructured surface meshes propose displacement measure order analyse local differences between designs1 The measure provides information the amount and the direction surface modifications recently introduced framework2 that uses the displacement data conjunction with statistical methods and techniques from machine learning provide meaningful knowledge from the dataset hand The framework comprises number approaches for the displacement analysis sensitivity analysis dimensionality reduction and rule extraction order demonstrate the feasibility the suggested framework applied the proposed methods data set ultra low aspect ratio transonic turbine stator blade small Honda turbofan engine that resulted from computational optimisation run3 Decision trees have been formulated generate set design rules which refer pre defined blade design The results have been verified means modifying the turbine blade geometry using direct manipulation free form deformation DMFFD techniques The performance the deformed blade design has been calculated running computational fluid dynamic CFD simulations shown that the suggested framework provides reasonable results which can directly transformed into design modifications order guide the design process 
9109 en Surrogate Assisted Optimization Methods Recent Developments and Challenges There ever increasing trend the use more and more accurate and often more computationally expensive analyses tools early stages design Optimization using such computationally expensive analyses tools demand the use surrogate assisted methods where surrogate approximation used lieu the expensive analysis contain the computational time within affordable limits The performance such methods known largely dependent the choice the underlying optimization algorithm the surrogate model the training and surrogate model management schemes This presentation will introduce surrogate assisted optimization framework developed the MDO Group UNSW ADFA which alleviates some the common problems associated with the current approaches the proposed approach surrogates multiple types MLP RBF Kriging and RSM coexist within the optimization framework all times and the surrogate with the least prediction error based neighborhood RMSE used approximate the objective and the constraint functions individually external archive all solutions evaluated via actual analysis maintained train the surrogates while surrogate validity check performed prior its use avoid misguiding the search the event poor approximation attempts approximate unexplored regions The underlying optimization algorithm population based elitist evolutionary algorithm which explicitly maintains marginally infeasible solutions for faster rate convergence Apart from standard recombination schemes used any evolutionary algorithm memetic recombination operator embedded further improve the rate convergence number examples will presented illustrate the performance the proposed schemes Finally the presentation will list areas further development and present some preliminary results constrained many objective optimization and spatial approximation schemes that are currently being developed the group 
9111 en Surrogate Based Optimization ONERA Some Recent Examples With the development computational resources and the increasing complexity industrial needs stohastic optimization strategies and especially those based evolutionary concepts have had growing success among the community the recent years Indeed they offer global focusing minimization opportunities potentially complex problems with multiple minima over non connected search spaces dis continuous state variables without relying the computation the objective function´ gradient and such remain almost completely independent the physical nature the problem treated analyzer and optimizer are two distinct and autonomous processes interfaced with one another hence the usual black box˝ denomination Yet the search optimum based the entire range possible solutions where formally nothing guarantees the absolute global character the result usually penalized its important computational cost which can increase exponentially with the complexity the problem Belmann´ curse dimensionality and become rapidly prohibitive especially when one deals with precise aerodynamic evaluations large configurations This remark partly explains the popularity surrogate based optimization procedures where the expensive analyzer replaced low fidelity but cheap model which the optimizer browses ONERA has been active the field surrogate optimization for some time now with topics ranging from surrogate modeling itself RBF ANN Kriging high order RSM efficient coupling and optimization sampling methods refinement criteria off line implementation for wide variety applications single multi objective performances multidisciplinary problems the aim this presentation review some the results obtained throughout some the most recent projects such the optimization flow control parameters for novel high lift design 
9112 en Multi Objective Design Exploration MODE Aerodynamic Applications Tohoku University With the development CFD techniques and design optimization methods aerodynamic optimizations have been widely used various aircraft designs Particularly the recent progress surrogate based aerodynamic optimization techniques enables efficient search over the wide range design space with high fidelity time consuming CFD The benefit surrogate based modeling not only the reduction number expensive CFD but also the spread sampling points that cover the whole design space This enables conduct various statistical analyses for data mining purpose that helps understand design problems detail for further improvement this presentation recent applications Multi Objective Design Exploration new aircraft designs will presented the workshop 
9114 en  the Use Supervised Learning Techniques Speed the Design Aeronautics Components crucial issue the design complex systems the evaluation large number potential alternative designs too expensive evaluation procedure can consequently slow down the search for good configurations mainly the case high dimensional parameter spaces The talk will discuss the use machine learning techniques for speeding the evaluation and the exploration large design spaces particular two supervised learning techniques feedforward neural networks and lazy learning are assessed and compared the task accelerating the design heat pipe cooling ndevice commonly used aeronautics and electronics 
9115 en Identification Eigenmodes Vibration Data Vibration the response system internal external stimulus causing oscillate Vibration causes dynamic stress the system excited the same frequency the called Eigenmodes and this can damage the system Thus the identi cation Eigenmodes vibration data important issue the aerospace industry jet engines need certi before going into service and any dangerous vibration has detected This data usually analyzed manually since this time consuming process machine learning can applied order support engineers their work The vibration data usually visualised images campbell plots and the Eigenmodes are displayed lines introduce iterative algorithm using background knowledge for the identi cation Eigenmodes Our algorithms extends the original Hough Transform image processing algorithm used for detection lines and other parametrisable shapes Finally show our evaluation that our approach for identifying Eigenmodes applied data set provided major European jet engine manufacturer outperforms the prediction the Finite Element Model and competitive the base model using lab measurements 
9116 en Differentiable and Quasi Differentiable Methods for Optimal Shape Design Aerospace Optimal shape design can approached either unknown boundary problems done for most problems fluid dynamics unknown domain problem done structural mechanics for topological optimization shall present both methods together with some applications aerospace Problems are discretized the finite element method differentiable optimization used when possible and pseudo differentiable methods for topological optimization Shape optimization usually computer intensive and parallel computing necessity While evolutionary methods have edge gradient methods can parallelized domain decomposition just well But sensitivity evaluation too computer intensive and problematic when black box solvers are used Data learning and surrogated models can applied provide low fidelity models for the state These can used gradient free quasi differentiable differentiable minimization methods Then incomplete sensitivity can used upgrade data learning zero cost beyond what available with just the functional This extra information also gives insights robustness the design and allows discriminate between Pareto points also enables the user have ideas the impact uncertainties independent parameters which are not design parameter This ensemble leads design method may less efficient for academic problems but more robust and reliable realistic situations with uncertainties all parameters 
9117 en Surrogate based Constrained Multi Objective Optimization Aerospace design synonymous with the use long running and computationally intensive simulations which are employed the search for optimal designs the presence multiple competing objectives and constraints The difficulty this search often exacerbated numerical noise and inaccuracies simulation data and the frailties complex simulations that they often fail return result Surrogate based optimization methods can employed solve mitigate circumvent problems associated with such searches This presentation gives overview constrained multi objective optimization using Gaussian process based surrogates with emphasis dealing with real world problems 
9122 en Opening Ceremony Artificial intelligence continues one the most vibrant challenging and forward looking areas computer science These proceedings collect the papers accepted for presentation the Twenty first International JointnConference Artificial Intelligence IJCAI held Pasadena California USA from July – 2009 This collection represents some the most exciting research taking place today continuing the tradition excellence established IJCAI its inception years ago 1969 The theme this year’ conference the interdisciplinary reach artificial intelligence Apart from its forward looking nature has always been outward looking and this theme allows explore the broad impact science engineering medicine social sciences arts and humanities through invited talks workshops tutorials and other events dedicated this theme Many the papers this volume are explicitly interdisciplinary and still more contribute draw from othernintellectual disciplines indirectly 
9123 en Computer Mediated Transactions These days nearly every economic transaction involves computer some form other What does this mean for economics argue that the ubiquity computers enables new and more efficient contractual forms better alignment incentives more sophisticated data extraction and analysis creates environment for controlled experimentation and allows for personalization and customization review some the long and rich history these phenomena and describe some their implications for current and future practices 
9124 en Scaling Through Multi Agent Organizations Scaling remains one the grand challenges for Lesser has been using organizational control build multiagent systems with hundreds thousands intelligent agents This approach can also used structure complex systems with extensive and heterogeneous knowledge Organizational control multi level approach which organizational goals roles and responsibilities are dynamically developed ndistributed and maintained serve guidelines for making detailed operational control decisions the individual agents Lesser will illustrate the use organizational control three distributed application areas adaptive sensor and interpretation vehicle tracking network peer peer information search and retrieval system and self improving task allocation system will highlight the importantnbalance between externally directed and self directed agent activities uncertain and dynamic environments Then will present the continuing research challenges including how automate the design organization and evolve conditions change create organizationally situated agent and evaluate and predict organization’ performance 
9125 en Video Competition Award Ceremony sequel the successful AAAI and AAAI Video Competitions IJCAI now solicits submissions for the 3rd annual video competition Its goal show the World how much fun documenting exciting artificial intelligence advances research education and application The rules are simple Compose short video about exciting project and narrate that accessible broad online audience Accepted videos will screened the IJCAI registration area during the conference the evening July 2009 00pm 30pm IJCAI immediately after and room adjacent the Computers and Thought Lectures will hold red carpet awards ceremony celebrate the nominees the best video awards The developers the winners will formally presented with trophies ceremony that resembles the Oscars strongly encourage student participation ahead and make cool online video about your project and get ton attention nnCheck also the previous editions the Video Competition http videolectures net aaai07 AAAI 2007 http videolectures net aaai08 AAAI 2008 http videolectures net ijcai09 video competition IJCAI 2009 
9126 en IJCAI 2009 Industry Day Panel This one day session scheduled for Friday July 2009 intended forum for industry tell their story The content entirely the industry participants The forum can utilized for networking recruiting marketing even just bragging All conference registrants have access the Industry Day event The day will structured around panel and series industry presentations 
9127 en How Optimized Environmental Sensing Helps Address Information Overload the Web this talk tackle fundamental problem that arises when using sensors monitor the ecological condition rivers and lakes the network pipes that bring water our taps the activities elderly individual when sitting chair Where should place the sensors order make effective and robust predictions Such sensing problems are typically hard and the past heuristics without theoretical guarantees about the solution quality have often been used this talk present algorithms which efficiently find provably near optimal solutions large complex sensing problems Our algorithms are based the key insight that many important sensing problems exhibit submodularity intuitive diminishing returns property Adding sensor helps more the fewer sensors have placed far addition identifying most informative locations for placing sensors our algorithms can handle settings where sensor nodes need able reliably communicate over lossy links where mobile robots are used for collecting data where solutions need robust against adversaries and sensor failures present results applying our algorithms several real world sensing tasks including environmental monitoring using robotic sensors activity recognition using built sensing chair and sensor placement competition conclude with drawing interesting connection between sensor placement for water monitoring and addressing the challenges information overload the web examples this connection address the problem selecting blogs read order learn about the biggest stories discussed the web and personalizing content turn down the noise the blogosphere 
9128 en STAIR The STanford Artificial Intelligence Robot Project This talk will describe the STAIR home assistant robot project and the satellite projects that led key STAIR components such robotic grasping previously unknown objects depth perception from single still image practical object recognition using multimodal sensors and software architecture for integrative Since its birth 1956 the dream has been build systems that exhibit broad spectrum competence and intelligence STAIR revisits this dream and seeks integrate onto single robot platform tools drawn from all areas including learning vision navigation manipulation planning and speech and NLP This distinct contrast and also represents attempt reverse the year old trend working fragmented sub fields STAIR’ goal useful home assistant robot and over the long term envision single robot that can perform tasks such tidying room using dishwasher fetching and delivering items and preparing meals this talk will describe our progress having the STAIR robot fetch items from around the office and having STAIR take inventory office items Specifically ’ describe learning grasp previously unseen objects including unloading items from dishwasher probabilistic multi resolution maps which enable the robot open use doors and robotic foveal plus peripheral vision system for object recognition and tracking will also outline some the main technical ideas such learning reconstructions from single still image and reinforcement learning algorithms for robotic control that played keynroles enabling these STAIR components 
9129 en IJCAI Computers and Thought Award The Computers and Thought Award presented IJCAI conferences outstanding young scientists artificial intelligence The award was established with royalties received from the book Computers and Thought edited Edward Feigenbaum and Julian Feldman currently supported income from IJCAI funds Past recipients this honor have been Terry Winograd 1971 Patrick Winston 1973 Chuck Rieger 1975 Douglas Lenat 1977 David Marr 1979 Gerald Sussman 1981 Tom Mitchell 1983 Hector Levesque 1985 Johan Kleer 1987 Henry Kautz 1989 Rodney Brooks 1991 Martha Pollack 1991 Hiroaki Kitano 1993 Sarit Kraus 1995 Stuart Russell 1995 Leslie Kaelbling 1997 Nicholas Jennings 1999 Daphne Koller 2001 Tuomas Sandholm 2003 and Peter Stone 2007 nnThere are two winners the 2009 IJCAI Computers and Thought Award Carlos Guestrin Assistant Professor the Machine Learning Department and the Computer Science Department Carnegie Mellon University and Andrew Assistant Professor the Computer Science Department Stanford University Professor Guestrin recognized for significant contributions machine learning probabilistic reasoning and intelligent distributed sensor networks Professor recognized for fundamental contributions the application machine learning robot perception and control for leadership constructing robots that perform unscripted tasks real environments and for major contributions machine learning 
9130 en Embodied Language Games for Autonomous Robots Artificial Intelligence methods and techniques have reached high level sophistication that can tackle difficult outstanding problems science this talk will show how the question the origins language can approached this way This question has puzzled evolutionary biologists since Darwin and still considered unsolved will outline theory language evolution linguistic selection and then report number concrete experiments with humanoid robots that attempt work out and validate this theory The experiments all center around the notion language game which routinized situated interaction that involves some form language Robots use linguistic strategies evolve communication system deal with particular class language games will discuss examples this and also address the question how new strategies can arise and how the robots can autonomously decide which strategies they will collectively use bootstrap their language 
9131 en Intelligent Tutoring Systems New Challenges and Directions Can devise educational systems that provide individualized instruction tailored the needs the individual learners many good teachers Intelligent Tutoring Systems the interdisciplinary field that investigates this question integrating research Artificial Intelligence Cognitive Science and Education Successful intelligent tutoring systems have been deployed support traditional problem solving activities tailoring the instruction the student domain knowledge this talk will present variety projects that illustrate our efforts extend the scope intelligent tutors both support novel forms pedagogical interactions example based and exploration based learning and adapt student traits beyond knowledge student meta cognitive abilities and affective states will discuss the challenges this research the results that have achieved far and future opportunities 
9132 en Machine Learning Ecosystem Informatics and Sustainability Ecosystem Informatics brings together mathematical and computational tools address scientific and policy challenges the ecosystem sciences These challenges include novel sensors for collecting data algorithms for automated data cleaning learning methods for building statistical models from data and for fitting mechanistic models data and algorithms for designing optimal policies for biosphere management This talk will describe recent work the first two these new devices for automated arthropod population counting and linear Gaussian DBNs for automated cleaning sensor network data will also give examples open problems along the whole spectrum from sensors policies 
9133 en From Low level Sensors High level Intelligence Activity Recognition Links the Knowledge Food Chain Sensors provide computer systems with window the outside world Activity recognition sees what the window predict the locations trajectories actions goals and plans humans and objects Building activity recognition system requires full range interaction from statistical inference lower level sensor data symbolic higher levels where prediction results and acquired knowledge are passed each level form knowledge food chain this talk will give overview activity recognition and explore its relation other fields including planning and knowledge acquisition machine learning and Web search will also describe its applications assistive technologies security monitoring and mobile commerce 
9283 en  Culture Creativity The Arnhem Nijmegen Region
9284 en Creative Partnerships Ten Years 
9285 en Inspiration Creativity Innovation Fostering Entrepreneurial Creativity
9286 en Motivation Fun Innovation Successful Competition for Ideas
9287 en Schools the Future The SKUB Project Reinventing Schools the City Gentofte
9288 en First Panel Session Innovation and Education
9295 en “Big Dipper” Moving Science Laboratory
9297 en Social Computing Enabling Creative and Innovative Learning Analysis Practices
9298 en Second Panel Session Innovation and Education
9334 en Computational Knowledge Science and Wolfram Alpha Wolfram will describe the concepts technology and science that underlie Wolfram Alpha— ambitious project make much knowledge possible computable Stephen Wolfram the founder and CEO Wolfram Research the creator Mathematica the author New Kind Science and now the creator Wolfram Alpha Disclaimer Videolectures Net emphasises that the quality this video was notably improved nbecause low light and sound quality conditions provided the lecture auditorium 
9335 en BioPlanner Plan Adaptation Approach for the Discovery Biological Pathways across Species
9336 en Human Computation This talk about harnessing human brainpower solve problems that computers cannot Although computers have advanced dramatically over the last years they still not possess basic conceptual intelligence perceptual capabilities that most humans take for granted leveraging human abilities novel way want solve large scale computational problems and collect data teach computers basic human talents this end treat human brains processors distributed system each performing small part massive computation nnLuis von Ahn works the Computer Science Department Carnegie Mellon University the recipient MacArthur Fellowship and Microsoft New Faculty Fellowship has been named one the Best Minds Science Discover Magazine one the Brilliant 2006 Popular Science Magazine one the most influential people technology Silicon com and one the Top Innovators the Arts and Sciences Smithsonian Magazine His research interests include encouraging people work for free well catching and thwarting cheaters online environments 
9338 en Welcome and Introduction The SemanticWeb initiative has brought forward the idea thatnthe web may become space not only for publishing and interlinkingndocuments through HTML hyperlinks but alsonfor publishing and interlinking knowledge bases thenform RDF graphs open and fully decentralized environment nThis how Tim Berners Lee expressed this idea inna note from 1998 nThe Semantic Web what will get performnthe same globalization process KnowledgenRepresentation that the Web initially did Hypertext1nEven though models and languages achieve this goalnhave been taken from long standing research importantnto remark that the priorities are different While traditionallynthe focus has been theories support sound andncomplete reasoning web oriented primarily aims dealingnwith issues web wide information interoperability andnintegration With respect this perhaps the most central issuesnis Principle Global Identifiers ”global naming leadsnto global network effects” see Architecture the WorldnWideWeb Volume One 2004 http www org nTR 2004 REC webarch 20041215 other words nif resource where resource may range from concretento abstract objects from particulars universals globallynidentified through uniform identifier any knowledgenrepository exposed the web RDF store thennany knowledge about would much easier gather andnintegrate distributed reasoning becomes practically possible nand knowledge based navigation across interlinked knowledgensources can enabled happened for the webnof documents the overall value such open and distributednnetwork interlinked knowledge sources would benimmensely bigger than the sum the value the components nTechnically URIs Uniform Resource Identifiers seenhttp www org Addressing are used identify entitiesnon the Semantic Web but how achieve shared URI understandingnand reuse object research This central role identity and reference for web scale poses new challengesnto traditional and many researchers have suggestednthat the concept URI may deeply affect the notionsnof language the semantics using the ”same” URI inndifferent models reference rigid non rigid designation ninterpretation the meaning ”links” acrossnknowlkedge bases reasoning distributed reasoningnacross theories traditional logic based nThe goal the workshop Identity and Reference innweb based Knowledge Representation workshop which innits past editions was mainly restricted the Web and SemanticnWeb communities see past editions WWW20062 nWWW20073 and ESWC20084 open the debate thenimpact and the challenges that web oriented poses tonsome the core concepts traditional nThese working notes collect the papers which have beennselected for presentation the workshop which was held innconjunction with IJCAI Pasadena July 2009 nThe papers provide different perspectives the issue identitynand reference and are also illustration the relevancenof the problem and the diversity views which exist onnit nWe’ like thank all the authors and the participants forntheir contribution the success the workshop 
9339 en  the Web Web Documents Things How design and structure our information thenWeb essentially influenced our philosophicalnviewpoints what the Web this paper wencompared two fundamentally different positions none takes the Web web documents andnthe other web things using Fred Dretske’snsemantic information theory discussed why wenshould favor the second model over the formernthrough our formulation two information triads nThe first one the Knowledge Information Datan KID triad that allows clearly define thesenconcepts within communicative praxis The secondnone the Symbol Information Referent SIR ntriad that allows clearly define and connect allnkinds information systems regardless they arenthe man made naturally occurring ones 
9346 en Welcome Statment Given the Program Chairs
9347 en How Infants Bootstrap into Spoken Language Models and Challenges Human infants learn spontaneously and effortlessly the language spoken their environments despite the extraordinary complexity the task Here will present overview the early phases language acquisition and focus one area where modeling approach currently being conducted using tools signal processing and automatic speech recognition the unsupervized acquisition phonetic categories During their first year life infants construct detailed representation the phonemes their native language and lose the ability distinguish nonnative phonemic contrasts Unsupervised statistical clustering not sufficient does not converge the inventory phonemes but rather contextual allophonic units subunits present information theoretic algorithm that groups together allophonic variants based three sources information that Can acquired independently the statistical distribution their contexts the phonetic plausibility the grouping and the existence lexical minimal pairs This algorithm tested several natural speech corpora find that these three sources information are probably not language specific What presumably unique language the way which they are combined optimize the emergence linguistic categories nnEmmanuel Dupoux the director the Laboratoire Sciences Cognitives Psycholinguistique Paris conducts research the early phases language and social acquisition human infants using mix behavioral and brain imaging techniques well computational modeling teaches the Ecole des Hautes Etudes Sciences sociales where has set interdisciplinary graduate program Cognitive Science 
9348 en Drifting Games Boosting and Online Learning
9349 en Can Learning Kernels Help Performance Kernel methods combined with large margin learning algorithms such SVMs have been used successfully tackle variety learning tasks since their introduction the early 90s However the standard framework these methods the choice appropriate kernel left the user and poor selection may lead sub optimal performance Instead sample points can used select kernel function suitable for the task out family kernels fixed the user While this appealing idea supported some recent theoretical guarantees experiments has proven surprisingly difficult consistently and significantly outperform simple fixed combination schemes kernels This talk will survey different methods and algorithms for learning kernels and will present novel results that tend suggest that significant performance improvements can obtained with large number kernels Includes joint work with Mehryar Mohri and Afshin Rostamizadeh 
9351 en Solution Stability Linear Programming Relaxations Graph Partitioning and Unsupervised Learning propose new method quantify the solutionnstability large class combinatorialnoptimization problems arising machinenlearning practical example apply thenmethod correlation clustering clusteringnaggregation modularity clustering and relativenperformance signi cance clustering Ournmethod extensively motivated the ideanof linear programming relaxations proventhat when relaxation used solve thenoriginal clustering problem then the solutionnstability calculated our method conservative nthat never overestimates the solutionnstability the true unrelaxed problem nWe also demonstrate how our methodncan used compute the entire path ofnoptimal solutions the optimization problemnis increasingly perturbed Experimentally nour method shown perform wellnon number benchmark problems 
9352 en  Scalable Framework for Discovering Coherent clusters Noisy Data Clustering problems often involve datasetsnwhere only part the data relevant tonthe problem microarray data anal nysis only subset the genes show cohe nsive expressions within subset the con nditions features The existence largennumber non informative data points andnfeatures makes challenging hunt for nherent and meaningful clusters from suchndatasets Additionally since clusters couldnexist different subspaces the featurenspace clustering algorithm that simul ntaneously clusters objects and features nten more suitable compared one thatnis restricted traditional “one sided” clus ntering propose Robust Overlapping nClustering ROCC scalable and very ver nsatile framework that addresses the problemnof efficiently mining dense arbitrarily posi ntioned possibly overlapping clusters fromnlarge noisy datasets ROCC has several nsirable properties that make extremely wellnsuited number real life applications 
9353 en Multi View Clustering via Canonical Correlation Analysis Clustering data high dimensions believednto hard problem general Annumber efficient clustering algorithms developednin recent years address this problemnby projecting the data into lower dimensionalnsubspace via PrincipalnComponents Analysis PCA random projections nbefore clustering Here considernconstructing such projections using multiplenviews the data via Canonical CorrelationnAnalysis CCA nUnder the assumption that the views are uncorrelatedngiven the cluster label shownthat the separation conditions required fornthe algorithm successful are significantly weaker than prior results the literature nWe provide results for mixturesnof Gaussians and mixtures log concavendistributions also provide empiricalnsupport from audio visual speaker clusteringn where desire the clusters correspond tonspeaker and from hierarchical Wikipediandocument clustering where one view thenwords the document and the other thenlink structure 
9354 en Spectral Clustering Based the Graph Laplacian present generalized version spectralnclustering using the graph Laplacian nonlinear generalization the standardngraph Laplacian show that the secondneigenvector the graph Laplacian interpolatesnbetween relaxation the normalizednand the Cheeger cut Moreover wenprove that the limit the cutnfound thresholding the second eigenvectornof the graph Laplacian converges thenoptimal Cheeger cut Furthermore providenan efficient numerical scheme computenthe second eigenvector the graph nLaplacian The experiments show that thenclustering found spectral clustering atnleast good normal spectral clustering nbut often leads signifi cantly better results 
9355 en Nearest Neighbors High Dimensional Data The Emergence and Influence Hubs High dimensionality can pose severe difficulties nwidely recognized different aspects ofnthe curse dimensionality this paper wenstudy new aspect the curse pertaining tonthe distribution occurrences the numbernof times point appears among the nearestnneighbors other points data set shownthat dimensionality increases this distributionnbecomes considerably skewed and hub pointsnemerge points with very high occurrences nWe examine the origin this phenomenon nshowing that inherent property highdimensionalnvector space and explore its influencenon applications based measuring distancesnin vector spaces notably classification nclustering and information retrieval 
9356 en Fitting Graph Vector Data introduce measure how well combinatorialngraph collection vectors nThe optimal graphs under this measure maynbe computed solving convex quadraticnprograms and have many interesting properties nFor vectors dimensional space thengraphs always have average degree mostn2 and for vectors dimensions theynare always planar compute these graphsnfor many standard data sets and show thatnthey can used obtain good solutions tonclassifi cation regression and clustering problems 
9357 en The Adaptive Meteorologists Problem and Its Application Structure Learning and Feature Selection Reinforcement Learning The purpose this paper three fold First formalize and study problem learning probabilistic concepts the recently proposed KWIK framework give details algorithm known the Adaptive Meteorologists Algorithm analyze its sample complexity upper bound and give matching lower bound Second this algorithm used create new reinforcement learning algorithm for factoredstate problems that enjoys significant improvement over the previous state the art algorithm Finally apply the Adaptive Meteorologists Algorithm remove limiting assumption existing reinforcement learning algorithm The effectiveness our approaches are demonstrated empirically couple benchmark domains well robotics navigation problem 
9358 en Optimistic Initialization and Greediness Lead Polynomial Time Learning Factored MDPs this paper propose algorithm for polynomial time reinforcement learning factored Markov decision processes FMDPs The factored optimistic initial model FOIM algorithm maintains empirical model the FMDP conventional way and always follows greedy policy with respect its model The only trick the algorithm that the model initialized optimistically prove that with suitable initialization FOIM converges the fixed point approximate value iteration AVI the number steps when the agent makes non near optimal decisions with respect the solution AVI polynomial all relevant quantities iii the per step costs the algorithm are also polynomial our best knowledge FOIM the first algorithm with these properties 
9359 en Dynamic Analysis Multiagent learning with greedy Exploration The development mechanisms understand and model the expected behaviour multiagent learners becoming increasingly important the area rapidly find application variety domains this paper present framework model the behaviour learning agents using the greedy exploration mechanism For this analyse continuous time version the learning update rule and study how the presence other agents and the greedy mechanism affect then model the problem system difference equations which used theoretically analyse the expected behaviour the agents The applicability the framework tested through experiments typical games selected from the literature 
9360 en Hoeffding and Bernstein Races for Selecting Policies Evolutionary Direct Policy Search Uncertainty arises reinforcement learning from various sources and therefore necessary consider statistics based several roll outs for evaluating behavioral policies add adaptive uncertainty handling based Hoeffding and empirical Bernstein races the CMA variable metric evolution strategy proposed for direct policy search The uncertainty handling adjusts individually the number episodes considered for the evaluation policy The performance estimation kept just accurate enough for sufficiently good ranking candidate policies which turn sufficient for the CMA find better solutions This increases the learning speed well the robustness the algorithm 
9361 en  Simpler Unified Analysis Budget Perceptrons The kernel Perceptron appealing online learning algorithm that has drawback whenever makes error must increase its support set which slows training and testing the number errors large The Forgetron and the Randomized Budget Perceptron algorithms overcome this problem restricting the number support vectors the Perceptron allowed have These algorithms have regret bounds whose proofs are dissimilar this paper propose unified analysis both these algorithms observing that the way which they remove support vectors can seen types regularization casting these algorithms instances online convex optimization problems and applying variant Zinkevich theorem for noisy and incorrect gradient can bound the regret these algorithms more easily than before Our bounds are similar the existing ones but the proofs are less technical 
9362 en Efficient Learning Algorithms for Changing Environments study online learning oblivious changing environment The standard measure regret bounds the difference between the cost the online learner and the best decision hindsight Hence regret minimizing algorithms tend converge the static best optimum clearly suboptimal behavior changing environments the other hand various metrics proposed strengthen regret and allow for more dynamic algorithms produce inefficient algorithms nnWe propose different performance metric which strengthens the standard metric regret and measures performance with respect changing comparator then describe series data streaming based reductions which transform algorithms for minimizing standard regret into adaptive algorithms albeit incurring only poly logarithmic computational overhead nnUsing this reduction obtain efficient low adaptive regret algorithms for the problem online convex optimization This can applied various learning scenarios online portfolio selection for which describe experimental results showing the advantage adaptivity 
9363 en Online Learning Ellipsoid Method this work extend the ellipsoid method which was originally designed for convex optimization for online learning The key idea approximate ellipsoid the classification hypotheses that are consistent with all the training examples received far This contrast most online learning algorithms where only single classifier maintained each iteration Efficient algorithms are presented for updating both the centroid and the positive definite matrix ellipsoid given misclassified example addition the classical ellipsoid method improved version for online learning also presented Mistake bounds for both ellipsoid methods are derived Evaluation with the USPS dataset and three UCI data sets shows encouraging results when comparing the proposed online learning algorithm two state the art online learners 
9364 en Learning Prediction Suffix Trees with Winnow Prediction suffix trees PSTs are popular tool for modeling sequences and have been successfully applied many domains such compression and language modeling this work adapt the well studied Winnow algorithm the task learning PSTs The proposed algorithm automatically grows the tree that provably remains competitive with any fixed PST determined hindsight the same time prove that the depth the tree grows only logarithmically with the number mistakes made the algorithm Finally empirically demonstrate its effectiveness two different tasks 
9365 en Identifying Suspicious URLs Application Large Scale Online Learning This paper explores online learning approaches for detecting malicious Web sites those involved criminal scams using lexical and host based features the associated URLs show that this application particularly appropriate for online algorithms the size the training data larger than can efficiently processed batch and because the distribution features that typify malicious URLs changing continuously Using real time system developed for gathering URL features combined with real time source labeled URLs from large Web mail provider demonstrate that recently developed online algorithms can accurate batch techniques achieving classification accuracies over balanced data set 
9366 en Ranking with Ordered Weighted Pairwise Classiﬁcation ranking with the pairwise classiﬁcation approach the loss associated predicted ranked list the mean the pairwise classiﬁca ntion losses This loss inadequate for tasks such information retrieval where prefer ranked lists with high precision the top the nlist propose optimize larger class loss functions for ranking based ordered weighted average OWA Yager the nclassiﬁcation losses Convex OWA aggregation operators range from the max the mean depending their weights and can used nfocus the top ranked elements they give more weight the largest losses When aggregating hinge losses the optimization problem nis similar the SVM for interdependent output spaces Moreover show that OWA aggregation margin based classiﬁcation losses nhas good generalization properties Experiments the Letor benchmark dataset for information retrieval validate our approach 
9367 en BoltzRank Learning Maximize Expected Ranking Gain Ranking set retrieved documents according their relevance query popular problem information retrieval Methods nthat learn ranking functions are difﬁcult optimize ranking performance typically judged metrics that are not smooth this paper nwe propose new listwise approach learning rank Our method creates conditional probability distribution over rankings assigned nto documents for given query which allows for gradient ascent optimization the expected value some performance measure The nrank probabilities take the form Boltzmann distribution based energy function that depends scoring function composed nindividual and pairwise potentials Including pairwise potentials novel contribution allowing the model encode regularities the nrelative scores documents existing models assign scores test time based only individual documents with pairwise constraints nbetween documents Experimental results the LETOR3 data sets show that our method out performs existing learning approaches nranking 
9368 en Decision Tree and Instance Based Learning for Label Ranking The label ranking problem consists learning model that maps instances total orders over ﬁnite set predeﬁned labels This npaper introduces new methods for label ranking that complement and improve upon existing approaches More speciﬁcally propose nextensions two methods that have been used extensively for classiﬁcation and regression far namely instance based learning and ndecision tree induction The unifying element the two methods procedure for locally estimating predictive probability models for nlabel rankings 
9369 en Ranking Interesting Subgroups Subgroup discovery the task identifying the top patterns database with most signiﬁcant deviation the distribution ntarget attribute Subgroup discovery popular approach for identifying interesting patterns data because effectively combines nstatistical signiﬁcance with understandable representation patterns logical formula However often problem that some nsubgroups even they are statistically highly signiﬁcant are not interesting the user for some reason this paper present napproach based the work ranking Support Vector Machines that ranks subgroups with respect the user’ concept interestingness and ﬁnds subgroups that are interesting the user will shown that this approach can signiﬁcantly increase the quality the subgroups 
9370 en Generalization Analysis Listwise Learning Rank Algorithms This paper presents theoretical framework for ranking and demonstrates how perform generalization analysis listwise ranking nalgorithms using the framework Many learning rank algorithms have been proposed recent years Among them the listwise approach nhas shown higher empirical ranking performance when compared the other approaches However there theoretical study the nlistwise approach far know this paper propose theoretical framework for ranking which can naturally describe various nlistwise learning rank algorithms With this framework prove theorem which gives generalization bound listwise ranking nalgorithm the basis Rademacher Average the class compound functions The compound functions take listwise loss functions nas outer functions and ranking models inner functions then compute the Rademacher Averages for existing listwise algorithms nListMLE ListNet and RankCosine also discuss the tightness the bounds different situations with regard the list length and ntransformation function 
9371 en Structure Preserving Embedding Structure Preserving Embedding SPE isnan algorithm for embedding graphs Euclideannspace such that the embedding lowdimensionalnand preserves the global topologicalnproperties the input graph Topologynis preserved connectivity algorithm suchnas nearest neighbors can easily recover thenedges the input graph from only the coordinatesnof the nodes after embedding SPEnis formulated semidefinite program thatnlearns low rank kernel matrix constrainednby set linear inequalities which capturesnthe connectivity structure the input graph nTraditional graph embedding algorithms donnot preserve structure according our definition nand thus the resulting visualizationsncan misleading less informative SPEnprovides significant improvements termsnof visualization and lossless compression ofngraphs outperforming popular methods suchnas spectral embedding and Laplacian eigenmaps nWe find that many classical graphsnand networks can properly embedded usingnonly few dimensions Furthermore nintroducing structure preserving constraintsninto dimensionality reduction algorithms producesnmore accurate representations highdimensionalndata 
9372 en Graph Construction and Matching for Semi Supervised Learning Graph based semi supervised learning SSL nmethods play increasingly important rolenin practical machine learning systems Ancrucial step graph based SSL methodsnis the conversion data into weightedngraph However most the SSL literaturenfocuses developing label inference algorithmsnwithout extensively studying thengraph building method and its effect performance nThis article provides empiricalnstudy leading semi supervised methodsnunder wide range graph constructionnalgorithms These SSL inference algorithmsninclude the Local and Global Consistencyn LGC method the Gaussian RandomnField GRF method the Graph Transductionnvia Alternating Minimization GTAM nmethod well other techniques Severalnapproaches for graph construction sparsificationnand weighting are explored includingnthe popular nearest neighbors methodn kNN and the matching method opposednto the greedily constructed kNN graph nthe matched graph ensures each node thengraph has the same number edges and producesna balanced regular graph Experimentalnresults both artificial data and realnbenchmark datasets indicate that matchingnproduces more robust graphs and thereforenprovides significantly better prediction accuracynwithout any significant change computationntime 
9373 en Partial Order Embedding with Multiple Kernels consider the problem embedding arbitrarynobjects images audio documents into Euclideannspace subject partial order over pairwisendistances Partial order constraints arise naturallynwhen modeling human perception similarity nOur partial order framework enables thenuse graph theoretic tools more efficientlynproduce the embedding and exploit global structurenwithin the constraint set nWe present embedding algorithm based onnsemidefinite programming which can parameterizednby multiple kernels yield unifiednspace from heterogeneous features 
9374 en Probabilistic Dyadic Data Analysis with Local and Global Consistency Dyadic data arises many real world applicationsnsuch social network analysis and informationnretrieval order discover the underlyingnor hidden structure the dyadic data manyntopic modeling techniques were proposed Thentypical algorithms include Probabilistic LatentnSemantic Analysis PLSA and Latent DirichletnAllocation LDA The probability density functionsnobtained both these two algorithmsnare supported the Euclidean space However nmany previous studies have shown naturally occurringndata may reside close underlyingnsubmanifold introduce probabilisticnframework for modeling both the topical and geometricalnstructure the dyadic data that explicitlyntakes into account the local manifold structure nSpecifically the local manifold structure isnmodeled graph The graph Laplacian analogousnto the Laplace Beltrami operator manifolds nis applied smooth the probability densitynfunctions result the obtained probabilisticndistributions are concentrated around the datanmanifold Experimental results real data setsndemonstrate the effectiveness the proposed approach 
9375 en Non Linear Matrix Factorization with Gaussian Processes popular approach collaborative filtering matrix factorization this paper consider the probabilistic matrix factorization and taking latent variable model perspective show its equivalence Bayesian PCA This inspires consider probabilistic PCA and its non linear extension the Gaussian process latent variable model LVM approach for probabilistic non linear matrix factorization apply approach benchmark movie recommender data sets The results show better than previous state the art performance 
9376 en Analytic Moment Based Gaussian Process Filtering propose analytic moment based filter for nonlinear stochastic dynamical systems modeled Gaussian processes Exact expressions for the expected value and the covariance matrix are provided for both the prediction and the filter step where additional Gaussian assumption exploited the latter case The new filter does not require further approximations particular avoids sample approximations compare the filter variety available Gaussian filters such the EKF the UKF and the UKF recently proposed 2007 
9377 en Function Factorization Using Warped Gaussian Processes introduce new approach non linear regression called function factorization that suitable for problems where output variable can reasonably modeled number multiplicative interaction terms between non linear functions the inputs The idea approximate complicated function high dimensional space the sum products simpler functions lower dimensional subspaces Function factorization can seen generalization matrix and tensor factorization methods which the data are approximated the sum outer products vectors present non parametric Bayesian approach function factorization where the priors over the factorizing functions are warped Gaussian processes and inference using Hamiltonian Markov chain Monte Carlo demonstrate the superior predictive performance the method food science data set compared Gaussian process regression and tensor factorization using PARAFAC and GEMANOVA models 
9378 en Tractable Nonparametric Bayesian Inference Poisson Processes with Gaussian Process Intensities The inhomogeneous Poisson process point process that has varying intensity across its domain usually time space For nonparametric Bayesian modeling the Gaussian process useful way place prior distribution this intensity The combination Poisson process and known Gaussian Cox process doubly stochastic Poisson process Likelihood based inference these models requires intractable integral over infinite dimensional random function this paper present the first approach Gaussian Cox processes which possible perform inference without introducing approximations finite dimensional proxy distributions call our method the Sigmoidal Gaussian Cox Process which uses generative model for Poisson data enable tractable inference via Markov chain Monte Carlo compare our methods competing methods synthetic data and also apply several real world data sets 
9379 en Large Scale Collaborative Prediction Using Nonparametric Random Effects Model nonparametric model introduced that allows multiple related regression tasks take inputs from common data space Traditional transfer learning models can inappropriate the dependence among the outputs cannot fully resolved known input specific and task specific predictors The proposed model treats such output responses conditionally independent given known predictors and appropriate unobserved random effects The model nonparametric the sense that the dimensionality random effects not specified priori but instead determined from data approach estimating the model presented uses algorithm that efficient very large scale collaborative prediction problem The obtained prediction accuracy competitive with state the art results 
9380 en Hilbert Space Embeddings Conditional Distributions with Applications Dynamical Systems this paper extend the Hilbert space embedding approach handle conditional distributions This leads nonparametric method for modeling dynamical systems and allows update the belief state dynamical system maintaining conditional embedding Our method very general terms both the domains and the types distributions that can handle and demonstrate the effectiveness our method various dynamical systems expect that Hilbert space embedding conditional distributions will have wide applications beyond modeling dynamical systems 
9381 en Learning Nonlinear Dynamic Models present novel approach for learning nonlinear dynamic models which leads new set tools capable solving problems that are otherwise difficult provide theory showing this new approach consistent for models with long range structure and apply the approach motion capture and high dimensional video data yielding results superior standard alternatives 
9383 en Learning Linear Dynamical Systems without Sequence Information Virtually all methods learning dynamic systems from data start from the same basic assumption that the learning algorithm will provided with sequence trajectory data generated from the dynamic system this paper consider the case where the data not sequenced The learning algorithm presented set data points from the system operation but with temporal ordering The data are simply drawn individual disconnected points nnWhile making this assumption may seem absurd first glance observe that many scientific modeling tasks have exactly this property this paper restrict our attention learning linear discrete time models propose several algorithms for learning these models based optimizing approximate likelihood functions and test the methods several synthetic data sets 
9384 en Dynamic Mixed Membership Block Model for Evolving Networks dynamic social biological environment the interactions between the underlying actors can undergo large and systematic changes Each actor the networks can assume multiple related roles and their affiliation each role determined the dynamic links will also exhibit rich temporal phenomenon propose state space mixed membership stochastic blockmodel which captures the dependency between these multiple correlated roles and enables track the mixed membership each actor the latent space across time derived efficient approximate learning and inference algorithms for our model and applied the learned models analyze email network Enron Corp and rewiring gene interaction network yeast collected during its full cell cycle both cases our model reveals interesting patterns the dynamic roles the actors 
9385 en Gradient Descent with Sparsiﬁcation Iterative Algorithm for Sparse Recovery with Restricted Isometry Property this paper present algorithm for ﬁnding sparse vector that minimizes the square errorn n2nwhere satisﬁes thenrestricted isometry property RIP Our algorithm called GraDeS Gradient Descent with Sparsiﬁcation starts from arbitrary sparsenx and iteratively updates Hsx · where constant and sets all but largest coordinates innabsolute value zero nWe show that GraDeS constant number iterations computes the correct sparse solution the system where satisﬁesnthe condition that the isometric constant This the most general condition for which near linear time algorithm known Inncomparison the best condition under which any polynomial time algorithm known √ important contribution thenpaper analyze how the hard thresholding function acts the potentialn n2n special case GraDeS correspondingnto called Iterative Hard Thresholding IHT was previously shown converge when √ nOur Matlab implementation GraDeS out performs previously proposed algorithms like Subspace Pursuit StOMP OMP and Lassonby order magnitude Curiously our experiments also uncovered several cases where regularized regression Lasso fails butnGraDeS ﬁnds the correct solution 
9386 en Learning Dictionaries Stable Autoregressive Models for Audio Scene Analysis this paper explore application basis pursuit audio scene analysis The goal our work detect when certain nsounds are present mixed audio signal focus the regime where out large number possible sources small but unknown nnumber combine and overlap yield the observed signal infer which sounds are present decompose the observed signal linear ncombination small number active sources cast the inference regularized form linear regression whose sparse solutions nyield decompositions with few active sources characterize the acoustic variability individual sources autoregressive models ntheir time domain waveforms When not have prior knowledge the individual sources the coefﬁcients these autoregressive nmodels must learned from audio examples analyze the dynamical stability these models and show how estimate stable models nby substituting simple convex optimization for difﬁcult eigenvalue problem demonstrate our approach learning dictionaries nmusical notes and using these dictionaries analyze polyphonic recordings piano cello and violin 
9387 en Online Dictionary Learning for Sparse Coding Sparse coding—that modelling data vectors sparse linear combinations basis elements— widely used machine learning nneuroscience signal processing and statistics This paper focuses learning the basis set also called dictionary adapt speciﬁc ndata approach that has recently proven very effective for signal reconstruction and classiﬁcation the audio and image processing ndomains This paper proposes new online optimization algorithm for dictionary learning based stochastic approximations which nscales gracefully large datasets with millions training samples proof convergence presented along with experiments with nnatural images demonstrating that leads faster performance and better dictionaries than classical batch algorithms for both small and nlarge datasets 
9388 en Learning Non Redundant Codebooks for Classifying Complex Objects Codebook based representations are widely employed the classiﬁcation complex objects such images and documents Most nprevious codebook based methods construct single codebook via clustering that maps bag low level features into ﬁxed length nhistogram that describes the distribution these features This paper describes simple yet effective framework for learning multiple nnon redundant codebooks that produces surprisingly good results this framework each codebook learned sequence extract ndiscriminative information that was not captured preceding codebooks and their corresponding classiﬁers apply this framework nto two application domains visual object categorization and document classiﬁcation Experiments large classiﬁcation tasks show nsubstantial improvements performance compared single codebook codebooks learned bagging style 
9389 en Prototype Vector Machine for Large Scale Semi Supervised Learning Practical data analysis and mining rarely falls exactly into the supervised learning scenario Rather the growing amount unlabelled ndata from various scientiﬁc domains poses big challenge large scale semi supervised learning SSL note that the computational nintensiveness graph based SSL arises largely from the manifold graph regularization which may turn lead large models that nare difﬁcult handle alleviate this proposed the prototype vector machine PVM highly scalable graph based algorithm for nlarge scale SSL Our key innovation the use “prototypes vectors” for efﬁcient approximation both the graph based regularizer nand the model representation The choice prototypes are grounded upon two important criterion they not only perform effective low nrank approximation the kernel matrix but also span model suffering the minimum information loss compared with the complete nmodel These criterion lead consistent prototype selection scheme allowing design uniﬁed algorithm PVM that demonstrates nencouraging performance while the same time possessing appealing scaling properties empirically linear with sample size 
9390 en Multi Assignment Clustering for Boolean Data Conventional clustering methods typically assume that each data item belongs single cluster This assumption does not hold general order overcome this limitation propose generative method for clustering vectorial data where each object can assigned multiple clusters Using deterministic annealing scheme our method decomposes the observed data into the contributions individual clusters and infers their parameters Experiments synthetic Boolean data show that our method achieves higher accuracy the source parameter estimation and superior cluster stability compared state the art approaches also apply our method important problem computer security known role mining Experiments real world access control data show performance gains generalization new employees against other multi assignment methods challenging situations with high noise levels our approach maintains its good performance while alternative state the art techniques lack robustness 
9391 en  Means Space Radiation Sensitivity Evaluation Spacecraft are increasingly making use onboard data analysis inform additional data collection and prioritization decisions However many spacecraft operate high radiation environments which the reliability data intensive computation not known This paper presents the first study radiation sensitivity for means clustering Our key findings are that means data structures differ sensitivity and sensitivity not determined the amount memory exposed special radiation protection needed below data set dependent radiation threshold enabling the use faster smaller and cheaper onboard memory some cases and subsampling improves radiation tolerance slightly but the use trees unfortunately reduces tolerance Our conclusions can used tailor means for future use high radiation environments 
9392 en Information Theoretic Measures for Clusterings Comparison Correction for Chance Necessary Information theoretic based measures form fundamental class similarity measures for comparing clusterings beside the class pair counting based and set matching based measures this paper discuss the necessity correction for chance for information theoretic based measures for clusterings comparison observe that the baseline for such measures average value under random partitioning data set does not take constant value and tends have larger variation when the ratio between the number data points and the number clusters small This effect similar some other non information theoretic based measures such the well known Rand Index Assuming hypergeometric model randomness derive the analytical formula for the expected mutual information value between pair clusterings and then propose the adjusted version for several popular information theoretic based measures Some examples are given demonstrate the need and usefulness the adjusted measures 
9393 en Fast Evolutionary Maximum Margin Clustering The maximum margin clustering approach recently proposed extension the concept support vector machines the clustering problem Briefly stated aims finding optimal partition the data into two classes such that the margin induced subsequent application support vector machine maximal propose method based stochastic search address this hard optimization problem While direct implementation would infeasible for large data sets present efficient computational shortcut for assessing the quality intermediate solutions Experimental results show that our approach outperforms existing methods terms clustering accuracy 
9394 en Discriminative Metrics The flats algorithm generalization the popular means algorithm where dimensional best fit affine sets replace centroids the cluster prototypes this work modification the flats framework for pattern classification introduced The basic idea replace the original reconstruction only energy which optimized obtain the affine spaces new energy that incorporates discriminative terms This way the actual classification task introduced part the design and optimization The presentation the proposed framework complemented with experimental results showing that the method computationally very efficient and gives excellent results standard supervised learning benchmarks 
9395 en Orbit Product Representation and Correction Gaussian Belief Propagation present new view Gaussian beliefnpropagation GaBP based representa ntion the determinant product over nbits graph show that the GaBPndeterminant estimate captures totally back ntracking orbits the graph and consider hownto correct this estimate show that thenmissing orbits may grouped into equiva nlence classes corresponding backtracklessnorbits and the contribution each equiv nalence class easily determined from thenGaBP solution Furthermore demon nstrate that this multiplicative correction fac ntor can interpreted the determinant anbacktrackless adjacency matrix the graphnwith edge weights based GaBP Finally nan efficient method proposed computena truncated correction factor including allnbacktrackless orbits specified length 
9396 en Convex Variational Bayesian Inference for Large Scale Generalized Linear Models show how variational Bayesian inference can implemented for very large generalized linear models Our relaxation proven convex problem for any log concave model provide generic double loop algorithm for solving this relaxation models with arbitrary super Gaussian potentials iteratively decoupling the criterion most the work can done solving large linear systems rendering our algorithm orders magnitude faster than previously proposed solvers for the same problem evaluate our method problems Bayesian active learning for large binary classification models and show how address settings with many candidates and sequential inclusion steps 
9397 en Archipelago Nonparametric Bayesian Semi Supervised Learning Semi supervised learning SSL classificationnwhere additional unlabeled data can benused improve accuracy Generative approachesnare appealing this situation asna model the data’ probability density cannassist identifying clusters NonparametricnBayesian methods while ideal theory duento their principled motivations have been difficultnto apply SSL practice presentna nonparametric Bayesian method that usesnGaussian processes for the generative model navoiding many the problems associatednwith Dirichlet process mixture models Ournmodel fully generative and take advantagenof recent advances Markov chainnMonte Carlo algorithms provide practicalninference method Our method comparesnfavorably competing approaches syntheticnand real world multi class data 
9398 en The Bayesian Group Lasso for Analyzing Contingency Tables Group Lasso estimators useful many applications nsuffer from lack meaningful variance estimatesnfor regression coefficients overcomensuch problems propose full Bayesian treatmentnof the Group Lasso extending the standardnBayesian Lasso using hierarchical expansion nThe method then applied Poisson modelsnfor contingency tables using highly efficientnMCMC algorithm The simulated experimentsnvalidate the performance this method artificialndatasets with known ground truth Whennapplied breast cancer dataset the methodndemonstrates the capability identifying the differencesnin interactions patterns marker proteinsnbetween different patient groups 
9399 en Split Variational Inference propose deterministic method eval nuate the integral positive function basednon soft binning functions that smoothly cutnthe integral into smaller integrals that areneasier approximate combination withnmean field approximations for each individ nual sub part this leads tractable algo nrithm that alternates between the optimiza ntion the bins and the approximation thenlocal integrals introduce suitable choicesnfor the binning functions such that stan ndard mean field approximation can ntended split mean field approximationnwithout the need for extra derivations Thenmethod can seen revival the ideasnunderlying the mixture mean field approach nThe latter can obtained special casenby taking soft max functions for the binning 
9400 en Proto Predictive Representation States with Simple Recurrent Temporal Difference Networks propose new neural network architecture called Simple Recurrent Temporal Difference Networks TDNs that learns predict future observations partially observable environments TDNs incorporate the structure simple recurrent neural networks SRNs into temporal difference networks use proto predictive representation states Although they deviate from the principle predictive representations ground state representations observations they follow the same learning strategy networks applying learning general predictions Simulation experiments revealed that TDNs can correctly represent states with incomplete set core tests question networks and consequently TDNs have better line learning capacity than networks various environments 
9401 en Regularization and Feature Selection Least Squares Temporal Difference Learning consider the task reinforcement learning with linear value function approximation Temporal difference algorithms and particular the Least Squares Temporal Difference LSTD algorithm provide method for learning the parameters the value function but when the number features large this algorithm can over fit the data and computationally expensive this paper propose regularization framework for the LSTD algorithm that overcomes these difficulties particular focus the case regularization which robust irrelevant features and also serves method for feature selection Although the regularized LSTD solution cannot expressed convex optimization problem present algorithm similar the Least Angle Regression LARS algorithm that can efficiently compute the optimal solution Finally demonstrate the performance the algorithm experimentally 
9402 en Fast Gradient Descent Methods for Temporal Difference Learning with Linear Function Approximation Sutton Szepesvari and Maei 2009 recently introduced the first temporal difference learning algorithm compatible with both linear function approximation and off policy training and whose complexity scales only linearly the size the function approximator Although their gradient temporal difference GTD algorithm converges reliably can very slow compared conventional linear policy problems where convergent calling into question its practical utility this paper introduce two new related algorithms with better convergence rates The first algorithm GTD2 derived and proved convergent just GTD was but uses different objective function and converges significantly faster but still not fast conventional The second new algorithm linear with gradient correction TDC uses the same update rule conventional except for additional term which initially zero our experiments small test problems and Computer application with million features the learning rate this algorithm was comparable that conventional This algorithm appears extend linear off policy learning with penalty performance while only doubling computational requirements 
9403 en Kernelized Value Function Approximation for Reinforcement Learning recent surge research kernelized approaches reinforcement learning has sought bring the benefits kernelized machine learning techniques reinforcement learning Kernelized reinforcement learning techniques are fairly new and different authors have approached the topic with different assumptions and goals Neither unifying view nor understanding the pros and cons different approaches has yet emerged this paper offer unifying view the different approaches kernelized value function approximation for reinforcement learning show that except for different approaches regularization Kernelized LSTD KLSTD equivalent model based approach that uses kernelized regression find approximate reward and transition model and that Gaussian Process Temporal Difference learning GPTD returns mean value function that equivalent these other approaches also demonstrate the relationship between our model based approach and the earlier Gaussian Processes Reinforcement Learning GPRL Finally decompose the Bellman error into the sum transition error and reward error terms and demonstrate through experiments that this decomposition can helpful choosing regularization parameters 
9404 en Constraint Relaxation Approximate Linear Programs Approximate linear programming ALP reinforcement learning technique with nice theoretical properties but often performs poorly practice identify some reasons for the poor quality ALP solutions problems where the approximation induces virtual loops then introduce two methods for improving solution quality One method rolls out selected constraints the ALP guided the dual information The second method relaxation the ALP based external penalty methods The latter method applicable domains which rolling out constraints impractical Both approaches show promising empirical results for simple benchmark problems well for more realistic blood inventory management problem 
9405 en Evaluation Methods for Topic Models natural evaluation metric for statistical topic models the probability held out documents given trained model While exact ncomputation this probability intractable several estimators for this probability have been used the topic modeling literature including nthe harmonic mean method and empirical likelihood method this paper demonstrate experimentally that commonly used methods nare unlikely accurately estimate the probability held out documents and propose two alternative methods that are both accurate and nefﬁcient 
9406 en Accounting for Burstiness Topic Models Many different topic models have been used successfully for variety applications However even state the art topic models nsuffer from the important ﬂaw that they not capture the tendency words appear bursts fundamental property language nthat word used once document more likely used again introduce topic model that uses Dirichlet compound nmultinomial DCM distributions model this burstiness phenomenon both text and non text datasets the new model achieves better nheld out likelihood than standard latent Dirichlet allocation LDA straightforward incorporate the DCM extension into topic models nthat are more complex than LDA 
9407 en Topic Link LDA Joint Models Topic and Author Community Given large scale linked document collection such collection blog posts research literature archive there are two nfundamental problems that have generated lot interest the research community One identify set high level topics covered nby the documents the collection the other uncover and analyze the social network the authors the documents far these nproblems have been viewed separate problems and considered independently from each other this paper argue that these two nproblems are fact inter dependent and should addressed together develop Bayesian hierarchical approach that performs topic nmodeling and author community discovery one uniﬁed framework The effectiveness our model demonstrated two blog data sets nin different domains and one research paper citation data from CiteSeer 
9408 en MedLDA Maximum Margin Supervised Topic Models for Regression and Classiﬁcation Supervised topic models utilize document’ side information for discovering predictive low dimensional representations documents nand existing models apply likelihood based estimation this paper present max margin supervised topic model for both continuous nand categorical response variables Our approach the maximum entropy discrimination latent Dirichlet allocation MedLDA utilizes the nmax margin principle train supervised topic models and estimate predictive topic representations that are arguably more suitable for nprediction develop efﬁcient variational methods for posterior inference and demonstrate qualitatively and quantitatively the advantages nof MedLDA over likelihood based topic models movie review and Newsgroups data sets 
9409 en Independent Factor Topic Models Topic models such Latent Dirichlet Allocation LDA and Correlated Topic Model CTM have recently emerged powerful nstatistical tools for text document modeling this paper improve upon CTM and propose Independent Factor Topic Models IFTM nwhich use linear latent variable models uncover the hidden sources correlation between topics There are main contributions this nwork First using sparse source prior model can directly visualize sparse patterns topic correlations Secondly the conditional nindependence assumption implied the use latent source variables allows the objective function factorize leading fast Newton nRalphson based variational inference algorithm Experimental results synthetic and real data show that IFTM runs average times nfaster than CTM while giving competitive performance measured perplexity and log likelihood held out data 
9410 en Semi Supervised Learning Using Label Mean Semi Supervised Support Vector Machines S3VMs typically directly estimate the label assignments for the unlabeled instances This often inefficient even with recent advances the efficient training the supervised SVM this paper show that S3VMs with knowledge the means the class labels the unlabeled data closely related the supervised SVM with known labels all the unlabeled data This motivates first estimate the label means the unlabeled data Two versions the meanS3VM which work maximizing the margin between the label means are proposed The first one based multiple kernel learning while the second one based alternating optimization Experiments show that both the proposed algorithms achieve highly competitive and sometimes even the best performance compared the state the art semi supervised learners Moreover they are more efficient than existing S3VMs 
9411 en Partially Supervised Feature Selection with Regularized Linear Models This paper addresses feature selection techniques for classification high dimensional data such those produced microarray experiments Some prior knowledge may available this context bias the selection towards some dimensions genes priori assumed more relevant propose feature selection method making use this partial supervision extends previous works embedded feature selection with linear models including regularization enforce sparsity practical approximation this technique reduces standard SVM learning with iterative rescaling the inputs The scaling factors depend here the prior knowledge but the final selection may depart from Practical results several microarray data sets show the benefits the proposed approach terms the stability the selected gene lists with improved classification performances 
9412 en Optimal Reverse Prediction Unified Perspective Supervised Unsupervised and Semi Supervised Learning raining principles for unsupervised learning are often derived from motivations that appear independent supervised learning causing proliferation semisupervised training methods this paper present simple unification several supervised and unsupervised training principles through the concept optimal reverse prediction predict the inputs from the target labels optimizing both over model parameters and any missing labels particular show how supervised least squares principal components analysis means clustering and normalized graph cut clustering can all expressed instances the same training principle differing only constraints made the target labels Natural forms semi supervised regression and classification are then automatically derived yielding semi supervised learning algorithms for regression and classification that surprisingly are novel and refine the state the art These algorithms can all combined with standard regularizers and made non linear via kernels 
9413 en Supervised Learning from Multiple Experts Whom Trust When Everyone Lies Bit describe probabilistic approach for supervised learning when have multiple experts annotators providing possibly noisy labels but absolute gold standard The proposed algorithm evaluates the different experts and also gives estimate the actual hidden labels Experimental results indicate that the proposed method clearly beats the commonly used majority voting baseline 
9414 en Good Learners for Evil Teachers consider supervised machine learning scenario where labels are provided heterogeneous set teachers some which are mediocre incompetent perhaps even malicious present algorithm built the SVM framework that explicitly attempts cope with low quality and malicious teachers decreasing their influence the learning process Our algorithm does not receive any prior information the teachers nor does resort repeated labeling where each example labeled multiple teachers provide theoretical analysis our algorithm and demonstrate its merits empirically Finally present second algorithm with promising empirical results but without formal analysis 
9415 en Stochastic Methods for Regularized Loss Minimization describe and analyze two stochastic methods for ell regularized loss minimization problems such the Lasso The first method updates the weight single feature each iteration while the second method updates the entire weight vector but only uses single training example each iteration both methods the choice feature example uniformly random Our theoretical runtime analysis suggests that the stochastic methods should outperform state the art deterministic approaches including their deterministic counterparts when the size the problem large demonstrate the advantage stochastic methods experimenting with synthetic and natural data sets 
9416 en Blockwise Coordinate Descent Procedures for the Multi Task Lasso with Applications Neural Semantic Basis Discovery develop cyclical blockwise coordinate descent algorithm for the multi task Lasso that efficiently solves problems with thousands features and tasks The main result shows that closed form Winsorization operator can obtained for the sup norm penalized least squares regression This allows the algorithm find solutions very large scale problems far more efficiently than existing methods This result complements the pioneering work Friedman 2007 for the single task Lasso case study use the multi task Lasso variable selector discover semantic basis for predicting human neural activation The learned solution outperforms the standard basis for this task the majority test participants while requiring far fewer assumptions about cognitive neuroscience demonstrate how this learned basis can yield insights into how the brain represents the meanings words 
9417 en  Efficient Projection for Infinity Regularization recent years the Infinity norm has been proposed for joint regularization essence this type regularization aims extending the framework for learning sparse models setting where the goal learn set jointly sparse models this paper derive simple and effective projected gradient method for optimization Infinity regularized problems The main challenge developing such method resides being able compute efficient projections the Infinity ball present algorithm that works log time and memory where the number parameters test our algorithm multi task image annotation problem Our results show that Infinity leads better performance than both and regularization and that effective discovering jointly sparse solutions 
9418 en  Accelerated Gradient Method for Trace Norm Minimization consider the minimization smooth loss function regularized the trace norm the matrix variable Such formulation finds applications many machine learning tasks including multi task learning matrix classification and matrix completion The standard semidefinite programming formulation for this problem computationally expensive addition due the non smoothness nature the trace norm the optimal first order black box method for solving such class problems converges sqrt where the iteration counter this paper exploit the special structure the trace norm based which propose extended gradient algorithm that converges further propose accelerated gradient algorithm which achieves the optimal convergence rate for smooth problems Experiments multi task learning problems demonstrate the efficiency the proposed algorithms 
9419 en Group Lasso with Overlaps and Graph Lasso propose new penalty function which when used regularization for empirical risk minimization procedures leads sparse estimators The support the sparse vector typically union potentially overlapping groups covariates defined priori set covariates which tend connected each other when graph covariates given study theoretical properties the estimator and illustrate its behavior simulated and breast cancer gene expression data 
9420 en Uniting priori and posteriori knowledge research framework The ability perform machine classification ancritical component intelligent system Wenpropose unite the logical priori approachnto this problem with the empirical posteriorinapproach describe particular how the anpriori knowledge encoded Cyc can mergednwith technology for probabilistic inference usingnMarkov logic networks describe two problemndomains – the Whodunit Problem and noun phrasenunderstanding – and show that Cyc’ commonsensenknowledge can fruitfully combined with probabilisticnreasoning 
9421 en Denotation Two Step Mapping Semantic Web Architecture RDF URIs are used denote resources thingsnin the universe discourse According RDFnsemantics interpretation defines the mappingnfrom URI resource Many interpretations maynbe consistent with given RDF graph and RDFnsemantics does not specify how select suitableninterpretation from among the possible candidates nIn other writings the author has advocated that innsemantic web architecture such denotation shouldnbe viewed two step mapping from the URI anset core assertions specified URI declaration nand thence the resource The reason for this viewnis that permits consistent resource identity benassociated with URI the constraints expressed innthe URI declaration represent common identity fornthat URI This paper shows how this view ofndenotation corresponds established RDFnsemantics 
9422 en From unstructured linked data Entity extraction and disambiguation collective similarity maximization this paper describe pipeline methods fornidentifying and resolving entities from unstructuredndata using semi structured background knowledgendatabase For this purpose employ namednentity extraction reference resolution and investigatenperformance disambiguation using collectivenmaximization inter entity similarity comparednto using only pair wise disambiguation Wenexplore possibilities using DBpedia and Yago asnbackground knowledge databases with the goal ofnannotating unstructured text documents with globalnentity references 
9423 en The URI Lifecycle Semantic Web Architecture Abstract Various parties are typically involved innthe creation and use URI including the URInowner RDF statement author and consumer ofnthat RDF statement What principles should thesenparties follow ensure that consistent resourcenidentity established and the extent possible nmaintained throughout that URI lifetime Thisnpaper proposes set roles and responsibilities fornestablishing and determining URI resourcenidentity through its lifecycle 
9424 en Identity and Reference for the Global Giant Graph this paper address the issue how data onnthe Global Giant Graph GGG can used answernglobal queries start with formal modelnfor the GGG and then use provide formalnspecification three very general modes fornanswering query the GGG called bounded nnavigational and direct access mode respectively nIn the final discussion connect our model recentndiscussions URI reference and identity innthe Semantic Web community 
9425 en Sig Entity centric search the Web
9427 en Web datasets integration with RDF With the recent publication large quantitiesnof RDF data the Semantic Web now allowsnconcrete applications developed Multiplendatasets are effectively published accordingnto the linked data principles Integrating thesendatasets through interlink fusion needednin order assure interoperability between thenresources composing them There thus angrowing need for tools providing datasets management nWe present this paper RDF anframework and tool for managing the integrationnof RDF datasets The framework includesnfive modules for pre processing matching fusing ninterlinking and post processing datasets nThe framework inplementation results toolnproviding RDF datasets integration functionalitiesnin linked data context Evaluation ofnRDF existing datasets shows promisingnresults towards Semantic Web aware datasetsnintegration tool 
9428 en Text Mining and Link Analysis The tutorial Text Mining and Link Analysis for Web Data will focus two main analytical approaches when analyzing web data text mining and link analysis for the purpose analyzing web documents and their linkage First the tutorial will cover some basic steps and problems when dealing with the textual and network graph data showing what possible achieve without very sophisticated technology The idea this first part present the nature unstructured and semi structured data Next the second part more sophisticated methods for solving more difficult and challenging problems will shown the last part some the current open research issues will presented and some practical pointers the available tolls for solving previously mentioned problems will provided 
9430 en Learning vehicular dynamics models with application helicopter modeling and control
9431 en Optimized Information Gatheringin Robotics and Sensor Networks
9432 en Adaptation and Self Supervision Mobile Robots Poster Spotlight Presentations
9433 en The Role Function Approximation for both Regression and Classifiction Robotics
9434 en Going forward with Probablistic Local Learning Approaches
9435 en Function Approximation for Imitation Learning Humanoid Robots
9436 en Reinforcement Learning Reward Weighted Regression
9438 en Bayesian Clustering for Email Campaign Detection discuss the problem clustering elements according the sources that have generated them For elements that are characterized nby independent binary attributes closed form Bayesian solution exists derive solution for the case dependent attributes that nbased transformation the instances into space independent feature functions derive optimization problem that produces nmapping into space independent binary feature vectors the features can reﬂect arbitrary dependencies the input space This problem nsetting motivated the application spam ﬁltering for email service providers Spam traps deliver real time stream messages nknown spam elements the same campaign can recognized reliably entire spam and phishing campaigns can contained nWe present case study that evaluates Bayesian clustering for this application 
9439 en  Novel Lexicalized HMM Based Learning Framework for Web Opinion Mining Merchants selling products the Web often ask their customers share their opinions and hands experiences products they have npurchased commerce becoming more and more popular the number customer reviews product receives grows rapidly This nmakes difﬁcult for potential customer read them make informed decision whether purchase the product this research nwe aim mine customer reviews product and extract highly speciﬁc product related entities which reviewers express their opinions nOpinion expressions and sentences are also identiﬁed and opinion orientations for each recognized product entity are classiﬁed positive nor negative Different from previous approaches that have mostly relied natural language processing techniques statistic information nwe propose novel machine learning framework using lexicalized HMMs The approach naturally integrates linguistic features such npart speech and surrounding contextual clues words into automatic learning The experimental results demonstrate the effectiveness nof the proposed approach web opinion mining and extraction from product reviews 
9440 en Learning Spectral Graph Transformations for Link Prediction present uniﬁed framework for learning link prediction and edge weight prediction functions large networks based the ntransformation graph’ algebraic spectrum Our approach generalizes several graph kernels and dimensionality reduction methods and nprovides method estimate their parameters efﬁciently show how the parameters these prediction functions can learned nreducing the problem one dimensional regression problem whose runtime only depends the method’ reduced rank and that can nbe inspected visually derive variants that apply undirected weighted unweighted unipartite and bipartite graphs evaluate our nmethod experimentally using examples from social networks collaborative ﬁltering trust networks citation networks authorship graphs nand hyperlink networks 
9441 en Interactively Optimizing Information Retrieval Systems Dueling Bandits Problem present online learning framework tailored towards real time learning from observed user behavior search engines and other information retrieval systems particular only require pairwise comparisons which were shown reliably inferred from implicit feedback will present algorithm with theoretical guarantees well simulation results 
9442 en Transfer Learning for Collaborative Filtering via Rating Matrix Generative Model Cross domain collaborative ﬁltering solves the sparsity problem transferring rating knowledge across multiple domains this paper propose rating matrix generative model RMGM for effective cross domain collaborative ﬁltering ﬁrst show that the relatedness across multiple rating matrices can established ﬁnding shared implicit cluster level rating matrix which next extended nto cluster level rating model Consequently rating matrix any related task can viewed drawing set users and items from user item joint mixture model well drawing the corresponding ratings from the cluster level rating model The combination these two models gives the RMGM which can used ﬁll the missing ratings for both existing and new users major advantage RMGM that can share the knowledge pooling the rating data from multiple tasks even when the users and items these tasks not overlap nWe evaluate the RMGM empirically three real world collaborative ﬁltering data sets show that RMGM can outperform the individual models trained separately 
9443 en Curriculum Learning Humans and animals learn much better when the examples are not randomly presented but organized meaningful order which illustrates gradually more concepts and gradually more complex ones Here formalize such training strategies the context machine learning and call them curriculumnlearning the context recent research studying the difficulty training the presence non convex training criteria for deep deterministic and stochastic neuralnnetworks explore curriculum learning various set ups The experiments show that signi cant improvements generalization can achieved hypothesize that curriculum learning has both ffect the speed convergence the training process minimum and the case non convex criteria the quality the local minima obtained curriculum learning can seen particular form continuation methodn general strategy for global optimization non convex functions 
9444 en Herding Dynamical Weights Learn new herding algorithm proposed which directly converts observed moments into sequence pseudo samples The pseudo samples respect the moment constraints and may used estimate unobserved quantities interest The procedure allows sidestep the usual approach first learning joint model which intractable and then sampling from that model which can easily get stuck local mode Moreover the algorithm fully deterministic avoiding random number generation and does not need expensive operations such exponentiation 
9445 en Sequential Bayesian Prediction the Presence Changepoints introduce new sequential algorithmnfor making robust predictions the presence changepoints Unlike previous approaches which focus the problem detecting and locating changepoints our algorithm focuses the problem making predictions even when such changes might present introduce nonstationary variance functions used Gaussian process prediction that model such changes then proceed demonstrate how effectively manage the hyperparameters associated with those covariance functions using Bayesian quadrature can integrate out the hyperparameters allowing calculate the marginal predictive distribution nFurthermore desired the posterior distribution over putative changepoint locations can calculated natural byproduct our prediction algorithm 
9446 en Model Free Reinforcement Learning Mixture Learning cast model free reinforcement learning the problem maximizing the likelihood probabilistic mixture model via sampling addressing both the nite and nite horizon cases describe Stochastic ApproximationnEM algorithm for likelihood maximizationnthat the tabular case equivalentnto non bootstrapping optimistic policy iteration algorithm like Sarsa that can applied both MDPs and POMDPs the theoretical side relating the proposednstochastic algorithm the family optimistic policy iteration algorithms provide new tools that permit the design and analysis algorithms that family thenpractical side preliminary experiments POMDP problem demonstrated encouraging results 
9447 en Active Learning for Directed Exploration Complex Systems Physics based simulation codes are widely used science and engineering model complex systems that would infeasible study otherwise Such codes provide the highest fidelity representation system behavior but are often slow run that insightninto the system limited For example nconducting exhaustive sweep over and dimensional input parameter space with steps along each dimension requires simulation trials translating into CPU days for one our current simulations alternative directed exploration which the next simulation trials are cleverly chosen each step Given the results previous trials supervised learning techniques SVM KDE are applied build simplified predictive models system behavior nThese models are then used within active learning framework identify the most valuable trials run next Several active learning strategies are examined including recently proposed information theoretic approach nPerformance evaluated set thirteen synthetic oracles which serve surrogates for the more expensive simulations and enable the experiments replicated other researchers 
9448 en Bayesian Inference for Plackett Luce Ranking Models This paper gives efficient Bayesian method for inferring the parameters Plackett Luce ranking model Such models are parameterised distributions over rankings nite set objects and have typically been studied and applied within the psychometric sociometric and econometric literature The inference scheme application Power expectation propagation The scheme robust and can readily applied large scale data sets The inference algorithm extends tonvariations the basic Plackett Luce model including partial rankings show number advantages the approach over the traditional maximum likelihood method apply the method aggregate rankings NASCAR racing drivers over the 2002 season and also rankings movie genres 
9449 en Incorporating Domain Knowledge into Topic Modeling via Dirichlet Forest Priors Users topic modeling methods often have knowledge about the composition words that should have high low probability various topics incorporate such domain knowledge using novel Dirichlet Forest prior Latent Dirichlet Allocation framework nThe prior mixture Dirichlet tree distributions with special structures present its construction and inference via collapsed Gibbs sampling Experiments synthetic and real datasets demonstrate our model’ ability follow and generalize beyond userspecified domain knowledge 
9450 en Nonparametric Factor Analysis with Beta Process Priors propose nonparametric extension the factor analysis problem using beta process prior This beta process factor analysis BPFA model allows for dataset decomposed into linear combination sparse set factors providing information thenunderlying structure the observations with the Dirichlet process the beta process fully Bayesian conjugate prior which allowsnfor analytical posterior calculation andnstraightforward inference derive variational Bayes inference algorithm and demonstrate the model the MNIST digits and HGDP CEPH cell line panel datasets 
9451 en Accelerated Gibbs Sampling for the Indian Buffet Process often seek identify occurring hidden features set observations The Indian Buffet Process IBP provides nonparametric prior the features present each observation but current inference techniques for the IBP often scale poorly The collapsed Gibbs sampler for the IBP has running time cubic the number observations and the uncollapsed Gibbs sampler while linear often slow mix presentna new linear time collapsed Gibbs sampler for conjugate likelihood models and demonstrate its efficacy large real world datasets 
9452 en  Stochastic Memoizer for Sequence Data propose unbounded depth hierarchical Bayesian nonparametric model for discrete sequence data This model can estimated from single training sequence yet shares statistical strength between subsequentnsymbol predictive distributions suchna way that predictive performance generalizes well The model builds specific parameterization unbounded depth hierarchical Pitman Yor process introduce analytic marginalization steps using coagulationnoperators reduce this model onenthat can represented time and space linear the length the training sequence show how perform inference such model without truncation approximation and introduce fragmentation operators necessary predictive inference demonstrate the sequence memoizer using language model achieving state the art results 
9453 en Binary Action Search for Learning Continuous Action Control Policies Reinforcement Learning methods for controlling stochastic processes typically assume small and discrete action space While continuous action spaces are quite common real world problems the most common approach still employed practice coarse discretization the action space This paper presents novel method called Binary Action Search for realizing continuous action policies searching efficiently the entire action range through increment and decrement modifications the values the action variables according internal binary policy defined over augmented state space The proposed approach essentially approximates any continuous action space arbitrary resolution and can combined with any discrete action reinforcement learning algorithm for learning continuous action policies Binary Action Search eliminates the restrictive modification steps Adaptive Action Modification and requires temporal action locality the domain Our approach coupled with two well known reinforcement learning algorithms Least Squares Policy Iteration and Fitted Iteration and its use and properties are thoroughly investigated and demonstrated the continuous state action Inverted Pendulum Double Integrator and Car the Hill domains 
9454 en Predictive Representations for Policy Gradient POMDPs consider the problem estimating the policy gradient Partially Observable Markov Decision Processes POMDPs with special class policies that are based Predictive State Representations PSRs compare PSR policies Finite State Controllers FSCs which are considered standard model for policy gradient methods POMDPs present general actor critic algorithm for learning both FSCs and PSR policies The critic part computes value function that has variables the parameters the policy These latter parameters are gradually updated maximize the value function show that the value function polynomial for both FSCs and PSR policies with potentially smaller degree the case PSR policies Therefore the value function PSR policy can have less local optima than the equivalent FSC and consequently the gradient algorithm more likely converge global optimal solution 
9455 en Stochastic Search Using the Natural Gradient optimize unknown fitness functions introduce Natural Search novel stochastic search method that constitutes principled alternative standard evolutionary methods maintains multinormal distribution the set solution candidates The Natural Gradient used update the distribution parameters the direction higher expected fitness efficiently calculating the inverse the exact Fisher information matrix whereas previous methods had use approximations Other novel aspects our method include optimal fitness baselines and importance mixing procedure adjusting batches with minimal numbers fitness evaluations The algorithm yields competitive results number benchmarks 
9456 en Approximate Inference for Planning Stochastic Relational Worlds Relational world models that can learned from experience stochastic domains have received significant attention recently However efficient planning using these models remains major issue propose convert learned noisy probabilistic relational rules into structured dynamic Bayesian network representation Predicting the effects action sequences using approximate inference allows for planning complex worlds evaluate the effectiveness our approach for online planning simulated blocksworld with articulated manipulator and realistic physics Empirical results show that our method can solve problems where existing methods fail 
9457 en Discovering Options from Example Trajectories present novel technique for automated problem decomposition address the problem scalability Reinforcement Learning Our technique makes use set near optimal trajectories discover options and incorporates them into the learning process dramatically reducing the time takes solve the underlying problem run series experiments two different domains and show that our method offers fold speedup over the baseline 
9458 en Nonparametric Estimation the Precision Recall Curve The Precision Recall curve widely used visual tool evaluate the performance scoring functions regards their capacities discriminate between two populations The purpose this paper examine both theoretical and practical issues related the statistical estimation curves based classification data Consistency and asymptotic normality the empirical counterpart the curve sup norm are rigorously established Eventually the issue building confidence bands the space considered and specific resampling procedure based smoothed and truncated version the empirical distribution the data promoted Arguments theoretical and computational nature are presented explain why such bootstrap preferable naive bootstrap this setup 
9459 en Surrogate Regret Bounds for Proper Losses present tight surrogate regret bounds for the class proper Fisher consistent losses The bounds generalise the margin based bounds due Bartlett 2006 The proof uses Taylor theorem and leads new representations for loss and regret and simple proof the integral representation proper losses also present different formulation duality result Bregman divergences which leads demonstration the convexity composite losses using canonical link functions 
9460 en Robust Bounds for Classification via Selective Sampling introduce new algorithm for binary classification the selective sampling protocol Our algorithm uses Regularized Least Squares RLS base classifier and for this reason can efficiently run any RKHS Unlike previous margin based semi supervised algorithms our sampling condition hinges simultaneous upper bound bias and variance the RLS estimate under simple linear label noise model This fact allows prove performance bounds that hold for arbitrary sequence instances particular show that our sampling strategy approximates the margin the Bayes optimal classifier any desired accuracy asking widetilde scO bigl bigr queries the RKHS case replaced suitable spectral quantity While these are the standard rates the fully supervised case the best previously known result our harder setting was widetilde scO bigl bigr Preliminary experiments show that some our algorithms also exhibit good practical performance 
9461 en PAC Bayesian Learning Linear Classifiers present general PAC Bayes theorem from which all known PAC Bayes bounds are simply obtained particular cases also propose different learning algorithms for finding linear classifiers that minimize these PAC Bayes risk bounds These learning algorithms are generally competitive with both AdaBoost and the SVM 
9462 en Piecewise Stationary Bandit Problems with Side Observations consider sequential decision problem where the rewards are generated piecewise stationary distribution However the different reward distributions are unknown and may change unknown instants Our approach uses limited number side observations past rewards but does not require prior knowledge the frequency changes spite the adversarial nature the reward process provide algorithm whose regret with respect the baseline with perfect knowledge the distributions and the changes log where the number changes time This contrast the case where side observations are not available and where the regret least Omega sqrt 
9463 en Bandit Based Optimization Graphs with Application Library Performance Tuning The problem choosing fast implementations for class recursive algorithms such the fast Fourier transforms can formulated nas optimization problem over the language generated suitably deﬁned grammar propose novel algorithm that solves this nproblem reducing maximizing objective function over the sinks directed acyclic graph This algorithm valuates nodes using nMonte Carlo and grows subgraph the most promising directions considering local maximum armed bandits When used inside nan adaptive linear transform library cuts down the search time order magnitude compared the existing algorithm some ncases the performance the implementations found also increased which considerable practical importance since nconsequently improves the performance all applications using the library 
9464 en Robust Feature Extraction via Information Theoretic Learning this paper present robust feature extraction framework based information theoretic learning Its formulated objective aims nat dual targets motivated the Renyi’ quadratic entropy the features and the Renyi’ cross entropy between features and class labels nrespectively This objective function reaps the advantages robustness from both redescending estimator and manifold regularization nand can efﬁciently optimized via half quadratic optimization iterative manner addition the popular algorithms LPP SRDA and nLapRLS for feature extraction are all justiﬁed the special cases within this framework Extensive comparison experiments several nreal world data sets with contaminated features labels well validate the encouraging gain algorithmic robustness from this proposed nframework 
9465 en Block Wise Construction Acyclic Relational Features with Monotone Irreducibility and Relevancy Properties describe algorithm for constructing set acyclic conjunctive relational features combining smaller conjunctive blocks nUnlike traditional level wise approaches which preserve the monotonicity frequency our block wise approach preserves form nmonotonicity the irreducibility and relevancy feature properties which are important propositionalization employed the context nof classiﬁcation learning With pruning based these properties our block wise approach efﬁciently scales features including tens nﬁrst order literals far beyond the reach state the art propositionalization inductive logic programming systems 
9466 en Rule Learning with Monotonicity Constraints the ordinal classiﬁcation with monotonicity constraints assumed that the class label should increase with increasing values nthe attributes this paper aim formalizing the approach learning with monotonicity constraints from statistical point view nwhich results the algorithm for learning rule ensembles The algorithm ﬁrst ”monotonizes” the data using nonparametric classiﬁcation nprocedure and then generates rule ensemble consistent with the training set The procedure justiﬁed theoretical analysis and veriﬁed nin computational experiment 
9467 en Grammatical Inference Principal Component Analysis Problem One the main problems probabilistic grammatical inference consists inferring stochastic language probability distribu ntion some class probabilistic models from sample words independently drawn according ﬁxed unknown target distribution nHere consider the class rational stochastic languages composed stochastic languages that can computed muliplicity automata nwhich can viewed generalization probabilistic automata Rational stochastic languages have useful algebraic characterization nall the mappings ¿ lie ﬁnite dimensional vector subspace the vector space composed all real valued functions ndeﬁned over Hence ﬁrst step the grammatial inference process can consist identifying the subspace this paper study nthe possibility using principal component analysis achieve this task provide inference algorithm which computes estimate nof the target distribution prove sometheoreticalpropertiesofthisalgorithmandweprovideresultsfromnumericalsimulationsthatconﬁrm the relevance our approach 
9468 en Polyhedral Outer Approximations with Application Natural Language Parsing Recent approaches learning structured predictors often require approximate inference for tractability yet its effects the learned model are unclear Meanwhile most learning algorithms act computational cost was constant within the model class This paper sheds some light the first issue establishing risk bounds for max margin learning with relaxed inference and addresses the second issue proposing new paradigm that attempts penalize time consuming hypotheses Our analysis relies geometric characterization the outer polyhedra associated with the relaxation then apply these techniques the problem dependency parsing for which concise formulation provided that handles non local output features significant improvement shown over arc factored models 
9469 en  Primal and Dual Sparsity Markov Networks Sparsity desirable property high dimensional learning The ell norm regularization can lead primal sparsity while max margin methods achieve dual sparsity but achieving both single structured prediction model remains difficult This paper presents ell norm max margin Markov network ell which enjoys both primal and dual sparsity and analyzes its connections the Laplace max margin Markov network LapM which inherits the dual sparsity max margin models but pseudo primal sparse show that ell extreme case LapM when the regularization constant infinity also show equivalence between ell and adaptive from which develop robust style algorithm for ell demonstrate the advantages the simultaneously pseudo primal and dual sparse models over the ones which enjoy either primal dual sparsity both synthetic and real data sets 
9470 en Learning Structural SVMs with Latent Variables present large margin formulation and algorithm for structured output prediction that allows the use latent variables The paper identifies particular formulation that covers large range application problems while showing that the resulting optimization problem can generally addressed using Concave Convex Programming The generality and performance the approach demonstrated motif finding application noun phrase coreference resolution and optimizing precision information retrieval 
9471 en  Efficient Sparse Metric Learning High Dimensional Space via Penalized Log Determinant Regularization This paper proposes efficient sparse metric learning algorithm high dimensional space via ell penalized log determinant regularization Compare the most existing distance metric learning algorithms the proposed algorithm exploits the sparsity nature underlying the intrinsic high dimensional feature space This sparsity prior learning distance metric serves regularize the complexity the distance model especially the less example number and high dimension setting Theoretically analogy the covariance estimation problem find the proposed distance learning algorithm has consistent result rate mathcal left sqrt left log right right the target distance matrix with most nonzeros per row Moreover from the implementation perspective this ell penalized log determinant formulation can efficiently optimized block coordinate descent fashion which much faster than the standard semi definite programming which has been widely adopted many other advanced distance learning algorithms compare this algorithm with other state the art ones various datasets and competitive results are obtained 
9472 en Learning Instance Specific Distances Using Metric Propagation many real world applications such image retrieval would natural measure the distances from one instance others using textit instance specific distance which captures the distinctions from the perspective the concerned instance However there complete framework for learning instance specific distances since existing methods are incapable learning such distances for test instance and unlabeled data this paper propose the ISD method address this issue The key ISD textit metric propagation that propagating and adapting metrics individual labeled examples individual unlabeled instances formulate the problem into convex optimization framework and derive efficient solutions Experiments show that ISD can effectively learn instance specific distances for labeled well unlabeled instances The metric propagation scheme can also used other scenarios 
9473 en Convolutional Deep Belief Networks for Scalable Unsupervised Learning Hierarchical Representations There has been much interest unsupervisednlearning hierarchical generative modelsnsuch deep belief networks Scalingnsuch models full sized high dimensionalnimages remains difficult problem addressnthis problem present the convolutional deep belief network hierarchical generativenmodel which scales realistic imagensizes This model translation invariant andnsupports efficient bottom and top downnprobabilistic inference Key our approachnis probabilistic max pooling novel techniquenwhich shrinks the representations highernlayers probabilistically sound way Ournexperiments show that the algorithm learnsnuseful high level visual features such objectnparts from unlabeled images objectsnand natural scenes demonstrate excellentnperformance several visual recognitionntasks and show that our model can performnhierarchical bottom and top down ninference over full sized images 
9474 en Using Fast Weights Improve Persistent Contrastive Divergence The most commonly used learning algorithmnfor restricted Boltzmann machines contrastive divergence which starts Markovnchain data point and runs the chainnfor only few iterations get cheap lownvariance estimate the sufficient statisticsnunder the model Tieleman 2008 showednthat better learning can achieved estimating the model’ statistics using smallnset persistent ”fantasy particles” that arennot reinitialized data points after eachnweight update With sufficiently small weightnupdates the fantasy particles represent thenequilibrium distribution accurately but explain why the method works with much largernweight updates necessary consider theninteraction between the weight updates andnthe Markov chain show that the weightnupdates force the Markov chain mix fast nand using this insight develop evennfaster mixing chain that uses auxiliary setnof ”fast weights” implement temporarynoverlay the energy landscape The fastnweights learn rapidly but also decay rapidlynand not contribute the normal energynlandscape that defines the model 
9475 en Large Scale Deep Unsupervised Learning Using Graphics Processors The promise unsupervised learning methodsnlies their potential use vast amountsnof unlabeled data learn complex highlynnonlinear models with millions free parameters nWe consider two well known unsupervisednlearning models deep belief networksn DBNs and sparse coding that have recentlynbeen applied flurry machine learningnapplications Hinton Salakhutdinov 2006 nRaina 2007 Unfortunately currentnlearning algorithms for both models are toonslow for large scale applications forcing researchersnto focus smaller scale models ornto use fewer training examples nIn this paper suggest massively parallelnmethods help resolve these problems nWe argue that modern graphics processorsnfar surpass the computational capabilities ofnmulticore CPUs and have the potential tonrevolutionize the applicability deep unsupervisednlearning methods develop generalnprinciples for massively parallelizing unsupervisednlearning tasks using graphics processors nWe show that these principles cannbe applied successfully scaling learningnalgorithms for both DBNs and sparse coding nOur implementation DBN learning ton70 times faster than dual core CPU implementationnfor large models For example wenare able reduce the time required learn anfour layer DBN with 100 million free parametersnfrom several weeks around singlenday For sparse coding develop simple ninherently parallel algorithm that leads an5 fold speedup over previous methods 
9476 en Factored Conditional Restricted Boltzmann Machines for Modeling Motion Style The Conditional Restricted Boltzmann Machine CRBM recently proposed model for time series that has rich distributed hidden state and permits simple exact inference present new model based the CRBM that preserves its most important computational properties and includes multiplicative three way interactions that allow the effective interaction weight between two units modulated the dynamic state third unit factorize the three way weight tensor implied the multiplicative model reducing the number parameters from The result efficient compact model whose effectiveness demonstrate modeling human motion Like the CRBM our model can capture diverse styles motion with single set parameters and the three way interactions greatly improve the model ability blend motion styles transition smoothly between them 
9477 en Deep Learning from Temporal Coherence Video This work proposes learning method forndeep architectures that takes advantage ofnsequential data particular from the temporalncoherence that naturally exists unlabelednvideo recordings That two successivenframes are likely contain the samenobject objects This coherence used asna supervisory signal over the unlabeled data nand used improve the performance ansupervised task interest demonstratenthe effectiveness this method some poseninvariant object and face recognition tasks 
9478 en Robot Trajectory Optimization Using Approximate Inference The general stochastic optimal control SOC problem robotics scenarios often too complex solved exactly and near real time classical approximate solution first compute optimal deterministic trajectory and then solve local linear quadratic gaussian LQG perturbation model handle the system stochasticity present new algorithm for this approach which improves upon previous algorithms like iLQG consider probabilistic model for which the maximum likelihood trajectory coincides with the optimal trajectory and which the LQG case reproduces the classical SOC solution The algorithm then utilizes approximate inference methods similar expectation propagation that efficiently generalize non LQG systems demonstrate the algorithm simulated DoF humanoid robot 
9479 en Trajectory Prediction Learning Map Situations Robot Trajectories Trajectory planning and optimization fundamental problem articulated robotics Algorithms used typically for this problem compute optimal trajectories from scratch new situation effect extensive data accumulated containing situations together with the respective optimized trajectories but this data practice hardly exploited The aim this paper learn from this data Given new situation want predict suitable trajectory which only needs minor refinement conventional optimizer Our approach has two essential ingredients First generalize from previous situations new ones need appropriate situation descriptor propose sparse feature selection approach find such well generalizing features situations Second the transfer previously optimized trajectories new situation should not made joint angle space propose more efficient task space transfer old trajectories new situations Experiments trajectory optimization for simulated humanoid reaching problem show that can predict reasonable motion prototypes new situations for which the refinement much faster than optimization from scratch 
9480 en Learning Complex Motions Sequencing Simpler Motion Templates Abstraction complex longer motor tasks into simpler elemental movements enables humans and animals exhibit motor skills which have not yet been matched robots Humans intuitively decompose complex motions into smaller simpler segments For example when describing simple movements like drawing triangle with pen can easily name the basic steps this movement nnSurprisingly such abstractions have rarely been used artificial motor skill learning algorithms These algorithms typically choose new action such torque force very fast time scale result both policy and temporal credit assignment problem become unnecessarily complex often beyond the reach current machine learning methods nnWe introduce new framework for temporal abstractions reinforcement learning with motion templates present new algorithm for this framework which can learn high quality policies making only few abstract decisions 
9481 en Learning When Stop Thinking and Something anytime algorithm capable returning response the given task essentially any time typically the quality the response improves the time increases Here consider the challenge learning when should terminate such algorithms each sequence iid tasks optimize the expected average reward per unit time provide algorithm for answering this question combine the global optimizer Cross Entropy method and the local gradient ascent and theoretically investigate how far the estimated gradient from the true gradient empirically demonstrate the applicability the proposed algorithm toy problem well real world face detection task 
9482 en Monte Carlo Simulation Balancing this paper introduce the first algorithms for efficiently learning simulation policy for Monte Carlo search Our main idea optimise the balance simulation policy that accurate spread simulation outcomes maintained rather than optimising the direct strength the simulation policy develop two algorithms for balancing simulation policy gradient descent The first algorithm optimises the balance complete simulations using policy gradient algorithm whereas the second algorithm optimises the balance over every two steps simulation compare our algorithms reinforcement learning and supervised learning algorithms for maximising the strength the simulation policy test each algorithm the domain 5x5 Computer using softmax policy that parameterised weights for hundred simple patterns When used simple Monte Carlo search the policies learnt simulation balancing achieved significantly better performance with half the mean squared error uniform random policy and equal overall performance sophisticated engine 
9483 en Boosting Products Base Classiﬁers this paper show how boost products simple base learners Similarly trees call the base learner subroutine but nin iterative rather than recursive fashion The main advantage the proposed method its simplicity and computational efﬁciency nbenchmark datasets our boosted products decision stumps clearly outperform boosted trees and the MNIST dataset the algorithm nachieves the second best result among domain knowledge algorithms after deep belief nets second contribution present nimproved base learner for nominal features and show that boosting the product two these new subset indicator base learners solves nthe maximum margin matrix factorization problem used formalize the collaborative ﬁltering task small benchmark dataset get nexperimental results comparable the semi deﬁnite programming based solution but much lower computational cost 
9484 en ABC Boost Adaptive Base Class Boost for Multi Class Classiﬁcation propose ABC Boost Adaptive Base Class Boost for multi class classiﬁcation and present ABC MART implementation nABC Boost The original MART Multiple Additive Regression Trees algorithm has been popular certain industry applications nWeb search For binary classiﬁcation ABC MART recovers MART For multi class classiﬁcation ABC MART improves MART nevaluated several public data sets 
9485 en Compositional Noisy Logical Learning describe new method for learning the conditional probability distribution binary valued variable from labelled training nexamples Our proposed Compositional Noisy Logical Learning CNLL approach learns noisy logical distribution compositional nmanner CNLL alternative the well known AdaBoost algorithm which performs coordinate descent alternative error measure nWe describe two CNLL algorithms and test their performance compared AdaBoost two types problem noisy logical data such nas noisy exclusive and four standard datasets from the UCI repository Our results show that outperform AdaBoost while using nsigniﬁcantly fewer weak classiﬁers thereby giving more transparent classiﬁer suitable for knowledge extraction 
9486 en Boosting with Structural Sparsity derive generalizations AdaBoost and related gradient based coordinate descent methods that incorporate sparsity promoting npenalties for the norm the predictor that being learned The end result family coordinate descent algorithms that integrate nforward feature induction and back pruning through regularization and give automatic stopping criterion for feature induction study npenalties based the and ∞ norms the predictor and introduce mixed norm penalties that build upon the initial penalties nThe mixed norm regularizers facilitate structural sparsity parameter space which useful property multiclass prediction and other nrelated tasks report empirical results that demonstrate the power our approach building accurate and structurally sparse models 
9487 en Learning with Structured Sparsity This paper investigates new learning formulation called structured sparsity which natural extension the standard sparsity nconcept statistical learning and compressive sensing allowing arbitrary structures the feature set this concept generalizes the ngroup sparsity idea general theory developed for learning with structured sparsity based the notion coding complexity associated nwith the structure Moreover structured greedy algorithm proposed efﬁciently solve the structured sparsity problem Experiments ndemonstrate the advantage structured sparsity over standard sparsity 
9517 en Acquisition and Understanding Process Knowledge Using Problem Solving Methods the defense his PhD thesis Madrid April 23rd 2009 Jose Manuel talks about process knowledge and how possible enable users without any kind skills model processes and analyze the provenance process executions without the intervention software knowledge engineers Jose Manuel proposes the utilization Problem Solving Methods PSMs key enablers for the accomplishment such objectives and demonstrates the solutions developed evaluated the contexts Project Halo and the Provenance Challenge respectively Jose Manuel concludes the talk with process centric overview the challenges raised the new web driven computing paradigm where large amounts data are contributed and exploited users the web requiring scalable non monotonic reasoning techniques well stimulating collaboration while preserving trust nJose Manuel’ advisors Oscar Corcho Universidad Politécnica Madrid and Richard Benjamins Telefónica were present the defense whose PhD committee comprised the following members Manuel Hermenegildo Universidad Politécnica Madrid Asunción Gómez Pérez Universidad Politécnica Madrid Mark Greaves Vulcan Inc Luc Moreau University Southampton and Bert Bredeweg University Amsterdam 
9518 en Reductions Machine Learning Machine learning reductions are about reusing solutions simple core problems order solve more complex problems basic difficulty applying machine learning practice that often need solve problems that don quite match the problems solved standard machine learning algorithms Reductions are techniques that transform such practical problems into core machine learning problems These can then solved using any existing learning algorithm whose solution can turn used solve the original problem nThe material that plan cover both algorithmic and analytic will discuss existing and new algorithms along with the methodology for analyzing and creating new reductions will also discuss common design flaws folklore reductions our experience this approach effective tool for designing empirically successful automated solutions learning problems 
9519 en Convergence Natural Dynamics Eqilibria Recently lot ort has been devoted analyzing response dynamics various games Questionsnabout the dynamics themselves and their convergence properties attracted great deal attention Thisnincludes for example questions like “How long uncoordinated agents need reach equilibrium ”nand “ uncoordinated agents quickly reach state with low social cost ” important aspect innstudying such dynamics the learning model employed self interested agents these models Studyingnthe ect learning algorithms the convergence rate players crucial for developing solidnunderstanding the corresponding games nIn this tutorial ﬁrst describe overview the required terminology from game theory Then wensurvey results about the convergence myopic and learning based best responses players equilibrianand approximately optimal solutions and study the ect various learning algorithms convergencen rate Throughout the tutorial describe fundamental connections between local search algorithmsnand learning algorithms with the convergence best response dynamics multi agent games 
9520 en Learning with Dependencies between Several Response Variables analyze situations where modeling several response variables for given input improves the prediction accuracy for each individual response variable Interestingly this setting has appeared different context and number different but related approaches have been proposed all these approaches some assumptions about the dependency structure between the response variables made nHere small selection labels describing relevant work nmultitask learning multi class classification multi label prediction hierarchical Bayes inductive transfer learning hierarchical linear models mixed effect models partial least squares canonical correlation analysis maximal covariance regression multivariate regression structured prediction relational learning nThe large number approaches confusing for the novice and often even for the expert this tutorial systematically introduce some the major approaches and describe them from common viewpoint 
9521 en Survey Boosting from Optimization Perspective Boosting has become well known ensemble method The algorithm maintainsna distribution the ± labeled examples and new base learner added angreedy fashion The goal obtain small linear combination base learnersnthat clearly separates the examples focus recent view Boostingnwhere the update algorithm for distribution the examples characterized byna minimization problem that uses relative entropy regularization nThe most well known boosting algorithms AdaBoost This algorithmnapproximately maximizes the hard margin when the data separable Wenfocus recent algorithms that provably maximize the soft margin when thendata noisy will teach the new algorithms give uni and versatilenview Boosting terms relative entropy regularization and show how tonsolve large scale problems based state the art optimization techniques nOur goal motivate people mimic the recent successes the SVMncommunity for scaling the solvable problem size This goal challengingnbecause Boosting the regularization relative entropy more complicatednthan the one used for SVMs squared Euclidean distance Nevertheless cannsolve dense problems with 200K examples less than minute laptop 
9522 en The Neuroscience Reinforcement Learning Overview and goals nnOne the most influential contributions machine learning understanding the human brain the fairly recent formulation learning real world tasks terms the computational framework reinforcement learning This confluence ideas not limited abstract ideas about how trial and error learning should proceed but rather current views regarding the computational roles extremely important brain substances such dopamine and brain areas such the basal ganglia draw heavily from reinforcement learning The results this growing line research stand contribute not only neuroscience and psychology but also machine learning human and animal brains are remarkably adept learning new tasks uncertain dynamic and extremely complex world Understanding how the brain implements reinforcement learning efficiently may suggest similar solutions engineering and artificial intelligent problems This tutorial will present the current state the study neural reinforcement learning with emphasis both what teaches about the brain and what teaches about reinforcement learning nnTarget Audience nThe target audience are researchers working the field reinforcement learning who are interested the current state the art neuroscientific applications this theoretical framework well researchers working related fields machine learning such engineering and robotics Familiarity basic knowledge reinforcement learning MDPs dynamic programming online temporal difference methods will assumed basic knowledge neuroscience psychology will not nnTutorial outline nIntroduction coarse grain overview the brain and what currently know about how worksnLearning and decision making animals and humans this really reinforcement learning problem nDopamine and prediction errors what know about dopamine why think computes temporal difference prediction error and why should care Evidence for the prediction error hypothesis dopaminenActor Critic architectures the basal ganglia distribution functions learning networknSARSA versus learning can dopamine reveal what algorithm the brain actually uses nMultiple learning systems the brain what the evidence for both model based and model free reinforcement learning systems the brain why have more than one system and how arbitrate between themnBeyond phasic dopamine average reward reinforcement learning tonic dopamine and the control response vigornRisk and reinforcement learning can the brain tell something about learning the variance rewards nOpen challenges and future directions what more can reinforcement learning teach about the brain and where can expect the brain teach about reinforcement learning 
9523 en Active Learning Active learning defined contrast the passive model supervised learning where all the labels for learning are obtained without reference the learning algorithm while active learning the learner interactively chooses which data points label The hope active learning that interaction can substantially reduce the number labels required making solving problems via machine learning more practical This hope known valid certain special cases both empirically and theoretically nnVariants active learning have been investigated over several decades and fields The focus this tutorial general techniques which are applicable many problems mathematical level this corresponds approaches with provable guarantees under weakest possible assumptions since real problems are more likely fit algorithms which work under weak assumptions nnWe believe this tutorial should broad interest People working using supervised learning are often confronted with the need for more labels where active learning can help Similarly reinforcement learning generalizing while interacting more complex ways active research topic Please join 
9524 en Modeling Social and Information Networks Opportunities for Machine Learning Emergence the web social media and online social networking websites gave rise detailed traces human social activity This offers many opportunities analyze and model behaviors millions people For example can now study planetary scale dynamics full Microsoft Instant Messenger network 240 million people with more than 255 billion exchanged messages per month nMany types data especially web and social data come form network graph This tutorial will cover several aspects such network data macroscopic properties network data sets statistical models for modeling large scale network structure static and dynamic networks properties and models network structure and evolution the level groups nodes and algorithms for extracting such structures will also present several applications and case studies blogs instant messaging Wikipedia and web search nMachine learning topic will present throughout the tutorial The idea the tutorial introduce the machine learning community recent developments the area social and information networks that underpin the Web and other line media 
9525 en Tutorial Learning Deep Architectures This short tutorial deep learning will review variety methods for learning multi level hierarchical representations emphasizing their common traits While deep architectures have theoretical advantages terms expressive power and efficiency representation they also provide possible model for information processing the mammalian cortex which seems rely representations with multiple levels abstractions number deep learning methods have been proposed since 2005 that have yielded surprisingly good performance several areas particularly vision object recognition and natural language processing They all learn multiple levels representation using some form unsupervised learning Hypotheses explain why these algorithms work well will discussed the light new experimental results Many these algorithms can cast the framework the energy based view unsupervised learning which generalizes graphical models used building blocks for deep architectures such the Restricted Boltzmann Machines RBM and variations regularized auto encoders Old and new algorithms will presented for training sampling and estimating the partition function RBMs and Deep Belief Networks Applications deep architectures computer vision and natural language processing will described number open problems and future research avenues will discussed with active participation from the audience 
9526 en Unsupervised Structure Learning Hierarchical Recursive Composition Suspicious Coincidence and Competitive Exclusion describe new method for unsupervised structure learning hierarchical compositional model HCM for deformable objects The learning unsupervised the sense that are given training data set images containing the object cluttered backgrounds but not know the position boundary the object The structure learning performed bottom and top down process The bottom process novel form hierarchical clustering which recursively composes proposals for simple structures generate proposals for more complex structures combine standard clustering with the suspicious coincidence principle and the competitive exclusion principle prune the number proposals practical number and avoid exponential explosion possible structures The hierarchical clustering stops automatically when fails generate new proposals and outputs proposal for the object model The top down process validates the proposals and fills missing elements tested our approach using learn hierarchical compositional model for parsing and segmenting horses Weizmann dataset show that the resulting model comparable with better than alternative methods The versatility our approach demonstrated learning models for other objects faces pianos butterflies monitors etc worth noting that the low levels the object hierarchies automatically learn generic image features while the higher levels learn object specific features then describe more recent work which uses similar principles learn hierarchies for many objects simultaneously nnThis talk based two research projects The full authors for these projects are Project ECCV 2008 Zhu UCLA Lin Microsoft Beijing Huang Microsoft Beijing Chen USTC and Yuille UCLA Project Zhu MIT Chen USTC Freeman MIT Torrabla MIT and Yuille UCLA 
9527 en Deep Learning via Semi Supervised Embedding show how nonlinear embedding algorithms popular for use with shallow semi supervised learning techniques such kernel methods can applied deep multi layer architectures either regularizer the output layer each layer the architecture This provides simple alternative existing approaches deep learning whilst yielding competitive error rates compared those methods and existing shallow semi supervised techniques nnWe then generalize this approach take advantage sequential data for images and text nnFor images take advantage the temporal coherence that naturally exists unlabeled video recordings That two successive frames are likely contain the same object objects demonstrate the effectiveness this method semi supervised setting some pose invariant object and face recognition tasks nnFor text describe unified approach tagging single convolutional neural network architecture that given sentence outputs host language processing predictions part speech tags chunks named entity tags and semantic roles State the art performance attained learning word embeddings using text specific semi supervised task called language model nnJoint work with Ronan Collobert Frederic Ratle Hossein Mobahi Pavel Kuksa and Koray Kavukcuoglu 
9528 en Convex Sparse Methods for Feature Hierarchies Sparse methods usually deal with the selection few elements from large collection pre computed features While theoretical results suggest that techniques based the norm can deal with exponentially many irrelevant features current algorithms cannot handle more than millions variables this talk will show how structured norms can deal polynomial time with exponentially many features that are organized directed acyclic graph 
9529 en Unsupervised Discovery Structure Succinct Representations and Sparsity describe class unsupervised learning methods that learn sparse representations the training data and thereby identify useful features Further show that deep learning multilayer versions these ideas ones based sparse DBNs learn rich feature hierarchies including part whole decompositions objects Central this the idea probabilistic max pooling which allows implement convolutional DBNs large scale while maintaining probabilistically sound semantics the case images the lowest level this method learns detect edges the next level puts together edges form object parts and finally the highest level puts together object parts form whole object models The features this method learns are useful for wide range tasks including object recognition text classification and audio classification also present the result comparing two layer version the model trained natural images visual cortical areas and the brain the first and second stages visual processing the cortex Finally conclude with discussion some open problems and directions for future research 
9530 en  Factor Model for Learning Higher Order Features Natural Images The visual system hierarchy processing stages Each stage this pathway addition encoding increasingly complex features the input performs complex non linear computations What the functional role these non linear behaviors and how incorporate them into generative models natural images nnA number non linear properties visual neurons can predicted from the statistical dependencies observed natural images For example the magnitudes linear filter outputs are correlated normalizing filter responses removes this correlation making the responses more independent and marginally Gaussian and reproduces neural gain control addition the pattern these correlations itself highly informative and can used infer the context patches sampled from large scene Here will focus these statistical patterns and describe generative model that captures them using set factors the space log covariance multivariate Gaussian distribution Trained natural images the model learns compact code for correlations observed pixel linear feature distributions that represents more abstract properties the image will also connect this work recent generative models that incorporate multiplicative interactions between observed and latent variables 
9531 en Strategies for Prediction under Imperfect Monitoring propose simple randomized strategies for sequential decision prediction under imperfect monitoring that when the decision maker forecaster does not have access the past outcomes but rather feedback signal The proposed strategies are consistent the sense that they achieve asymptotically the best possible average reward among all fixed actions was Rustichini who first proved the existence such consistent predictors The forecasters presented this talk offer the first constructive proof consistency Moreover the proposed algorithms are computationally efficient also establish upper bounds for the rates convergence the case deterministic feedback signals these rates are optimal logarithmic terms Joint work with Shie Mannor and Gilles Stoltz 
9532 en Trading Regret Rate for Computational Efficiency Online Learning with Limited Feedback study low regret algorithms for online learning with limited feedback where there additional constraint the computational power the learner Focusing multi armed bandit with side information demonstrate cases which there trade off between the regret rate and the computational efficiency the online learning algorithm particular for the class linear hypotheses show that the EXP4 prediction strategy achieves the optimal regret but not efficient contrast propose much more efficient strategies still with vanishing regret but worse regret rate 
9536 en Strategic Considerations Bandit Settings The Price Truthfulness Online Auctions Research the intersection machine learning and economics has flourished recent years due the realization that many technological systems such the internet are better understood and managed when they are viewed economic systems rather than just merely technological ones particular there much recent work understanding learning algorithms and models settings where the strategic considerations the participants must taken into account spam detection nThis talk will examine the this broader issue the setting online auctions particular pay per click auctions where advertisers are charged only those rounds when their clicked Designing such auction faces the classic explore exploit dilemma while gathering information about the click through rates advertisers the mechanism may loose revenue however this gleaned information may prove valuable the future for more profitable allocation this sense such mechanisms are prime candidates designed using multi armed bandit techniques However naive application multi armed bandit algorithms would not take into account the strategic considerations the players players might manipulate their bids which determine the auction revenue way maximize their own utility Hence consider the natural restriction that the auction truthful nThis work sharply characterizes what regret achievable under this truthful restriction Interestingly show that this restriction imposes statistical limits the achievable regret that Theta while for traditional bandit algorithms without this truthful restriction the achievable regret where the number rounds term the extra factor the price truthfulness 
9539 en Bandit Algorithms for Online Linear Optimization the online linear optimization problem forecaster chooses each time instance vector from certain given subset the dimensional Euclidean space and suffers time dependent loss that linear The goal the forecaster achieve that the long run the accumulated loss not much larger than that the best possible vector this talk consider the bandit setting the linear optimization problem which the forecaster has only access the losses the chosen vectors survey some recent algorithms that solve this problem For the special case which subset the dimensional Boolean hypercube describe new forecaster whose performance for variety concrete choices better than all previously known bounds and not improvable general also point out that computationally efficient implementations for various interesting choices exist Joint work with Gabor Lugosi Barcelona 
9543 en Piecewise Stationary Bandit Problems with Side Information consider sequential decision problem wherenthe rewards are generated piecewise stationaryndistribution However the different reward distributionsnare unknown and may change unknownninstants Our approach uses limited number ofnside observations past rewards but does not requirenprior knowledge the frequency changes nIn spite the adversarial nature the reward process nwe provide algorithm whose regret withnrespect the baseline with perfect knowledge ofnthe distributions and the changes log nwhere the number changes time nThis contrast the case where side observationsnare not available and where the regret atnleast √ also show that our bound tightnfor natural class algorithms earlier versionnof this work appears YM09 
9545 en Multi Armed Bandits with Betting study extension the stochastic multiarmednbandit problem where the learner has anbudget ofK “coins” can use each round Thenlearner can use the coins play multiple arms inneach round having the option “bet” multiplencoins arm the end the round thenarms generate reward that proportional thenamount coins invested them 
9546 en Forced Exploration Based Algortihms for Playing Stochastic Linear Bandits
9547 en The Offset Tree for Learning with Partial Labels
9550 en One Pass Approximate Means Optimization
9552 en Monte Carlo Sampling for Regret Minimization Extensive Games
9555 en Introduction and General Problem Statement Most machine learning algorithms rely fundamentally concepts numerical mathematics Standard reductions black box computational primitives not usually meet real world demands and have modified all levels The increasing complexity problems requires layered approaches where algorithms are components rather than stand alone tools fitted individually with much human effort this modern context predictable run time and numerical stability behavior algorithms become fundamental Unfortunately these aspects are widely ignored today researchers which limits the applicability algorithms complex problems nBackground and ObjectivesnnOur workshop aims address these shortcomings trying distill compromise between inadequate black box reductions and highly involved complete numerical analysis will invite speakers with interest both numerical methodology and real problems applications close machine learning While numerical software packages interest will pointed out our focus will rather how best bridge the gaps between requirements and these computational libraries subordinate goal will address the role parallel numerical computation Examples machine learning founded numerical methods include low level computer vision and image processing non Gaussian approximate inference Gaussian filtering smoothing state space models approximations kernel methods and many more nImpact and Expected OutcomennWe will call the community attention the increasingly critical issue numerical considerations algorithm design and implementation set essential rules for how use and modify numerical software required for which aim lay the groundwork this workshop These efforts should lead awareness the problems well increased focus efficient and stable implementations will encourage speakers point out useful software packages together with their caveats asking them focus examples interest Raising awareness about the increasing importance stability and predictable run time behaviour numerical machine learning algorithms and primitives Establishing code conduct for how best select and modify existing numerical mathematics code for machine learning problems Learning about developments current numerical mathematics major backbone most machine learning methods 
9556 en Variance Approximation Large Scale Gaussian Markov Random Fields this talk discuss framework for computing accurate approximate variances large scale Gaussian Markov Random Fields start motivating the need compute variances GMRFs and discuss related problems machine learning Our approach based constructing certain low rank aliasing matrix which takes advantage the Markov graph the model first construct such matrix for models with short range correlation and then describe wavelet based construction for models with long range correlation The approach based fast solution sparse linear systems and describe suitable preconditioners also describe how the approach can used for problems with sparse plus low rank structure for example approximate Kalman filtering with large state spaces 
9557 en Statistical Leverage and Improved Matrix Algorithms Given matrix and rank parameter define the leverage the row the diagonal element the projection matrix onto the span the top left singular vectors this case high leverage rows have disproportionately large amount the mass the top singular vectors Historically this statistical concept and generalizations has found extensive applications diagnostic regression analysis Recently this concept has also been central the development improved randomized algorithms for several fundamental matrix problems that have broad applications machine learning and data analysis Two examples the use statistical leverage for improved worst case analysis matrix algorithms will described The first problem the least squares approximation problem which there are constraints and variables Classical algorithms dating back Gauss and Legendre use nd2 time describe randomized algorithm that uses only log time compute relative error epsilon approximation The second problem the problem selecting good set exactly columns from matrix and the algorithm and Eisenstat provides the best previously existing result describe two stage algorithm that improves their result Recent applications statistical leverage ideas modern large scale machine learning and data analysis will also briefly described This concept has proven particularly fruitful large data applications where modeling decisions regarding what computations perform are made for computational reasons opposed having any realistic hope that the statistical assumptions implicit those computations are satisfied the data 
9558 en Matrix Computations Machine Learning Matrix Computations are ubiquitous all areas science and engineering this talk will first survey some traditional problems matrix computations and discuss issues that arise solving them such accuracy algorithms and software Then will discuss various matrix computation problems that arise machine learning especially specialized computations such non negative matrix factorization multilevel graph clustering and kernel learning will conclude with pointer resources and discussion 
9559 en Using Interior Point Methods for Optimization Training Very Large Scale Support Vector Machines this talk shall discuss the issues Interior Point Methods IPMs applied solve optimization problems arising the context very large scale Support Vector Machine SVM training First will briefly introduce IPMs for linear and quadratic programming and comment their advantages polynomial complexity ability solve very large problems excellent practical behaviour much better than that predicted the worst case complexity analysis and eligibility parallelisation will then address specific features optimization problems arising SVM training particular the presence large datasets which are stored dense matrices and make problems very well suited the use IPMs will survey numerical techniques applicable this context such suitable factorization methods and will comment several interesting developments made over the last decade which aimed using IPMs for SVM training will demonstrate that the key success applying IPMs the ability formulate SVM problems separable quadratic optimization ones which then can successfully tackled appropriate linear algebra tools IPMs Finally will comment the existing challenges for IPMs SVM training context and touch number research issues which still remain open particular will discuss need developing new algorithms which may take advantage new multi core architectures challenges problems getting larger and larger and the use non linear and indefinite kernels This joint work with Kristian Woodsend 
9560 en Gaussian Processes and Fast Matrix Vector Multiplies
9561 en The Parallel Machine Learning PML Framework and Numerical Aspects the Transform Regression Algorithm
9562 en GADGET SVM Gossip bAseD sub GradiEnT SVM solver
9563 en Condition Number Analysis Kernel Based Density Ratio Estimation
9566 en Dyna Multi Step Dyna Planning Dyna planning efficient way learningnfrom real and imaginary experience Existingntabular and linear Dyna algorithms arensingle step because imaginary featurenis predicted only one step into the future Innthis paper introduce multi step Dynanplanning that predicts more steps into thenfuture Multi step Dyna able figure outna sequence multi step results when realninstance happens given that the instance itself nor similar experience has been imaginedn simulated from the model andnplanned Our multi step Dyna based anmulti step model which call the model nThe model interpolates between the onestepnmodel and nite step model andncan learned efficiently online The multistepnDyna algorithm Dyna uses the nmodel generate predictions steps aheadnof the imagined feature and applies onnthis imaginary multi step transitioning 
9567 en Manifold Embeddings for Model Based Reinforcement Learning Neurostimulation Policies Real world reinforcement learning problems often exhibit nonlinear continuous valued nnoisy partially observable state spaces that are prohibitively expensive explore Thenformal reinforcement learning framework unfortunately has not been successfully demonstrated real world domain having all these constraints approach this domainnwith two part solution First overcome continuous valued partially observable state spaces constructing manifold embeddings the system’ underlying dynamics whichnsubstitute complete state space representation then define generative modelnover this manifold learn policy off line The model based approach preferred because enables simplification the learning problem domain knowledge this work formally integrate manifold embeddings into the reinforcement learning framework summarize spectral method for estimating embedding parameters and demonstrate the model based approach complex domain adaptive seizure suppression epileptic neural system 
9568 en  Empirical Comparison Abstraction Models Markov Decision Processes Reinforcement learning studies the problem solving sequential decision making problems Model based methods learn effective policy few actions learning model the domain and simulating experience their models Typical model based methods must visit each state least once which can infeasible large domains overcome this problem the model learning algorithm needs generalize knowledge unseen states and provide information about the states which needs more experience this paper use existing supervised learning techniques learn the model the domain empirically compare theirneffectiveness generalizing knowledge across states three different domains Our resultsnindicate that tree based models perform the best after training small number transitions while support vector machines perform the best after large number transitions 
9569 en Basis Function Construction for Hierarchical Reinforcement Learning This paper introduces approach automatic basis function construction for HierarchicalnReinforcement Learning HRL tasks describe some considerations that arisenwhen constructing basis functions for multilevel task hierarchies extend previousnwork using Laplacian bases for value function approximation situations where thenagent provided with multi level action hierarchy experimentally evaluate thesentechniques the Taxi domain 
9570 en Poster Spotlights Situation Dependent Spatial Abstraction Reinforcement Learning Based Structural Knowledge State space abstraction reduces the size representation factoring out details thatnare not relevant for solving task hand But even abstract representations not every detail relevant any situation cases where the structure the environmentnonly allows for one particular action selection all information that does not relate tonthe structure can omitted present method identify such cases reinforcement learning setting and abstract from non structural details when appropriate tonshrink the state space and allow for knowledge reuse significant performance improvement this approach demonstrated goal directed robot navigation task 
9571 en Poster Spotlights Automated Discovery Options Factored Reinforcement Learning Factored Reinforcement Learning FRL method solve Factored Markov Decision Processesnwhen the structure the transition and reward functions the problem must learned nIn this paper present TeXDYNA algorithm that combines the abstraction techniquesnof Semi Markov Decision Processes perform the automatic hierarchical decomposition thenproblem with FRL method The algorithm evaluated the taxi problem 
9572 en Poster Spotlights Hierarchical Skill Learning for High Level Planning present skill bootstrapping proposednnew research direction for agent learning andnplanning that allows agent start withnlow level primitive actions and develop skillsnthat can used for higher level planning nSkills are developed over the course solvingnmany different problems domain nusing reinforcement learning techniques toncomplement the bene fits and disadvantagesnof heuristic search planning describenthe overall architecture the proposed approach ndiscuss how relates other work nand give motivating examples for why thisnapproach would successful 
9573 en Welcome Statment the last years reinforcement learning research has made great strides and has had significant impact within several fields includingnn artificial intelligencen optimal controln neurosciencen psychologyn economicsn operations researchnnThese are diverse areas with different goals and different evaluation criteria striking that reinforcement learning ideas are playing new roles all them The purposes this meeting are recognize and assess this confluence fieldsn celebrate the diversity reinforcement learning researchn exchange information among the fieldsnnMSRL consisted series invited talks and evening poster session Participation the poster session was based extended abstracts nnMSRL was located with cluster other meetings including the International Conference Machine Learning the Conference Uncertainty Artificial Intelligence and the Conference Learning Theory 
9574 en Deconstructing Reinforcement Learning The premise this symposium that the ideas reinforcement learning have impacted many fields including artificial intelligence neuroscience control theory psychology and economics But what are these ideas and which them key the idea reward and reward prediction way structuring the problem facing both natural and artificial systems temporal difference learning sample based algorithm for approximating dynamic programming the idea learning online trial and error searching find way behaving that might not known any human supervisor all these ideas and others all coming renewed prominence and significance these fields focus the common problem that faces animals machines and societies how predict and control hugely complex world that can never understood incompletely but only gross ever changing approximation this talk seek start the process phrasing and answering these questions some cases from own experience can identify which ideas have been the most important and guess which will the future For others can only ask the other speakers and attendees provide informed perspectives from their own fields nnn
9575 en Birdsong Learning Zebra finch are born the spring when they are exposed con specific male song Later the spring the bird begins vocalize and the song gradually converges the tutor song There increasing evidence that birdsong learning occurs through associative reward penalty reinforcement learning 
9576 en Fifty Years Games Many researchers have advocated game domains highly useful testbeds where one can cleanly isolate and study important issues faced and more general methods tackling messy real world problems this talk like survey some the highlights the numerous studies various game domains since Samuel seminal work fifty years ago definition games broad and will include puzzles competitions simulated marketplaces and video online games will also talk about the relationship and differences between traditional single agent and more recent multiagent learning algorithms which are likely necessary general multi player games The goal the talk draw larger perspective what have learned from studying games and where promising future opportunities may lie not only theory advances but games themselves continue evolve with advancing technology 
9577 en Reinforcement Learning Apprenticeship Learning and Robotic Control Reinforcement learning has proved powerful method for robotic control this talk drawing examples from autonomous helicopter flight quadruped robot control and autonomous driving describe some the challenges faced applying algorithms various control problems such Problems where the reward function exceedingly difficult specify hand and must itself learned Safe exploration where one wishes explore without damaging the robot and iii Learning high performance controllers even have only extremely inaccurate model our robot dynamics Using apprenticeship learning which learn watching expert demonstration unifying theme also describe few algorithms for addressing these challenges 
9578 en Third Annual Reinforcement Learning Competition Building last year competition and the benchmarking events that preceded this event will forum for reinforcement learning researchers rigorously compare the performance their methods suite challenging domains The competition finals and workshop will take place during the Multidisciplinary Symposium Reinforcement Learning part the 2009 International Conference Machine Learning ICML Montreal Canada encourage student participation will awarding travel scholarships for student competitors nnIn order encourage even greater participation our technical committee has been working hard lower the bar for entry The competition software easy install and contains sample code that you can get started with minimal effort addition travel scholarships there are number exciting prizes for grabs are also including resources make easy for instructors use the competition software part course Reinforcement Learning Machine Learning Artificial Intelligence http 2009 competition org index php 
9584 en Near Bayesian Exploration Polynomial Time consider the exploration exploitation problem reinforcement learning The Bayesian approach model based offers elegant solution this problem considering distribution over possible models and acting maximize expected reward unfortunately the Bayesian solution intractable for all but very restricted cases this paper present simple algorithm and prove that with high probability able perform epsilon close the true intractable optimal Bayesian policy after some small polynomial quantities describing the system number time steps The algorithm and analysis are motivated the called PAC MDP approach and extend such results into the setting Bayesian this setting show that are able achieve lower sample complexity bounds than existing PAC MDP algorithms while using exploration strategies that are much greedier than the extremely cautious exploration strategies used these existing algorithms 
9588 en Scalable Link Mining and Analysis Information Networks With the ubiquity information networks and their broad applications there have been numerous studies the construction online analytical processing and mining information networks multiple disciplines including social network analysis World Wide Web database systems data mining machine learning and networked communication and information systems Algorithms like PageRank and HITS have been developed late 1990s explore links among Web pages discover authoritative pages and hubs Links have also been popularly used citation analysis and social network analysis However there lack systematic treatment how fully explore the power links scalable data analysis this talk the power links are examined details improve the effectiveness and efficiency typical data analysis tasks including information integration line analytic processing and other interesting data mining tasks especially the multi relational databases and the World Wid Web environments 
9589 en Bottom Search and Transfer Learning SRL This talk addresses two important issues motivated our recent research SRL First the value data driven bottom search learning the structure SRL models Bottom induction has long history traditional ILP however its use SRL has been somewhat limited review recent results several structure learning methods for Markov Logic Networks MLNs that highlight the value bottom search Second the value transfer learning reducing the data and computational demands SRL inducing predicate mapping between seemingly disparate domains effective SRL models can efficiently learned from very small amounts domain training data For example transferring model learned from data about department have induced reasonably accurate models for IMDB movie data given training data about only single person 
9590 en Large Networks Clusters and Kronecker Products Emergence the web and online computing applications gave rich datanon human social activity that can represented form anninteraction graph One the principal challenges then buildnmodels and understanding the structure such large networks Innthis talk will present our work the cluster communitynstructure large networks where clusters are thought sets ofnnodes that are better connected internally than the rest thennetwork find that large networks have very different clusteringnstructure from well studied small social networks and graphs that arenwell embeddable low dimensional structure networks ofnmillions nodes tight clusters exist only very small size scalesnup around 100 nodes while large size scales networks becomesnexpander like this behavior not explained even anqualitative level any the commonly used network generationnmodels will then present network model based Kronecker productsnthat able produce graphs exhibiting network structure similarnto our observations 
9591 en  Tutorial Logic Based Approaches SRL The relations Statistical Relational Learning are often expressed using first order logic leading formalisms which combine both logical and probabilistic representations this talk intend explain the most important consequences adopting logical approach SRL Defining distributions over possible worlds common theme many such approaches Two prominent logic based formalisms Markov logic networks and PRISM programs will used exemplars Although the talk tutorial nature hope make interesting those already familiar with this area 
9592 en First Order Models for Sequential Decision Making this talk will discuss first order models and algorithms for sequential decision making specifically those approaches that admit exact lifted solutions The first emphasis the talk will the insights that underlie these models and algorithms along with potential caveats for their practical application The second emphasis the talk will variety extensions the first order Markov decision process MDP framework such the factored first order MDP and the first order partially observable MDP The third emphasis the talk will the algorithmic tricks the trade that allow the practical application these models this includes useful data structures efficient solution techniques for first order linear programs new techniques for first order variable elimination and practical methods for maintaining compact consistent first order representations without theorem proving 
9593 en Weighted Deduction Abstraction Level for The field has become implementation bound have plenty ideas but increasingly laborious try them out our models become more ambitious and our datasets become larger noisier and more heterogeneous The software engineering burden makes hard start new work hard reuse and combine existing ideas and hard educate our students this talk propose hide many common implementation details behind new level abstraction that are developing Dyna declarative programming language that combines logic programming with functional programming also supports modularity may regarded kind deductive database theorem prover truth maintenance system equation solver will illustrate how Dyna makes easy specify the combinatorial structure typical computations needed natural language processing machine learning and elsewhere Then will sketch implementation strategies and program transformations that can help make these computations fast and memory efficient Finally will suggest that machine learning should used search for the right strategies for program particular workload 
9606 en Measuring Language the Brain Merjenje jezika ganih Attempts understand the relationship between language and the brain have long history Recent theoretical technological methodological and analytic developments have provided with the opportunity look little closer the workings the intact and damaged brain this talk will give overview recent attempts measure brain activity related Language processes One important aspect this endeavour that truly multi disciplinary involving cooperation between linguists psychologists mathematicians geneticists physicists and others This level scientific integration challenging requires flexibility and willingness reconceptualise problems and recognize common interests but returns synergistic results Current best practice neuro linguistic research not only uses the available methods analytic approaches and technologies reveal the neural architecture and processes underpinning language but also use language vehicle probe and extend the limits the methods analytic approaches and technologies will try survey this multi disciplinary landscape addressing three basic questions where what parts the brain are associated with language use when what the time course language processing how what mechanisms support the processing language nnand maybe even little why nZnanstveni namenjen pregledu najnovej poskusov merjenja ganske aktivnosti povezane procesiranjem jezika Podan natan nej pregled trenutne dobre prakse nevrolingvisti nih raziskavah ter uporabe jezika kot ina preizku anje metod analiti nih pristopov tehnologij nevrologiji ter irjenje mej njihovih zmogljivosti Obenem poskusil odgovoriti tri osnovna vpra anja kje – kateri deli ganov povezani rabo jezika kdaj – kak asovni potek jezikovnega procesiranja kako – kateri mehanizmi podpirajo procesiranje jezika 
9608 en  tutorial Deep Learning Complex probabilistic models unlabeled data can created combining simpler models Mixture models are obtained averaging the densities simpler models and products experts are obtained multiplying the densities together and renormalizing far more powerful type combination form composition experts treating the values the latent variables one model the data for learning the next model The first half the tutorial will show how deep belief nets directed generative models with many layers hidden variables can learned one layer time composing simple undirected product expert models that only have one hidden layer will also explain why composing directed models does not work Deep belief nets are trained generative models large unlabeled datasets but once multiple layers features have been created unsupervised learning they can fine tuned give excellent discrimination small labeled datasets The second half the tutorial will describe applications deep belief nets several tasks including object recognition non linear dimensionality reduction document retrieval and the interpretation medical images will also show how the learning procedure for deep belief nets can extended high dimensional time series and hierarchies Conditional Random Fields 
9647 en Electroencephalographic EEG Coherence Study Working Memory Brain Oscillations Different brain areas process various aspects information parallel well segregated way not known how this information integrated into unitary percept action The binding problem one the key problems understanding brain function Synchronized oscillatory activity neurons one possible mechanism the functional integration different communicating brain areas The binding has been well studied the visual system but could also serve mechanism visuomotor integration functional coupling present with other brain processes and behavioural modes perception complex motor behaviour selective attention learning working memory etc Interregional synchronization the electroencephalographic EEG signal can determined EEG coherence analysis the article present research example coherence changes visuomotor task During this task coherence between visual and motor brain areas increased This might reflect functional coupling between those areas but could also influenced other cognitive processes selective attention Coherence analysis suitable for studying integrative brain function Because measures only one the possible mechanisms integration offers promise especially when combined with other electrophysiological and functional imaging methods 
9703 en Structured Prediction for Natural Language Processing This tutorial will discuss the use structured prediction methods from machine learning natural language processing The field NLP has the past two decades come simultaneously rely and challenge the field machine learning Statistical methods now dominate NLP and have moved the field forward substantially opening new possibilities for the exploitation data developing NLP components and applications However formulations NLP problems are often simplified for computational practical convenience the expense system performance This tutorial aims introduce several structured prediction problems from NLP current solutions and challenges that lie ahead Applications NLP are mainstay ICML conferences many researchers view NLP primary secondary application area interest This tutorial will help the broader community understand this important application area how progress measured and the trade offs that make challenge 
9705 en Networking Genes And Drugs Understanding Gene Function And Drug Mode Action From Large Scale Experimental Data cell can described synergistic ensemble biological entities mRNA proteins ncRNA metabolites etc interacting with each other whose collective behaviour causes the observed phenotypes great research effort ongoing identifying and mapping the network interactions among biomolecules mammalian species nThe idea harnessing this network understand human diseases the molecular level and possibly find suitable drugs for their treatment fascinating but still unfulfilled nWe will show how possible harness experimental data human cells and tissue identify the gene regulatory networks among tens thousands genes and how use this information analyse the modular structure the cell and predict the function each gene Moreover will show how using these data also possible identify suitable drug combination drugs that can restore the physiological behaviour the affected pathways human diseases 
9706 en Predicting the Functions Proteins PPI Networks from Global Information
9707 en Integrated Network Construction Using Event Based Text Mining
9708 en Quantitative Microscopy Bridge Between Wet Biology and Computer Science Quantification experimental evidence important aspect modern life science microscopy this causes shift from pure presentation supporting cases toward the quantification the processes under study Computer image processing breaks through the light microcopy diffraction limit allows track individual molecules the life specimen quantify distribution and localization compartment markers etc The quantified experimental data forms basis for the models the biological processes Quality predictive models crucially dependent the accuracy the quantified experimental data The quality experimental data function algorithms well the imperfections the wet experiment The number research papers devoted the algorithms microcopy image analysis segmentation classification and tracking has grown very fast the last two decades The analysis the source noise wet biology and microscopy has gotten less attention this talk will focus the correction experimental data before applying analysis algorithms These corrections have two faces They are obligatory compensate for imperfections wet microscopy while the same time this correction can break some assumptions which form the basis algorithms for subsequent analysis The examples the different approaches for pre and post correction will presented 
9709 en  Utility Gene Set Signatures Gene Expression Based Class Prediction
9710 en Evaluation Method For Feature Rankings And Their Aggregations For Biomarker Discovery
9711 en Matching Models Data Modelling Morphogen Diffusion
9712 en Evaluation Signaling Cascades Based The Weights From Microarray And ChIP seq Data
9713 en Synthetic Biology Achievements And Future Prospects Synthetic biology which combines engineering approach biological systems getting strong momentum due the recent technological advances which allow manipulate the genetic information unprecedented scale nCurrently synthetic biology exploiting its potentials and advantages but also bottlenecks will review some success stories synthetic biology different field applications such medicine energy and materials Medical applications synthetic biology are some the most promising areas synthetic biology particularly for the alternative methods drug production biosensors and also different therapeutic applications Recent developments our understanding cellular signaling and host pathogen interactions provide the opportunity for new types medical intervention where can utilize parts the existing reengineer signaling responses connected various pathological conditions Knowledge the ways that microbes use avoid the human immune response allows devise approach bypass those microbial strategies nWe will look three different applications synthetic biology which involve reengineering cell signaling pathways which have prepared for the international genetically engineered machines competition years 2006 2008 have designed and demonstrated proof the concept antiviral detection and defense system based essential viral functions that independent mutations and synthetic vaccine that activates both innate and adaptive immune response 
9714 en Machine Learning Methods For Protein Analyses Computational biologists and biologists more generally spend lot time trying more fully characterize proteins this talk will describe several our recent efforts use machine learning methods gain better understanding proteins First tackle one the oldest problems computational biology the recognition distant evolutionary relationships among protein sequences show that exploiting global protein similarity network coupled with latent space embedding can detect remote protein homologs more accurately than state the art methods such PSI BLAST and HHPred Second use machine learning methods improve our ability identify proteins complex biological samples the basis shotgun proteomics data will describe two quite different approaches this problem one generative and one discriminative 
9715 en  Comparison AUC Estimators Small Sample Studies
9716 en Accuracy Rejection Curves ARCs For Comparison Classification Methods With Reject Option
9717 en Metadata For Systems Biology The ease with which modern computational and theoretical tools can applied modeling has led exponential increase the size and complexity computational models biology the same time the accelerating pace progress also highlights limitations current approaches modeling One these limitations the insufficient degree which the semantics and qualitative behaviour models are systematised and expressed formally enough support unambiguous interpretation software systems result human intervention required interpret and connect model mathematical structures with information about the its meaning semantics Often this critical information usually communicated through free text descriptions non standard annotations however free text descriptions cannot easily interpreted current modeling tools nWe will describe three efforts standardize the encoding missing semantics for kinetic models The overall approach involves connecting model elements common external sources information that can extended existing knowledge expanded and refined These external sources are carefully managed public free consensus ontologies the Systems Biology Ontology SBO the Kinetic Simulation Algorithm Ontology KiSAO and the Terminology for the Description Dynamics TeDDy Together they provide means for annotating model with stable and perennial identifiers which reference machine readable regulated terms defining the semantics the three facets the modeling process the relationship between the model and the biology aims describe the process used simulate the model and obtain expected results and the results themselves 
9718 en Hierarchical Cost Sensitive Algorithms For Genome Wide Gene Function Prediction
9719 en Simple Ensemble Methods Are Competitive With State The Art Data Integration Methods For Gene Function Prediction
9720 en  Subgroup Discovery Approach For Relating Chemical Structure And Phenotype Data Chemical Genomics
9721 en Evaluation Methods Gene Association Studies Yet Another Case For Bayesian Networks
9722 en Automating Science The basis science the hypothetico deductive method and the recording experiments sufficient detail enable reproducibility report the development the Robot Scientist Adam which advances the automation both Adam has autonomously generated functional genomics hypotheses about the yeast Saccharomyces cerevisiae and experimentally tested these hypotheses using laboratory automation have confirmed Adam conclusions through manual experiments describe Adam research have developed ontology and logical language The resulting formalization involves over 000 different research units nested tree like structure ten levelsdeep that relates the million biomass measurements their logical description This formalization describes how machine discovered new scientific knowledge Describing scientific investigations this way opens new opportunities apply machine learning and data mining discover new knowledge 
9758 en Bayesian Frequentist Which Are You 
9760 en Towards Simulation based Communication Tool Support Semantic Business Process Management Successfully communicating Business Executive’ goals andndesires Architect with regard organizational change presents majornchallenge The most significant problem relating the changes desired ansemantically consistent and understandable manner and then reflecting thenpotential impact those changes the organizational structure and thenbusiness processes carried out within that organization This paper presents anproposal for simulation based communication tool that employs ansemantically driven natural language component capture BusinessnExecutive’ needs These needs are translated into simulation businessnprocess consisting semantic web services that represent the evolution thenorganizations infrastructure and policies Through iterativencommunication loop with the Architect the simulation can used tonaccurately represent the changes necessary meet the Business Executive’snneeds 
9761 en Contextualized Ontology Based Similarity the Human Resources Domain Business Use Case are currently devoloping integrated business applicationnplatform named Corinna3 where the long term goal combinenSemantic Web technologies with Natural Language Processing NLP tonincrease the efficiency the enterprise search process nIn this paper consider one the Corinna use cases namely thenHuman Resource use case which has already reached prototypenimplementation While NLP used for automatic categorizationnof unstructured resource ontologies represent these resources antaxonomical way with arbitrary properties top the resource ontologiesnwe use both the NLP for the information extraction well asnontology based similarity order get more acceptable similar searchnresults Our implemented approach contextualized hybrid similaritynsearch within the Corinna platform derives strongly from the definednbusiness use cases combines and extends existing similarity measuresnunder consideration additional context information 
9762 en Quest for Superconductivity Compounds Divalent Silver Years after the Prediction Fluorine the most electronegative among all chemical bond–forming elements Because this the vast majority binary and higher inorganic fluorides are high–melting large–band gap electronic insulators which are transparent the visible region the electromagnetic spectrum Rare examples metallic fluorides are known but valence orbitals marginally participate the electronic transport these compounds this account describe recent theory–driven attempts turn family fluorides into novel class high–temperature superconductors Substantial mixing ’ orbitals and metal valence functions ‘covalence’ well partial band occupation are needed generate band crossing judged responsible for unusually strong vibronic coupling and for the appearance superconductivity This precondition satisfied for unusual fluorides divalent silver – fluoroargentates These fascinating materials share lots common features with oxides Unfortunately all known layered fluorides silver the unpaired electrons silver order ferromagnetically This contrast antiferromagnetic ordering observed for undoped oxocuprates this account attempts will described crystal engineering fluoroargentates which target layered antiferromagnetic precursor superconductor 
9769 en How InJo Topic Placed Globally The Overview InJo Practice the World
9772 en Innovation Slovenian Media Findings and Recommendations from the Slovenian Jury InJo Award from 2006 2009
9778 en Presentation the Slovene Scholarship for Innovation Journalism Fellowship Program University Stanford 2010
9779 en Experience from Innovation Journalism Fellowship Program
9780 en How Gain the Right Knowledge for Efficient Reporting Innovation
9781 en Introduction New Media Business Models
9782 en Story SamaaTV Check the YouTube video mentioned the presentation http www youtube com watch jehP0BOeBJI here 
9783 en BBC Innovative Media Enterprise Check the video mentioned the presentation http gallery com hgyr 100005 here 
9785 en What Can Learn from the New Media Business Model 
9804 en Learning Herd and Herding Learn Learning the traditional sense focuses finding point estimate for the parameters its model Bayesian approaches extend this posterior distributions but are computationally intractable for Markov random fields and inference can easily get trapped local modes third possibility define dynamical system herding that mixes very efficiently over attractor set and where each point this set defines energy function over some state space The collection all these energy minima represent sample collection that shares certain moment statistics with the input data will briefly introduce this system and present very preliminary ideas the following issues Can learn hyper parameters for herding that can run with the data decoupled from Which herding systems should considered equivalent and what are the implications for the use fast weights learning Among all non equivalent herding systems that reproduce the same moment constraints can learn the one that performs optimal terms generalization Can characterize the attractor set herding and its dynamics chaotic How useful can herding for producing deep representations 
9829 en Considering Unseen States Impossible Factored Reinforcement Learning The Factored Markov Decision Process FMDP framework standard representation for sequential decision problems under uncertainty where the state represented collection random variables Factored Reinforcement Learning FRL Model based Reinforcement Learning approach FMDPs where the transition and reward unctions the problem are learned this paper show how model theoretically well founded way the problems where some combinations state variable values may not occur giving rise impossible states Furthermore propose new heuristics that considers impossible the states that have not been seen far derive algorithm whose improvement performance with respect the standard approach illustrated through benchmark experiments 
9830 en  Convex Method for Locating Regions Interest with Multi Instance Learning content based image retrieval CBIR and image screening often desirable automatically locate the regions interest ROI the images This can accomplished with multi instance learning techniques treating each image bag instances regions Many SVM based methods are successful predicting the bag label However very few them can locate the ROIs and often they are based either the local search type strategy which may get stuck local minima address this problem propose this paper two convex optimization methods which maximize the margin concepts via key instance generation the instance level and bag level respectively Moreover this can efficiently solved with cutting plane algorithm Experiments show that the proposed methods can effectively locate ROIs Moreover the benchmark data sets they achieve performance that are competitive with state the art algorithms 
9831 en Efficient Decoding Ternary Error Correcting Output Codes for Multiclass Classification present adaptive decoding algorithm for ternary ECOC matrices which reduces the number needed classifier evaluations for multiclass classification The resulting predictions are guaranteed equivalent with the original decoding strategy except for ambiguous final predictions The technique works for Hamming Decoding and several commonly used alternative decoding strategies show its effectiveness extensive empirical evaluation considering various code design types Nearly all cases considerable reduction possible also show that the performance gain depends the sparsity and the dimension the ECOC coding matrix 
9832 en Simulated Iterative Classification new Learning Procedure for Graph Labeling Collective classification refers the classification interlinked and relational objects described nodes graph The Iterative Classification Algorithm ICA simple efficient and widely used method solve this problem representative family methods for which inference proceeds iterative process each step nodes the graph are classified according the current predicted labels their neighbors show that learning this class models suffers from training bias propose new family methods called Simulated ICA which helps reducing this training bias simulating inference during learning Several variants the method are introduced They are both simple efficient and scale well Experiments performed series datasets show that the proposed methods outperform representative state the art algorithms while keeping low complexity 
9833 en Combining Instance Based Learning and Logistic Regression for Multi Label Classification Multilabel classification extension conventional classification innwhich single instance can associated with multiple labels Recentnresearch has shown that just like for conventional classification instance based learning algorithms relying the nearest neighbor estimation principle can used quite successfully this context However since hitherto existing algorithms not take correlations and interdependencies between labels into account their potential has not yet been fully exploited this paper propose new approach multilabel classification which based framework that unifies instance based learning and logistic regression comprising both methods special cases This approach allows one capture interdependencies between labels and moreover combine model based and similarity based inference for multilabel classification will shown experimental studies our approach able improve predictive accuracy terms several evaluation criteria for multilabel prediction 
9834 en Within Network Classification Using Local Structure Similarity Within network classification where the goal classify the nodes partly labeled network semi supervised learning problem that has applications several important domains like image processing the classification documents and the detection malicious activities While most methods for this problem infer the missing labels collectively based the hypothesis that linked nearby nodes are likely have the same labels there are many types networks for which this assumption fails molecular graphs trading networks etc this paper present collective classification method based relaxation labeling that classifies entities network using their local structure This method uses marginalized similarity kernel that compares the local structure two nodes with random walks the network Through experimentation different datasets show our method more accurate than several state the art approaches for this problem 
9835 en Learning Preferences with Hidden Common Cause Relations Gaussian processes have successfully been used learn preferences among entities they provide nonparametric Bayesian approaches for model selection and probabilistic inference For many entities encountered real world applications however there are complex relations between them this paper present preference model which incorporates information relations among entities Specifically propose probabilistic relational kernel model for preference learning based Silva ’ mixed graph Gaussian processes new prior distribution enhanced with relational graph kernels proposed capture the correlations between preferences Empirical analysis the LETOR datasets demonstrates that relational information can improve the performance preference learning 
9836 en  Regularization Framework for Optimal Rule Combination this paper regularization introduced into relational learning produce sparse rule combination other words few possible rules are contained the final rule set Furthermore design rule complexity penalty encourage rules with fewer literals The resulted optimization problem has formulated infinite dimensional space horn clauses associated with their corresponding complexity mathcal proved that locally optimal rule generated each iteration the final obtained rule set will globally optimal The proposed meta algorithm applicable any single rule generator bring forward two algorithms namely ell FOIL and ell Progol Empirical analysis carried ten real world tasks from bioinformatics and cheminformatics The results demonstrate that our approach offers competitive prediction accuracy while the interpretability straightforward 
9838 en Enhancing the Performance Centroid Classifier ECOC and Model Refinement With the aim improving the performance centroid text classifier attempt make use the advantages Error Correcting Output Codes ECOC strategy The framework decompose one multi class problem into multiple binary problems and then learn the individual binary classification problems centroid classifier However this kind decomposition incurs considerable bias for centroid classifier which results noticeable degradation performance for centroid classifier order address this issue use Model Refinement strategy adjust this called bias The basic idea take advantage misclassified examples the training datanto iteratively refine and adjust the centroids text data The experimental results reveal that Model Refinement strategy can dramatically decrease the bias introduced ECOC and the combined classifier comparable even better than SVM classifier performance 
9839 en PLSI The True Fisher Kernel and Beyond The Probabilistic Latent Semantic Indexing model introduced Hofmann 1999 has engendered applications numerous fields notably document classification and information retrieval this context the Fisher kernel was found appropriate document similarity measure However the kernels published far contain unjustified features some which hinder their performances Furthermore PLSI not generative for unknown documents shortcoming usually remedied ”folding them ” the PLSI parameter space This paper contributes both points introducing new rigorous development the Fisher kernel for PLSI addressing the role the Fisher Information Matrix and uncovering its relation the kernels proposed far and proposing novel and theoretically sound document similarity which avoids the problem ”folding ” unknown documents For both aspects experimental results are provided several information retrieval evaluation sets 
9840 en Dependency Tree Kernels for Relation Extraction from Natural Language Text The automatic extraction relations from unstructured natural text challenging but offers practical solutions for many problems like automatic text understanding and semantic retrieval Relation extraction can formulated classification problem using support vector machines and kernels for structured data that may include parse trees account for syntactic structure this paper present new tree kernels over dependency parse trees automatically generated from natural language text Experiments public benchmark data set show that our kernels with richer structural features significantly outperform all published approaches for kernel based relation extraction from dependency trees addition optimize kernel computations improve the actual runtime compared previous solutions 
9841 en The Sensitivity Latent Dirichlet Allocation for Information Retrieval has been shown that the use topic models for Information retrieval provides increase precision when used the appropriate form Latent Dirichlet Allocation LDA generative topic model that allows model documents using Dirichlet prior Using this topic model are able obtain fitted Dirichlet parameter that provides the maximum likelihood for the document set this article examine the sensitivity LDA with respect the Dirichlet parameter when used for Information retrieval compare the topic model computation times storage requirements and retrieval precision fitted LDA LDA with uniform Dirichlet prior The results show there there significant benefit using fitted LDA over the LDA with constant Dirichlet parameter hence showing that LDA insensitive with respect the Dirichlet parameter when used for Information retrieval 
9842 en Protein Identification from Tandem Mass Spectra with Probabilistic Language Modeling This paper presents interdisciplinary investigation statistical information retrieval techniques for protein identification from tandem mass spectra challenging problem proteomic data analysis formulate the task problem constructing “query vector” whose elements are system predicted peptides with confidence scores based spectrum analysis the input sample and defining the vector space “documents” with protein profiles each which constructed based the theoretical spectrum protein This formulation establishes new connection from the protein identification problem probabilistic language modeling approach well the vector space models and enables compare fundamental differences the models and common approaches protein identification Our experiments benchmark spectrometry query sets and large protein databases demonstrate that the models significantly outperform well established methods protein identification enhancing precision high recall regions particular where the conventional approaches are weak 
9843 en One Graph Worth Thousand Logs Uncovering Hidden Structures Massive System Event Logs this paper describe our work pattern discovery system event logs For discovering the patterns developed two novel algorithms The first sequential and efficient text clustering algorithm which automatically discovers the templates generating the messages The second the PARIS algorithm Principle Atom Recognition Sets novel algorithm which discovers patterns messages that represent processes occurring the system demonstrate the usefulness our analysis real world logs from various systems for debugging complex systems efficient search and visualization logs and characterization system behavior 
9844 en Leveraging Higher Order Dependencies Between Features for Text Classification Traditional machine learning methods only consider relationships between feature values within individual data instances while disregarding the dependencies that link features across instances this work develop general approach supervised learning leveraging higher order dependencies between features introduce novel Bayesian framework for classification named Higher Order Naive Bayes HONB Unlike approaches that assume data instances are independent HONB leverages occurrence relations between feature values across different instances Additionally generalize our framework developing novel data driven space transformation that allows any classifier operating vector spaces take advantage these higher order occurrence relations Results obtained several benchmarkntext corpora demonstrate that higher order approaches achieve significant improvements classification accuracy over the baseline first order methods 
9845 en Mining Peculiar Compositions Frequent Substrings from Sparse Text Data Using Background Texts consider mining unusual patterns from text Unlike existing methods which assume probabilistic models and use simple estimation methods employ set background text addition and compositions and patterns string peculiar there exist and such that each and more frequent than and conversely more frequent The frequency very small since and are infrequent but relatively abundant compared Despite these complex conditions for peculiar compositions develop fast algorithm find peculiar compositions using the suffix tree Experiments using DNA sequences show scalability our algorithm due our pruning techniques and the superiority the concept the peculiar composition 
9846 en Learning Disambiguate Search Queries from Short Sessions Web searches tend short and ambiguous therefore not surprising that Web query disambiguation actively researched topic provide personalized experience for user most existing work relies search engine log data which the search activities that particular user well other users are recorded over long periods time Such approaches may raise privacy concerns and may difficult implement for pragmatic reasons present approach Web query disambiguation that bases its predictions only short glimpse user search activity captured brief session previous searches average Our method exploits the relations the current search session previous similarly short sessions other users order predict the user’ intentions and based Markov logic statistical relational learning model that has been successfully applied challenging language problems the past present empirical results that demonstrate the effectiveness our proposed approach data collected from commercial general purpose search engine 
9847 en Topic Significance Ranking LDA Generative Models Topic models like Latent Dirichlet Allocation LDA have been recently used automatically generate text corpora topics and subdivide the corpus words among those topics However not all the estimated topics are equal importance correspond genuine themes the domain Some the topics can collection irrelevant words represent insignificant themes Current approaches topic modeling perform manual examination find meaningful topics This paper presents the first automated unsupervised analysis LDA models identify junk topics from legitimate ones and rank the topic significance Basically the distance between topic distribution and three definitions “junk distributions” computed using variety measures from which expressive figure the topic significance implemented using phase Weighted Combination approach Our experiments synthetic and benchmark datasets show the effectiveness the proposed approach ranking the topic significance 
9848 en Identifying the Original Contribution Document via Language Modeling One major goal text mining provide automatic methods help humans grasp the key ideas ever increasing text corpora this effect propose statistically well founded method for identifying the original ideas that document contributes corpus focusing self referential diachronic corpora such research publications blogs email and news articles Our statistical model passage impact defines interesting original content through combination impact and novelty and the model used identify each document’ most original passages Unlike heuristic approaches the statistical model extensible and open analysis evaluate the approach both synthetic data and real data the domains research publications and news showing that the passage impact model outperforms heuristic baseline method 
9856 en Discovering Patterns Flows Privacy Preserving Approach with the ACSM
9857 en Enhanced Web Page Content Visualization with Firefox
9858 en Semi Automatic Categorization Videos VideoLectures net Visual OntoBridge Semi Automatic Semantic Annotation Software
9860 en TeleComVis Exploring Temporal Communities Telecom Networks
9861 en OTTHO the Tip Thought
9863 en Omiotis Thesaurus based Measure Text Relatedness WEB 
9864 en Protecting Sensitive Topics Text Documents with PROTEXTOR
9865 en  Community Based Platform for Machine Learning Experimentation
9866 en  Flexible and Efficient Algorithm for Regularized Fisher Discriminant Analysis Fisher linear discriminant analysis LDA and its kernel extension—kernel discriminant analysis KDA —are well known methods that consider dimensionality reduction and classification jointly While widely deployed practical problems there are still unresolved issues surrounding their efficient implementation and their relationship with least mean squared error procedures this paper address these issues within the framework regularized estimation Our approach leads flexible and efficient implementation LDA well KDA also uncover general relationship between regularized discriminant analysis and ridge regression This relationship yields variations conventional LDA based the pseudoinverse and direct equivalence ordinary least squares estimator Experimental results collection benchmark data sets demonstrate the effectiveness our approach 
9867 en Syntactic Structural Kernels for Natural Language Interfaces Databases core problem data mining retrieve data easy and human friendly way Automatically translating natural language questions into SQL queries would allow for the design effective and useful database systems from user viewpoint Interesting previous work has been focused the use machine learning algorithms for automatically mapping natural language questions SQL queries this paper present many structural kernels and their combinations for inducing the relational semantics between pairs questions and SQL queries measure the effectiveness such kernels using them Support Vector Machines select the queries that correctly answer questions Experimental results two different datasets show that our approach viable and that syntactic information under the form pairs ofnsyntactic tree fragments from queries and questions plays major role deriving the relational semantics between the two languages nnn
9868 en Kernels for Periodic Time Series Arising Astronomy present method for applying machine learning algorithms the automatic classification astronomy star surveys using time series star brightness Currently such classification requires large amount domain expert time show that combination phase invariant similarity and explicit features extracted from the time series provide domain expert level classification facilitate this application investigate the cross correlation general phase invariant similarity function for time series establish several theoretical properties cross correlation showing that intuitively appealing and algorithmically tractable but not positive semidefinite and therefore not generally applicable with kernel methods solution introduce positive semidefinite similarity function with the same intuitive appeal cross correlation experimental evaluation the astronomy domain well several other data sets demonstrates the performance the kernel and related similarity functions 
9869 en Kernel Based Copula Processes Kernel based Copula Processes KCPs new versatile tool for analyzing multiple time series are proposed here unifying framework model the interdependency across multiple time series and the long range dependency within individual time series KCPs build the celebrated theory copula which allows for the modeling complex interdependence structure while leveraging the power kernel methods for efficient learning and parsimonious model specification Specifically KCPs can viewed generalization the Gaussian processes enabling non Gaussian predictions made Such non Gaussian features are extremely important variety application areas one application consider temperature series from weather stations across the Not only are KCPs found have modeled the heteroskedasticity the individual temperature changes well the KCPs also successfully discovered the interdependencies among different stations Such results are beneficial for weather derivatives trading and risk management for example 
9870 en Parameter Free Hierarchical Clustering Ary Splits Clustering high dimensional data challenging Classic metrics fail identifying real similarities between objects Moreover the huge number features makes the cluster interpretation hard tackle these problems several clustering approaches have been proposed which try compute partition objects and partition features simultaneously Unfortunately these approaches identify only predefined number flat clusters Instead useful the clusters are arranged hierarchical fashion because the hierarchy provides insides the clusters this paper propose novel hierarchical clustering which builds two coupled hierarchies one the objects and one features thus providing insights both them Our approach does not require pre specified number clusters and produces compact hierarchies because makes ary splits where automatically determined validate our approach several high dimensional datasets with state the art competitors 
9871 en  Matrix Factorization Approach for Integrating Multiple Data Views many domains there will exist different representations “views” describing the same set objects Taken alone these views will often deficient incomplete Therefore key problem for exploratory data analysis the integration multiple views discover the underlying structures domain This problem made more difficult when disagreement exists between views introduce new unsupervised algorithm for combining information from related views using “late integration” strategy Combination performed applying approach based matrix factorization group related clusters produced individual views This yields projection the original clusters the form new set “meta clusters” covering the entire domain also provide novel model selection strategy for identifying the correct number meta clusters Evaluations performed number multi view text clustering problems demonstrate the effectiveness the algorithm 
9873 en MACs Multi Attribute Clusters with High Correlation Information many real world applications that analyze correlations between two groups diverse entities each group entities can characterized multiple attributes such there need cluster multiple attributes’ values into pairs highly correlated clusters denote this clustering problem the multi attribute clustering problem this paper introduce generalization the mutual information between two attributes into mutual information between two attribute sets The generalized formula enables use correlation information discover multi attribute clusters MACs develop novel algorithm MACminer mine MACs with high correlation information from datasets demonstrate the mining efficiency MACminer datasets with multiple attributes and show that MACs with high correlation information have higher classification and predictive power compared MACs generated alternative high dimensional data clustering and pattern mining techniques 
9874 en Integrating Logical Reasoning and Probabilistic Chain Graphs Probabilistic logics have attracted great deal attention during the past few years While logical languages have taken central position research knowledge representation and automated reasoning probabilistic graphical models with their probabilistic basis have taken similar position when comes reasoning with uncertainty The formalism chain graphs increasingly seen natural probabilistic graphical formalism generalises both Bayesian networks and Markov networks and has semantics which allows any Bayesian network have unique graphical representation the same time chain graphs not support modelling and learning relational aspects domain this paper new probabilistic logic chain logic developed along the lines probabilistic Horn logic The logic leads relational models domains which associational and causal knowledge are relevant and where probabilistic parameters can learned from data 
9875 en Relevance Grounding for Planning Relational Domains Probabilistic relational models are efficient way learn and represent the dynamics realistic environments consisting many objects Autonomous intelligent agents that ground this representation for all objects need plan exponentially large state spaces and large sets stochastic actions key insight for computational efficiency that successful planning typically involves only small subset relevant objects this paper introduce probabilistic model represent planning with subsets objects and provide definition object relevance Our definition sufficient prove consistency between repeated planning partially grounded models restricted relevant objects and planning the fully grounded model propose algorithm that exploits object relevance plan efficiently complex domains Empirical results simulated blocksworld with articulated manipulator and realistic physics prove the effectiveness our approach 
9876 en  Structured Output Training Hard Cases and Efficient Alternative consider class structured prediction problems for which the assumptions made state the art algorithms fail deal with exponentially sized output sets these algorithms assume for instance that the best output for given input can found efficiently While this holds for many important real world problems there are also many relevant and seemingly simple problems where these assumptions not hold this paper consider route prediction which the problem finding cyclic permutation some points interest example and show that state the art approaches cannot guarantee polynomial runtime for this output set then present novel formulation the learning problem that can trained efficiently whenever particular ’super structure counting’ problem can solved efficiently for the output set also list several output sets for which this assumption holds and report experimental results 
9877 en Applying Electromagnetic Field Theory Concepts Clustering with Constraints This work shows how concepts from the electromagnetic field theory can efficiently used clustering with constraints The proposed framework transforms vector data into fully connected graph just works straight the given graph data User constraints are represented electromagnetic fields that affect the weight the graph’ edges clustering algorithm then applied the adjusted graph using distinct shortest paths the distance measure Our framework provides better accuracy compared MPCK Means Kernel KMeans and KMeans Diagonal Metric even when very few constraints are used significantly improves clustering performance some datasets that other methods fail partition successfully and can cluster both vector and graph datasets All these advantages are demonstrated through thorough experimental evaluation 
9878 en Max Margin Weight Learning for Markov Logic Networks Markov logic networks MLNs are expressive representation for statistical relational learning that generalizes both first order logic and graphical models Existing discriminative weight learning methods for MLNs all try learn weights that optimize the Conditional Log Likelihood CLL the training examples this work present new discriminative weight learning method for MLNs based max margin framework This results new model Max Margin Markov Logic Networks M3LNs that combines the expressiveness MLNs with the predictive accuracy structural Support Vector Machines SVMs train the proposed model design new approximation algorithm for loss augmented inference MLNs based Linear Programming The experimental result shows that the proposed approach generally achieves higher scores than the current best discriminative weight learner for MLNs 
9879 en Adaptive XML Tree Classification Evolving Data Streams propose new method classify patterns using closed and maximal frequent patterns features Generally classification requires previous mapping from the patterns classify vectors features and frequent patterns have been used features the past Closed patterns maintain the same information frequent patterns using less space and maximal patterns maintain approximate information use them reduce the number classification features present new framework for XML tree stream classification For the first component our classification framework use closed tree mining algorithms for evolving data streams For the second component use state the art classification methods for data streams the best our knowledge this the first work tree classification streaming data varying with time give first experimental evaluation the proposed classification method 
9880 en Integrating Novel Class Detection with Classification for Concept Drifting Data Streams typical data stream classification task assumed that the total number classes are fixed This assumption may not valid real streaming environment where new classes may evolve Traditional data stream classification techniques are not capable recognizing novel class instances until the appearance the novel class manually identified and labeled instances that class are presented the learning algorithm for training The problem becomes more challenging the presence concept drift when the underlying data distribution changes over time propose novel and efficient technique that can automatically detect the emergence novel class the presence concept drift quantifying cohesion among unlabeled test instances and separation the test instances from training instances Our approach non parametric meaning does not assume any underlying distributions data Comparison with the state the art stream classification techniques prove the superiority our approach 
9881 en Harnessing the Strengths Anytime Algorithms for Constant Data Streams Anytime algorithms have been proposed for many different applications data mining Their strengths are the ability first provide result after very short initialization and second improve their result with additional time Therefore anytime algorithms have far been used when the available processing time varies varying data streams this paper propose employ anytime algorithms constant data streams for tasks with constant time allowance introduce two approaches that harness the strengths anytime algorithms constant data streams and thereby improve the over all quality the result with respect the corresponding budget algorithm derive formulas for the expected performance gain and demonstrate the effectiveness our novel approaches using existing anytime algorithms benchmark data sets The goal that was set and reached this paper improve the quality the result over that traditional budget approaches which are used annabundance stream mining applications Using anytime classification annexample application show for SVM Bayes and nearest neighbor classifiers that both our novel approaches improve the classification accuracy for slow and fast data streams The results confirm our general theoretic models and show the effectiveness our approaches The simple yet effective idea can employed for any anytime algorithm along with quality measure and motivates further research classification confidence measures anytime algorithms 
9882 en  Directional Joint Inference for Entity Resolution and Segmentation Using Imperatively Defined Factor Graphs There has been growing interest using joint inference across multiple subtasks mechanism for avoiding the cascading accumulation errors traditional pipelines Several recent papers demonstrate joint inference between the segmentation entity mentions and their duplication however they have various weaknesses inference information flows only one direction the number uncertain hypotheses severely limited the subtasks are only loosely coupled This paper presents highly coupled directional approach joint inference based efficient Markov chain Monte Carlo sampling relational conditional random field The model specified with our new probabilistic programming language that leverages imperative constructs define factor graph structure and operation Experimental results show that our approach provides dramatic reduction error while also running faster than the previous state the art system 
9883 en Variational Graph Embedding for Globally and Locally Consistent Feature Extraction Existing feature extraction methods explore either global statistical local geometric information underlying the data this paper propose general framework learn features that account for both types information based variational optimization nonparametric learning criteria Using mutual information and Bayes error rate example criteria show that high quality features can learned from variational graph embedding procedure which solved through iterative stylenalgorithm where the Step learns variational affinity graph and the Step turn embeds this graph spectral analysis The resulting feature learner has several appealing properties such maximum discrimination maximum relevance minimum redundancy and locality preserving Experiments benchmark face recognition data sets confirm the effectiveness our proposed algorithms 
9884 en Dynamic Factor Graphs for Time Series Modeling This article presents method for training Dynamic Factor Graphs DFG with continuous latent state variables DFG includes factors modeling jointnprobabilities between hidden and observed variables and factors modelingndynamical constraints hidden variables The DFG assigns scalar energy each configuration hidden and observed variables radient based inference procedure finds the minimum energy state sequence for givennobservation sequence Because the factors are designed ensure constant partition function they can trained minimizing the expected energy over training sequences with respect the factors’ parameters These alternated inference and parameter updates can seen deterministic like procedure Using smoothing regularizers DFGs are shown reconstruct chaotic attractors and separate mixture independent oscillatory sources perfectly DFGs outperform the best known algorithm the CATS competition benchmark for time series prediction DFGs also successfully reconstruct missing motion capture data 
9885 en RTG Recursive Realistic Graph Generator using Random Typing propose new recursive model generate realistic graphs nevolving over time Our model has the following properties nflexible capable generating the cross product weighted unweighted directed undirected uni bipartite graphs realistic giving graphs thatnobey eleven static and dynamic laws that real graphs follow formallynprove that for several the power laws and estimate their exponentsnas function the model parameters parsimonious requiring only four parameters fast being linear the number edges simple intuitively leading the generation macroscopic patterns empirically show that our model mimics two real world graphs very well Blognet unipartite undirected unweighted with 27K nodes and 125K edges and Committee Candidate campaign donations bipartite directed nweighted with 23K nodes and 880K edges also show how handle time that edge weight additions are bursty and self similar 
9886 en Mining Graph Evolution Rules this paper introduce graph evolution rules novel type frequency based pattern that describe the evolution large networks over time local level Given sequence snapshots evolving graph aim discovering rules describing the local changes occurring Adopting definition support based minimum image study the problem extracting patterns whose frequency larger than minimum support threshold Then similar the classical association rules framework derive graph evolution rules from frequent patterns that satisfy given minimum confidence constraint discuss meritsand limits alternative definitions support and confidence justifying the chosen framework evaluate our approach devise GERM Graph Evolution Rule Miner algorithm mine all graph evolution rules whose support and confidence are greater than given thresholds The algorithm applied analyze four large real world networks two social networks and two authorship networks from bibliographic data using different time granularities Our extensive experimentation confirms the feasibility and utility the presented approach further shows that different kinds networks exhibit different evolution rules suggesting the usage these local patterns globally discriminate different kind networks 
9887 en Binary Decomposition Methods for Multipartite Ranking Bipartite ranking refers the problem learning ranking function from training set positively and negatively labeled examples Applied set unlabeled instances ranking function expected establish total order which positive instances precede negative ones The performance ranking function typically measured terms the AUC this paper study the problem multipartite ranking extension bipartite ranking the multi class case this regard discuss extensions the AUC metric which are suitable evaluation criteria for multipartite rankings Moreover learn multipartite ranking functions propose methods the basis binary decomposition techniques that have previously been used for multi class and ordinal classification compare these methods both analytically and experimentally not only against each other but also existing methods applicable the same problem 
9888 en Cost sensitive learning based Bregman divergences This paper analyzes the application particular class Bregman divergences design cost sensitive classifiers for multiclass problems show that these divergence measures can used estimate posterior probabilities with maximal accuracy for the probability values that are close the decision boundaries Asymptotically the proposed divergence measures provide classifiers minimizing the sum decision costs non separableproblems and maximizing margin separable MAP problems 
9889 en  Self Training Approach Cost Sensitive Uncertainty Sampling Uncertainty sampling effective method for performing active learning that computationally efficient compared other active learning methods such loss reduction methods However unlike lossreduction methods uncertainty sampling cannot minimize total misclassification costs when errors incur different costs This paper introduces method for performing cost sensitive uncertainty sampling that makes use self training show that even when misclassification costs are equal this self training approach results faster reduction loss function number points labeled and more reliable posterior probability estimates compared standard uncertainty sampling also show why other more naive methods modifying uncertainty sampling minimize total misclassification costs will not always work well 
9890 en Statistical Relational Learning with Formal Ontologies propose learning approach for integrating formal knowledge into statistical inference exploiting ontologies semantically rich and fully formal representation prior knowledge The logical constraints deduced from ontologies can utilized enhance and control the learning task enforcing description logic satisfiability latent multi relational graphical model demonstrate the feasibility our approach provide experiments using real world social network data form SHOIN ontology The results illustrate two main practical advancements First entities and entity relationships can analyzed via the latent model structure Second enforcing the ontological constraints guarantees that the learned model does not predict inconsistent relations our experiments this leads improved predictive performance 
9891 en Inference and Validation Networks develop statistical methodology validate the result network inference algorithms based principles statistical testing and machine learning The comparison results with reference networks means similarity measures and null models allows measure the significance results well their predictive power The use Generalised Linear Models allows explain the results terms available ground truth which expect partially relevant present these methods for the case inferring network News Outlets based their preference stories cover compare three simple network inference methods and show how our technique can used choose between them All the methods presented here can directly applied other domains where network inference used 
9892 en Neural Networks for State Evaluation General Game Playing Unlike traditional game playing General Game Playing concerned with agents capable playing classes games Given the rules unknown game the agent supposed play well without human intervention For this purpose agent systems that use deterministic game tree search need automatically construct state value function guide search Successful systems this type use evaluation functions derived solely from the game rules thus neglecting further improvements experience addition these functions are fixed their form and not necessarily capture the game’ real state value function this work present approach for obtaining evaluation functions the basis neural networks that overcomes the aforementioned problems network initialization extracted from the game rules ensures reasonable behavior without the need for prior training Later training however can lead significant improvements evaluation quality our results indicate 
9893 en Learning Multi Linear Representations Probability Distributions for Efficient Inference examine the class multi linear polynomial representations MLR for expressing probability distributions over discrete variables Recently MLR have been considered intermediate representations that facilitate inference distributions represented graphical models show that MLR expressive representation discrete distributions and can used concisely represent classes distributions which have exponential size other commonly used representations while supporting probabilistic inference time linear the size the representation Our key contribution presenting techniques for learning bounded size distributions represented using MLR which support efficient probabilistic inference propose algorithms for exact and approximate learning for MLR and through comparison with Bayes Net representations demonstrate experimentally that MLR representations provide faster inference without sacrificing inference accuracy 
9894 en Subspace Regularization New Semi Supervised Learning Method Most existing semi supervised learning methods are based the smoothness assumption that data points the same high density region should have the same label This assumption though works well many cases has limitations overcome this problems introduce into semi supervised learning the classic low dimensionality embedding assumption stating that most geometric information high dimensional data embedded low dimensional manifold Based this formulate the problem semi supervised learning task finding subspace and decision function the subspace such that the projected data are well separated and the original geometric information preserved much possible Under this framework the optimal subspace and decision function are iteratively found via projection pursuit procedure The low computational complexity the proposed method lends applications large scale data sets Experimental results demonstrates the effectiveness our method 
9895 en Active and Semi Supervised Data Domain Description Data domain description techniques aim deriving concise descriptions objects belonging category interest For instance the support vector domain description SVDD learns hypersphere enclosing the bulk provided unlabeled data such that points lying outside the ball are considered anomalous However relevant information such expert and background knowledge remain unused the unsupervised setting this paper rephrase data domain description semi supervised learning task that propose semi supervised generalization data domain description SSSVDD process unlabeled and labeled examples The corresponding optimization problem non convex translate into unconstraint continuous problem that can optimized accurately gradient based techniques Furthermore devise effective active learning strategy query low confidence observations Our empirical evaluation network intrusion detection and object recognition tasks shows that our SSSVDDs consistently outperform baseline methods relevant learning settings 
9896 en Semi Supervised Multi Task Regression Labeled data are needed for many machine learning applications but the amount available some applications scarce Semi supervised learning and multi task learning are two the approaches that have been proposed alleviate this problem this paper seek integrate these two approaches for regression applications first propose new supervised multi task regression method called SMTR which based Gaussian processes with the assumption that the kernel parameters for all tasks share common prior then incorporate unlabeled data into SMTR changing the kernel function the prior data dependent kernel function resulting semi supervised extension SMTR called SSMTR Moreover incorporate pairwise information into SSMTR further boost the learning performance for applications which such information available Experiments conducted two commonly used data sets for multi task regression demonstrate the effectiveness our methods 
9897 en Transductive Classification via Dual Regularization Semi supervised learning has witnessed increasing interest the past decade One common assumption behind semi supervised learning that the data labels should sufficiently smooth with respect the intrinsic data manifold Recent research has shown that the features also lie manifold Moreover there duality between data points and features that data points can classified based their distribution features while features can classified based their distribution the data points nHowever existing semi supervised learning methods neglect these points this paper present dual regularization which consists two graph regularizers and clustering type regularizer Furthermore propose novel transductive classification framework based dual regularization which can solved alternating minimization algorithm and its convergence theoretically guaranteed Experiments demonstrate that the proposed methods outperform many state the art transductive classification methods 
9898 en New Regularized Algorithms for Transducitve Learning propose new graph based label propagation algorithm for transductive learning Each example associated with vertex undirected graph and weighted edge between two vertices represents similarity between the two corresponding example build Adsorption recently proposed algorithm and analyze its properties then state our learning algorithm convex optimization problem over multi label assignments and derive efficient algorithm solve this problem state the conditions under which our algorithm guaranteed converge provide experimental evidence various real world datasets demonstrating the effectiveness our algorithm over other algorithms for such problems also show that our algorithm can extended incorporate additional prior information and demonstrate with classifying data where the labels are not mutually exclusive 
9899 en Graph Based Discrete Differential Geometry for Critical Instance Filtering Graph theory has been shown provide powerful tool for representing andntackling machine learning problems such clustering semi supervised learning and feature ranking This paper proposes graph based discrete differential operator for detecting and eliminating competence critical instances and class label noise from training set order improve classification performance Results extensive experiments artificial and real life classification problems substantiate the effectiveness the proposed approach 
9900 en Active Learning for Reward Estimation Inverse Reinforcement Learning Inverse reinforcement learning addresses the general problem recovering reward function from samples policy provided expert demonstrator this paper introduce active learning for inverse reinforcement learning propose algorithm that allows the agent query the demonstrator for samples specific states instead relying only samples provided ”arbitrary” states The purpose our algorithm estimate the reward function with similar accuracy other methods from the literature while reducing the amount policy samples required from the expert also discuss the use our algorithm higher dimensional problems using both Monte Carlo and gradient methods present illustrative results our algorithm several simulated examples different complexities 
9901 en Heteroscedastic Probabilistic Linear Discriminant Analysis with Semi Supervised Extension Linear discriminant analysis LDA commonly used method for dimensionality reduction Despite its successes has limitations under some situations including the small sample size problem the homoscedasticity assumption that different classes have the same Gaussian distribution and its inability produce probabilistic output and handle missing data this paper propose semi supervised and heteroscedastic extension probabilistic LDA called HPLDA which aims overcoming all these limitations under common principled framework Moreover apply automatic relevance determination determine the required dimensionality the low dimensional space for dimensionality reduction empirically compare our method with several related probabilistic subspace methods some face and object databases Very promising results are obtained from the experiments showing the effectiveness our proposed method 
9902 en Two Way Analysis High Dimensional Collinear Data present Bayesian model for two way ANOVA type analysis high dimensional small sample size datasets with highly correlated groups variables Modern cellular measurement methods are main application area typically the task differential analysis between diseased and healthy samples complicated additional covariates requiring multi way analysis The main complication the combination high dimensionality and low sample size which renders classical multivariate techniques useless introduce hierarchical model which does dimensionality reduction assuming that the input variables come similarly behaving groups and performs ANOVA type decomposition for the set reduced dimensional latent variables apply the methods study lipidomic profiles recent large cohort human diabetes study 
9903 en Feature Weighting Using Margin and Radius Based Error Bound Optimization SVMs The Support Vector Machine error bound function the margin and radius Standard SVM algorithms maximize the margin within given feature space therefore the radius fixed and thus ignored the optimization propose extension the standard SVM optimization which also account for the radius order produce even tighter error bound than what get controlling only for the margin use second set parameters vect that control the radius introducing like that explicit feature weighting mechanism the SVM algorithm impose constraint vect which results sparse vector thus performing feature selection Our original formulation not convex give convex approximation and show how solve experiment with real world datasets and report very good predictive performance compared standard SVM 
9904 en Margin and Radius Based Multiple Kernel Learning serious drawback kernel methods and Support Vector Machines SVM particular the difficulty choosing suitable kernel function for given dataset One the approaches proposed address this problem Multiple Kernel Learning MKL which several kernels are combined adaptively for given dataset Many the existing MKL methods use the SVM objective function and try find linear combination basic kernels such that the separating margin between the classes maximized However these methods ignore the fact that the theoretical error bound depends not only the margin but also the radius the smallest sphere that contains all the training instances present novel MKL algorithm that optimizes the error bound taking account both the margin and the radius The empirical results show that the proposed method compares favorably with other state the art MKL methods 
9905 en Sparse Kernel SVMs via Cutting Plane Training explore algorithm for training SVMs with Kernels that can represent the learned rule using arbitrary basis vectors not just the support vectors SVs from the training set This results two benefits First the addednflexibility makes possible find sparser solutions good quality nsubstantially speeding prediction Second the improved sparsity can also make training Kernel SVMs more efficient especially for high dimensional and sparse data text classification This has the potential make training Kernel SVMs tractable for large training sets where conventional methods scale quadratically due the linear growth the number SVs addition theoretical analysis the algorithm also present empirical evaluation 
9906 en Kernel Polytope Faces Pursuit Polytope Faces Pursuit PFP greedy algorithm that approximates the sparse solutions recovered regularised least squares Lasso similar vein Orthogonal Matching Pursuit OMP The algorithm based the geometry the polar polytope where each step basis function chosen finding the maximal vertex using path following method The algorithmic complexity similar order OMP whilst being able solve problems known hard for Matching Pursuit was extended build kernel based solutions machine learning problems resulting the sparse regression algorithm Kernel Matching Pursuit KMP develop new algorithm build sparse kernel based solutions using PFP which call Kernel Polytope Faces Pursuit KPFP show the usefulness this algorithm providing generalisation error bound that takes into account natural regression loss and experimental results several benchmark datasets 
9907 en Decomposition Algorithms for Training Large scale Semiparametric Support Vector Machines describe method for solving large scale semiparametric support vector machines SVMs for regression problems Most the approaches proposed date for large scale SVMs cannot accommodate the multiple equality constraints that appear semiparametric problems Our approach uses decomposition framework with primal dual algorithm find approximate saddle point for the min max formulation each subproblem compare our method with algorithms previously proposed for semiparametric SVMs and show that scales well the number training examples grows 
9908 en Universal Learning over Related Distributions and Adaptive Graph Transduction The basis assumption “training and test data drawn from the same distribution” often violated propose one common solution cover various scenarios learning under “different but related distributions” single framework Examples include sample selection bias transfer learning and uncertain training data The main motivation that one could ideally solve many problems possible with single approach The proposed solution extends graph transduction using the maximum margin principle over unlabeled data The error the proposed method bounded even when the training and testing distributions are different Experiment results demonstrate that the proposed method improves the traditional graph transduction much accuracy and AUC all common situations distributionndifference Most importantly outperforms accuracy several state art approaches proposed solve specific category distribution difference 
9909 en Reconstructing Data Perturbed Random Projections when the Mixing Matrix Known Random Projection has drawn great interest from the research privacy preserving data mining due its high efficiency and security was proposed cite Liu where the original data set composed attributes multiplied with mixing matrix dimensions times which random and orthogonal expectation and then the series perturbed data are released for mining purposes our knowledge little work has been done from the view the attacker reconstruct the original data get some sensitive information given the data perturbed and some priori knowledge the mixing matrix the means and variances the original data the case that the attributes the original data are mutually independent and sparse the reconstruction can treated problem Underdetermined Independent Component Analysis UICA but UICA has some permutation and scaling ambiguities this paper propose reconstruction framework based UICA and also some techniques reduce the ambiguities The cases that the attributes the original data are correlated and not sparse are also common data mining also propose reconstruction method for the typical case Multivariate Gaussian Distribution based the method Maximum Posterior MAP Our experiments show that our reconstructions can achieve high recovery rates and outperform the reconstructions based Principle Component Analysis PCA 
9910 en  Subgroup Discovery Numerical Domains Subgroup discovery Knowledge Discovery task that aims finding subgroups population with high generality and distributional unusualness While several subgroup discovery algorithms have been presented the past they focus databases with nominal attributes make use discretization get rid the numerical attributes this paper illustrate why the replacement numerical attributes nominal attributes can result suboptimal results Thereafter present new subgroup discovery algorithm that prunes large parts the search space exploiting bounds between related numerical subgroup descriptions The same algorithm can also applied ordinal attributes experimental section show that the use our new pruning scheme results huge performance gain when more that just few split points are considered for the numerical attributes 
9911 en Evaluation Measures for Multi Class Subgroup Discovery Subgroup discovery aims finding subsets population whose class distribution significantly different from the overall distribution has previously predominantly been investigated two class context This paper investigates multi class subgroup discovery methods consider six evaluation measures for multi class subgroups four them new and study their theoretical properties extend the two class subgroup discovery algorithm CN2 incorporate the new evaluation measures and new weighting scheme inspired AdaBoost demonstrate the usefulness multi class subgroup discovery experimentally using discovered subgroups features for decision tree learner Not only the number leaves the decision tree reduced with factor between and average but significant improvements accuracy and AUC are achieved with particular evaluation measures and settings Similar performance improvements can observed when using naive Bayes 
9912 en Non Redundant Subgroup Discovery Using Closure System Subgroup discovery local pattern discovery task which descriptions subpopulations database are evaluated against some quality function standard quality functions are functions the described subpopulation propose search for equivalence classes descriptions with respect their extension the database rather than individual descriptions These equivalence classes have unique maximal representatives forming closure system show that minimum cardinality representatives each equivalence class can found during the enumeration process that closure system without additional cost while finding minimum representative single equivalence class hard With several real world datasets demonstrate that search space and output are significantly reduced considering equivalence classes instead individual descriptions and that the minimum representatives constitute family subgroup descriptions that same better expressive power than those generated traditional methods 
9913 en Debt Detection Social Security Sequence Classification Using Both Positive and Negative Patterns Debt detection important for improving payment accuracy social security Since debt detection from customer transactional data can generally modelled fraud detection problem straightforward solution extract features from transaction sequences and build sequence classifier for debts The existing sequence classification methods based sequential patterns consider only positive patterns However according our experience large social security application negative patterns are very useful accurate debt detection this paper present successful case study debt detection large social security application The central technique building sequence classification using both positive and negative sequential patterns 
9914 en  Condensed Representation Itemsets for Analyzing their Evolution over Time Driven the need understand change within domains there emerging research methods which aim analyzing how patterns and particular itemsets evolve over time practice however these methods suffer from the problem that many the observed changes itemsets are temporally redundant the sense that they are the side effect changes other itemsets hence making the identification the fundamental changes difficult solution propose temporally closed itemsets novel approach for condensed representation itemsets which based removing temporal redundancies investigate how our approach relates the well known concept closed itemsets the latter would directly generalized account for the temporal dimension Our experiments support the theoretical results showing that the set temporally closed itemsets significantly smaller than the set closed itemsets 
9915 en Taxonomy Driven Lumping for Sequence Mining Given taxonomy events and dataset sequences these events nwe study the problem finding efficient and effective ways produce compact representation the sequences model sequences with Markov models whose states correspond nodes the provided taxonomy and each state represents the events the subtree under the corresponding node lumping observed events states that correspond internalnnodes the taxonomy allow more compact models that are easier tonunderstand and visualize the expense decrease the data likelihood nWe formally define and characterize our problem and propose scalable search method for finding good trade off between two conflicting goals maximizing the data likelihood and minimizing the model complexity implement these ideas Taxomo taxonomy driven modeler which apply two different domains query log mining and mining trajectories 
9916 en Identifying the Components Most not all databases are mixtures samples from different distributions many cases however nothing known about the source components these mix tures Therefore many methods that induce models regard database sampled from single data distribution Models that take into account that databases actu ally are sampled from mixtures distributions are often superior those that not independent whether this modelled explicitly implicitly Transaction databases are different with regard data distribution 
9917 en  Feature Selection Bias Variance and Bagging examine the mechanism which feature selection improves the accuracy supervised learning empirical bias variance analysis feature selection progresses indicates that the most accurate feature set corresponds the best bias variance trade off point for the learning algorithm Often this not the point separating relevant from irrelevant features but where increasing variance outweighs the gains from adding more weakly relevant features other words feature selection can viewed variance reduction method that trades off the benefits decreased variance from the reduction dimensionality with the harm increased bias from eliminating some the relevant features variance reduction method like bagging used more weakly relevant features can exploited and the most accurate feature set usually larger many cases the best performance obtained using all available features 
9918 en Multi Task Feature Selection Using the Multiple Inclusion Criterion MIC address the problem joint feature selection multiple related classification regression tasks When doing feature selection with multiple tasks usually one can “borrow strength” across these tasks get more sensitive criterion for deciding which features select propose novel method the Multiple Inclusion Criterion MIC which modifies stepwise feature selection more easily select features that are helpful across multiple tasks Our approach allows each feature added none some all the tasks MIC most beneficial for selecting small set predictive features from large pool potential features common genomic and biologicalndatasets Experimental results such datasets show that MIC usually outperforms other competing multi task learning methods not only terms accuracy but also building simpler and more interpretable models 
9919 en Stable and Accurate Feature Selection addition accuracy stability also measure success for feature selection algorithm Stability could especially concern when the number samples data set small and the dimensionality high this study introduce stability measure and perform both accuracy and stability measurements MRMR Minimum Redundancy Maximum Relevance feature selection algorithm different data sets The two feature evaluation criteria used MRMR MID Mutual Information Difference and MIQ Mutual Information Quotient result similar accuracies but MID more stable also introduce new feature selection criterion MIDalpha where redundancy and relevance selected features are controlled parameter alpha 
9920 en Feature Selection Transfer Learning with Linear Regularized Models This paper presents novel feature selection method for classification high dimensional data such those produced microarrays includes partial supervision smoothly favor the selection some dimensions genes new dataset classified The dimensions favored are previously selected from similar datasets large microarray databases hence performing inductive transfer learning the feature level This technique relies feature selection method embedded within regularized linear model estimation practical approximation this technique reduces linear SVM learning with iterative input rescaling The scaling factors depend the selected dimensions from the related datasets The final selection may depart from those whenever necessary optimize the classification objective Experiments several microarray datasets show that the proposed method both improves the selected gene lists stability with respect sampling variation well the classification performances 
9921 en Feature Selection for Value Function Approximation Using Bayesian Model Selection Feature selection reinforcement learning choosing basis functions such that useful approximations the unkown value function can obtained one the main challenges scaling real world applications Here consider the Gaussian process based framework GPTD for approximate policy evaluation and propose feature selection through marginal likelihood optimization the associated hyperparameters Our approach has two appealing benefits given just sample transitions nwe can solve the policy evaluation problem fully automatically without looking the learning task and theory independent the dimensionality the state space and model selection allows consider more sophisticated kernels which turn enable identify relevant subspaces and eliminate irrelevant state variablesnsuch that can achieve substantial computational savings and improved prediction performance 
9922 en Capacity Control for Partially Ordered Feature Sets Partially ordered feature sets appear naturally classification settings with structured instances For example when the instances are graphs and the features represent subgraph occurrence checks the features can partially ordered according “ subgraph ” relation investigate how the redundancy such datasets affects the capacity control behavior linear classification methods While the capacity does not decrease general derive better capacity bounds for distributions which assign lower probabilities instances the lower levels the feature hierarchy For itemset subsequence and subtrees the capacity finite even for data with infinite number features validate these results empirically and show that the limited capacity linear classifiers makes underfitting rather than overfitting the more prominent capacity control problem avoid underfitting propose substructure classes with “elastic edges” and demonstrate how such broad feature classes can used with large datasets 
9923 en Feature Selection for Density Level Sets frequent problem density level set estimation the choice the right features that give rise compact and concise representations the observed data present efficient feature selection method for density level set estimation where optimal kernel mixing coefficients and model parameters are determined simultaneously Our approach generalizes one class support vector machines and can equivalently expressed semi infinite linear program that can solved with interleaved cutting plane algorithms The experimental evaluation the new method network intrusion detection and object recognition tasks demonstrate that our approach not only attains competitive performance but also spares practitioners from priori decisions feature sets used 
9924 en The Feature Importance Ranking Measure Most accurate predictions are typically obtained learning machines with complex feature spaces induced kernels Unfortunately such decision rules are hardly accessible humans and cannot easily used gain insights about the application domain Therefore one often resorts linear models combination with variable selection thereby sacrificing some predictive power for presumptive interpretability Here introduce the Feature Importanc Ranking Measure FIRM which retrospective analysis arbitrary learning machines allows achieve both excellent predictive performance and superior interpretation contrast standard raw feature weighting FIRM takes the underlying correlation structure the features into account Thereby able discover the most relevant features even their appearance the training data entirely prevented noise The desirable properties FIRM are investigated analytically and illustrated simulations 
9926 en Learning the Difference between Partially Observable Dynamical Systems propose new approach for estimating the difference between two partially observable dynamical systems assume that one can interact with the systems performing actions and receiving observations The key idea define Markov Decision Process MDP based the systems compared such way that the optimal value the MDP initial state can interpreted divergence dissimilarity between the systems This dissimilarity can then estimated reinforcement learning methods Moreover the optimal policy will contain information about the actions which most distinguish the systems Empirical results show that this approach useful detecting both big and small differences well comparing systems with different internal structure 
9927 en Optimal Online Learning Procedures for Model Free Policy Evaluation this study extend the framework semiparametric statistical inference introduced recently reinforcement learning Ueno 2008 online learning procedures for policy evaluation This generalization enables investigate statistical properties value function estimators both batch and online procedures unified way terms estimating functions Furthermore propose novel online learning algorithm with optimal estimating functions which achieve the minimum estimation error Our theoretical developments are confirmed using simple chain walk problem 
9928 en Boosting Active Learning Optimality Tracable Monte Carlo Billiard Based Algorithm This paper focuses Active Learning with limited number queries application domains such Numerical Engineering the size the training set might limited few dozen hundred examples due computational constraints Active Learning under bounded resources formalized finite horizon Reinforcement Learning problem where the sampling strategy aims minimizing the expectation the generalization error tractable approximation the optimal intractable policy presented the Bandit based Active Learner Baal algorithm Viewing Active Learning single player game Baal combines UCT the tree structured multi armed bandit algorithm proposed Kocsis and Szepesvari 2006 and billiard algorithms proof principle the approach demonstrates its good empirical convergence toward optimal policy and its ability incorporate prior criteria Its hybridization with the Query Committee approach found improve both stand alone Baal and stand alone QbC 
9930 en Opening the First International Workshop LEarning and data Mining for Robotics LEMIR 2009 
9931 en Controlling Humanoid Robots Means Genetic Programming show the real world applications evolutionary computation nto robotics which called evolutionary robotics nMachine Learning techniques can applied tona robot order achieve task for the appropriatenactions are not predetermined such situation the robot cannlearn the appropriate actions using trial and error realnenvironment Genetic Programming can generate programs controlna robot directly and many studies have been done showing this nGA Genetic Algorithms combinationnwith neural networks can also used control robots nRegardless the method used the evaluation real robotsnrequires significant amount time partly due their complexnmechanical actions Moreover evaluations have repeated overnseveral generations for many individuals both and nTherefore most studies the learning conducted innsimulation and the acquired results are applied real robots nTo solve these difficulties propose integrated technique ofngenetic programming and reinforcement learning enable anreal robot adapt its actions real environment Ourntechnique does not require precise simulator because learning isnachieved through the real robot addition our technique makesnit possible for real robots learn effective actions Based onnthis proposed technique evolve common programs using nwhich are applicable various types robots Using thisnevolved program execute reinforcement learning realnrobot With our method the robot can adapt its own operationalncharacteristics and learn effective actions The effectiveness ofnour proposed approach demonstrated performing experimentsnwith real humanoid robots 
9932 en Quantification and Minimization the Simulation Reality Gap BRIO Labyrinth Game this paper present new method the called  ntunnel that can used quantify the simulation reality gap comparingnthe behavior the state trajectory baseline system for instancena real robotic system and model this system physicbasednsimulation With this  tunnel the impact change thenmodel parameter can analyzed Furthermore present approachnto automate the optimization these parameters and presentnsome results obtained robot system that based BRIOR labyrinthngame 
9933 en Toward Using Symbolic Discovery Designing Controllers Autonomous Swarm Robots this paper propose approach which iterates designtest nanalysis cycle using symbolic data mining methods for designing controllersnof autonomous swarm robots The approach applicable even ifnthe onboard signal unavailable the designer which common fornsuch kinds robots the first step tackle specific task whichntwo swarm robots try visit many cells possible square fieldnbefore fatal collision Quick analysis using conventional techniques relyingnalso human inspection revealed interesting essentials including andesirable type interaction between the swarm robots and possible refinementsnof the controllers consider possible usages data miningnmethods including efficient trajectory discovery method effectivenminority subset discovery method and robust partial classifier discoverynmethod 
9934 en Robotics Planetary Exploration Some the problems faced designing robots fornplanetary exploration will described The context refers the projectnSTEPS targeting future Mars missions speci cally the design the lan nder the capsule for reaching the planet surface and the rover robot fornexploring the environment Both the lander and the rover are equippednwith several sensors among which camera plays fundamental role nVision based landing and environment reconstruction are considered pri nmary goals for the success the mission 
9935 en  Road Map for Motor Skill Learning Autonomous robots that can assist humans situations daily lifenhave been long standing vision robotics artificial intelligence nand cognitive sciences first step towards this goal createnrobots that can learn tasks triggered environmental context ornhigher level instruction However learning techniques have yet tonlive this promise only few methods manage scale tonhigh dimensional manipulator humanoid robots this tutorial wengive general overview motor skill learning For doing wendiscuss task appropriate representations and algorithms for learningnin robotics Among the topics are the learning basic movements ornmotor primitives imitation and reinforcement learning learningnrhytmic and discrete movements fast regression methods for learningninverse dynamics and setups for learning task space policies Examplesnon various robots will shown these include ball paddling nball cup robot darts robot table tennis learning inversendynamics learning operational space control and many others 
9936 en Solving Deterministic Policy MDPs using The viewpoint solving Markov Decision Processes andntheir partially observable extension refers nding policies that max nimise the expected reward follow the rephrasing this problem asnlearning related probabilistic model Our trans dimensional distri nbution formulation obtains equivalent results previous work thenin nite horizon case and also rigorously handles the nite horizon casenwithout discounting contrast previous expositions our frameworknelides auxiliary variables simplifying the algorithm development For anynMDP the optimal policy deterministic meaning that this importantncase needs dealt with explicitly Whilst this case has been discussednby previous authors their treatment has not been formally equivalent tonan algorithm but rather based xed point iteration analogousnto policy iteration contrast derive true approach for thisncase and show that this has signi cantly faster convergence rate thannnon deterministic Our approach extends naturally the POMDPncase well the special case deterministic environments standardnEM algorithms break down and show how this can addressed ning convex combination the original deterministic environment andna ctitious stochastic antifreeze environment 
9937 en Panel Challenges Machine Learning Based Abutonomouas Robotics
9938 en Invited Talk Towards Theoretical Understanding Domain Adaptation Learning Machine learning enjoys deep and powerful theory that has led wide variety highly successful practical tools However most this theory developed under some simplifying assumptions that clearly fail the real world particular fundamental assumption the theory that the data available for training and the data the target application come from the same source When this assumption fails the learner faced with “domain adaptation” challenge the past few years the range machine learning applications have been expanded include various tasks requiring domain adaptation Such application have been addressed several heuristic paradigms However the common theoretical models fall short providing useful analysis these techniques The key domain adaptation the similarity between the training and target domains this talk will discuss several parameters along which task similarity can defined and measured and discuss what extent can they utilized direct learning algorithms and guarantee their success Recent work can provide theoretical justification some existing practical heuristics well guide the development novel algorithms for handling some types data discrepancies However our current understanding leaves much desired shall devote the last part the talk describing some the challenges and open questions that will have addressed before one can claim satisfactory understanding learning the presence training test discrepancies The talk based joint works with John Blitzer Koby Crammer and Fernando Pereira and with students David Pal Teresa Luu and Tyler 
9939 en Invited Talk Empirical Risk Minimization with Statistics Higher Order with Examples from Bipartite Ranking Statistical learning theory was mainly developed the framework binary classification under the assumption that observations the training set form sample The techniques involved order provide statistical guarantees for state the art learning algorithms are borrowed from the theory empirical processes This made possible not only because the assumption the data but also because the nature the performance measures such classification error margin error which are statistics order one the talk will discuss variety questions which arise the theory when more involved criteria are considered The problem bipartite ranking through ROC curve optimization provides prolific source optimization functionals which are statistics order strictly larger than one and several examples will presented 
9940 en Robustness and Generalizability for Markovian Samples consider robustness learning algorithms and prove thatnunder very general setup robustness algorithm implies that generalizes nand consequently robust algorithm that asymptotically minimizesnempirical risk consistent particular this relationship holds innthe case where both training samples and testing samples are generatednaccording evolving Markovian chain satisfying the Doeblin condition nWe further provide conditions that ensure robustness and hencengeneralizability and some cases consistency all under the Markoviannsetup Two notable examples are support vector machines and Lasso 
9941 en PAC Bayesian Bounds the Non IID Case
9942 en Hybrid Stochastic Adversarial Line Learning Most the research online learning focused either thenproblem adversarial classification both inputs and labels are arbitrarilynchosen adversary the traditional supervised learningnproblem which samples are according probability distribution nNonetheless number domains the relationship betweenninputs and labels may adversarial whereas inputs are generated accordingnto fixed distribution This scenario can formalized annhybrid classification problem which inputs are while labels arenadversarial this paper introduce the hybrid stochastic adversarialnproblem propose online learning algorithm for its solution andnwe analyze its performance particular show that given hypothesisnspace with finite dimension possible incrementallynbuild suitable finite set hypotheses that can used input for annexponentially weighted forecaster achieving cumulative regret over nnrounds order npnnV log with overwhelming probability 
9943 en Nonparametric ICA for Nonstationary Instantaneous Mixtures this work use nonparametric sample Fisher informationnlike matrix instead the sample covariance matrix find the mixingnmatrix nonstationary ICA model This replacement may resultsnin faster and robust separation 
9944 en Descriptive Subgroup Mining Folk Music Descriptive analysis music corpora important musicologistsnwho are interested identifying the properties that characterizenspecifi genres music this study present such analysis anlarge corpus folk tunes all labeled their origin Subgroup Discoveryn rule learning technique located the intersection predictivenand descriptive induction One the advantages using this techniquenis the intuitive and interpretable result the form collection simplenrules Classifi cation accuracy not the goal this study Instead wendiscuss some the highest scoring rules with respect their descriptivenpower 
9945 en Detecting Key Features Popular Music Case Study Singing Voice Detection Detecting distinct features modern pop music importantnproblem that can have significant applications areas such multimedianentertainment They can used for example give visually coherentnrepresentation the sound propose integrate singing voice detectornwith multimedia multi touch game where the user has perform simplentasks certain key points the music While the ultimate goal tonautomatically create visual content response features extracted from thenmusic here give special focus the detection voice segments musicnsongs The solution presented extracts the Mel Frequency Cepstral Coefficientsnof the sound and uses Hidden Markov Model infer the sound has voice nThe classification rate obtained high when compared other singing voicendetectors that use Mel Frequency Cepstral Coefficients 
9946 en  Framework for Performer Identification Audio Recordings present general framework for the task identifyingnperformers from their playing styles investigate how musicians express and communicate their view the musical content pieces andnhow use this information order automatically identify performers study note level deviations parameters such timing andnamplitude Our approach performer identification consists inducingnan expressive performance model for each the interpreters essentiallynestablishing performer dependent mapping inter note features antiming and amplitude expressive transformations outline two successful performer identification case studies 
9947 en Melodic Models for Polyphonic Music Classification The classification polyphonic music still presents challengesnfor current music data mining methods this paper explorenthe performance classifiers specifically created for melody the polyphonicnclassification task small dataset string quartet movementsnof Haydn and Mozart the melodic gram model outperforms thenmelodic global feature model for composer recognition Furthermore ansimple model that combines the predictions made from different instrumentalnparts outperforms models created from any single voice Thenresults indicate that models taking into account polyphonic informationnachieve higher classification accuracy 
9948 en Audio Genre Classification with Semi Supervised Feature Ensemble Learning Widespread availability and use music have madenautomated audio genre classification important field research nThanks feature extraction systems not only music data but alsonfeatures for them have become readily available However handlabelingnof large amount music data time consuming Innthis study introduce semi supervised random feature ensemblenmethod for audio classification which uses labeled and unlabeledndata together for better genre classification order have diversensubsets features which are both relevant and non redundant withinnthemselves introduce the Prob mRMR Probabilistic minimumnRedundancy Maximum Relevance feature selection algorithm ProbmRMRnis based mRMR Ding and Peng 2003 and selectsnthe features probabilistically according relevance and redundancynmeasures Experimental results show that ensembles classifiers usingnProb mRMR feature subsets outperform both training and RASCOn Random Subspace Method for training Wang 2008 which usesnrandom feature subsets 
9949 en Modeling the Influence Performance Controls Violin Timbre means sensing system are able capture bowingnand ¯ngering actions executed violinist during real performances nThe aim this research model the relation between those actionsnand the sound produced describe the process for training and optimizing the model means neural networks Given set controlnactions the model able predict the spectral envelopes the harmonic and noisy components the sound which are used for soundnsynthesis The model validated comparing real recording with thencorresponding synthetic sound produced 
9950 en Modeling Expressive Performances the Singing Voice The long term goal this work develop models operaticnsingers and use them generate expressive performances similar innvoice quality and style with what original performances those singersnwould sound like This paper focuses learning timing models expressivenperformance using high level descriptors extracted from existingnaudio recordings Our approach based applying machine learningnto discover singer specific timing patterns expressive singing basednon existing performances The experimental results show significantncorrelation between the note durations real performances and thosenpredicted our model 
9951 en  Probabilistic Approach Melodic Similarity Melodic similarity important research topic musicninformation retrieval The representation symbolic music meansnof trees has proven suitable melodic similarity computation nbecause they are able code rhythm their structure leaving only pitchnrepresentations degree freedom for coding order comparentrees different edit distances have been previously used this paper nstochastic testable tree models formerly used other domains likenstructured document compression natural language processing havenbeen used for computing similarity measure between melody trees anprobability and their performance has been compared classical treenedit distance 
9952 en Interactive Segmentation Electro Acoustic Music
9953 en Information Networks State the Art This paper provides overview different types information networks and categorizes them identifying several key properties information units and relations These properties reflect the expressiveness and thus ability information network model data diverse nature 
9954 en Characterizing Semantic Relatedness Search Query Terms Mining for semantic information search engine query logsnbears great potential for both the optimization search engines and bootstrapping Semantic Web applications The interaction user with search engine more specifi cally clicklog information has recently beennviewed implicit tagging resources query terms The resulting structure previously called logsonomy exhibits structural similarities folksonomies which evolve during the explicit process annotating resourcesnwith freely chosen keywords social bookmarking systems Fornthe folksonomy case appropriate measures relatedness have shown tonbe capable harvest the emerging semantics inherent the tripartitengraph users tags and resources Motivated the reported structuralnsimilarities this work extend this methodology logsonomies Morenspecifi cally apply several measures query term relatedness thenlogsonomy graph and provide semantic characterization for each measurenby grounding against user validated relatedness measures based onnWordNet Comparing the outcome with prior results analyzing folksonomyndata that the formalization log data logsonomies retainsnthe semantic information Some relatedness measures applied prove tonbe able capture these emergent semantics similarly the folksonomyncase while others exhibit fferent characteristics this way providena novel and systematic approach compare the emergent semantics ofnuser interactions with search engines and social bookmarking systems Wenconclude that the type semantic information inherent both emergingnstructures similar and inform the choice appropriate measure ofnquery term relatedness for given task 
9955 en Constructing Information Networks from Text Documents major challenge for next generation data mining systems isncreative knowledge discovery from diverse and distributedndata knowledge sources this task important challenge isninformation fusion diverse representations into uniquendata knowledge format This paper focuses the graph representationnof data knowledge generated from text documents available the web nThe problem addressed how efficiently and effectively create anninformation network named BisoNet from large text corpora Severalnoptions concerning node and arc representation are discussed and ancase study information network created from articles concerningnautism downloaded from the PubMed repository medicalnpublications Open issues and lessons learned concerning representationnchoices are discussed 
9956 en Gene Analytics Discovery and Contextualization Enriched Gene Sets The paper present preliminary study creative knowledgendiscovery through bisociative data analysis Bisociative reasoning atnthe heart creative accidental discovery serendipity and focused finding unexpected links crossing different contexts Contextualizationnand linking between highly diverse and distributed data and knowledgensources therefore crucial for implementation bisociative reasoning nIn the paper explore these ideas the problem analysis microarrayndata show how enriched gene sets are found using ontologyninformation background knowledge semantic subgroup discovery nThese genes are then contextualized the computation probabilisticnlinks diverse bioinformatics resources Results two case studies are used illustrate the approach 
9957 en Review Network Abstraction Techniques Networks are common way representing linked information nThe goal network abstraction transform large networkninto smaller one that the smaller useful summary the originalngraph nIn this paper review erent approaches and techniques proposed tonabstract large network classify the approaches along two axes Then rst one consists elementary simpli cation techniques used pruningnof irrelevant nodes and edges partitioning several smaller networks nand generalization replacement subnetworks more general structures nThe other axis objective subjective methods the latter onesnaim maintain more information about those parts network thatnthe user has indicated interesting nWe conclude the review brief analysis which intersections thentwo axes are least researched and could therefore have future potential 
9958 en Probabilistic and Logical Inference for Network Mining this talk shall analyze network mining and bisociationnfrom logical and probabilistic inference point view This inspirednby the work ProbLog for link mining Raedt Kimmig Toivonen nIJCAI 2007 which turn based Biomine Sevonen DILSn06 The talk shall introduce probabilistic semantics for networks andndatabases and use clarify notions deduction abduction and explanations induction analogy abstraction and spread influence Allnnotions will illustrated the context the Biomine network 
9959 en Finding Representative Nodes Probabilistic Graphs introduce the problem identifying representative nodesnin probabilistic graphs motivated the need produce fferent simplenviews large networks defi probabilistic similarity measurenfor nodes and then apply clustering methods groups nodes nFinally representative output from each cluster report experimentsnwith real biomedical data using both the medoids and hierarchicalnclustering methods the clustering step The results suggest thatnthe clustering based approaches are capable finding representativenset nodes 
9960 en Pure Spreading Activation Pointless Spreading activation popular technique for retrievingnand ranking indirectly related information activating query items andnspreading their activation along relatedness links Almost every use ofnthe technique accompanied its own set restrictions the dynamics though and the usual motivation reduced computationalndemand improved specifi types data show thatnin linear constraint free scenarios spreading activation would actuallynyield query independent results that applications crucially depend onnthe imposed restrictions avoid this undesirable behavior studynnatural modifi cations that ensure query dependent results even withoutnheuristic restrictions and provide experimental evidence for their effectiveness 
9961 en  BisoNet Generation Using Textual Data According Koestler the notion bisociation denotesna connection between pieces information from habitually separatedndomains categories this paper consider methodology findnsuch bisociations using network representation knowledge which isncalled BisoNet because promises contain bisociations rstnstep consider how create BisoNets from several textual databasesntaken from fferent domains using simple text mining techniques Tonachieve this introduce procedure link nodes BisoNet andnto endow such links with weights which based new measure forncomparing text frequency vectors second step try rediscovernknown bisociations which were originally found human domainnexpert namely indirect relations between migraine and magnesium asnthey are hidden medical research articles published before 1987 Wenobserve that these bisociations are easily rediscovered simply following the strongest links Future work includes extending our methods tonnon textual data improving the similarity measure and applying morensophisticated graph mining methods 
9962 en Creative Knowledge Discovery Literature Outlier Detection This paper investigates the role outliers literature basednknowledge discovery shows that detecting interesting outliers that appear innthe literature about given phenomenon can help generate novel plausiblenscientific hypotheses The underlying assumption that whereas the majoritynof domain literatures describe matters related common understanding thendomain some particular observations that appear rarely the literature cannindicate promising direction towards novel discoveries This rarity principle isnused our method called RaJoLink guide the knowledge discovery process nThe presented method focuses the role outliers the closed discoverynprocess implemented the RaJoLink literature mining methodology 
9963 en Interactive Visualization Continuous Node Features Graphs Ordinary graphs only support discrete structures this paper presentnan approach towards embedding continuous data – like time stamps series measurementsn– discrete graph models These continuous meta information implicitlyndefine relations between vertices which are not explicitly defined the graph itself nWe call this induced Non Discrete Graph Structure NoDeS The model helpfulnfor visualization time dependent models values from physical domains providena formal definition NoDeS based graphs and two mappings instance andnannotation based already known graph structures and visualizations visualizationnof multi partite projection provides representation information from severalncontexts enabling NoDeS for generic context switching mechanism which usednfor interaction with these structures Finally introduce application concept fornagent driven event scheduling using NoDeS 
9965 en From Ranking Intransitive Preference Learning Rock Paper Scissors and Beyond Incorporating Exceptions
9966 en Kernel Principal Component Ranking Robust Ranking Noisy Data
9968 en Decision Rule Based Algorithm for Ordinal Classification Based Rank Loss Minimization
9969 en Learning Various Classes Models Lexicographic Orderings
9970 en  the Combination Two Decompositive Multi Label Classification Methods
9971 en Label Ranking with Partial Abstention Using Ensemble Learning
9973 en UTA Explaining Stated Preferences with Additive Non Monotonic Utility Functions
9977 en Evolution Four Dimensions Ideas about heredity and evolution are undergoing revolutionary change New findings molecular biology challenge the gene centered version Darwinian theory according which adaptation occurs only through natural selection chance DNA variations Evolution Four Dimensions Eva Jablonka and Marion Lamb argue that there more heredity than genes They trace four dimensions evolution—four inheritance systems that play role evolution genetic epigenetic non DNA cellular transmission traits behavioral and symbolic transmission through language and other forms symbolic communication These systems they argue can all provide variations which natural selection can act Evolution Four Dimensions offers richer more complex view evolution than the gene based one dimensional view held many today The new synthesis advanced Jablonka and Lamb makes clear that induced and acquired changes also play role evolution nnAfter discussing each the four inheritance systems detail Jablonka and Lamb put Humpty Dumpty together again showing how all these systems interact They consider how each may have originated and guided evolutionary history and they discuss the social and philosophical implications the four dimensional view evolution Each chapter ends with dialogue which the authors engage the contrarieties the fictional and skeptical Ifcha Mistabra—Aramaic for the opposite conjecture —refining their arguments against vigorous counterarguments The lucid and accessible text accompanied artist physician Anna Zeligowski lively drawings which humorously and effectively illustrate the authors points 
9978 en NMR and mSR SmFeAsO1 xFx Superconductors Among the recently discovered pnictide superconductors the highest superconducting critical temperature has been measured for SmFeAsO1 xFx family brief overview recent results obtained means 19F nuclear magnetic resonance and muon spin rotation SmFeAsO1 xFx superconductors will presented 19F nuclear spin lattice relaxation which allows probe the low energy excitations within the layers shows behavior which rather characteristic heavy fermion compounds with magnetic ground state From the temperature dependence the NMR linewidth information the static properties the flux lines lattice and the superconducting order parameter can derived These results are compared with the ones obtained muon spin rotation which represents powerful tool study the doping and temperature dependence the London penetration depth and evidence the possible coexistence superconductivity and magnetism the microscopic level comparison between the phenomenology observed cuprates and based superconductors will made throughout the seminar 
9980 en Learning Deep Hierarchies Representations Whereas theoretical work suggests that deep architectures might computationally and statistically more efficient representing highly varying functions training deep architectures was unsuccessful until the recent advent algorithms based unsupervised pre training each level hierarchically structured model Several unsupervised criteria and procedures were proposed for this purpose starting with the Restricted Boltzmann Machine RBM which when stacked gives rise Deep Belief Networks DBN Although the partition function RBMs intractable inference tractable and review several successful learning algorithms that have been proposed particular those using weights that change quickly during learning instead converging addition being impressive generative models deep architectures based RBMs and other unsupervised learning methods have made impact being used initialize deep supervised neural networks Even though these new algorithms have enabled training deep models many questions remain the nature this difficult learning problem attempt shed some light these questions comparing different successful approaches training deep architectures and through extensive simulations investigating explanatory hypotheses Finally describe our current research program objectives and challenges regarding learning representations multiple levels abstraction compare web objects such images documents and search engine requests comparisons that are the core several information retrieval applications 
9998 en Parameters influencing noise emissions – proposal for Interdependency Matrix
9999 en  overviewof the TYROSAFE project Tyre and Road Surface Optimisation for Skid Resistance and Further Effects
10002 en WP3 Experts Workshop Contributory Factors
10004 en Task Parameters influencing rolling resistance
10007 en TYROSAFE basic information Tyrp Running resistance
10051 en Structured Output Prediction Enzyme Function via Reaction Kernels Enzyme function prediction important problem post genomicnbioinformatics There are two general methods for solving the problem ntransfer annotation from similar already annotated protein andnmachine learning approaches that treat the problem classificationnagainst fixed taxonomy such Gene Ontology the hierarchy nThese methods are suitable cases where the function has beennpreviously characterized and included the taxonomy However given annew function that not previously described existing approachesnarguably not offer adequate support for the human expert nnIn this presentation will present structured output learningnapproach where the enzyme function enzymatic reaction describednin fine grained fashion with called reaction kernels which allowninterpolation and extrapolation the output reaction space Anstructured output model learned predict enzymatic reactions fromnsequence motifs bring forward several choices for constructingnreaction kernels and experiment with them the remote homology casenwhere the functions the test set have not been seen the trainingnphase Our experiments demonstrate the viability our approach 
10094 en Centre for knowledge transfer VideoLectures NET World Summit award and future plans Centre for knowledge transfer information technologies performs educational promotional and infrastructural activities and provides direct exchange information and experience between researchers and the users their research results partnering and active engagement the different European research projects the Centre successfully extends its activities the research and development Most the research performed the area knowledge management for traditional and emerging forms organizations like networked and virtual organizations nnThe Centre operating two web portals The first one VideoLectures NETwhich now becoming reference portal presenting high quality scientific lectures and second one IST World that offers services for automatic data collection and analysis the European research 
10104 en Brains Meaning and Corpus Statistics Google Tech TalksnMarch 3009nnABSTRACTnnPresented bynnTom MitchellnE Fredkin Professor and Department HeadnMachine Learning DepartmentnCarnegie Mellon UniversitynnHow does the human brain represent meanings words and pictures terms the underlying neural activity This talk will present our research using machine learning methods together with fMRI brain imaging study this question One line our research has involved training classifiers that identify which word person thinking about based their neural activity observed using fMRI more recent line involves developing computational model that predicts the neural activity associated with arbitrary English words including words for which not yet have brain image data This computational model trained using combination fMRI data associated with several dozen concrete nouns together with statistics gathered from trillion word text corpus Once trained the model predicts fMRI activation for any other concrete noun appearing the text corpus with highly significant accuracies over the nouns for which currently have fMRI data nnTom Mitchell the Fredkin Professor and head the Machine Learning Department Carnegie Mellon University Mitchell past President the American Association Artificial Intelligence AAAI and Fellow the AAAS and the AAAI His general research interests lie machine learning artificial intelligence and cognitive neuroscience Mitchell believes the field machine learning will the fastest growing branch computer science during the 21st century nnMitchell web home page www cmu edu tom
10182 en Multiframe Motion Segmentation via Penalized MAP Estimation and Linear Programming
10217 en Task – Non destructive testing
10220 en Sustainable Pavements for European New member states
10221 en Guidelines for the environmental assessment various pavement types including recommendations road authorities New Member States
10222 en  gaze central European highway structures
10223 en Bridge safety assessment and maintenance wizh the use monitoring techniques
10224 en Traffic load models for bridges Central and Eastern European Countries
10225 en Recommendations for dynamic allowance bridge assessment
10227 en Role measurements and experimental data optimised bridge assessment
10228 en Laboratory and field implementation high modulus asphalt concrete
10230 en Soft diagnostic and proof load testing routine bridge assessment
10232 en Upgrading asphalt macadam and light asphalt pavements the bearing capacity level needed regulations
10233 en The use corrosion resistant reinforcement the chance for durable concrete reinforced structures
10234 en Improvement Pavement Structures Long Term Performance Reinforced Pavements
10235 en Application steel slag aggregate road construction
10236 en Cathodic protection for extending the life concrete bridges
10237 en  methodology for testing and implementing crushed concrete road construction
10239 en Systematic decision making processes within Bridge Management System
10241 en Ultra High Performance Fibre Reinforced Concretes UHPFRC for rehabilitation bridges recent advances Slovenia
10242 en Practical mix design model for asphalt mixtures
10243 en Composite UHPFRC concrete construction for CO2 emission savings
10244 en Discussion Structures Hardening and Strengthening
10247 en Next steps the CERTAIN project
10251 en The importance corrosion monitoring for the durability structures
10252 en Load test results Internet data base new tool bridge assessment
10413 en  buyer guide continious optimization
10414 en Compressive Sensing for Computer Vision Hype Hope
10415 en  the completeness coding with image features
10416 en Learning Models for Object Recognition from Natural Language Descriptions
10417 en Better appearance models for pictorial structures
10418 en Bilateral Symmetry Detection via Symmetry Growing
10419 en Real time texture boundary detection from ridges the standard deviation space
10420 en Category Specific Object Recognition and Segmentation Using Skeletal Shape Model
10421 en  Constant Time Efficient Stereo SLAM System
10422 en Multi View Geometry the Refractive Plane
10423 en Estimation Location Uncertainty for Scale Invariant Features Points
10424 en Multiple Target Localisation over 100 FPS
10425 en What can the world tell about image 
10426 en Semantic Scene Segmentation using Random Multinomial Logit
10428 en Combining Appearance and Structure from Motion Features for Road Scene Understanding
10429 en Object Localization with Global and Local Context Kernels
10430 en PRISM PRincipled Implicit Shape Model
10432 en Specularity and Shadow Interpolation via Robust Polynomial Texture Maps
10433 en Learning generative texture models with extended Fields Experts
10434 en Get Out Picture Internet based Inpainting
10436 en  head pose estimation from multiple distant views
10437 en  assisted Facial Texture Super Resolution
10438 en Head Pose Classification Crowded Scenes
10439 en Subtitle free Movie Script Alignment
10440 en Multi view synchronization human actions and dynamic scenes
10441 en Attribute Multiset Grammars for Global Explanations Activities
10442 en Evaluation local spatio temporal features for action recognition
10444 en Introduction Neon NeOn million Euros project involving European partners and funded the European Commission’ Sixth Framework Programme under grant number IST 2005 027595 NeOn started March 2006 and has duration years Our aim advance the state the art using ontologies for large scale semantic applications the distributed organizations Particularly aim improving the capability handle multiple networked ontologies that exist particular context are created collaboratively and might highly dynamic and constantly evolving 
10447 en Lecture How You Know Professor McBride outlines the course with its goals and requirements including the required laboratory course the course prime question How you know proposes two unacceptable answers divine and human authority and two acceptable answers experiment and logic illustrates the fruitfulness experiment and logic using the rise science the seventeenth century London Royal Society and the crucial experiment light Isaac Newton provide examples his correspondence with Newton Samuel Pepys diarist and naval purchasing officer illustrates the attitudes and habits which are most vital for budding scientists especially those who would like succeed this course The lecture closes introducing the underlying goal for the first half the semester understanding the Force Law that describes chemical bonds nnProblem sets Reading assignment nnReading assignments problem sets PowerPoint presentations and other resources for this lecture can accessed from Professor McBride campus course website which was developed for his Fall 2008 students Please see Resources section below nnResources http webspace yale edu chem125 oyc L01 Professor McBride web resources for CHEM 125 Fall 2008 
10448 en Lecture Force Laws Lewis Structures and Resonance Professor McBride begins following Newton admonition search for the force law that describes chemical bonding Neither direct Hooke Law nor inverse Coulomb Gravity dependence distance will composite like the Morse potential needed Lewis devised cubic octet theory based the newly discovered electron and developed into shared pair model explain bonding After discussing Lewis dot notation and formal charge Professor McBride shows that some single minimum cases the Lewis formalism inadequate and salvaging required introducing the confusing concept resonance nnProblem sets Reading assignment nnReading assignments problem sets PowerPoint presentations and other resources for this lecture can accessed from Professor McBride campus course website which was developed for his Fall 2008 students Please see Resources section below nnResources http webspace yale edu chem125 oyc L02 Professor McBride web resources for CHEM 125 Fall 2008 
10449 en Lecture Double Minima Earnshaw Theorem and Plum Puddings Continuing the discussion Lewis structures and chemical forces from the previous lecture Professor McBride introduces the double well potential the ozone molecule and its structural equilibrium The inability for inverse square force laws account for stable arrangements charged particles prescribed Earnshaw Theorem which may visualized means lines force Thomson circumvented Earnshaw prohibition structure postulating plum pudding atom When Rutherford showed that the nucleus was point Thomson had conclude that Coulomb law was invalid small distances nnProblem sets Reading assignment nnReading assignments problem sets PowerPoint presentations and other resources for this lecture can accessed from Professor McBride campus course website which was developed for his Fall 2008 students Please see Resources section below nnResources http webspace yale edu chem125 oyc L03 Professor McBride web resources for CHEM 125 Fall 2008 
10450 en Lecture Coping with Smallness and Scanning Probe Microscopy This lecture asks whether possible confirm the reality bonds seeing feeling them first describes the work clairvoyant charlatans from the beginning the twentieth century who claimed see details atomic and molecular structure order discuss proper bases for scientific belief then shows that the molecular scale not inconceivably small and that Newton and Franklin performed simple experiments that measure such small distances the last years various realizations Scanning Probe Microscopy have enabled chemists feel individual molecules and atoms but not bonds nnProblem sets Reading assignment nnReading assignments problem sets PowerPoint presentations and other resources for this lecture can accessed from Professor McBride campus course website which was developed for his Fall 2008 students Please see Resources section below nnResources http webspace yale edu chem125 oyc L04 Professor McBride web resources for CHEM 125 Fall 2008 
10451 en Lecture Ray Diffraction Professor McBride introduces the theory behind light diffraction charged particles and its application the study the electron distribution molecules ray diffraction The roles molecular pattern and crystal lattice repetition are illustrated shining laser light through diffraction masks generate patterns reminiscent those encountered ray studies ordered solids nnProblem sets Reading assignment nnReading assignments problem sets PowerPoint presentations and other resources for this lecture can accessed from Professor McBride campus course website which was developed for his Fall 2008 students Please see Resources section below nnResources http webspace yale edu chem125 oyc L05 Professor McBride web resources for CHEM 125 Fall 2008 
10452 en Lecture Seeing Bonds Electron Difference Density Professor McBride uses hexagonal benzene pattern and Franklin ray pattern DNA continue his discussion ray crystallography explaining how diffraction pattern reciprocal space relates the distribution electrons molecules and the repetition molecules crystal lattice then uses electron difference density mapping reveal bonds and unshared electron pairs and their shape and show that they are only one twentieth dense would expected for Lewis shared pairs Anomalous difference density the carbon fluorine bond raises the course second great question Compared what nnProblem sets Reading assignment nnReading assignments problem sets PowerPoint presentations and other resources for this lecture can accessed from Professor McBride campus course website which was developed for his Fall 2008 students Please see Resources section below nnResources http webspace yale edu chem125 oyc L06 Professor McBride web resources for CHEM 125 Fall 2008 
10453 en Lecture Quantum Mechanical Kinetic Energy After pointing out several discrepancies between electron difference density results and Lewis bonding theory the course proceeds quantum mechanics search fundamental understanding chemical bonding The wave function which beginning students find confusing was equally confusing the physicists who created quantum mechanics The Schrödinger equation reckons kinetic energy through the shape When curves toward zero kinetic energy positive but when curves away kinetic energy negative nnProblem sets Reading assignment nnReading assignments problem sets PowerPoint presentations and other resources for this lecture can accessed from Professor McBride campus course website which was developed for his Fall 2008 students Please see Resources section below nnResources http webspace yale edu chem125 oyc L07 Professor McBride web resources for CHEM 125 Fall 2008 
10454 en Lecture One Dimensional Wave Functions Professor McBride expands the recently introduced concept the wave function illustrating the relationship the magnitude the curvature the wave function the kinetic energy the system well the relationship the square the wave function the electron probability density The requirement that the wave function not diverge areas negative kinetic energy leads only certain energies being allowed property which explored for the harmonic oscillator Morse potential and the Columbic potential Consideration the influence mass reveals isotope effect dynamics the energy vibration frequency and length bonds nnProblem sets Reading assignment nnReading assignments problem sets PowerPoint presentations and other resources for this lecture can accessed from Professor McBride campus course website which was developed for his Fall 2008 students Please see Resources section below nnResources http webspace yale edu chem125 oyc L08 Professor McBride web resources for CHEM 125 Fall 2008 
10455 en Lecture Chladni Figures and One Electron Atoms After showing how double minimum potential generates one dimensional bonding Professor McBride moves multi dimensional wave functions Solving Schrödinger three dimensional differential equation might have been daunting but was not because the necessary formulas had been worked out more than century earlier connection with acoustics Acoustical Chladni figures show how nodal patterns relate frequencies The analogy pursued studying the form wave functions for hydrogen like one electron atoms Removing normalizing constants from the formulas for familiar orbitals reveals the underlying simplicity their shapes nnProblem sets Reading assignment nnReading assignments problem sets PowerPoint presentations and other resources for this lecture can accessed from Professor McBride campus course website which was developed for his Fall 2008 students Please see Resources section below nnResources http webspace yale edu chem125 oyc L09 Professor McBride web resources for CHEM 125 Fall 2008 
10456 en Lecture Reality and the Orbital Approximation discussions the Schrödinger equation thus far the systems described were either one dimensional involved single electron After discussing how increased nuclear charge affects the energies one electron atoms and then discussing hybridization this lecture finally addresses the simple fact that multi electron systems cannot properly described terms one electron orbitals nnProblem sets Reading assignment nnReading assignments problem sets PowerPoint presentations and other resources for this lecture can accessed from Professor McBride campus course website which was developed for his Fall 2008 students Please see Resources section below nnResources http webspace yale edu chem125 oyc L10 Professor McBride web resources for CHEM 125 Fall 2008 
10457 en Lecture Orbital Correction and Plum Pudding Molecules The lecture opens with tricks effective and Self Consistent Field that allow one correct approximately for the error using orbitals that due electron repulsion This error hidden naming correlation energy Professor McBride introduces molecules modifying Thomson Plum Pudding model the atom rationalize the form molecular orbitals There close analogy form between the molecular orbitals CH4 and NH3 and the atomic orbitals neon which has the same number protons and neutrons The underlying form due kinetic energy distorted pulling protons out the nucleus play the role atoms nnProblem sets Reading assignment nnReading assignments problem sets PowerPoint presentations and other resources for this lecture can accessed from Professor McBride campus course website which was developed for his Fall 2008 students Please see Resources section below nnResources http webspace yale edu chem125 oyc L11 Professor McBride web resources for CHEM 125 Fall 2008 
10458 en Lecture Overlap and Atom Pair Bonds This lecture begins applying the united atom plum pudding view molecular orbitals introduced the previous lecture more complex molecules then introduces the more utilitarian concept localized pairwise bonding between atoms Formulating atom pair molecular orbital the sum atomic orbitals creates electron difference density through the cross product that enters upon squaring sum This overlap term the key bonding The hydrogen molecule used illustrate how close simple sum atomic orbitals comes matching reality especially when the atomic orbitals are allowed hybridize nnProblem sets Reading assignment nnReading assignments problem sets PowerPoint presentations and other resources for this lecture can accessed from Professor McBride campus course website which was developed for his Fall 2008 students Please see Resources section below nnResources http webspace yale edu chem125 oyc L12 Professor McBride web resources for CHEM 125 Fall 2008 
10459 en Lecture Overlap and Energy Match Professor McBride uses this lecture show that covalent bonding depends primarily two factors orbital overlap and energy match First discusses how overlap depends hybridization then how bond strength depends the number shared electrons this way quantum mechanics shows that Coulomb law answers Newton query about what makes the Particles Bodies stick together very strong Attractions Energy mismatch between the constituent orbitals shown weaken the influence their overlap The predictions this theory are confirmed experimentally measuring the bond strengths and during heterolysis and homolysis nnProblem sets Reading assignment nnReading assignments problem sets PowerPoint presentations and other resources for this lecture can accessed from Professor McBride campus course website which was developed for his Fall 2008 students Please see Resources section below nnResources http webspace yale edu chem125 oyc L13 Professor McBride web resources for CHEM 125 Fall 2008 
10460 en Lecture Checking Hybridization Theory with XH3 This lecture brings experiment bear the previous theoretical discussion bonding focusing hybridization the central atom three XH3 molecules Because independent electron pairs must not overlap hybridization can related molecular structure simple equation The Umbrella Vibration and the associated rehybridization the central atom used illustrate how competition between strong bonds and stable atoms works create differences molecular structure that discriminate between bonding models Infrared and electron spin resonance experiments confirm our understanding the determinants molecular structure nnProblem sets Reading assignment nnReading assignments problem sets PowerPoint presentations and other resources for this lecture can accessed from Professor McBride campus course website which was developed for his Fall 2008 students Please see Resources section below nnResources http webspace yale edu chem125 oyc L14 Professor McBride web resources for CHEM 125 Fall 2008 
10461 en Lecture Chemical Reactivity SOMO HOMO and LUMO Professor McBride begins using previous examples pathological bonding and the BH3 molecule illustrate how chemist use localized bonds vacant atomic orbitals and unshared pairs understand molecules compares with views based the molecule own total electron density computational molecular orbitals This lecture then focuses understanding reactivity terms the overlap singly occupied molecular orbitals SOMOs and more commonly unusually high energy highest occupied molecular orbital HOMO with unusually low energy lowest unoccupied molecular orbital LUMO This shown generalization the traditional concepts acid and base Criteria for assessing reactivity are outlined and illustrated nnProblem sets Reading assignment nnReading assignments problem sets PowerPoint presentations and other resources for this lecture can accessed from Professor McBride campus course website which was developed for his Fall 2008 students Please see Resources section below nnResources http webspace yale edu chem125 oyc L15 Professor McBride web resources for CHEM 125 Fall 2008 
10462 en Lecture Recognizing Functional Groups This lecture continues the discussion the HOMO LUMO view chemical reactivity focusing ways recognizing whether particular HOMO should unusually high energy basic particular LUMO should unusually low acidic The approach illustrated with BH3 which both acidic and basic and thus dimerizes forming unusual bonds The low LUMOs that make both and CH3F acidic are analyzed and compared underlining the distinction between nodes that derive from atomic orbitals nodes AON and those that are antibonding ABN Reaction acid with shown involve simultaneous bond making and bond breaking nnProblem sets Reading assignment nnReading assignments problem sets PowerPoint presentations and other resources for this lecture can accessed from Professor McBride campus course website which was developed for his Fall 2008 students Please see Resources section below nnResources http webspace yale edu chem125 oyc L16 Professor McBride web resources for CHEM 125 Fall 2008 
10463 en Lecture Reaction Analogies and Carbonyl Reactivity Continuing the examination molecular orbital theory predictor chemical reactivity this lecture focuses the close analogy among seemingly disparate organic chemistry reactions acid base SN2 substitution and elimination All these reactions involve breaking existing bonds where LUMOs have antibonding nodes while new bonds are being formed The three stage oxidation ammonia elemental chlorine analyzed the same terms The analysis extended the reactivity the carbonyl group and predicts the trajectory for attack high HOMO This predicted trajectory was validated experimentally Bürgi and Dunitz who compared numerous crystal structures determined ray diffraction nnProblem sets Reading assignment nnReading assignments problem sets PowerPoint presentations and other resources for this lecture can accessed from Professor McBride campus course website which was developed for his Fall 2008 students Please see Resources section below nnResources http webspace yale edu chem125 oyc L17 Professor McBride web resources for CHEM 125 Fall 2008 
10464 en Lecture Amide Carboxylic Acid and Alkyl Lithium This lecture completes the first half the semester analyzing three functional groups terms the interaction localized atomic pairwise orbitals Many key properties biological polypeptides derive from the mixing such localized orbitals that associate with resonance the amide group The acidity carboxylic acids and the aggregation methyl lithium into solvated tetramers can understood analogous terms More amazing than the panoply modern experimental and theoretical tools that their results would not have surprised traditional organic chemists who already had developed understanding organic structure with much cruder tools The next quarter the semester aimed understanding how our scientific predecessors developed the structural model and nomenclature organic chemistry that still use nnProblem sets Reading assignment nnReading assignments problem sets PowerPoint presentations and other resources for this lecture can accessed from Professor McBride campus course website which was developed for his Fall 2008 students Please see Resources section below nnResources http webspace yale edu chem125 oyc L18 Professor McBride web resources for CHEM 125 Fall 2008 
10465 en Lecture Oxygen and the Chemical Revolution Beginning 1789 This lecture begins series describing the development organic chemistry chronological order beginning with the father modern chemistry Lavoisier The focus understand the logic the development modern theory technique and nomenclature use them more effectively Chemistry begins before Lavoisier Chemical Revolution with the practice ancient technology and alchemy and with discoveries like those Scheele the Swedish apothecary who discovered oxygen and prepared the first pure samples organic acids Lavoisier Traité Élémentaire Chimie launched modern chemistry with its focus facts ideas and words Lavoisier weighed gases and measured heat with calorimeter well clarifying language and chemical thinking His key concepts were conservation mass for the elements and oxidation process which reaction with oxygen could make radical base into acid nnProblem sets Reading assignment nnReading assignments problem sets PowerPoint presentations and other resources for this lecture can accessed from Professor McBride campus course website which was developed for his Fall 2008 students Please see Resources section below nnResources http webspace yale edu chem125 oyc L19 Professor McBride web resources for CHEM 125 Fall 2008 
10466 en Lecture Rise the Atomic Theory 1790 1805 This lecture traces the development elemental analysis technique for the determination the composition organic compounds beginning with Lavoisier early combustion and fermentation experiments which showed new naïve attitude toward handling experimental data Dalton atomic theory was consistent with the empirical laws definite equivalent and multiple proportions The basis our current notation and precise analysis was established Berzelius but confusion about atomic weight multiples which could have been clarified early the law Avogadro and Gay Lussac would persist for more than half century nnProblem sets Reading assignment nnReading assignments problem sets PowerPoint presentations and other resources for this lecture can accessed from Professor McBride campus course website which was developed for his Fall 2008 students Please see Resources section below nnResources http webspace yale edu chem125 oyc L20 Professor McBride web resources for CHEM 125 Fall 2008 
10467 en Lecture Berzelius Liebig and Wöhler 1805 1832 The most prominent chemist the generation following Lavoisier was Berzelius Sweden Together with Gay Lussac Paris and Davy London discovered new elements and improved atomic weights and combustion analysis for organic compounds Invention electrolysis led not only new elements but also the theory dualism with elements being held together electrostatic attraction Wöhler report the synthesis urea revealed isomerism but also persistent naiveté about treating quantitative data their collaborative investigation oil bitter almonds Wöhler and Liebig extended dualism organic chemistry via the radical theory nnProblem sets Reading assignment nnReading assignments problem sets PowerPoint presentations and other resources for this lecture can accessed from Professor McBride campus course website which was developed for his Fall 2008 students Please see Resources section below nnResources http webspace yale edu chem125 oyc L21 Professor McBride web resources for CHEM 125 Fall 2008 
10468 en Lecture Radical and Type Theories 1832 1850 Work Wöhler and Liebig benzaldehyde inspired general theory organic chemistry focusing called radicals collections atoms which appeared behave elements and persist unchanged through organic reactions Liebig French rival Dumas temporarily advocated radicals but converted the competing theory types which could accommodate substitution reactions These decades teach more about the psychology sociology and short sightedness leading chemists than about fundamental chemistry but both theories survive competing schemes modern organic nomenclature The HOMO LUMO mechanism addition alkenes and the SOMO mechanism free radical chain reactions are introduced nnProblem sets Reading assignment nnReading assignments problem sets PowerPoint presentations and other resources for this lecture can accessed from Professor McBride campus course website which was developed for his Fall 2008 students Please see Resources section below nnResources http webspace yale edu chem125 oyc L22 Professor McBride web resources for CHEM 125 Fall 2008 
10469 en Lecture Valence Theory and Constitutional Structure 1858 Youthful chemists Couper and Kekulé replaced radical and type theories with new approach involving atomic valence and molecular structure and based the tetravalence and self linking carbon Valence structures offered the first explanation for isomerism and led the invention nomenclature notation and molecular models closely related those use today nnProblem sets Reading assignment nnReading assignments problem sets PowerPoint presentations and other resources for this lecture can accessed from Professor McBride campus course website which was developed for his Fall 2008 students Please see Resources section below nnResources http webspace yale edu chem125 oyc L23 Professor McBride web resources for CHEM 125 Fall 2008 
10470 en Lecture Determining Chemical Structure Isomer Counting 1869 Half century before direct experimental observation became possible most structures organic molecules were assigned inspired guessing based plausibility But Wilhelm Körner developed strictly logical system for proving the structure benzene and its derivatives based isomer counting and chemical transformation His proof that the six hydrogen positions benzene are equivalent the outstanding example this chemical logic but was widely ignored because Palermo was far from the seats chemical authority nnProblem sets Reading assignment nnReading assignments problem sets PowerPoint presentations and other resources for this lecture can accessed from Professor McBride campus course website which was developed for his Fall 2008 students Please see Resources section below http webspace yale edu chem125 oyc L24 Professor McBride web resources for CHEM 125 Fall 2008 
10471 en Lecture Models Space 1869 1877 Optical Isomers Despite cautions from their conservative elders young chemists like Paternó and van Hoff began interpreting molecular graphs terms the arrangement molecule atoms dimensional space Benzene was one such case but still more significant was the prediction based puzzling isomerism involving optical activity that molecules could chiral that right left handed Louis Pasteur effected the first artificial separation racemic acid into tartaric acid and its mirror image nnProblem sets Reading assignment nnReading assignments problem sets PowerPoint presentations and other resources for this lecture can accessed from Professor McBride campus course website which was developed for his Fall 2008 students Please see Resources section below nnResources http webspace yale edu chem125 oyc L25 Professor McBride web resources for CHEM 125 Fall 2008 
10472 en Lecture Van Hoff Tetrahedral Carbon and Chirality With his tetrahedral carbon models van Hoff explained the mysteries known optical isomers possessing stereogenic centers and predicted the existence chiral allenes class molecules that would not observed for another sixty one years Symmetry operations that involve inverting odd number coordinate axes interconvert mirror images Like printed words only small fraction molecules are achiral Verbal and pictorial notation for stereochemistry are discussed nnProblem sets Reading assignment nnReading assignments problem sets PowerPoint presentations and other resources for this lecture can accessed from Professor McBride campus course website which was developed for his Fall 2008 students Please see Resources section below nnResources http webspace yale edu chem125 oyc L26 Professor McBride web resources for CHEM 125 Fall 2008 
10473 en Lecture Communicating Molecular Structure Diagrams and Words important that chemists agree notation and nomenclature order communicate molecular constitution and configuration best when diagram faithful possible the dimensional shape molecule but the conventional Fischer projection which has been indispensable understanding sugar configurations for over century involves highly distorted bonds Ambiguity diagrams words has led multibillion dollar patent disputes involving popular drugs International agreements provide descriptive unambiguous unique systematic IUPAC names that are reasonably convenient for most organic molecules modest molecular weight nnProblem sets Reading assignment nnReading assignments problem sets PowerPoint presentations and other resources for this lecture can accessed from Professor McBride campus course website which was developed for his Fall 2008 students Please see Resources section below nnResources http webspace yale edu chem125 oyc L27 Professor McBride web resources for CHEM 125 Fall 2008 
10474 en Lecture Stereochemical Nomenclature Racemization and Resolution Determination the actual atomic arrangement tartaric acid 1949 motivated change stereochemical nomenclature from Fischer 1891 genealogical convention the CIP scheme based conventional group priorities Configurational isomers can interconverted racemization and epimerization Pure enantiomers can separated from racemic mixtures resolution schemes based selective crystallization conglomerates temporary formation diastereomers nnProblem sets Reading assignment nnReading assignments problem sets PowerPoint presentations and other resources for this lecture can accessed from Professor McBride campus course website which was developed for his Fall 2008 students Please see Resources section below nnResources http webspace yale edu chem125 oyc L28 Professor McBride web resources for CHEM 125 Fall 2008 
10475 en Lecture Preparing Single Enantiomers and the Mechanism Optical Rotation Within lecture biological resolution the synthesis single enantiomers and the naming and visualization omeprazole Professor Laurence Barron the University Glasgow delivers guest lecture the subject how chiral molecules rotate polarized light Mixing wave functions coordinated application light perpendicular electric and magnetic fields shifts electrons along helix that can right left handed but many mixings are involved and their magnitudes are subtle that predicting net optical rotation practical cases rarely simple nnProblem sets Reading assignment nnReading assignments problem sets PowerPoint presentations and other resources for this lecture can accessed from Professor McBride campus course website which was developed for his Fall 2008 students Please see Resources section below nnResources http webspace yale edu chem125 oyc L29 Professor McBride web resources for CHEM 125 Fall 2008 
10476 en Lecture Esomeprazole Example Drug Testing and Usage The chemical mode action omeprazole expected insensitive its stereochemistry making clinical trials the proposed virtues chiral switch crucial Design the clinical trials discussed the context marketing Otolaryngologist Dianne Duffey provides clinician perspective the testing and marketing pharmaceuticals the FDA approval process clinical trial system off label uses and individual and institutional responsibility for evaluating pharmaceuticals nnProblem sets Reading assignment nnReading assignments problem sets PowerPoint presentations and other resources for this lecture can accessed from Professor McBride campus course website which was developed for his Fall 2008 students Please see Resources section below nnResources http webspace yale edu chem125 oyc L30 Professor McBride web resources for CHEM 125 Fall 2008 
10477 en Lecture Preparing Single Enantiomers and Conformational Energy After mentioning some legal implications chirality the discussion configuration concludes using esomeprazole example three general methods for producing single enantiomers Conformational isomerism more subtle because isomers differ only rotation about single bonds which requires careful physico chemical consideration energies and their relation equilibrium and rate constants Conformations have their own notation and nomenclature Curiously the barrier rotation about the bond ethane was established measuring its heat capacity nnProblem sets Reading assignment nnReading assignments problem sets PowerPoint presentations and other resources for this lecture can accessed from Professor McBride campus course website which was developed for his Fall 2008 students Please see Resources section below nnResources http webspace yale edu chem125 oyc L31 Professor McBride web resources for CHEM 125 Fall 2008 
10478 en Lecture Stereotopicity and Baeyer Strain Theory Why ethane has rotational barrier still debatable Analyzing conformational and configurational stereotopicity relationships among constitutionally equivalent groups reveals subtle discrimination enzyme reactions When Baeyer suggested strain induced reactivity due distorting bond angles away from those ideal tetrahedron assumed that the cyclohexane ring flat was soon corrected clever Sachse but Sachse weakness rhetoric led quarter century confusion nnProblem sets Reading assignment nnReading assignments problem sets PowerPoint presentations and other resources for this lecture can accessed from Professor McBride campus course website which was developed for his Fall 2008 students Please see Resources section below nnResources http webspace yale edu chem125 oyc L32 Professor McBride web resources for CHEM 125 Fall 2008 
10479 en Lecture Conformational Energy and Molecular Mechanics Understanding conformational relationships makes easy draw idealized chair structures for cyclohexane and visualize axial equatorial interconversion After quantitative consideration the conformational energies ethane propane and butane cyclohexane used illustrate the utility molecular mechanics alternative quantum mechanics for estimating such energies give useful accuracy this empirical scheme requires thousands arbitrary parameters Unlike quantum mechanics assigns strain specific sources such bond stretching bending and twisting and van der Waals repulsion attraction nnProblem sets Reading assignment nnReading assignments problem sets PowerPoint presentations and other resources for this lecture can accessed from Professor McBride campus course website which was developed for his Fall 2008 students Please see Resources section below nnResources http webspace yale edu chem125 oyc L33 Professor McBride web resources for CHEM 125 Fall 2008 
10480 en Lecture Sharpless Oxidation Catalysts and the Conformation Cycloalkanes Professor Barry Sharpless Scripps describes the Nobel prizewinning development titanium based catalysts for stereoselective oxidation the mechanism their reactions and their use preparing esomeprazole Conformational energy cyclic alkanes illustrates the use molecular mechanics nnProblem sets Reading assignment nnReading assignments problem sets PowerPoint presentations and other resources for this lecture can accessed from Professor McBride campus course website which was developed for his Fall 2008 students Please see Resources section below nnResources http webspace yale edu chem125 oyc L34 Professor McBride web resources for CHEM 125 Fall 2008 
10481 en Lecture Understanding Molecular Structure and Energy through Standard Bonds Although molecular mechanics imperfect useful for discussing molecular structure and energy terms standard covalent bonds Analysis the Cambridge Structural Database shows that predicting bond distances within required detailed categorization bond types Early attempts predict heats combustion terms composition proved adequate for physiology but not for chemistry Group bond additivity schemes are useful for understanding heats formation especially when corrected for strain Heat atomization the natural target for bond energy schemes but experimental measurement requires spectroscopic determination the heat atomization elements their standard states nnProblem sets Reading assignment nnReading assignments problem sets PowerPoint presentations and other resources for this lecture can accessed from Professor McBride campus course website which was developed for his Fall 2008 students Please see Resources section below nnResources http webspace yale edu chem125 oyc L35 Professor McBride web resources for CHEM 125 Fall 2008 
10482 en Lecture Bond Energies the Boltzmann Factor and Entropy After discussing the classic determination the heat atomization graphite Chupka and Inghram the values bond dissociation energies and the utility average bond energies the lecture focuses understanding equilibrium and rate processes through statistical mechanics The Boltzmann factor favors minimal energy order provide the largest number different arrangements bits energy The slippery concept disorder illustrated using Couette flow Entropy favors disordered arrangements because there are more them than there are recognizable ordered arrangements nnProblem sets Reading assignment nnReading assignments problem sets PowerPoint presentations and other resources for this lecture can accessed from Professor McBride campus course website which was developed for his Fall 2008 students Please see Resources section below nnResources http webspace yale edu chem125 oyc L36 Professor McBride web resources for CHEM 125 Fall 2008 
10851 en Morphology and Characteristics the Advanced Electro Ceramics Remarkable progress the electronics components enabled the tremendous development the recent electronics devices particular the electro ceramics has played important role cooperate with the circuits The major subjects for the components have been functionality miniaturization volumetric efficiency reliability safety materials and lower price nnSeveral research works morphology designing the ceramics has been done develop the new components with higher performance The functionality the electronics devices has been developed using specific morphologies the ceramics such bulk Dimention plate fiber and particle Device designing has been remarkably progressed cooperate with ceramic materials and process technologies nnMultilayer most popular technology design the ceramics devices consist dielectric piezo electric magnetic semiconductor and insulator ceramics How can prepare the thinner dielectric layer than 3mm most important work for the ceramic capacitor engineering Miniaturized module circuits are realized embedding the passive components into the multiplayer ceramic and polymer substrates nnMorphology control the ceramic structure such core shell and arrangements crystal axis has been developed improve the electric performances enhance the piezoelectricity the non lead ferroelectric materials textured grain orientation and ultra high magnetic field application are known useful process methods nnSelf assembling the nano particles challenging technology build the super lattice structure and tailoring the more functional materials and devices Preparation and characterization the ceramic nano particles are presented 
10855 en Anatomy Financial Crisis Much the recent financial crisis originates from the common practice financial firms making investments with large sums borrowed money leverage The collateral for these borrowed funds usually put the form financial assets which are far from being ’solid’ values The dependence the value collateral asset prices often the heart credit crisis simple agent based model study ’ecology’ financial players such informed noise traders informed funds banks and investors hedge funds This model economy allows identify the effects leverage the stability the financial system becomes possible understand how minor random fluctuations can trigger financial crisis eventually leading the collapse the entire system The main message that novel means monitoring specific collection financial indicators could used foresee the likelihood for the development crisis and meltdown 
10856 en Space Research Europe Europe had joined forces more than three decades ago creating the European Space Agency ESA Today the commercially most successful launcher european and our space research and technology cutting edge Our spacecraft observe the earth study the Universe and orbit other planets nnThese achievements build coherent approach which ESA plays major role Two major scientific satellites have been launched this year Herschel the largest telescope yet launched mankind and Planck which looking back the dawn time Examples recent results will presented and view future missions will given The lecture will cast some light onto the structure and working ESA and its interactions with european industry and research institutions 
10862 en Recommendations for modified binder usage pavement
10875 en Lecture Welcome CS106A welcome CS106A you don think you should CS106A you think younshould somewhere different now probably good time not that wouldndiscourage anyone from taking this class think have lovely time here But thisnclass CS106A E70A you like Wait thought was E70A you fine nThey the same class the same thing worries okay nnSee the whole transcript http see stanford edu materials icspmcs106a transcripts ProgrammingMethodology Lecture01 pdf Programming Methodology Lecture 
10876 en Lecture Handout Information Alrighty welcome back CS106A you stuck thenback just come down have seat Originally thought maybe would havenslightly fewer people today than last time but that appears not the case whilenwe waiting everyone loves babies decided put – that Karel the Robot thenearly days nnSee the whole transcript http see stanford edu materials icspmcs106a transcripts ProgrammingMethodology Lecture02 pdf Programming Methodology Lecture 
10877 en Lecture Karel and Java Couple quick announcements before dive into things nThere one handout which hopefully you should have gotten will contain the Karelnexample did class last time the steeple chase well some more examples thatnwe gonna over this time But encourage you actually pay attention what wendo class rather than sort looking the handout because one thing that alwaysntrue about programs once you see the solution program easy lull yourselfninto thinking could have done that seems easy nnSee the whole transcript http see stanford edu materials icspmcs106a transcripts ProgrammingMethodology Lecture03 pdf Programming Methodology Lecture 
10878 en Lecture The History Computing welcome back Now ’ officially started with thenclass hope you had good weekend was just asking people before class what kind ofnstuff they did this weekend anyone wants come early ’ just engage innrandom conversation nnSee the whole transcript http see stanford edu materials icspmcs106a transcripts ProgrammingMethodology Lecture04 pdf Programming Methodology Lecture 
10879 en Lecture Variables All righty Let’ ahead and get started couple ofnquick announcements before start today – hopefully you’ all busy working awaynon Karel and life good Just quick poll – how many people have actually finished Karelnalready yeah won’ ask how many people have not yet downloaded Eclipse Therenare handouts today Getting’ little breather – handouts Don’ worry you’ getnsome more that next time nnSee the whole transcript http see stanford edu materials icspmcs106a transcripts ProgrammingMethodology Lecture05 pdf Programming Methodology Lecture 
10880 en Lecture readInt and readDouble All righty want take quick pain pole before start let’ actually dive intonthe real sort meaningful things What the pain pole really – remember asked you tonthink about how much time actually took you the assignment total overnall the Karel problems how many total hours think about took you actually thenassignment Right And ’ just going through and quick show hands nnSee the whole transcript http see stanford edu materials icspmcs106a transcripts ProgrammingMethodology Lecture06 pdf Programming Methodology Lecture 
10881 en Lecture The Loop and Half Problem All right one real quick point before dive into the main meat the lecture ’snjust clarification something did last time called The Cast remember last timenwhere had cast which was this thing that allowed say treat this one data point nor this one data item this one variable different type for one particular operation nnSee the whole transcript http see stanford edu materials icspmcs106a transcripts ProgrammingMethodology Lecture07 pdf Programming Methodology Lecture 
10882 en Lecture Information Hiding Alrighty Welcome back yet another day CS106a nCouple quick announcements before start – first announcement there onenhandout which ’ not sure ’ here yet but will here momentarily ’ not herennow You can pick the way out think Ben might have just been delayed thenway there one handout hopefully you can pick the way out youndidn’ see back there now ’ already posted online well you don’ get innclass you can get online you can get – there’ the Handout Hangout like tonrefer which bunch file folders the first floor Gates where there’snhardcopies all the handouts that get left over from class nnSee the whole transcript http see stanford edu materials icspmcs106a transcripts ProgrammingMethodology Lecture08 pdf Programming Methodology Lecture 
10883 en Lecture Strings couple quick announcements One that there two handouts one codingnstyle and one the use variables encourage you read both them becausenthey are both extremely critical concepts this class There are some things that – snlike Yeah not important These two are really important please make sure tonread the handout nnSee the whole transcript http see stanford edu materials icspmcs106a transcripts ProgrammingMethodology Lecture09 pdf Programming Methodology Lecture 
10884 en Lecture Importance Private Variables Okay would just even this point just email text nMight easier think need get started nLet’ ahead and get started Couple quick announcements before start one ofnthem that there are three handouts the back including your next assignment Andnyour next assignment’ little game called Breakout How many people have ever heardnof game called Breakout nnSee the whole transcript http see stanford edu materials icspmcs106a transcripts ProgrammingMethodology Lecture10 pdf Programming Methodology Lecture 
10885 en Lecture The GImage Class couple quick announcements before dive into things There two handouts today nThere whole bunch coding examples There coding examples the wazoo nThey sort like – gave you bunch code that might just useful for you looknout for Breakout just because good times nnSee the whole transcript http see stanford edu materials icspmcs106a transcripts ProgrammingMethodology Lecture11 pdf Programming Methodology Lecture 
10886 en Lecture Enumeration welcome back yet another fun filled exciting day ofnCS106A couple quick announcements before start There’ actually handoutsnfor today and you’ like there’ handouts for today why are there two handouts innthe back you already picked the two handouts from last class you might want tondouble check make sure you don’ already have them but you don’ have them feelnfree pick them just don’ want cut down any more trees than need sonif you accidentally picked them you can put them back the end the class passnthem friend whatever you’ like nnSee the whole transcript http see stanford edu materials icspmcs106a transcripts ProgrammingMethodology Lecture12 pdf Programming Methodology Lecture 
10887 en Lecture String Processing And now since getting the middle the quarter ’ that time for the mid termnto coming fact the mid term next week ’ week from Tuesday Inknow The quarters quickly you have conflict with the mid term and bynconflict mean unmovable academic conflict nnSee the whole transcript http see stanford edu materials icspmcs106a transcripts ProgrammingMethodology Lecture13 pdf Programming Methodology Lecture 
10888 en Lecture Memory The other two handouts are the practice midterm and practice midterm solutions thosenwill also here the end class That will give you whole bunch details about thenmidterm and what the midterm actually covers but will also give you examples realnexam problems that have been given the past you can work them thentime you know time sort setting you can see what you’ slow and what you’renfast But ’ kind flavor very similar what the real exam’ gonna termsnof what covers the kind complexity the problems cetera you can get thatnafter class nnSee the whole transcript http see stanford edu materials icspmcs106a transcripts ProgrammingMethodology Lecture14 pdf Programming Methodology Lecture 
10889 en Lecture Pointer Recap But few announcements before delve into things today The handouts from last time nif you didn’ get the handouts from last time namely especially the practice midterm andnsolutions the practice midterm well assignment you didn’ get those nthey’ available the back today you already got them you don’ need pick upnadditional copies There’ additional handouts for today but there are just copies ofnthe ones from last week nnSee the whole transcript http see stanford edu materials icspmcs106a transcripts ProgrammingMethodology Lecture15 pdf Programming Methodology Lecture 
10890 en Lecture Array ’ the day before the midterm This kind like you know the calm before – wellnI shouldn’ even say the calm before the storm ’ probably lot more calm for menthan for you But hopefully you’ getting prepared for the midterm fewnannouncements before start nnSee the whole transcript http see stanford edu materials icspmcs106a transcripts ProgrammingMethodology Lecture16 pdf Programming Methodology Lecture 
10891 en Lecture Multi dimensional Arrays All right welcome back yet another fun fillednexciting day cs106a couple quick announcements before start First which nthere one handout which kind quick reference for you ArrayLists ’ sort ofnall the ArrayLists you need know for the hangman assignment part three younhaven’ already done now you have quickie reference for you’ already donenit you don’ need the quickie reference but presumably you saw everything you needednalready the textbook what did last time class nnSee the whole transcript http see stanford edu materials icspmcs106a transcripts ProgrammingMethodology Lecture17 pdf Programming Methodology Lecture 
10892 en Lecture Wrap Multi dimensional Arrays You – one the handouts also solutions for the midterm and you can – you gotnanything wrong you can compare your answers with the solutions One thing also keepnin mind that the actual solutions were looking for are shorter than the solutions thatnI give you The solutions that give you have comments For one the problems Inactually gave you two different ways doing just you see different approaches Butnyou weren expected actually write that much code All wanted was sort thencode without the comments which actually pretty slim you consider how much codenthere there without comments But you get those back after class nnSee the whole transcript http see stanford edu materials icspmcs106a transcripts ProgrammingMethodology Lecture18 pdf Programming Methodology Lecture 
10893 en Lecture Interface Howdy welcome back yet another fun filled nexciting day CS106A don’ know there’ any days actually started where Indidn’ say that don’ know Someday should back and watch the video Butnthey’ all fun filled and exciting aren’ they ’ not like false advertising There’snno handouts today little breather after the four handouts you got last time And anothernquick announcement you didn’ pick your midterm already you can pick nThey’ along the back wall over there alphabetical order hopefully you can pick itnup you haven’ already gotten yours you’ SITN student and you’ worryingnabout where you can get your midterm will sent back you through the SITNncourier unless you come into class and you picked which case won’ sentnback you because then you already have nnSee the whole transcript http see stanford edu materials icspmcs106a transcripts ProgrammingMethodology Lecture19 pdf Programming Methodology Lecture 
10894 en Lecture GUI give you appropriate incentive for this what going when you turnnthem Ben and are going look through them going take first pass andntake sub set them that think are the best Then have the section leaders innthe class collectively vote what the winners are both the categories You get atnmost one entry Your entry you don have designate for category look atnevery entry being entered both categories You just get one entry nnSee the whole transcript http see stanford edu materials icspmcs106a transcripts ProgrammingMethodology Lecture20 pdf Programming Methodology Lecture 
10895 en Lecture Review Interactors and Listeners There two handouts today One handout your section handout for this week Sectionsnare still happening this week The other handout some code interactors that you sawnlast time well some additional code that over today interactors Othernannouncement computer science career panel just quick show hands how manynpeople are thinking about computers science major nnSee the whole transcript http see stanford edu materials icspmcs106a transcripts ProgrammingMethodology Lecture21 pdf Programming Methodology Lecture 
10896 en Lecture Overview NameSurfer The Next Assignment Howdy welcome back yet another fun filled nexciting day CS106a ’ getting close that Thanksgiving recess which alwaysna good time the days yore used not whole week used you got likenone two days off You got like Thursday and Friday which means you would havengotten only one day off from this class and now you get whole week mellow stylenor catch all your other work the case may nnSee the whole transcript http see stanford edu materials icspmcs106a transcripts ProgrammingMethodology Lecture22 pdf Programming Methodology Lecture 
10897 en Lecture Introduction Lecture material Searching You may wondering who would have thought before got back mid quarternevaluations that you stood chance recognizing the your class but thencomment more than half the people who responded the question how Benndoing was “ don’ know Ben ’ never interacted with Ben assume ’ doing angreat job ” nnSee the whole transcript http see stanford edu materials icspmcs106a transcripts ProgrammingMethodology Lecture23 pdf Programming Methodology Lecture 
10898 en Lecture Principles Good Software Engineering for Managing Large Amounts Data couple quick announcements before get into things One there one handout nwhich your section handout for this week And kind one the themes this weeknis bigness some sense writing bigger programs bigger data structures that’ the wholendeal And ’ kind talk about that along nnSee the whole transcript http see stanford edu materials icspmcs106a transcripts ProgrammingMethodology Lecture24 pdf Programming Methodology Lecture 
10899 en Lecture Defining Social Network for Our Purposes welcome back another fun filled exciting day ofncs106a couple quick announcements before start First announcement there twonhandouts One those handouts which spend some time talking about today isnyour last assignment for the class which assignment worth noting sort ofntalked about the very first day class when talked about late days The very firstnhandout says late days can used assignment that’ important tonremember late days can used for assignment because due the last day ofnthe class nnSee the whole transcript http see stanford edu materials icspmcs106a transcripts ProgrammingMethodology Lecture25 pdf Programming Methodology Lecture 
10900 en Lecture Introduction the Standard Java Libraries The graphics context for those you who are doing due today Just wondering nquick show hands how many people entered the graphics contest Wow Not manynas would thought There could couple people who are home even you don tnwin getting 100 the final random drawing that good sign nnSee the whole transcript http see stanford edu materials icspmcs106a transcripts ProgrammingMethodology Lecture26 pdf Programming Methodology Lecture 
10901 en Lecture Life After CS106A welcome back Wow That’ little loud our lastnweek cs106a course another fun filled exciting day despite being our lastnweek ’ getting down the end have class today there’ class Wednesday nthere’ class Friday next time will our last day But few announcements nThere’ actually just load announcements because ’ close the end thenquarter First announcement there’ one handout which your section handout for thisnweek There are still sections this week despite the fact that don’ have class onnFriday still your sections this week nnSee the whole transcript http see stanford edu materials icspmcs106a transcripts ProgrammingMethodology Lecture27 pdf Programming Methodology Lecture 
10902 en Lecture The Graphics Contest Winners there’ two handouts today the last two handouts except for the final exam which arena practice final and the solutions for the practice final The problems that are that arenactually taken from – most them Some them were written just for that but most ofnthem were taken from actual final exams the past just like the midterm shouldngive you chance get notion what kind questions would ask what sort ofntopical coverage there would the level difficulty and ’ left the blank pages outnof the exam just save trees but would have space the exam for you actuallyntake nnSee the whole transcript http see stanford edu materials icspmcs106a transcripts ProgrammingMethodology Lecture28 pdf Programming Methodology Lecture 
10958 en Lecture Course Overview introduction robotics are going really covernthe foundations robotics That are going look mathematical models thatnrepresent robotic systems many different ways fact you just saw simulation anhumanoid robotic system that are controlling the same time you think about anmodel that you are going use for the simulation you need represent the kinematicsnof the system You need also able actuate the system going the motors andnfinding the right torques make the robot move nnSee the whole transcript http see stanford edu materials aiircs223a transcripts IntroductionToRobotics Lecture01 pdf Programming Introduction Robotics Lecture 
10959 en Lecture Spatial Descriptions Then obviously when determine the location link need able transformnthat description the next link describe the position and orientation the endeffectornin our previously link need really handle transformations Then neednto discuss how represent the position and orientation There are many different waysnthrough which can describe position orientation and will discuss fewndifferent representations nnSee the whole transcript http see stanford edu materials aiircs223a transcripts IntroductionToRobotics Lecture02 pdf Introduction robotics Lecture 
10962 en Lecture Summary Frame Attachment The moving style Gibbons shown this video isncalled brachiation The brachiation robot dynamically mobile robot modeled thenGibbon moves from branch branch swinging its body like them The brachiationnrobot which have developed has two arms and body The total length one meternand the total weight kilograms The arms and grippers are actuated with motorsnthrough harmonic drive gears This the movement without actuation first the robotndoesn’ know how move all nnSee the whole transcript http see stanford edu materials aiircs223a transcripts IntroductionToRobotics Lecture05 pdf Introduction robotics Lecture 
10963 en Lecture Instantaneous Kinematics Polypod reconfigurable module robot ’ made two types modules callednsegments and nods Segments are two degree freedom modules with two motors forcenand position sensing and microcomputer board Nods are inaudible shapednhousings for batteries Segments may mounted parallel each other they may benmounted perpendicular each other Modules may also attach any face nod nSimple locomotion gaits are statically stable gaits that move along straight line nnSee the whole transcript http see stanford edu materials aiircs223a transcripts IntroductionToRobotics Lecture06 pdf Introduction robotics Lecture 
10964 en Lecture Jacobian Explicit Form Future robots are going work your houses and hospitals with humans Toshiba hasndeveloped beach ball volley playing robot demonstration such human friendlynrobot technology consider that essential interact with robots using everydaynwords such let’ play volleyball For the everyday word commands work the robotnneeds measure the target’ relative position with respect the robot position knownthe mechanics and procedures the tasks and have good database for thenenvironment and the target nnSee the whole transcript http see stanford edu materials aiircs223a transcripts IntroductionToRobotics Lecture07 pdf Introduction robotics Lecture 
10965 en Lecture Scheinman Arm Demo inaudible have developed and tested automatic parallel parking and pulling outnmaneuvers experimental electric car The car can driven manually movenautonomously with automatic steering and velocity control equipped with variousnsensors including sonars monitor its surroundings nnSee the whole transcript http see stanford edu materials aiircs223a transcripts IntroductionToRobotics Lecture08 pdf Introduction robotics Lecture 
10966 en Lecture Intro Guest Lecturer Gregory Hager Okay Let’ get started today ’ really greatnopportunity for all have guest lecturer One the leaders robotics vision AnGregory Hager from John Hopkins who will giving this guest lecture Monday Inwanted mention that Wednesday have the mid term class Tonight andntomorrow have the review sessions think everyone has signed for thosensessions And next Wednesday the lecture will given former student fromnStanford University Krasimir Kolarov who will giving the lecture trajectories andninverse kinematics welcome back nnSee the whole transcript http see stanford edu materials aiircs223a transcripts IntroductionToRobotics Lecture09 pdf Introduction robotics Lecture 
10967 en Lecture Guest Lecturer Krasimir Kolarov Good afternoon name Krasimir Kolarov amngoing teaching the lecture today and also the author the notes for the course nSo you have any complaints direct you have any praises direct tonOussama did inaudible here Stanford about years ago was yournshoes and ’ been kinda doing few lectures well some the classes completelynsince ’ not working the robotics area right now but ’ staying pretty current innthat nnSee the whole transcript http see stanford edu materials aiircs223a transcripts IntroductionToRobotics Lecture10 pdf Introduction robotics Lecture 
10968 en Lecture Joint Space Dynamics the second tier the Ranger Rangers are larger robots used transport deploy andncoordinate the Scouts Scouts are wholly original robots with cylindrical bodies 40nmillimeters diameter and 110 millimeters length The Scout carries sensor payloadnused relay environmental information other robots The most common Scoutnpayload small video camera but other payloads such microphones are also used nVideo data broadcast other systems via analog transmitter Scoutsncommunicate with other robots using data link nnSee the whole transcript http see stanford edu materials aiircs223a transcripts IntroductionToRobotics Lecture11 pdf Introduction robotics Lecture 
10969 en Lecture Lagrange Equations Autonomous mobile robots have become key technology for unmanned planetarynmissions cope with the rough terrain encountered most the planets interest nnew locomotion concepts for rovers and micro rovers have developed andninvestigated this video sequence present innovative off road rover able tonpassively overcome unstructured obstacles two times its wheel diameter Using anrhombus configuration this rover has one wheel mounted fork the front onenwheel the rear and two bogies each side nnSee the whole transcript http see stanford edu materials aiircs223a transcripts IntroductionToRobotics Lecture12 pdf Introduction robotics Lecture 
10970 en Lecture Control Overview Okay who’ interested juggling Well those whonare interested juggling could try next quarter Experimental Robotics fact lotnof the projects Experimental Robotics involve dynamic skills throwing ball into anbasket playing ping pong whatever juggling quite challenging actually Well njuggling requires control and here are this little bit concept that arengoing see over the discussions control And the concept instead really thinkingnabout the robot programmable machine where you need find all the join motionsncorresponding your task you want move some location and you want benable reach that location with some orientation your vector nnSee the whole transcript http see stanford edu materials aiircs223a transcripts IntroductionToRobotics Lecture13 pdf Introduction robotics Lecture 
10971 en Lecture Control Well yeah sometimes you mean human – tactilensensing amazing you have the static information you grab something now thenwhole surface contact and you can determine the shape right what does meannin term like designing tactile sensor just you think about the static case nnSee the whole transcript http see stanford edu materials aiircs223a transcripts IntroductionToRobotics Lecture14 pdf Introduction robotics Lecture 
10972 en Lecture Manipulator Control Okay you can imagine maybe sort resistive orncapacitive sensor that will deflect little bit and give you that information How many ofnthose you would need You need sort array right how large like let’ say thisnis the end factor ’ trying see you did that problem – you’ going have lotnof information here and you need take back and you have lot wires you have anmatrix and you’ going have lot basically information transmit thendesign tactile sensors being this problem how can put enough sensors and hownwe can extract this information and take back these guys came with anninteresting idea here nnSee the whole transcript http see stanford edu materials aiircs223a transcripts IntroductionToRobotics Lecture15 pdf Introduction robotics Lecture 
10973 en Lecture Compliance this video about very important aspect robotics which isncompliant motion You see the sponge pushing and you see reflection onnthe sponge right That means there force applied Here are coming ansurface that unknown and the robot sliding over the surface makingncontact different points even remove the whole object Now here wavynsurface that being followed just saying press down and move the right ncleaning window without breaking very important nnSee the whole transcript http see stanford edu materials aiircs223a transcripts IntroductionToRobotics Lecture16 pdf Introduction robotics Lecture 
10974 en Lecture Previous Knowledge Recommended Matlab are the air Okay Welcome one and all And saidnon the when you were walking but just make sure everybody knows this isnEE261 The Fourier Transform and its Applications Fourier Transforms Fourier nAnd name Brad Osgood nnSee the whole transcript http see stanford edu materials lsoftaee261 transcripts TheFourierTransformAndItsApplications Lecture01 pdf The Fourier Transform and its ApplicationsnCo Lecture 
10975 en Lecture Periodicity How Sine And Cosine Can Used Model More Complex Functions Second – our second main – our third main thing would the office hours for the ’snhave been set Information available the course website under the link coursenstaff You’ see the left hand side there’ link course staff and our individualnoffice hours have been set and they will start Monday October 1st nnSee the whole transcript http see stanford edu materials lsoftaee261 transcripts TheFourierTransformAndItsApplications Lecture02 pdf The Fourier Transform and its ApplicationsnCo Lecture 
10976 en Lecture Summary Previous Lecture Analyzing General Periodic Phenomena Sum Simple Periodic Phenomena last time say took the first step analyzing general periodic phenomena via thensum several combination linear combination simple building blocks simplenperiodic phenomena let remind you what did because ’ very important thatnyou realize what did and what didn’ said suppose that you can write anperiodic signal certain form what has happen start off saying angiven periodic function periodic signal Function signal same thing And just bendefinite took have period one all right And the question can representednin terms others and suppose can represented terms other simple signals ofnperiod one namely the complex exponential nnSee the whole transcript http see stanford edu materials lsoftaee261 transcripts TheFourierTransformAndItsApplications Lecture03 pdf The Fourier Transform and its ApplicationsnCo Lecture 
10977 en Lecture Wrapping Fourier Series Making Sense Infinite Sums And Convergence doesn’ work anything else except – use the Mac thenword from over there you have use Safari which the one that comes with And Indon’ know about other ones Anybody else have issues with this can find out and cannpost announcement suppose nnSee the whole transcript http see stanford edu materials lsoftaee261 transcripts TheFourierTransformAndItsApplications Lecture04 pdf The Fourier Transform and its ApplicationsnCo Lecture 
10978 en Lecture Continued Discussion Fourier Series And The Heat Equation But you find yourself wanting fill those last minute comments would say that –nthe policy the homework should due Wednesday and you can turn innto the magic filing cabinet Across from office – office 271 Packard and there’sna little hallway sort across from there and there are several gray filing cabinets one ofnwhich has name and the course number nnSee the whole transcript http see stanford edu materials lsoftaee261 transcripts TheFourierTransformAndItsApplications Lecture05 pdf The Fourier Transform and its ApplicationsnCo Lecture 
10979 en Lecture Correction Heat Equation Discussion First thing want say that made little mistake last time lecture was gentlynpointed out When was talking about the heat equation the floorshow was fine nthe discussion was fine but then said this thing about tens infinity thentemperature tens zero That wasn’ right forgot about the zero – because somebodynsaid look the fusion man you don’ lose anything just diffuses ’ not right saynthe temperature changes zero was thinking while was escaping the universenor something like that nnSee the whole transcript http see stanford edu materials lsoftaee261 transcripts TheFourierTransformAndItsApplications Lecture06 pdf The Fourier Transform and its ApplicationsnCo Lecture 
10980 en Lecture Review Fourier Transform And Inverse Definitions again signal and the Fourier Transform function same thing the FouriernTransform use this notation want comment about that again just second nIntegral from infinity – infinity either the and the inversenFourier Transform looks very similar except for change sign the exponential Sonthe inverse Fourier Transform – use different function although doesn’ matter nWe’ gonna from either the okay nnSee the whole transcript http see stanford edu materials lsoftaee261 transcripts TheFourierTransformAndItsApplications Lecture07 pdf The Fourier Transform and its ApplicationsnCo Lecture 
10981 en Lecture Effect Fourier Transform Shifting Signal that what gonna today going down more the second path includingnan extremely important operation gonna have three big items today each ofnwhich are important themselves and come all the time One delays what donwith Fourier transform when the signal delayed One formula for what happens tonthe Fourier transform under stretch and finally very general operation which wenhave now seen couple times different forms but today gonna see them today innthe context the Fourier transform its full glory speak and that convolution nnSee the whole transcript http see stanford edu materials lsoftaee261 transcripts TheFourierTransformAndItsApplications Lecture08 pdf The Fourier Transform and its ApplicationsnCo Lecture 
10982 en Lecture Continuing Convolution Review The Formula Now this picture you see not much you see couple examples You see angenerally periodic phenomenon but you see lot jaggedness there you see lot ofnjaggedness the picture like said the horizontal scale time think periodnof months and the vertical scale whatever And you certainly see periodicnphenomenon here but noisy jagged nnSee the whole transcript http see stanford edu materials lsoftaee261 transcripts TheFourierTransformAndItsApplications Lecture09 pdf The Fourier Transform and its ApplicationsnCo Lecture 
10984 en Lecture Central Limit Theorem And Convolution Main Idea All right Big day today going talk about – going our finalnapplication convolution suppose shouldn say final application convolution”nbecause the kind operation that comes repeatedly throughout the course Butnsort the – last treatment the kind areas been talking about wannantalk about application convolution the central limit theorem nnSee the whole transcript http see stanford edu materials lsoftaee261 transcripts TheFourierTransformAndItsApplications Lecture10 pdf The Fourier Transform and its ApplicationsnCo Lecture 
10985 en Lecture Correction The End The CLT Proof There’ single function which describes how each one them distributed nSo ’ distribution for each And then formed was the distribution for thensum scaled square root ’ the average – excuse There was somenassumption made the normalation that assume they had mean zeronand assume they had standard deviation variance one and then you form thensum the mean the sum zero but the standard deviation the variant centerndeviation the sum the square root ’ scaled the square root nnSee the whole transcript http see stanford edu materials lsoftaee261 transcripts TheFourierTransformAndItsApplications Lecture11 pdf The Fourier Transform and its ApplicationsnCo Lecture 
10986 en Lecture Cop Story They infinitely differentiable and any derivative decays faster than any power Inwill write that down First all Phi infinitely differentiable smooth youncould want has many derivatives you could want and more differentiable andnsecondly that said any derivative decreases faster than any power For any Mnand greater than equal zero the the inaudible derivative ofnPhi inaudible also tends zero tends plus minus infinity Those twonproperties This the and are independent here this says – there nothingnmysterious here nnSee the whole transcript http see stanford edu materials lsoftaee261 transcripts TheFourierTransformAndItsApplications Lecture12 pdf The Fourier Transform and its ApplicationsnCo Lecture 
10987 en Lecture Setting The Fourier Transform Distribution the air what these people miss before the cameranstarts rolling Okay sent out note yesterday over the weekend about the mid termncoming the midterm coming week from Wednesday and without goingninto too much detail right now ’ going have three sessions – ’ minutenexam outside class ’ have class that day nnSee the whole transcript http see stanford edu materials lsoftaee261 transcripts TheFourierTransformAndItsApplications Lecture13 pdf The Fourier Transform and its ApplicationsnCo Lecture 
10988 en Lecture Derivative Distribution Anyway post the website and make the announcement next time say littlenbit more detail about the exam when you signing there just can have ansense how many people are going which slot You not signing your lifenaway anything but figuring that between one those slots from 30np from and from should able toncover most everybody nnSee the whole transcript http see stanford edu materials lsoftaee261 transcripts TheFourierTransformAndItsApplications Lecture14 pdf The Fourier Transform and its ApplicationsnCo Lecture 
10989 en Lecture Application The Fourier Transform Diffraction Setup Now again having said that ’ also true that you can’ avoid computation completely nso wanna try make balance will provide for you and already posted hasnbeen for while the formula sheet That’ formula sheet for the entire course ’lln– ’ make copies that and bring the exam That has all sorts helpful usefulnformulas nnSee the whole transcript http see stanford edu materials lsoftaee261 transcripts TheFourierTransformAndItsApplications Lecture15 pdf The Fourier Transform and its ApplicationsnCo Lecture 
10990 en Lecture More Results From Last Lecture Diffraction Patterns And The Fourier Transforms want talk little bit more about diffraction actually And way actually makingna transition our next topic this may seem little odd way – our next topic samplingnan interpolation And going from diffraction sampling interpolation may seem like anlittle odd way going but ’ – there’ interesting connection here that want tonexploit The topic itself that – the general areas diffraction and particular what Inwant talk about today interesting itself and does make actually for nice link nso want talk about the problem crystallography nnSee the whole transcript http see stanford edu materials lsoftaee261 transcripts TheFourierTransformAndItsApplications Lecture16 pdf The Fourier Transform and its ApplicationsnCo Lecture 
10991 en Lecture Review Main Properties The Shah Function They are some sense flip sides each other and ’ see that very strongly todaynbecause convulsion and multiplication are sort swapped back and forth taking thenFourier Transform the Inverse Fourier Transform for you Okay fact there’snactually sort two sides the same coin The final property the Shaw function thenremarkable property that falls from this inaudible formula the fact about the integers isnthe Fourier Transform property nnSee the whole transcript http see stanford edu materials lsoftaee261 transcripts TheFourierTransformAndItsApplications Lecture17 pdf The Fourier Transform and its ApplicationsnCo Lecture 
10992 en Lecture Review Sampling And Interpolation Results All right want spend little more time today Audio breaks theorem – sampling nand interpolation and some the phenomena that was associated with remind younwhat the setup was from last time And almost carry out the proof again – leastnI give you the setup for the proof again because said many times this – last time nand will say again today for the sampling Audio breaks the derivation then– the sampling theorem the formula identical with proof the sampling formula Inthink the two are closely related that understand one you really have think innterms the other All right nnSee the whole transcript http see stanford edu materials lsoftaee261 transcripts TheFourierTransformAndItsApplications Lecture18 pdf The Fourier Transform and its Applications Lecture 
10993 en Lecture Aliasing Demonstration With Music according the way things then the bandwidth the spectrum – slice ofnspectrum music would roughly say 000 hertz and then down minusn20 000 the frequency would – and beyond that ’ essentially zero least farnas you’ concerned ’ zero You can’ hear anything that’ picture thenspectrum slice music then ’ between minus 000 and 000 the way wenwrite things that would over The bandwidth 000 about 000 nwhich means that you wanna sample and reconstruct music you should roughly atna rate 000 hertz nnSee the whole transcript http see stanford edu materials lsoftaee261 transcripts TheFourierTransformAndItsApplications Lecture19 pdf The Fourier Transform and its Applications Lecture 
10994 en Lecture Review Definition The DFT And ’ defined its nth component the nth component the Fourier transform isnthe sum from say equals zero minus one the Nth component times thenminus two over All right everything defined here terms thenindices the exponential and these are the values the discrete function the indexnpoints zero one two and That’ the definition They say you don’tnsee all the fact that our derivation this came from starting with continuous signal nsampling sampling the Fourier transform and then somehow ultimately leading thisndefinition Here ’ just operation one discrete signal producing another discretensignal nnSee the whole transcript http see stanford edu materials lsoftaee261 transcripts TheFourierTransformAndItsApplications Lecture20 pdf The Fourier Transform and its Applications Lecture 
10995 en Lecture Review Basic DFT Definitions looked like this You have Discrete signal using both the signal notation andnvector notation here and continue that sort mix the two because thinknthey both useful the idea you have either tuple numbers Discretensignal whose value the nth point just the value here Okay Oops that doesn tnlook right That not much statement you can either consider Discretensignal who defined the integers the integers from zero minus one you cannthink tuple vector nnSee the whole transcript http see stanford edu materials lsoftaee261 transcripts TheFourierTransformAndItsApplications Lecture21 pdf The Fourier Transform and its Applications Lecture 
10996 en Lecture FFT Algorithm Setup DFT Matrix Notation Now what this means particular have give you little caution this thatnthere’ sort one more general topic this fast Fourier transform that wouldnordinarily talk about and that convolution circular convolution ’ not going donthat will leave that you read There’ not much There wouldn’ much donother than talk about the formulas and basic applications The applications ’ thencontext linear systems coming you’ see some that later nnSee the whole transcript http see stanford edu materials lsoftaee261 transcripts TheFourierTransformAndItsApplications Lecture22 pdf The Fourier Transform and its Applications Lecture 
10997 en Lecture Linear Systems Basic Definitions The 21st century – say this sweeping bold statement but stand The 21stncentury may the century non linearity don’ know yet but non linear problemsnare becoming increasingly more trackable because computational techniques One ofnthe reasons why linear problems were studied extensively and were useful isnbecause lot can done sort theoretically even you couldn’ compute And then ofncourse later when computational techniques – computational power was there thennthey became even more – they were able exploited even more What wanna get tonis the connection between the Fourier Transform and linear systems and that’ gonna benprimarily along the lines – definitely wanna see how the Fourier Transform appliesnto linear systems again fairly limited way nnSee the whole transcript http see stanford edu materials lsoftaee261 transcripts TheFourierTransformAndItsApplications Lecture23 pdf The Fourier Transform and its Applications Lecture 
10998 en Lecture Review Last Lecture Discrete Continuous Linear Systems The matrices are different You get matrix choosing basis the space inputs nand then you express the matrix terms what happens the bases And ’ notngonna through this because ’ assuming that you’ seen this linear algebra nalthough you may not have thought about quite these terms nnSee the whole transcript http see stanford edu materials lsoftaee261 transcripts TheFourierTransformAndItsApplications Lecture24 pdf The Fourier Transform and its Applications Lecture 
10999 en Lecture Review Last Lecture LTI Systems And Convolution equal then you actually get inaudible for minusninfinity All right once again the output the system isnobtained taking input the system and integrating that against the impulse response nIt’ very satisfactory result nnSee the whole transcript http see stanford edu materials lsoftaee261 transcripts TheFourierTransformAndItsApplications Lecture25 pdf The Fourier Transform and its Applications Lecture 
11000 en Lecture Approaching The Higher Dimensional Fourier Transform For what image after all What mathematical description image Well atnleast not two dimensional image least mathematically given function ofntwo variables say and Function where and are varying overnsome part the plane each point what the function prescribes thenintensity thinking about black and white images here you think and X2nas range numbers from zero one from black white you think X2nas the intensity from black white say the point nnSee the whole transcript http see stanford edu materials lsoftaee261 transcripts TheFourierTransformAndItsApplications Lecture26 pdf The Fourier Transform and its Applications Lecture 
11001 en Lecture Higher Dimensional Fourier Transforms Review The point inaudible getting know your higher dimensional Fourier transform Insaid you know You have convince yourself that There are differences and llnhighlight some them little bit today but even more next time Again the point ofnusing the notation that used and the approach that using make thenhigher dimensional transform look much like the one dimensional transform asnpossible nnSee the whole transcript http see stanford edu materials lsoftaee261 transcripts TheFourierTransformAndItsApplications Lecture27 pdf The Fourier Transform and its Applications Lecture 
11002 en Lecture Shift Theorem Higher Dimensions you make shift then that corresponds the minus pie ISB that’ thenphase shift times the Fourier Transform the original function All right That’ easynresult That’ one the very first results that proved when were talking aboutngeneral properties the Fourier Transform and follows like many other formulas justnby making change variable the interval that defines All right Interval defines anFourier Transform nnSee the whole transcript http see stanford edu materials lsoftaee261 transcripts TheFourierTransformAndItsApplications Lecture28 pdf The Fourier Transform and its Applications Lecture 
11003 en Lecture Shahs said this said the Fourier transform – all right you change thenvariables matrix nonsingular matrix – one over the determinate Antimes the Fourier transform evaluated inverse transpose the frequencynvariable Okay ’ very interesting formula derived last time and ’sncomplicated ’ more complicated than the one dimensional stretch case but includesnthe one dimensional stretch case but what you don’ see one dimensions this newnphenomenon say that reciprocal somehow means inverse transpose nnSee the whole transcript http see stanford edu materials lsoftaee261 transcripts TheFourierTransformAndItsApplications Lecture29 pdf The Fourier Transform and its Applications Lecture 
11004 en Lecture Tips For Filling Out Evals was introduced – actually knew the history this little bit more thoroughly and Incannot recall now was certainly not introduced the context ray tomographynor anything else was introduced for purely mathematical reasons for interestingngeometric reasons The idea was sort study the geometry region knowingnintegrals sections through just purely mathematical question don’ think therenwere any practical implications that were anticipated attempted certainly the time itnwas introduced our question – you know all these values All right You knownall these values and the question can you invert the transform Can you find givennthat you know all the values its transform nnSee the whole transcript http see stanford edu materials lsoftaee261 transcripts TheFourierTransformAndItsApplications Lecture30 pdf The Fourier Transform and its Applications Lecture 
11005 en Lecture Overview Linear Dynamical Systems And start actually just with some — cover some the mechanics the class andnthen start Today just gonna sort fun lecture not representative ofnthe class the end the — you leave thinking Well was interesting but itnwas kind like content free Anyway trust not representative the quarter nnSee the whole transcript http see stanford edu materials lsoeldsee263 transcripts IntroToLinearDynamicalSystems Lecture01 pdf Introduction Linear Dynamical Systems Lecture 
11006 en Lecture Linear Functions Continued The second announcement wanted make for contacting the TAs Please usenthe staff email address ’ the webpage That goes all and that’ very goodnway – that way can see which emails have been responded and which have not nPlease not email the TAs’ personal email addresses That means that other people innthe teaching staff haven’ seen your email Please use the staff address nnSee the whole transcript http see stanford edu materials lsoeldsee263 transcripts IntroToLinearDynamicalSystems Lecture02 pdf Introduction Linear Dynamical Systems Lecture 
11007 en Lecture Linearization Continued ’ get more into detail ’ see this example will come several times during thencourse here you have and two variables unknown coordinates the plane andnwe have bunch beacons locations PIQI these are and coordinates thenbeacons And what measure range And range because the beacons can onlynmeasure range ranges this point could course the other way around thatnthe point can measure its distance the range nnSee the whole transcript http see stanford edu materials lsoeldsee263 transcripts IntroToLinearDynamicalSystems Lecture03 pdf Introduction Linear Dynamical Systems Lecture 
11008 en Lecture Nullspace Matrix Continued Okay the next that have gotten more than just handful sort requests ornsuggestions something like linear algebra matrix review session That’ fornpeople who either never had detailed course this have successfully repressed thenmemories the course they may have taken for those people the ’ and havenbeen talking about and ’ probably something won’ formal session Itnmight simply one the office hours One block office hours will simply devotednto this topic And would course announce that email and the website thatnwould sort the idea nnSee the whole transcript http see stanford edu materials lsoeldsee263 transcripts IntroToLinearDynamicalSystems Lecture04 pdf Introduction Linear Dynamical Systems Lecture 
11009 en Lecture Orthonormal Set Vectors Let’ continue with orthonormal sets vectors Does anyone have any questions aboutnlast time not ’ continue Our topic course orthonormal sets vectors anset vectors orthonormal have vectors They’ orthonormal they’rennormalized That’ attribute the vectors separately and then mutually orthogonal nand that’ attribute the set vectors and ’ orthonormal both nnSee the whole transcript http see stanford edu materials lsoeldsee263 transcripts IntroToLinearDynamicalSystems Lecture05 pdf Introduction Linear Dynamical Systems Lecture 
11010 en Lecture Least Squares gonna talk about least squares something you probably seen couplenof different contexts and concerns overdetermined linear equations have setnof over determined linear equations Now here have where makenstrictly skinny overdetermined because you have more equations than unknowns nAnd course unless the range which you pick randomly and annevent probability zero you can solve one method approximately solveny and very important emphasize here not actually solving tonchoose minimize the norm this residual nnSee the whole transcript http see stanford edu materials lsoeldsee263 transcripts IntroToLinearDynamicalSystems Lecture06 pdf Introduction Linear Dynamical Systems Lecture 
11011 en Lecture Least Squares Polynomial Fitting the question there given and how you find out inaudible such that xnequals How you find – there such how you find one And this willnexplain And connected all the stuff been doing now that – that snofficial announced few parts here haven covered yet but will the nextnweek even hit today not sure nnSee the whole transcript http see stanford edu materials lsoeldsee263 transcripts IntroToLinearDynamicalSystems Lecture07 pdf Introduction Linear Dynamical Systems Lecture 
11012 en Lecture Multi Objective Least Squares started looking that last time thought experiment did the following nWe simply took ever XNRN and evaluated and the two objectives You wantnboth small For every put point All the shaded region shows you pairs ’venwritten which are achievable and then the clear area here are pairs that are notnachievable talked about this last time talked about the following idea that ancertain corresponds this point then basically all the corresponding that map intonwhat lower and the left – these are actually points that are unambiguously better thannthis one nnSee the whole transcript http see stanford edu materials lsoeldsee263 transcripts IntroToLinearDynamicalSystems Lecture08 pdf Introduction Linear Dynamical Systems Lecture 
11013 en Lecture Least Norm Solution least norm solution said last time this something like the dual least squaresnapproximate solution least norm solution ’ studying the equation Butnin this case fat And ’ assuming ’ full rank that means you have Mnequations that can strain variable But you have fewer equations and unknowns itnmeans you have extra degrees freedom What that means that actually hasnlots solutions There are lots solutions means the null space more than justna zero vector fact ’ exactly minus dimensional the null space there’ lotnof freedom choosing nnSee the whole transcript http see stanford edu materials lsoeldsee263 transcripts IntroToLinearDynamicalSystems Lecture09 pdf Introduction Linear Dynamical Systems Lecture 
11014 en Lecture Examples Autonomous Linear Dynamical Systems ’ – this buildup two coming from the decaying one – actually said itnwrong ’ buildup species because that’ byproduct the decay species one nand this actually then – actually the decay two – well whatever ’ thendecay two because some species turning into species And the final one isnthis which three dot equals two times two meaning that species here onlyncomes from the decay species two That’ this and this – that’ this bottom row nOkay nnSee the whole transcript http see stanford edu materials lsoeldsee263 transcripts IntroToLinearDynamicalSystems Lecture10 pdf Introduction Linear Dynamical Systems Lecture 
11015 en Lecture Solution Via Laplace Transform And Matrix Exponential posted the solutions literally minutes ago This Packard for pickup postednthe solutions few minutes before the lecture And ’ tell you let just say fewnthings about should say that usually the way that everything gets schedules outnand everything had with shift schedule tradition return the midtermsnthe day after the grade change option – deadline has finished that’ the tradition Thisntime however because the new schedule ’ actually able give you gradednmidterms beforehand That doesn’ apply the vast majority people but there mightnbe handful people who don know whatever decide they want change theirngrading option nnSee the whole transcript http see stanford edu materials lsoeldsee263 transcripts IntroToLinearDynamicalSystems Lecture11 pdf Introduction Linear Dynamical Systems Lecture 
11016 en Lecture Time Transfer Property here what tells you says that get this state time Tau plus from the state atntime Tau – first all they linearly related That alone – well not unexpected butnthey linearly related They related end end matrix that maps one thenother And that matrix simply the the time propagator Itnpropagates dot equals forward seconds time negative actually runsntime backwards and reconstructs what the state was some seconds ago nnSee the whole transcript http see stanford edu materials lsoeldsee263 transcripts IntroToLinearDynamicalSystems Lecture12 pdf Introduction Linear Dynamical Systems Lecture 
11017 en Lecture Markov Chain Example put vector front all ones – that’ row vector multiplied – getnthis row vector here This the matrix way saying that the column sums are allnone this also you look – you like could put lambda there and saynlambda one This basically says that – that the vector all ones left eigenvectornof associated with eigenvalue lambda equals one tells you particular has anneigenvalue one But has eigenvalue one also has right eigenvectornassociated with lambda equals one nnSee the whole transcript http see stanford edu materials lsoeldsee263 transcripts IntroToLinearDynamicalSystems Lecture13 pdf Introduction Linear Dynamical Systems Lecture 
11018 en Lecture Jordan Canonical Form Okay Now looked various things involving Jordan Form and the real questionnwas what does mean think saw some that from dynamic point view Wencan get some that looking the exponential Jordan Block the exponentialnof times Jordan Block looks like this You get the familiar the lambda thatnyou expect That the eigenvalue nnSee the whole transcript http see stanford edu materials lsoeldsee263 transcripts IntroToLinearDynamicalSystems Lecture14 pdf Introduction Linear Dynamical Systems Lecture 
11019 en Lecture Static Gain Matrix what this describes actually describes the system what relates the inputs thenoutputs under static conditions That exactly what this does you have staticnconditions that means and are all constant Then course you have dot and innthat case zero constant See zero and you eliminate xnfrom these equations solving for minus inverse here and you plug that innhere you get this Okay this assuming invertible here this what itndescribes nnSee the whole transcript http see stanford edu materials lsoeldsee263 transcripts IntroToLinearDynamicalSystems Lecture15 pdf Introduction Linear Dynamical Systems Lecture 
11020 en Lecture Circuit Example again you’ have sorta relearn – mean ’ not ancomplete relearning but you’ have relearn what means that way Now you might –nyou can just well assume that transpose other words you have A34 andnA43 these are the two contributions from equals three equals four and equals four Jnequals three You can see that these numbers are the same can pull them out andnmake A34 plus A43 And might well replace both those with the average thentwo doesn’ change anything matrix language you write this way You saynthat transpose – and let’ quick calculations this first Let’ take transposenAX and that scaler That’ scaler nnSee the whole transcript http see stanford edu materials lsoeldsee263 transcripts IntroToLinearDynamicalSystems Lecture16 pdf Introduction Linear Dynamical Systems Lecture 
11021 en Lecture Gain Matrix Direction Now there are cases when doesn’ vary with direction You’ seen one One when Anis orthogonal square and its columns are orthonormal then equals thennorm the norm the gain one all directions watch you’ going tonget the complete picture today that nnSee the whole transcript http see stanford edu materials lsoeldsee263 transcripts IntroToLinearDynamicalSystems Lecture17 pdf Introduction Linear Dynamical Systems Lecture 
11022 en Lecture Sensitivity Linear Equations Data Error Getting closer Well just not worry about still twisted but that okay Sonwe look what happens when varies course varies little bit then willnvary little bit and the change will inverse delta Last time think Inpointed this out but you have matrix which invertible nonsingular but where theninverse huge – and course this exactly what you get you had matrix whichnwas for example singular and then you perturbed slightly make nonsingular Younwill have matrix that now nonsingular but ’ inverse going huge nnSee the whole transcript http see stanford edu materials lsoeldsee263 transcripts IntroToLinearDynamicalSystems Lecture18 pdf Introduction Linear Dynamical Systems Lecture 
11023 en Lecture Reachability you could say ’ here Rio and ’rengonna talk about the singular value decomposition just something like that but wenhaven’ actually approached SCPD see they can pull that off but want thatnsometime Anyway this afternoon tape ahead Please come statically long asnsome you come guess that some people will come anyway All right Anynquestions about last time administrative stuff nnSee the whole transcript http see stanford edu materials lsoeldsee263 transcripts IntroToLinearDynamicalSystems Lecture19 pdf Introduction Linear Dynamical Systems Lecture 
11024 en Lecture Continuous Time Reachability And then wanna reserve some time the end this class tonjust say few things the very highest levels about what the class how all this stuffnfits together and all this sort stuff that’ what ’ continuous timenreachability looked last time which fact was guess for the people here realntime was this morning and looked what’ the reachability subspace for ancontinuous time system that’ the set all points you can hit seconds startingnfrom zero continuous time system nnSee the whole transcript http see stanford edu materials lsoeldsee263 transcripts IntroToLinearDynamicalSystems Lecture20 pdf Introduction Linear Dynamical Systems Lecture 
11044 en Lecture Course Logistics guess ’ guess ’ stay character and saynwelcome 364b and now ’ explain why that’ staying character believe ’renmaking history here This far know the world’ first tape behind knownyet that’ correct Okay ’ gonna have SCPD tell have thumbs ’renmaking history here This dramatic enactment the events the first lecture ofn364b let explain little bit the background nnSee the whole transcript http see stanford edu materials lsocoee364b transcripts ConvexOptimizationII Lecture01 pdf Convex Optimization Lecture 
11045 en Lecture Recap Subgradients Okay let see – and couple other announcements presume people will coming nwandering the next ten minutes that perfectly okay because you not this –nif you weren’ actually registered the access list something like that there –nyou scratching your head reading this sign over the other room about right now nand say about ten minutes later have bunch people coming nnSee the whole transcript http see stanford edu materials lsocoee364b transcripts ConvexOptimizationII Lecture02 pdf Convex Optimization Lecture 
11046 en Lecture Convergence Proof Okay there’ questions about last time then think ’ just jump innand start subgradient methods far subgradient methods look the – mean nsubgradient method embarrassingly simple right ’ – you make step the negativenin anegative ’ call the negative but the correct English would anegativensubgradient direction nnSee the whole transcript http see stanford edu materials lsocoee364b transcripts ConvexOptimizationII Lecture03 pdf Convex Optimization Lecture 
11047 en Lecture Project Subgradient For Dual Problem Sure ’ going need strong duality holds werenstrictly feasible ’ have Slater’ condition and strong duality would hold That givesnyou zero duality gap and guess you don’ have that then you can’ solve this all nbecause the optimal values aren’ even the same let’ assume that There’ more nactually than just that What the sledgehammer condition this What you’ neednis that when you find lambda what you want that the Lagrangian lambda shouldnhave unique minimizer does then that actually here Okay Sonthat’ the condition nnSee the whole transcript http see stanford edu materials lsocoee364b transcripts ConvexOptimizationII Lecture04 pdf Convex Optimization Lecture 
11048 en Lecture Stochastic Programming the way omega less than equal some – that constraint representsnsomething like resource usage means this the expected over utilization Somethingnlike that can all sorts things timing constraint saying something has tonbe done certain amount this called the expected tardiness your basic inequalitynsaid this job has finished this time that’ the expected tardiness That worksnbecause the plus function non decreasing and convex and Now another onenwould this you could take the expected value the maximum all the constraints nand this the expected worst violation nnSee the whole transcript http see stanford edu materials lsocoee364b transcripts ConvexOptimizationII Lecture05 pdf Convex Optimization Lecture 
11049 en Lecture Addendum Hit And Run Algorithm There’ got opening paragraph Innfact were even thinking defining formal XML scheme whatever for But ’sngot paragraph that has nothing but English and says kinda what the context thenproblem for example ’ doing air traffic control ’ blending covariantnmatrices from disparate sources something like that And says little bit about whatnthe challenges are and what you’ consider nnSee the whole transcript http see stanford edu materials lsocoee364b transcripts ConvexOptimizationII Lecture06 pdf Convex Optimization Lecture 
11050 en Lecture Example Piecewise Linear Minimization Doesn’ really matter what You find the analytic center the polyhedron which isnto say more precisely you find the analytic center the linear inequalities that representnthe polyhedron And you query the cutting plane oracle that point that point innyour target set you quit Otherwise you add you append this new cutting plane thenset course what happens now your point not definition nWell sorry might ’ neutral cut but ’ the boundary nnSee the whole transcript http see stanford edu materials lsocoee364b transcripts ConvexOptimizationII Lecture07 pdf Convex Optimization Lecture 
11051 en Lecture Recap Ellipsoid Method can this bisection now ’ integer Well Inguess that’ not given but ’ integer and ’ more than zero and less than two Sonone person showed the way ’ already graded their project – actually wenwrote the code for him assigned his grade access was very very sad really nSo let just remind everyone that attendance required even though ’ videonnow The flip side this there’ lot other people watching this other places nnSee the whole transcript http see stanford edu materials lsocoee364b transcripts ConvexOptimizationII Lecture08 pdf Convex Optimization Lecture 
11052 en Lecture Comments Latex Typesetting Style guess ’ start guess the most obvious thing guess most you have figured outnby now have looked through these preliminary project proposals and they’renfloating around make sure you get yours not throw those away because didn’tncopy them and wanna make sure there’ progress when you resubmit them wenwant look the old one again too and then judge whether enough progress was madento justify our even looking again nnSee the whole transcript http see stanford edu materials lsocoee364b transcripts ConvexOptimizationII Lecture09 pdf Convex Optimization Lecture 
11053 en Lecture Decomposition Applications Today ’ gonna – last time finished bunch ofnabstract stuff about decomposition but today ’ just going look two handfulnof applications details see how decomposition actually works where ’ actuallynapplied the first one ’ gonna rate control network Actually this sortnof big topic right now you were look this stuff you would you were gonto Google something you’ find zillions papers this topic that bounce yourn– what’ that nnSee the whole transcript http see stanford edu materials lsocoee364b transcripts ConvexOptimizationII Lecture10 pdf Convex Optimization Lecture 
11054 en Lecture Sequential Convex Programming The good news that can actually pull this off think one day ’ going toncome back later There’ several other lectures problems that are not convex andnvarious methods There’ going problem reluxations ’ going have anwhole study type methods for sparse solutions Those will come later But this isnreally our first foray outside convex optimization nnSee the whole transcript http see stanford edu materials lsocoee364b transcripts ConvexOptimizationII Lecture11 pdf Convex Optimization Lecture 
11055 en Lecture Recap Difference Convex Programming Let see couple other things you should watch for email and maybe the webnsite because may tape ahead next Tuesday lecture tomorrow some time – andnwe would You hear about that Okay can think any other administrativenthings guess posted new homework but guess most you know that Anynquestions about last time Because not what gonna gonna finish upnthis topic Heuristics based convex optimization for solving the non convexnproblem nnSee the whole transcript http see stanford edu materials lsocoee364b transcripts ConvexOptimizationII Lecture12 pdf Convex Optimization Lecture 
11056 en Lecture Recap Conjugate Gradient Method ’ looking solving symmetric positive definite systems equations and thisnwould come Newton’ method comes you know interior point methods nleast squares all these sorts things And last time talked about mean the CGnMethod the basic idea ’ method which solves where positive definite nAnd – but does different way nnSee the whole transcript http see stanford edu materials lsocoee364b transcripts ConvexOptimizationII Lecture13 pdf Convex Optimization Lecture 
11057 en Lecture Methods Truncated Newton Method this what ’ The problem was scaled such way that could pull off anCholesky factorization think the Cholesky factor had something like millionnnonzeros ’ take some time both the Cholesky factorization and also thenbackward and forward substitution but direct possible All have with thisnproblem scale factor ten and direct becomes kind out the question sonthen least little standard machine nnSee the whole transcript http see stanford edu materials lsocoee364b transcripts ConvexOptimizationII Lecture14 pdf Convex Optimization Lecture 
11058 en Lecture Recap Example Minimum Cardinality Problem All right think this means are There good waynin this room know you are – when the lecture starts Okay well are down anskeleton crew here mostly because ’ too hot outside ’ continue with 1nmethods today last time saw the basic idea The most – the simplest idea this Ifnyou want minimize the cardinality find the sparsest vector that’ convexnset the simplest heuristic – and actually today ’ see lots variations that arenmore sophisticated But the simplest one far simply minimize the one norm Xnsubject and nnSee the whole transcript http see stanford edu materials lsocoee364b transcripts ConvexOptimizationII Lecture15 pdf Convex Optimization Lecture 
11059 en Lecture Model Predictive Control Today ’ jumping around different order topics but this maybe think thennext topic that some people are working ’ obviously too late for them for theirnprojects but can least cover the material and for people who are doing this leastnit’ make lot sense For other people ’ actually very very good stuff knownabout ’ widely widely used ’ called Model Predictive Control fact ’ beennreading lot about the last couple days sit through very long airplane flights nread couple more books has got tons different names all different Basicallynall the different areas doing this don’ know about the others nnSee the whole transcript http see stanford edu materials lsocoee364b transcripts ConvexOptimizationII Lecture16 pdf Convex Optimization Lecture 
11060 en Lecture Stochastic Model Predictive Control what this that the next state depends actually two things – well three thingsnreally depends the current state that’ this depends your action and itndepends this random variable Actually this point ’ not yet random variable nbut ’ something – the idea will soon random variable – and depends onnsomething that you don’ know fully That’ nnSee the whole transcript http see stanford edu materials lsocoee364b transcripts ConvexOptimizationII Lecture17 pdf Convex Optimization Lecture 
11061 en Lecture Announcements But you’ not gonna give globalness – globality You’ gonna give neithernglobalness nor globality but you are gonna give speed what’ gonna happen isnthese are gonna methods that are slow but they don’ lie They will produce – anynpoint you can stop them and exactly like convex optimization method they will have anlower bound and they will have upper bound nnSee the whole transcript http see stanford edu materials lsocoee364b transcripts ConvexOptimizationII Lecture18 pdf Convex Optimization Lecture 
11110 en Immunization Hesitancy Rising Tide that Challenges the Public Health Societal support for traditional childhood immunization changing Increasingly parents are renegotiating recommended immunization schedules with pediatricians Marcuse also associate medical director Seattle Children Hospital discusses this hesitancy and the potential consequences for disease prevention this videotaped lecture also addresses balancing parental rights with protecting public health This lecture was part the Howard Schneiderman Memorial Bioethics Lecture Series which began 1990 with endowment from Schneiderman the third biological sciences school dean The series brings renowned experts UCI speak about the social and ethical implications advances biology and medicine 
11153 en Multi Label Prediction via Compressed Sensing consider multi label prediction problems with large output spaces under the assumption output sparsity that the target label vectors have small support develop general theory for variant the popular error correcting output code scheme using ideas from compressed sensing for exploiting this sparsity The method can regarded simple reduction from multi label regression problems binary regression problems show that the number subproblems need only logarithmic the total number possible labels making this approach radically more efficient than others also state and prove robustness guarantees for this method the form regret transform bounds general and also provide more detailed analysis for the linear prediction setting 
11155 en  Additive Latent Feature Model for Transparent Object Recognition Existing methods for recognition object instances and categories based quantized local features can perform poorly when local features exist transparent surfaces such glass plastic objects There are characteristic patterns the local appearance transparent objects but they may not well captured distances individual examples local pattern codebook obtained vector quantization The appearance transparent patch determined part the refraction background pattern through transparent medium the energy from the background usually dominates the patch appearance model transparent local patch appearance using additive model latent factors background factors due scene content and factors which capture local edge energy distribution characteristic the refraction implement our method using novel LDA SIFT formulation which performs LDA prior any vector quantization step discover latent topics which are characteristic particular transparent patches and quantize the SIFT space into transparent visual words according the latent topic dimensions knowledge the background scene required test time show examples recognizing transparent glasses domestic environment 
11156 en Semi Supervised Learning Gigantic Image Collections With the advent the Internet now possible collect hundreds millions images These images come with varying degrees label information Clean labels can manually obtained small fraction noisy labels may extracted automatically from surrounding text while for most images there are labels all Semi supervised learning principled framework for combining these different label sources However scales polynomially with the number images making impractical for use gigantic collections with hundreds millions images and thousands classes this paper show how utilize recent results machine learning obtain highly efficient approximations for semi supervised learning that are linear the number images Specifically use the convergence the eigenvectors the normalized graph Laplacian eigenfunctions weighted Laplace Beltrami operators combine this with label sharing framework obtained from Wordnet propagate label information classes lacking manual annotations Our algorithm enables apply semi supervised learning database million images with thousand classes 
11157 en Non Parametric Bayesian Dictionary Learning for Sparse Image Representations Non parametric Bayesian techniques are considered for learning dictionaries for sparse image representations with applications denoising inpainting and compressive sensing The beta process employed prior for learning the dictionary and this non parametric method naturally infers appropriate dictionary size The Dirichlet process and probit stick breaking process are also considered exploit structure within image The proposed method can learn sparse dictionary situ training images may exploited available but they are not required Further the noise variance need not known and can non stationary Another virtue the proposed method that sequential inference can readily employed thereby allowing scaling large images Several example results are presented using both Gibbs and variational Bayesian inference with comparisons other state the art approaches 
11158 en Locality Sensitive Binary Codes from Shift Invariant Kernels This paper addresses the problem designing binary codes for high dimensional data such that vectors that are similar the original space map similar binary strings introduce simple distribution free encoding scheme based random projections such that the expected Hamming distance between the binary codes two vectors related the value shift invariant kernel Gaussian kernel between the vectors present full theoretical analysis the convergence properties the proposed scheme and report favorable experimental performance compared recent state the art method spectral hashing 
11159 en Discriminative Network Models Schizophrenia Schizophrenia complex psychiatric disorder that has eluded characterization terms local abnormalities brain activity and hypothesized affect the collective emergent working the brain propose novel data driven approach capture emergent features using functional brain networks Eguiluzet extracted from fMRI data and demonstrate its advantage over traditional region interest ROI and local task specific linear activation analyzes Our results suggest that schizophrenia indeed associated with disruption global emergent brain properties related its functioning network which cannot explained alteration local activation patterns Moreover further exploitation interactions sparse Markov Random Field classifiers shows clear gain over linear methods such Gaussian Naive Bayes and SVM allowing reach accuracy over baseline random guess which quite remarkable given that based single fMRI experiment using simple auditory task 
11161 en Explaining Human Multiple Object Tracking Resource Constrained Approximate Inference Dynamic Probabilistic Model Multiple object tracking task commonly used investigate the architecture human visual attention Human participants show distinctive pattern successes and failures tracking experiments that often attributed limits object system tracking module other specialized cognitive structures Here use computational analysis the task object tracking ask which human failures arise from cognitive limitations and which are consequences inevitable perceptual uncertainty the tracking task find that many human performance phenomena measured through novel behavioral experiments are naturally produced the operation our ideal observer model Rao Blackwelized particle filter The tradeoff between the speed and number objects being tracked however can only arise from the allocation flexible cognitive resource which can formalized either memory attention 
11162 en Optimizing Multi Class Spatio Spectral Filters via Bayes Error Estimation for EEG Classification The method common spatio spectral patterns CSSPs extension common spatial patterns CSPs utilizing the technique delay embedding alleviate the adverse effects noises and artifacts the electroencephalogram EEG classification Although the CSSPs method has shown more powerful than the CSPs method the EEG classification this method only suitable for two class EEG classification problems this paper generalize the two class CSSPs method multi class cases this end first develop novel theory multi class Bayes error estimation and then present the multi class CSSPs MCSSPs method based this Bayes error theoretical framework minimizing the estimated closed form Bayes error obtain the optimal spatio spectral filters MCSSPs demonstrate the effectiveness the proposed method conduct extensive experiments the data set BCI competition 2005 The experimental results show that our method significantly outperforms the previous multi class CSPs MCSPs methods the EEG classification 
11163 en Functional Network Reorganization Motor Cortex Can Explained Reward Modulated Hebbian Learning The control neuroprosthetic devices from the activity motor cortex neurons benefits from learning effects where the function these neurons adapted the control task was recently shown that tuning properties neurons monkey motor cortex are adapted selectively order compensate for erroneous interpretation their activity particular was shown that the tuning curves those neurons whose preferred directions had been misinterpreted changed more than those other neurons this article show that the experimentally observed self tuning properties the system can explained the basis simple learning rule This learning rule utilizes neuronal noise for exploration and performs Hebbian weight updates that are modulated global reward signal contrast most previously proposed reward modulated Hebbian learning rules this rule does not require extraneous knowledge about what noise and what signal The learning rule able optimize the performance the model system within biologically realistic periods time and under high noise levels When the neuronal noise fitted experimental data the model produces learning effects similar those found monkey experiments 
11164 en Know Thy Neighbour Normative Theory Synaptic Depression Synapses exhibit extraordinary degree short term malleability with release probabilities and effective synaptic strengths changing markedly over multiple timescales From the perspective fixed computational operation network this seems like most unacceptable degree added noise suggest alternative theory according which short term synaptic plasticity plays normatively justifiable role This theory starts from the commonplace observation that the spiking neuron incomplete digital report the analog quantity that contains all the critical information namely its membrane potential suggest that one key task for synapse solve the inverse problem estimating the pre synaptic membrane potential from the spikes receives and prior expectations recursive filter show that short term synaptic depression has canonical dynamics which closely resemble those required for optimal estimation and that indeed supports high quality estimation Under this account the local postsynaptic potential and the level synaptic resources track the scaled mean and variance the estimated presynaptic membrane potential make experimentally testable predictions for how the statistics subthreshold membrane potential fluctuations and the form spiking non linearity should related the properties short term plasticity any particular cell type 
11165 en Efficient Learning using Forward Backward Splitting describe analyze and experiment with new framework for empirical lossnminimization with regularization Our algorithmic framework alternates betweenntwo phases each iteration first perform unconstrained gradient descentnstep then cast and solve instantaneous optimization problem that trades offnminimization regularization term while keeping close proximity the resultnof the first phase This yields simple yet effective algorithm for both batch penalizednrisk minimization and online learning Furthermore the two phase approachnenables sparse solutions when used conjunction with regularization functionsnthat promote sparsity such derive concrete and very simple algorithmsnfor minimization loss functions with 2n2 and ∞ regularization Wenalso show how construct efficient algorithms for mixed norm regularization nWe further extend the algorithms and give efficient implementations for verynhigh dimensional data with sparsity demonstrate the potential the proposednframework experiments with synthetic and natural datasets 
11166 en  Stochastic and Worst case Models for Investing practice most investing done assuming probabilistic model stock price returns known the Geometric Brownian Motion GBM While often acceptable approximation the GBM model not always valid empirically This motivates worst case approach investing called universal portfolio management where the objective maximize wealth relative the wealth earned the best fixed portfolio hindsight this paper tie the two approaches and design investment strategy which universal the worst case and yet capable exploiting the mostly valid GBM model Our method based new and improved regret bounds for online convex optimization with exp concave loss functions 
11167 en Bootstrapping from Game Tree Search this paper introduce new algorithm for updating the parameters heuristic evaluation function updating the heuristic towards the values computed alpha beta search Our algorithm differs from previous approaches learning from search such Samuel checkers player and the Leaf algorithm two key ways First update all nodes the search tree rather than single node Second use the outcome deep search instead the outcome subsequent search the training signal for the evaluation function implemented our algorithm chess program Meep using linear heuristic function After initialising its weight vector small random values Meep was able learn high quality weights from self play alone When tested online against human opponents Meep played master level the best performance any chess program with heuristic learned entirely from self play 
11168 en Kernel Choice and Classifiability for RKHS Embeddings Probability Distributions Embeddings probability measures into reproducing kernel Hilbert spaces have been proposed straightforward and practical means representing and comparing probabilities particular the distance between embeddings the maximum mean discrepancy MMD has several key advantages over many classical metrics distributions namely easy computability fast convergence and low bias finite sample estimates important requirement the embedding RKHS that characteristic this case the MMD between two distributions zero and only the distributions coincide Three new results the MMD are introduced the present study First established that MMD corresponds the optimal risk kernel classifier thus forming natural link between the distance between distributions and their ease classification important consequence that kernel must characteristic guarantee classifiability between distributions the RKHS Second the class characteristic kernels broadened incorporate all bounded continuous strictly positive definite kernels these include non translation invariant kernels and kernels non compact domains Third generalization the MMD proposed for families kernels the supremum over MMDs class kernels for instance the Gaussian kernels with different bandwidths This extension necessary obtain single distance measure large selection class characteristic kernels potentially appropriate This generalization reasonable given that corresponds the problem learning the kernel minimizing the risk the corresponding kernel classifier The generalized MMD shown have consistent finite sample estimates and its performance demonstrated homogeneity testing example 
11169 en  View the Best MAP Problem consider the problem finding the assignments with maximum probability probabilistic graphical model show how this problem can formulated linear program particular polytope prove that for tree graphs and junction trees general this polytope has particularly simple form and differs from the marginal polytope single inequality constraint use this characterization provide approximation scheme for non tree graphs using the set spanning trees over such graphs The method present puts the best inference problem the context relaxations which have recently received considerable attention and have proven useful solving difficult inference problems show empirically that our method often finds the provably exact best configurations for problems high tree width 
11170 en Fast Subtree Kernels Graphs this article propose fast subtree kernels graphs graphs with nodesnand edges and maximum degree these kernels comparing subtrees heightnh can computed whereas the classic subtree kernel Ramon nGärtner scales n24dh Key this efficiency the observation that thenWeisfeiler Lehman test isomorphism from graph theory elegantly computes ansubtree kernel byproduct Our fast subtree kernels can deal with labeledngraphs scale easily large graphs and outperform state the art graph kernelsnon several classification benchmark datasets terms accuracy and runtime 
11171 en Sharing Features among Dynamical Systems with Beta Processes propose Bayesian nonparametric approach relating multiple time series via set latent dynamical behaviors Using beta process prior allow data driven selection the size this set well the pattern with which behaviors are shared among time series Via the Indian buffet process representation the beta process predictive distributions develop exact Markov chain Monte Carlo inference method particular our approach uses the sum product algorithm efficiently compute Metropolis Hastings acceptance probabilities and explores new dynamical behaviors via birth death proposals validate our sampling algorithm using several synthetic datasets and also demonstrate promising unsupervised segmentation visual motion capture data 
11172 en Reading Tea Leaves How Humans Interpret Topic Models Probabilistic topic models are commonly used tool for analyzing text data where the latent topic representation used perform qualitative evaluation models and guide corpus exploration Practitioners typically assume that the latent space semantically meaningful but this important property has lacked quantitative evaluation this paper present new quantitative methods for measuring semantic meaning inferred topics back these measures with large scale user studies showing that they capture aspects the model that are undetected measures model quality based held out likelihood Surprisingly topic models which perform better held out likelihood may actually infer less semantically meaningful topics 
11173 en Time rescaling Methods for the Estimation and Assessment Non Poisson Neural Encoding Models Recent work the statistical modeling neural responses has focused modulated renewal processes which the spike rate function the stimulus and recent spiking history Typically these models incorporate spike history dependencies via either conditionally Poisson process with rate dependent linear projection the spike train history generalized linear model modulated non Poisson renewal process inhomogeneous gamma process Here show that the two approaches can combined resulting conditional renewal model for neural spike trains This model captures both real and rescaled time effects and can fit maximum likelihood using simple application the time rescaling theorem show that for any modulated renewal process model the log likelihood concave the linear filter parameters only under certain restrictive conditions the renewal density ruling out many popular choices gamma with kappa neq1 suggesting that real time history effects are easier estimate than non Poisson renewal properties Moreover show that goodness fit tests based the time rescaling theorem quantify relative time effects but not reliably assess accuracy spike prediction stimulus response modeling illustrate the model with applications both real and simulated neural data 
11217 en Introduction Presentations Different Views Clustering the Workshop Organizers
11220 en What Cluster Perspectives from Game Theory Instead insisting the idea determiningna partition the input data and hence obtaining the clusters product the partitioningnprocess this presentation propose reverse the terms the problem and attempt instead derivena rigorous formulation the very notion cluster Clearly the conceptual question “what isna cluster ” hopeless its full generality its companion “what optimal clustering ”nwhich has dominated the literature the past few decades both being two sides the same coin nAn attempt answer the former question however besides shedding fresh light into the nature ofnthe clustering problem would allow consequence naturally overcome the major limitationsnof the partitional approach alluded above and deal with more general problems where clusters may overlap and clutter elements may get unassigned thereby hopefully reducing thengap between theory and practice nnIn our endeavor provide answer the question raised above found that game theorynoffers very elegant and general perspective that serves well our purposes Hence the second nconstructive part the presentation will describe game theoretic framework for clustering n25 which has found applications fields diverse computer vision and bioinformatics nThe starting point the elementary observation that “cluster” may informally defined anmaximally coherent set data items subset the input data which satisfies both anninternal criterion all elements belonging should highly similar each other and externalnone larger cluster should contain proper subset then formulate the clustering problemnas non cooperative clustering game Within this context the notion cluster turns out benequivalent classical equilibrium concept from evolutionary game theory the latter reflectsnboth the internal and external cluster conditions mentioned above 
11221 en Clustering with Prior Information summary have demonstrated analytically that any small but finite amount semi–nsupervision suppresses the phase transition cluster detectability for the planted–bisection model nby shifting the detection threshold its lowest possible value For graphs where the links withinnand across the clusters have different weights found that semi–supervision leads detectionnthreshold that depends Furthermore then for the detection threshold convergesnto value lower better from the one obtained via balancing within–cluster and inter–clusternweights This suggests that for weighted graphs small but generic semi supervising can employednfor defining the very clustering structure This definition non trivial since performsnbetter than the weight balancing definition Note also that for weighted graphs the very notion ofnthe detection threshold not clear priori contrast unweighted networks where the onlynpossible definition goes via the connectivity balance illustrate this unclarity considerna node connected one cluster via few heavy links and another cluster via many light links nTo which cluster this node should belong principle Our speculative answer that the properncluster assignment this case can defined via semi supervising 
11222 en Finding Better Psychophysical Investigation Clustering Finding the number groups data set important problem thenfield unsupervised machine learning with applications across many scientificndomains The problem difficult however because ambiguous and hierarchical nand current techniques for finding often produce unsatisfying results nHumans are adept navigating ambiguous and hierarchical situations and thisnpaper measures human performance the problem finding across widenvariety data sets find that humans employ multiple strategies for choosingnk often simultaneously and the number possible interpretations even simplendata sets with very few samples can quite high addition twonleading machine learning algorithms are compared the human results 
11223 en Single Data Multiple Clusterings There has been extensive research the clustering community formalizing thendefinition the quality given data clustering However possible measurenthe quality clustering unless human judgment taken into consideration nThe notion quality subjective for example given the task clustering setnof movie reviews some users might want cluster them according sentiment nwhile others might want cluster them according genre the clustering algorithmnis passive does not have the ability produce multiple clusteringsnby actively taking user intent into account hard justify the algorithm tonbe qualitatively best across different domains There has been recent surge ofninterest quantifying how clusterable dataset Can similarly definenmulti clusterability this paper present really simple active clusteringnarchitecture that can help understand the multi clusterability dataset 
11224 en Empricial Study Cluster Evaluation Metrics wide range abstract characteristics partitions have been proposed for clusternevaluation empirically evaluated the performance these metrics for flowncytometry data and found that the set matching metrics perform closest human nnClustering increasingly popular module data processing applications Many clustering algorithmsnhave been developed and many more are anticipated emerge the future Thus methodsnfor assessing the performance clustering algorithms are great demand Such methods assessnthe performance clustering algorithm computing quality score the solution against anground truth partition usually designed human expert wide range these criterion havenbeen proposed Evaluating clustering algorithms heavily relies the chosen quality score however nit not practical study the performance these metrics domain independent way nIn this paper aim empirically evaluate the available metrics find the best metric for comparingnclustering solutions against ground truth partitions for flow cytometry FCM applications nThis work was motivated part the challenges faced choosing the best clustering comparisonnmetric for the FlowCap project FlowCap international open project designed providenan objective way compare and evaluate FCM data clustering methods and also establishnguidance about appropriate use and application these methods for more information visitnhttp flowcap flowsite org 
11226 en Some Ideas for Formalizing Clustering Despite being one the most commonly used tools for unsupervised exploratoryndata analisys and despite its and extensive literature very little known about thentheoretical foundations clustering methods have been working variousnmathematical approaches which allow the extension earlier results this areanbased ideas from topology and metric geometry will give overview atnthe workshop 
11227 en Characterization Linkage Based Clustering There are wide variety clustering algorithms that when run the same data often producenvery different clusterings Yet there principled method guide the selection clusteringnalgorithm The choice appropriate clustering course task dependent such mustnrely domain knowledge The challenge communicate such knowledge between the domainnexpert and the algorithm designer One approach providing guidance clustering users thenselection clustering algorithm identify important properties that user may want algorithmnto satisfy and determine which algorithms satisfy each these properties Clustering usersncan then utilize prior knowledge determine the properties that make sense for their application nnUltimately there would sufficiently rich set properties that would provide detailed enoughnguidelines for wide variety clustering users For property useful user needs benable easily determine the desirability the property Such description clustering algorithmsnwould yield principled guidelines for clustering algorithm selection answering series simplenquestions Bosagh Zadeh and Ben David make progress this direction providing setnof abstract properties that characterize single linkage this work give another result thensame direction characterizing family clustering algorithms These are initial steps toward thenambitious program developing broad guidelines for clustering algorithm selection nnLinkage based clustering one the most commonly used and widely studied clusteringnparadigms provide surprisingly simple set properties that uniquely identify linkage basednclustering algorithms Our characterization highlights how linkage based algorithms compare tonother clustering algorithms nnCombining previously proposed properties with our newly proposed ones show how these propertiesnpartition the space commonly used clustering algorithms Specifically show which ofnthese properties are satisfied common linkage based centroid based and spectral clustering algorithms nWe hope that this analysis well our characterization linkage based clustering nwill provide useful guidelines for users selecting clustering algorithms 
11228 en Information Theoretic Model Selection Clustering Model selection clustering requires specify clustering principle and nto decide appropriate number clusters depending the noise level thendata advocate information theoretic perspective where the uncertainty innthe data set induces uncertainty the solution space clusterings clusteringnmodel which can tolerate higher level noise the data than competingnmodels considered superior provided that the clustering solutionnis equally informative This tradeoff between informativeness and robustness isnused model selection criterion The request that solutions should generalizenfrom one data set equally probable second data set gives rise new notionnof structure induced information 
11229 en PAC Bayesian Approach Formulation Clustering Objectives Clustering widely used tool for exploratory data analysis However thentheoretical understanding clustering very limited still not have anwell founded answer the seemingly simple question “how many clusters arenpresent the data ” and furthermore formal comparison clusterings basednon different optimization objectives far beyond our abilities The lack goodntheoretical support gives rise multiple heuristics that confuse the practitionersnand stall development the field nWe suggest that the ill posed nature clustering problems caused the factnthat clustering often taken out its subsequent application context arguenthat one does not cluster the data just for the sake clustering but rather tonfacilitate the solution some higher level task evaluation the clustering’sncontribution the solution the higher level task possible compare differentnclusterings even those obtained different optimization objectives thenpreceding work was shown that such approach can applied evaluationnand design clustering solutions Here suggest that this approach can benextended other settings where clustering applied 
11230 en Planning under Uncertainty Using Distributions over Posteriors Modern control theory has provided large number tools for dealing with probabilistic systems However most these tools solve for local policies there are relatively few tools for solving for complex plans that for instance gather information contrast the planning community has provided ways compute plans that handle complex probabilistic uncertainty but these often don work for large continuous problems Recently our group has developed techniques for planners that can efficiently search for complex plans probabilistic domains taking advantage local solutions provided feedback and open loop controllers and predicting distribution over the posteriors This approach planning over distributions posteriors can incorporate surprisingly wide variety sensor models and objective functions will show some results couple domains including helicopter flight GPS denied environments 
11231 en  BayesFilters Gaussian Process Regression for Bayesian Filtering Bayes filters recursively estimate the state dynamical systems from streams sensor data Key components each Bayes filter are probabilistic prediction and observation models robotics these models are typically based parametric descriptions the physical process generating the data this talk will show how non parametric Gaussian process prediction and observation models can integrated into different versions Bayes filters namely particle filters and extended and unscented Kalman filters The resulting BayesFilters can have several advantages over standard filters Most importantly BayesFilters not require accurate parametric model the system Given enough training data they enable improved tracking accuracy compared parametric models and they degrade gracefully with increased model uncertainty extend Gaussian Process Latent Variable Models train BayesFilters from partially fully unlabeled training data The techniques are evaluated the context visual tracking micro blimp and IMU based tracking slotcar 
11232 en Imitation Learning and Purposeful Prediction Probabilistic and Non probabilistic Methods Programming robot behavior remains challenging task While often easy abstractly define even demonstrate desired behavior designing controller that embodies the same behavior difficult time consuming and ultimately expensive The machine learning paradigm offers the promise enabling programming demonstration for developing high performance robotic systems Unfortunately many behavioral cloning approaches that utilize the classical tools supervised learning decision trees neural networks support vector machines not fit the needs modern robotic systems Classical statistics and supervised machine learning exist vacuum predictions made these algorithms are explicitly assumed not affect the world which they operate nIn practice robotic systems are often built atop sophisticated planning algorithms that efficiently reason far into the future consequently ignoring these planning algorithms lieu supervised learning approach often leads myopic and poor quality robot performance While planning algorithms have shown success many real world applications ranging from legged locomotion outdoor unstructured navigation such algorithms rely fully specified cost functions that map sensor readings and environment models quantifiable costs Such cost functions are usually manually designed and programmed Recently our group has developed set techniques that learn these functions from human demonstration These algorithms apply Inverse Optimal Control IOC approach find cost function for which planned behavior mimics expert demonstration discuss these methodologies both probabilistic and otherwise for imitation learning focus the Principle Causal Maximum Entropy that generalizes the classical Maximum Entropy Principle widely used many fields including physics statistics and computer vision problems decision making and control This generalization enables MaxEnt apply new class problems including Inverse Optimal Control and activity forecasting This approach further elucidates the intimate connections between probabilistic inference and optimal control consider case studies activity forecasting drivers and pedestrians well the imitation learning robotic locomotion and rough terrain navigation These case studies highlight key challenges applying the algorithms practical settings that utilize state the art planners and are constrained efficiency requirements and imperfect expert demonstration 
11233 en Probabilistic Control Human Computer Interaction Continuous interaction with computers can treated control problem subject various sources uncertainty present examples interaction based multiple noisy sensors capacitive sensing location and bearing sensing and EEG domains which rely inference about user intention and where the use particle filters can improve performance use the metaphor for automated flexibly handover level autonomy control function the certainty control actions from the user analogous fashion loosening the reins when horse riding Integration the inference mechanisms with probabilistic feedback designs can have significant effect behaviour and some examples are presented Joint work with John Williamson Simon Rogers and Steven Strachan 
11234 en Estimating the Sources Motor Errors Motor adaptation usually defined the process which our nervous system produces accurate movements while the properties our bodies and our environment continuously change Many experimental and theoretical studies have characterized this process assuming that the nervous system uses internal models compensate for motor errors Here extend these approaches and construct probabilistic model that not only compensates for motor errors but estimates the sources these errors These estimates dictate how the nervous system should generalize For example estimated changes limb properties will affect movements across the workspace but not movements with the other limb extend previous studies that area account for temporal and context effects This extended model explains aspects savings along with aspects generalization 
11235 en Linear Bellman Equations Theory and Applications will provide brief overview class stochastic optimal control problems recently developed our group well Bert Kappen group This problem class quite general and yet has number unique properties including linearity the exponentially transformed Hamilton Jacobi Bellman equation duality with Bayesian inference convexity the inverse optimal control problem compositionality optimal control laws path integral representation the exponentially transformed value function will then focus function approximation methods that exploit the linearity the Bellman equation and illustrate how such methods scale high dimensional continuous dynamical systems Computing the weights for fixed set basis functions can done very efficiently solving large but sparse linear problem This enables work with hundreds millions localized bases Still the volume high dimensional state space too large filled with localized bases forcing consider adaptive methods for positioning and shaping those bases Several such methods will compared 
11236 en  Control Theory and Decision Making under Uncertainty control theory consists class control problems for which the control computation can solved graphical model inference problem this talk show how apply this theory the context delayed choice task and for collaborating agents first introduce the control framework Then show that delayed reward task when the future uncertain optimal delay the timing your decision show preliminary results human subjects that confirm this prediction Subsequently discuss two player games such the stag hunt game where collaboration can improve worsten result recursive reasoning about the opponents actions The Nash equilibria appear local minima the optimal cost but may disappear when monetary gain decreases This behaviour agreement with experimental findings humans 
11237 en Linear Bellman Combination for Simulation Human Motion Simulation natural human motion challenging because the relevant system dynamics high dimensional underactuated— direct control over global position and orientation—and non smooth—frequent and intermittent ground contacts order succeed control policy must look ahead determine stabilizing actions and must optimize generate lifelike motion this talk will review recently developed control systems that yield high quality agile movements for three dimensional human simulations Creating such controllers requires intensive computer optimization and reveals need for reusing many control policies possible will answer this problem partially with efficient combination that creates new optimal control policy reusing set optimal controls for related tasks remains seen the same approach can also applied control systems needed generate lifelike human motion 
11239 en Probabilistic Design Promises and Prospects The Fully Probabilistic Design FPD suggests probabilistic description the closed control loop behaviour well desired closed loop behaviour The optimal control strategy selected the minimiser the Kullback Leibler divergence these distributions The approach yields explicit minimiser with the evaluation reduced conceptually feasible solution integral equations randomised optimal strategy iii proper subset FPDs formed via standard Bayesian designs uncertain knowledge multiple control goals and optimisation constrains expressed the common probabilistic language implies easier approximation the dynamic programming counterpart the optimal strategy naturally explorative iii the goals expressing ideal distribution can even recursively tailored the observed closed loop behavior opportunity automatically harmonise knowledge and goals within flat cooperation structure decentralised task importance the last point has been confirmed huge amount societal industrial problems that cannot governed centralised way The anticipated decentralised solution based the FPD may concern either number interacting locally independent elements which have their local goals but have collaborate reach common group goal cooperative robots multi agent systems etc set independent elements with own goals that need coordinate their activities transportation The talk will recall the basic properties FPD and discusses the promises exploitation the FPD potential 
11240 en Approximate Inference Control Approximate Inference Control AICO method for solving Stochastic Optimal Control SOC problems The general idea think control the problem computing posterior over trajectories and control signals conditioned constraints and goals Since exact inference infeasible realistic scenarios the key for high speed planning and control algorithms the choice approximations this talk will introduce the general approach discuss its intimate relations DDP and the current research Kalman duality and discuss the approximations that use get towards real time planning high dimensional robotic systems will also mention recent work using Expectation Propagation and truncated Gaussians for inference under hard constraints and limits they typically arise robotics collision and joint limit constraints 
11241 en Inference for PCFGs and Adaptor Grammars This talk describes the procedures developed for adaptor grammar inference Adaptor grammars are non parametric extension PCFGs that can used describe variety phonological and morphological language learning tasks start reviewing MCMC sampler for Probabilistic Context Free Grammars that serves the basis for adaptor grammar inference and then explain how samples from PCFG whose rules depend the other sampled trees can used proposal distribution MCMC procedure for estimating adaptor grammars Finally describe several optimizations that dramatically speed inference complex adaptor grammars 
11242 en Learning Disambiguate Natural Language Using World Knowledge present general framework and learning algorithm for the task conceptnlabeling each word given sentence has tagged with the unique physicalnentity person object location abstract concept refers Our methodnallows both world knowledge and linguistic information used during learningnand prediction show experimentally that can handle natural language andnlearn use world knowledge resolve ambiguities language such wordnsenses coreference without the use hand crafted rules features 
11243 en Language Modeling with Tree Substitution Grammars show that tree substitution grammar TSG induced with collapsed Gibbsnsampler results lower perplexity test data than both standard context freengrammar and other heuristically trained TSGs suggesting that better suited tonlanguage modeling Training more complicated bilexical parsing model acrossnTSG derivations shows further though nuanced improvement conduct analysisnand point future areas research using TSGs language models 
11244 en  Preliminary Evaluation Word Representations for Named Entity Recognition use different word representations word features for named entity recognitionn NER system with linear model This work part larger empiricalnsurvey evaluating different word representations different NLP tasks evaluatenBrown clusters Collobert and Weston 2008 embeddings and HLBL Mnihn Hinton 2009 embeddings words All three representations improve accuracynon NER with the Brown clusters providing larger improvement than thentwo embeddings and the HLBL embeddings more than the Collobert and Westonn 2008 embeddings also discuss some the practical issues using embeddingsnas features Brown clusters are simpler than embeddings because theynrequire less hyperparameter tuning 
11245 en Learnable Representations for Natural Language The Chomsky hierarchy was explicitly intended represent the hypotheses from distributional learning algorithms yet these standard representations are well known hard learn even under quite benign learning paradigms because the computationally complexity inferring rich hidden structures like trees nnThere lot interest unsupervised learning natural language current approaches Klein and Manning Johnson Adaptor Grammars use modifications existing models such tree dependency structures together with sophisticated statistical models order recover structures that are close possible gold standard manual annotations nnThis tutorial will cover different approach recent algorithms for the unsupervised learning representations natural language based distributional learning Clark Eyraud 2007 Clark Eyraud and Habrard 2008 Clark 2009 This research direction involves abandoning the standard models and designing new representation classes for formal languages that are richly structured but where the structure not hidden but based observable structures the language the syntactic monoid lattice derived from that monoid These representation classes are result easy learn nnWe will look briefly algorithms for learning deterministic automata and then move algorithms for learning context free and context sensitive languages These algorithms explicitly model the distribution substrings the language they are efficient polynomial update time and provably correct for class languages that includes all regular languages many context free languages and few context sensitive languages This class may rich enough represent natural language syntax 
11246 en Learning Languages and Rational Kernels This talk will discuss several topics related learning automata and learning languages with rationalnkernels 
11249 en Where What Towards Semantic Mapping Urban Environments The availability continuous streams data from multiple modalities covering the same workspace has long been recognised privilege robotics researchers Data fusion has successful track record the field leading the now routine generation high quality large scale metric and topological maps unstructured environments With this success however comes the realisation that prominent applications robotics such action selection and human machine interaction require information beyond mere metric topological representations result researchers throughout the community are becoming increasingly interested adding higher order semantic information the maps obtained this context the availability rich set data from complimentary modalities once again comes into its own this talk provide snapshot ongoing work aiming enrich standard metric topological maps provided mobile robot with higher order semantic information Environmental cues are considered for classification different scales The first stage considers local scene properties using probabilistic bag words classifier The second stage incorporates contextual information across given scene spatial context and across several consecutive scenes temporal context via Markov Random Field MRF Our approach driven data from onboard camera and laser scanner and uses combination visual and geometric features demonstrate the virtue considering such spatial and temporal context during the classification task and analyse the performance our technique data gathered over track through city 
11250 en  Bayesian Approach Occupancy Mapping with Uncertain Inputs This work addresses the problem occupancy mapping with uncertain measurements taken from none more mobile robots Appropriate modeling sensor and localisation uncertainty critical nto obtaining consistent and robust maps which may subsequently used planning and motion ncontrol 
11251 en Domain Adaptation for Mobile Robot Navigation important challenge outdoor mobile robotic perception maintaining terrain classiﬁcation nperformance throughout the extremely variable conditions that may wish robot operate nunder Outdoor robots operate series “environments” that consist diverse terrain nvegetation weather and lighting conditions physical robot does not randomly jump between nenvironments typically will operate for long stretches time one particular environment nmaking advantageous adapt the robot’ performance its current environment 
11252 en Learning CRF Models from Drill Rig Sensors for Autonomous Mining This paper investigates approach that combines ensemble methods with graphical models analyse multiple sensor measurements the context mine automation Drill sensor measurements used for drilling automation have the potential provide estimate the subsurface geological properties the rocks nbeing drilled Boosting algorithm used local classiﬁer mapping drill measurements corresponding geological categories Conditional Random Field nthen uses this local information conjunction with neighbouring measurements nto jointly reason about their categories Model parameters are learned from training data maximizing the pseudo likelihood The probability distribution nclassiﬁed borehole sections calculated using belief propagation present experimental results applying the method classify rock types from sensor data ncollected from semi autonomous drill rig iron ore mine Australia 
11254 en Multi Task Learning with Gaussian Processes with Applications Robot Inverse Dynamics will discuss multi task learning and number ways which transfer between tasks can take place mainly kriging Gaussian process framework will then into more detail multi task Gaussian process learning robot inverse dynamics joint work with Kian Ming Chai Stefan Klanke Sethu Vijayakumar 
11255 en Multitask Learning Using Nonparametrically Learned Predictor Subspaces Given several related learning tasks propose nonparametric Bayesian learning model that captures task relatedness assuming that the task parameters nweight vectors share latent subspace More speciﬁcally the intrinsic dimensionality this subspace not assumed known priori use inﬁnite nlatent feature model the Indian Buffet Process automatically infer this number also propose extensions this model where the subspace learning can nincorporate labeled and additionally unlabeled available examples the task nparameters share mixture subspaces instead sharing single subspace The nlatter property can allow learning nonlinear manifold structure underlying the task nparameters and can also help preventing negative transfer from outlier tasks 
11256 en Bayesian Localized Multiple Kernel Learning Many problems machine learning involve datasets that are comprised multiple views The nseparate views can deﬁned over single input multiple image feature types from multiple information sources audio and video this context each view can provide redundant nindication the underlying class event interest useful for classiﬁcation 
11257 en Multi Way Multi View Learning extend multi way multivariate ANOVA type analysis cases where one ncovariate the view with features each view coming from different high ndimensional domains The different views are assumed connected having npaired samples this common our main application biological experiments nintegrating data from different sources Such experiments typically also include ncontrolled multi way experimental setup where disease status medical treatment ngroups gender and time the measurement are usual covariates introduce multi way latent variable model for this new task extending the generative model Bayesian canonical correlation analysis CCA both take multi way ncovariate information into account population priors and reducing the dimensionality integrated factor analysis that assumes the features come correlated groups 
11258 en Information Theoretic Kernel Integration this paper consider novel information theoretic approach multiple kernel learning based minimising Kullback Leibler divergence between nthe output kernel matrix and the input kernel matrix There are two formula ntions which refer MKLdiv and MKLdiv conv propose solve nMKLdiv difference convex programming method and MKLdiv nconv projected gradient descent algorithm The effectiveness the proposed napproaches evaluated benchmark dataset for protein fold recognition and nyeast protein function prediction problem 
11260 en Chordal Sparsity Semidefinite Programming and Machine Learning Chordal graphs play fundamental role algorithms for sparse matrix factorization graphical models and matrix completion problems matrix optimization chordal sparsity patterns can exploited fast algorithms for evaluating the logarithmic barrier function the cone positive definite matrices with given sparsity pattern and the corresponding dual cone will give survey chordal sparse matrix methods and discuss two applications more detail linear optimization with sparse matrix cone constraints and the approximate solution dense quadratic programs arising support vector machine training 
11261 en  Pathwise Algorithm for Covariance Selection Covariance selection seeks estimate covariance matrix maximum likelihoodnwhile restricting the number nonzero inverse covariance matrix coefficients single penalty parameter usually controls the tradeoff between log likelihoodnand sparsity the inverse matrix describe efficient algorithm forncomputing full regularization path solutions this problem 
11262 en Active Set Algorithm for Structured Sparsity Inducing Norm consider the empirical risk minimization problem for linear supervised learning nwith regularization structured sparsity inducing norms These are definednas sums Euclidean norms certain subsets variables extending the usualn norm and the group norm allowing the subsets overlap This leads tona specific set allowed nonzero patterns for the solutions such problems Wenfirst explore the relationship between the groups defining the norm and the resultingnnonzero patterns particular show how geometrical information aboutnthe variables can encoded our regularization finally present activenset algorithm efficiently solve the corresponding minimization problem 
11263 en  Recent Trends Extremely Large Scale Convex Optimization the talk focus algorithms for solving well structured large scale convex programs the case where huge problem sizes prevent processing polynomial time algorithms and thus make computationally cheap first order optimization methods the methods choice overview significant recent progress utilizing problem structure within the first order framework with emphasis algorithms with dimension independent and optimal the large scale case iteration complexity being the target accuracy then discuss the possibility further accelerate the first order algorithms randomization specifically passing from expensive the extremely large scale case precise deterministic first order oracles their computationally cheap stochastic counterparts Applications discussed include SVM minimization testing sensing matrices for goodness the Compressed Sensing context low dimensional approximation high dimensional samples and some others 
11264 en Tree Based Ensemble Models Regularization Convex Optimization Tree based ensemble methods can seen way learn kernel from samplenof input output pairs This paper proposes regularization framework incorporatennon standard information not used the kernel learning algorithm tontake advantage incomplete information about output values and some priorninformation about the problem hand this end generic convex optimizationnproblem formulated which first customized into manifold regularizationnapproach for semi supervised learning then way exploit censored outputnvalues and finally generic way exploit prior information about the problem 
11265 en  the Convergence the Convex Concave Procedure The concave convex procedure CCCP majorization minimization algorithmnthat solves difference convex functions programs sequence convexnprograms machine learning CCCP extensively used many learning algorithmsnlike sparse support vector machines SVMs transductive SVMs sparsenprincipal component analysis etc Though widely used many applications thenconvergence behavior CCCP has not gotten lot specific attention thisnpaper provide rigorous analysis the convergence CCCP addressingnthese questions When does CCCP find local minimum stationary pointnof the program under consideration When does the sequence generatednby CCCP converge nnWe also present open problem the issue localnconvergence CCCP 
11266 en SINCO Efficient Greedy Method for Learning Sparse INverse COvariance Matrix Herein propose simple greedy algorithm SINCO for solving this optimization problem nSINCO solves the primal problem unlike its predecessors such COVSEL and glasso nusing coordinate ascent greedy manner thus naturally preserving the sparsity the solution nAs demonstrated our empirical results SINCO has better capability reducing the false positivenerror rate while maintaining similar true positive rate when networks are sufficiently sparse thannglasso because its greedy incremental nature 
11267 en Super Linear Convergence Dual Augmented Lagrangian Algorithm for Sparse Learning analyze the convergence behaviour recently proposed algorithm for sparsenlearning called Dual Augmented Lagrangian DAL theoretically analyzenunder some conditions that DAL converges super linearly non asymptoticnand global sense experimentally confirm our analysis large scale regularized logistic regression problem and compare the efficiency DAL algorithmnto existing algorithms 
11296 en The End the Ubicomp World Near Friend live the golden age ubiquitous computing Many elements Weiser’ bold vision are today commonplace the lives billions people Without even thinking about today routinely search the web reach out people with our mobile internet devices and find places and things with positioning technologies Together the myriad devices and services that make the internet form unprecedented ubicomp platform simply tremendous possibilities have seen many wonderful ubicomp systems and research shows that more are heading our way The bad news greater failures are heading our way too nnEach new generation systems brings added functionality which inevitably means added complexity somewhere the systems This turn creates numerous new failure modes with each generation Moreover increasing connectivity brings novel ways propagate the failures into other systems see around major shortcomings terms usability interoperability and security and worse can expected should your cup half empty nnThis talk will explore some the factors that shape the ubicomp field – breakneck speeds innovation unstoppable technology development maturing services and information economies among others – and discuss why such developments may have undesirable consequences positive note this talk will also identify other promising factors that may ultimately render our cup more than half full 
11297 en The Art Mobility Screen cultures today are dominated narrative and its modes framing The advent “Pervasive” “Ubiquitous” media such mobile smartphones with GPS sensing means that new dispersed forms narrative interaction are now possible for the public The convergence mobile technologies and ubiquitous computing are creating world where information rich environments may mapped directly onto urban topologies Dispersed forms interaction raise intriguing new questions about the nature narrative and communication particularly relation modes audience’ participation and reception nnThis new and experimental work far undertaken the arena interactive public art spatialised interaction through mobile technologies pressing need exploration definition and documentation Emergent technologies interaction and the changing nature public interactive engagement present radical challenge Western narrative and its vehicles and traditions Boundaries between established forms games and cinema are thrown into question and the very concept creative authorship becomes problematic Whilst other emerging technologies are already redefining existing forms screen based exhibition and reception interactive television and digital cinema they still tie down the audience relation the screen Locative technology blurs the borders between physical and virtual space leading the redefinition the concept the virtual from that simulation that augmentation nnThis poses series questions around changing concepts space and place for wide range traditional disciplines ranging from Anthropology Art and Architecture Computer Studies Cultural and Media Studies Fashion Graphic design The talk will illustrated examples from Rieser recent practice including The Third Woman interactive mobile film 
11299 en Introduction Programming Applications for Mobile Devices Mobile phones are increasingly capable devices These devices are also increasingly friendly towards developers and now straightforward write your own programs The objective the Tutorial provide hands experience with creating applications for mobile devices This will achieved through example location aware application for three mobile platforms Google Android Windows Mobile and Apple iPhone platform Participants will guided through the development the Android platform with detailed descriptions how achieve similar objectives using Windows Mobile and Apple iPhone nnThe format will designed around attendees actively working through the example application their own computers nnRequirements nBasic knowledge the Java programming language will benefit but will aim make the content accessible everyone For active participation please bring laptop and install copy the Android SDK Here the list system requirements nnThe instructors will provide assistence with installing the Android SDK prior the tutorial session 
11300 en Security and Privacy only Matter Time before Massive Loss Personal Data Identity theft Happens Smart Mobile Platform have growing number smart platforms that are becoming established each with its own market place for applications Blackberry RIM Nokia Ovi Apple iPhone Google Vodafone 360 but don’ have security architecture that actually makes sense terms protecting end users against all the attacks that are common place the Internet today Securing the potentially massive amount interactions using mobile devices difficult because typically there will priori shared information such passwords addresses PIN codes between the phone its user and the service they want use nnAdditionally mobile devices often lack powerful user interfaces support classical authentication methods Personal content indeed private but with emerging mobile payment and ticketing solutions and the socialising contact information personal information becoming even more highly sensitive ’ only matter time before massive loss personal data identity theft happens one these platforms more than one and the economic and technical fallout will quite serious 
11301 en One Minute Madness Using OWL Provide Content Mobility Augmented Reality Babar Chaudary nn2 Construction User Scenarios with Machinima Technique http videolectures net arto puikkonen Arto Puikkonen Presenter nn3 Semantic Information Interoperability Smart Spaces http videolectures net antti evesti Antti Evesti Presenter nn4 Customizable Real time Delivery Flash Video iPhones http videolectures net francis marchese Francis Marchese Presenter nn5 1000 Cell Phones http videolectures net david carroll David Carroll Presenter nn6 weConnect Supporting Close Relationships through Mobile Broadcasting http videolectures net jamie costello Jamie Costello Presenter nn7 mGuide Rich Information Capture and Sharing Mobile Contexts http videolectures net jamie costello Jamie Costello Presenter nn8 SpARC Supplementary Assistance for Rowing Coaching http videolectures net simon fothergill Simon Fothergill Presenter nn9 Augmented Reality Explorer http videolectures net arto puikkonen Arto Puikkonen Presenter nn10 Mind Controlled Educational Computer Games http videolectures net ian glasscock Ian Glasscock Presenter 
11304 en SpARC Supplementary Assistance for Rowing Coaching This system gathers data and provides real time and post session feedback athletes aspects their technique measuring and analysing the kinetics their performance The motion the ergometer handle both relative the erg and the seat are used along with the forces applied through the handle and each foot Ideal performances can programmed and score similarity between this and current performance calculated every stroke motivate consistency the athlete technique nnThe data collected also used evaluate analysis algorithms provide more sophisticated feedback athletes 
11305 en weConnect Supporting Close Relationships through Mobile Broadcasting Building the Internet platforms available mobile devices and personal computers PCs implemented service called weConnect that facilitates broadcast content via dedicated and personal media channels weConnect includes simple tools for integrating content into media mixes and provides content viewers for ubiquitous access weConnect channels via mobile desktop and other enabled devices this paper present exploratory user study based deployment the weConnect service among individuals close relationships The study focuses the user perception and experience with the always channels delivering personalized content started with images text and animations familiar and easily accessible media observed high level reciprocity creating and exchanging expressive content and need for persistence reuse and notification content delivery The users voiced their enthusiasm for receiving personalized media across mobile and desktop devices The always nature the weConnect channels raised new requirements for the service design assist content producers with creating streams personalized media efficiently and enable recipients view the content flexibly 
11306 en mGuide Rich Information Capture and Sharing Mobile Contexts mGuide Web service and mobile application that incorporates location based awareness into the user communication nnIt assists users meeting particular location enabling mobile users exchange images and messages and see each other’ progress map nJourneys The user can record journey through images voice messages and location displayed maps nnThese journeys can shared with others real time retrospect both through PCs and the mobile devices ndClone dClone enables user maintain contact with another person through subtle unobtrusive communications nThe sender can compose display personal information from images voice text messages and general online information such local time weather information nThe recipient can choose have the information displayed home screen all times continuously connected and aware the sender’ experience 
11307 en Semantic Information Interoperability Smart Spaces Link YouTube com http www youtube com watch EU9alk9t7dA Semantic Information Interoperability Smart Spaces 
11308 en Customizable Real time Delivery Flash Video iPhones
11309 en 1000 Cell Phones Emerging out institutional collaboration between Parsons The New School for Design New YorknCity and the Academy Arts and Design Tsinghua University Beijing the mobile medianinstallation “1000 Cell Phones ” exposes the invisible conversations that constantly occur betweennthe networked devices carry throughout our nomadic urban daily life The installation consists ofnmultiple displays that playfully visualize and animate discovered Bluetooth devices within its situatednspace Devices are represented abstract discs dimensional screen space colored byntranscribing the devices’ unique identifiers distinctive tone and hue values This simple butnevocative effect emphasizes how number expressed one kind color not only makesnvisible distinguishing feature our portable networked device but also reshapes its obfuscatedntechnical datum into aesthetic and coherent design object asks this machine identifiernexpresses our persona and personality perhaps without our knowledge and complete understandingnof the implications addition discovered device names animate across the screens emphasizingnthe transient nature the tracking devices carry unwittingly broadcasting unique identifier fornanyone anything willing listen installing the work social space such café lobby “1000 Cell Phones” captures the unseen dialogue between mobile phones and laptops broadcastingntheir Bluetooth identities while owners lurk and socialize When participants realize how their devicennames render the displays they often engage the intervention altering their device settings tonaffect the textual content the visualization these moments the conversations between theninvisible and visible technical and aesthetic surveillance and dissemination machines and people allnbecome intertwined simple but enjoyable expression 
11318 en Lecture Potential Energy Surfaces Transition State Theory and Reaction Mechanism Overview nnAfter discussing the statistical basis the law mass action the lecture turns developing framework for understanding reaction rates potential energy surface that associates energy with polyatomic geometry can realized physically for linear triatomic system but more practical use collective energies for starting material transition state and product together with Eyring theory predict rates Free radical chain halogenation provides examples predicting reaction equilibria and rates from bond dissociation energies The lecture concludes with summary the semester topics from the perspective physical organic chemistry nnProblem sets Reading assignment nnReading assignments problem sets PowerPoint presentations and other resources for this lecture can accessed from Professor McBride campus course website which was developed for his Fall 2008 students Please see Resources section below nnResources http webspace yale edu chem125 oyc L37 Professor McBride web resources for CHEM 125 Fall 2008 
11335 en Topological Data Analysis Computational topology relatively new field between mathematics and computer science which one hand uses concepts and methods from topology formalize and solve problems computer science and the other hand designs algorithms for computing complex invariants algebraic topology this talk will present several topological approaches data and image analysis 
11339 en Parallel Exact Inference Multi Core Processors Exact inference Bayesian networks fundamental technique that has numerous applications including medical diagnosis consumer help desk pattern recognition credit assessment data mining genetics and others Inference hard and many applications real time performance required this talk show task and data parallel techniques achieve scalable performance general purpose multi core and heterogeneous multi core architectures develop collaborative schedulers dynamically map the junction tree tasks leading highly optimized implementations design lock free structures reduce thread coordination overheads scheduling while balancing the load across the threads For the Cell develop light weight centralized scheduler that coordinates the activities the synergistic processing elements SPEs Our scheduler further optimized run throughput oriented architectures such SUN Niagara processors demonstrate scalable and efficient implementations using Pthreads for wide class Bayesian networks with various topologies clique widths and number states random variables Our implementations show improved performance compared with OpenMP and complier based optimizations 
11340 en Parallel Online Learning fundamental limit the speed training and prediction imposed bandwidth there finite amount data that computer can access fixed amount time Somewhat surprisingly can build online learning algorithm fully capable hitting this limit will discuss approaches for breaking the bandwidth limit including empirical results 
11341 en Probabilistic Machine Learning Computational Advertising the past years online advertising has grown least order magnitude faster than advertising all other media This talk focuses advertising search engines where accurate predictions the probability that user clicks advertisement crucially benefit all three parties involved the user the advertiser and the search engine present Bayesian probabilistic classification model that has the ability learn from terabytes web usage data The model explicitly represents uncertainty allowing for fully probabilistic predictions positives out instances 200 out 1000 both give average but the first case the uncertainty about the prediction should larger also present scheme for approximate parallel inference that allows efficient training the algorithm distributed data architecture 
11343 en Scalable Learning Computer Vision Computer vision challenging application area machine learning Recent work has shown that large training sets may yield higher performance vision tasks like object detection overview our work object detection using scalable distributed training system capable training more than 100 million examples just few hours also briefly describe recent work with deep learning algorithms that may allow apply these architectures large datasets well 
11344 en Hadoop Infrastructure for the Rapid Implementation Parallel Reusable Analytics Hadoop open source implementation Google Map Reduce programming model Over the past few years has evolved into popular platform for parallelization industry and academia Furthermore trends suggest that Hadoop will likely the analytics platform choice forthcoming Cloud based systems Unfortunately implementing parallel machine learning data mining algorithms Hadoop complex and time consuming address this challenge present Hadoop infrastructure facilitate the implementation parallel algorithms Hadoop Hadoop has been designed allow for the specification both task parallel and data parallel algorithms Furthermore supports the composition parallel algorithms using both serial well parallel building blocks this allows one write reusable parallel code The proposed abstraction eases the implementation process requiring the user only specify computations and their dependencies without worrying about scheduling data management and communication consequence the codes are portable that the user never needs write Hadoop specific code This potentially allows one leverage future parallelization platforms without rewriting one code 
11345 en Recreational Activities and Discussion informal tutorial the Vowpal Wabbit algorithm 
11346 en Large Scale Machine Learning The Problems Algorithms and Challenges seed discussion will attempt organize research efforts large scale machine learning looking common computational problems across all machine learning and the challenges creating efficient parallel algorithms for them begin identifying four common types computational bottlenecks that occur across all machine learning prototype algorithmic problems body problems graph operations linear algebra and optimization Within each category discuss what can cannot learn from the existing body work scientific computing highlight few the most successful and recent specific serial algorithms that have been developed for concreteness and discuss what makes them easy hard parallelize synthesize some these observations obtain list desiderata for parallel machine learning algorithms research and software toolkits 
11347 en  Billion Instances Thousand Machines and Hours Training conditional maximum entropy models massive data sets requires significant computational resources but distributing the computation training time can significant reduced Recent theoretical results have demonstrated conditional maximum entropy models trained weight mixtures independently trained models converge the same rate traditional distributed schemes but significantly faster This efficiency achieved primarily reducing network communication costs cost not usually considered but actually quite crucial 
11348 en FPGA based MapReduce Framework for Machine Learning Machine learning algorithms are becoming increasingly important our daily life However training very large scale datasets usually very slow FPGA reconfigurable platform that can achieve high parallelism and data throughput Many works have been done accelerating machine learning algorithms FPGA this paper adapt Google MapReduce model FPGA realizing chip MapReduce framework for machine learning algorithms processor scheduler implemented for the maximum computation resource utilization and load balancing accordance with the characteristics many machine learning algorithms common data access scheme carefully designed maximize data throughput for large scale dataset This framework hides the task control synchronization and communication away from designers shorten development cycles case study RankBoost acceleration speedup achieved versus CPU based design which comparable with fully manually designed version also discuss the implementations two other machine learning algorithms SVM and PageRank demonstrate the capability the framework 
11349 en Large Scale Graph based Transductive Inference consider the issue scalability graph based semi supervised learning SSL algorithms this context propose fast graph node ordering algorithm that improves parallel spatial locality being cache cognizant This approach allows for linear speedup shared memory parallel machine achievable and thus means that graph based SSL can scale very large data sets use the above algorithm multi threaded implementation solve SSL problem 120 million node graph reasonable amount time 
11350 en Splash Belief Propagation Efficient Parallelization Through Asynchronous Scheduling this work focus approximate parallel inference loopy graphical models using loopy belief propagation demonstrate that the natural fully synchronous parallelization belief propagation highly inefficient bounding the achievable parallel performance loopy belief propagation chain graphical models develop theoretical understanding the parallel limitations belief propagation then introduce Splash belief propagation parallel asynchronous approach which achieves the optimal bounds and demonstrates linear super linear scaling large graphical models Finally discuss how these ideas may generalized parallel iterative graph algorithms the context our new GraphLab framework 
11362 en Lecture Goals the course what computation introduction data types operators and variables
11363 en Lecture Operators and operands statements branching conditionals and iteration
11364 en Lecture Common code patterns iterative programs
11365 en Lecture Decomposition and abstraction through functions introduction recursion
11366 en Lecture Floating point numbers successive refinement finding roots
11367 en Lecture Bisection methods Newton Raphson introduction lists
11368 en Lecture Lists and mutability dictionaries pseudocode introduction efficiency
11369 en Lecture Complexity log linear quadratic exponential algorithms
11370 en Lecture Binary search bubble and selection sorts
11371 en Lecture Divide and conquer methods merge sort exceptions
11372 en Lecture Testing and debugging
11373 en Lecture More about debugging knapsack problem introduction dynamic programming
11374 en Lecture Dynamic programming overlapping subproblems optimal substructure
11375 en Lecture Analysis knapsack problem introduction object oriented programming
11376 en Lecture Abstract data types classes and methods
11377 en Lecture Encapsulation inheritance shadowing
11378 en Lecture Computational models random walk simulation
11379 en Lecture Presenting simulation results Pylab plotting
11380 en Lecture Biased random walks distributions
11381 en Lecture Monte Carlo simulations estimating
11382 en Lecture Validating simulation results curve fitting linear regression
11383 en Lecture Normal uniform and exponential distributions misuse statistics
11384 en Lecture Stock market simulation
11385 en Lecture Course overview what computer scientists 
11469 en Lecture Prokofiev Visions Fugitives student presentations and composition workshop
11470 en Lecture Running Clinic with Danny Abshire
11552 en Biomine search engine for probabilistic graphs Biomine search engine prototype under development can usednto find biological entities that are indirectly related given querynentities well display and evaluate the relations Biomine isnbased integrated index number public biological databases nThe representation probabilistic graph where nodes correspond tonbiological entities typically record biological database andnedges their relationships typically cross reference betweenndatabase records Edges are annotated with probabilities that reflectnthe strength the reliability the relation will discuss researchnproblems and challenges for search such graphs 
11565 en Ensembles for predicting structured outputs many real world domains such bioinformatics functionalngenomics text classification and image annotation the goal tonpredict complex output For example functional genomics thengoal predict the function gene while the set functionsncan organized tree FunCat graph ontology nIn this talk present approach for predicting structured outputsnusing ensembles trees The proposed approach scalable largendatasets different types outputs and applicable widenrange domains First describe the types structured outputsnthat typically encounter and then explain the base classifiersn predictive clustering trees PCTs Next discuss the ensemblenmethods that extended bagging and random forests deal withnstructured outputs and accordingly adapted the voting schemes nAfterwards present experimental evaluation the proposednapproach wide range real world domains the end presentnan application the proposed approach functional genomics andnshow that our approach competitive with state the art approaches 
11566 en Italy Space Italy has been making important investments space since 1960s The first European country the third the world launch scientific satellites Italy was one the founding countries the European Space Agency 1975 and now the third contributor ESA European Space Agency Established 1988 ASI Governmental Agency for promotion development and diffusion scientific and technological research the fields space and aerospace scientific observation and exploration the universe earth observation telecommunications and navigation microgravity and education Important the contribution the International space station where relevant part the habitable volume the orbiting platform has been mainly built Italy 
11570 en Polarization Light Waves Rainbows and Cheap Sunglasses this lecture taped before live audience elementary and middle school students and their families MIT Physics Professor Walter Lewin explains polarization and demonstrates properties light rainbows smoke and the sky answers the perennial question why the sky blue and creates red sunset the laboratory Link http mitworld mit edu video Lecture´ Homepage Host http web mit edu museum MIT Museum Series http mitworld mit edu series view Family Adventures Science and Technology Program 
11571 en The Sounds Music Have you ever wondered about the annoying hum your car makes certain speed particular stretch highway why flute’ notes are higher than trombone’ Walter Lewin uses rubber hose wooden boxes with holes metal plates and assortment other home made instruments demonstrate how objects produce sound all boils down how something vibrates pushing air out all directions nnLewin illustrates the shape sounds taking rope tethered one end shaking and down different speeds and producing specific wave shapes These shapes are the rope’ resonant frequencies harmonics ’ the same for bowed violin where the oscillations the strings generate set harmonics producing the notes hear the faster the oscillations the higher the tones Lewin invites children from the audience produce sounds with their musical instruments and shows the amplitude and frequency the tones Later demonstrates destructive resonances video bridge that twists violently that collapses and then live the laboratory the shattering wine glass with progressively louder and higher tones this event where physics meets performance art Lewin provides surprises throughout Link http mitworld mit edu video 168 Lecture´ Homepage Host http web mit edu museum MIT Museum Series http mitworld mit edu series view Family Adventures Science and Technology Program 
11572 en The Wonders Electricity and Magnetism The inimitable Walter Lewin gives literally hair raising performance this MIT Museum lecture demonstration for learners young and old unveils the real meaning behind words and things most use everyday without reflecting what marvels they really represent nnHere are some the mysteries exhibited explored and explained this talk How can you make two perfectly normal balloons zoom apart from each other What happens when you connect volt light bulb 110 volt outlet you toss handful confetti onto comb why does some stick and some fly away What’ the best way make sure your flashlight will work the next time you really need you guessed putting new batteries the back the class nnLewin his electrifying best when working with children from the audience gives year old girl the worst hair day her life and offers young boy cents for hours backbreaking labor But Lewin reaches new high low when repeatedly beats one his young assistants with swatch cat fur Lewin doesn’ exempt himself from the torture though even makes serious attempt electrocute himself with 150 000 volt Van der Graaf generator nnLewin indulges the armchair physicist who’ mathematically challenged covering all the basics electricity and magnetism while introducing just one equation you’ still undecided check out some the unique special effects – sparks flashes smashes and more –pinpointed the Video Index Keep watching and you will find out why Walter Lewin was recently honored with MIT’ Everett Moore Baker Memorial Award for Excellence Undergraduate Teaching nnWith the addition this video MIT World Lewin has total 100 lectures available line OpenCourseWare and MIT World Link http mitworld mit edu video 319 Lecture´ Homepage Host http web mit edu museum MIT Museum Series http mitworld mit edu series view Family Adventures Science and Technology Program 
11647 en Bridging the Structured Structured Gap
11654 en Online Advertising Using Theory and Data Optimize Marketplaces
11656 en Leveraging Temporal Dynamics Document Content Relevance Ranking Many web documents are dynamic with content changing varying amounts varying frequencies However current document search algorithms have static view the document content with only single version the document the index any point time this paper present the first published analysis using the temporal dynamics document content improve relevance ranking show that there strong relationship between the amount and frequency content change and relevance develop novel probabilistic document ranking algorithm that allows differential weighting terms based their temporal characteristics leveraging such content dynamics show significant performance improvements for navigational queries 
11657 en Towards Recency Ranking Web Search web search recency ranking refers ranking documents relevance which takes freshness into account this paper propose retrieval system which automatically detects and responds recency sensitive queries The system detects recency sensitive queries using high precision classifier The system responds recency sensitive queries using machine learned ranking model trained for such queries use multiple recency features provide temporal evidence which effectively represents document recency Furthermore propose several training methodologies important for training recency sensitive rankers Finally develop new evaluation metrics for recency sensitive queries Our experiments demonstrate the efficacy the proposed approaches 
11658 en Ranking Mechanisms Twitter Like Forums study the problem designing mechanism rank items forums making use the user reviews such thumb and star ratings compare mechanisms where forum users rate individual posts and also mechanisms where the user asked perform pairwise comparison and state which one better The main metric used evaluate mechanism the ranking accuracy the cost reviews where the cost measured the average number reviews used per post show that for many reasonable probability models there thumb star based ranking mechanism that can produce approximately accurate rankings with bounded number reviews per item the other hand provide review mechanism based pairwise comparisons which achieves approximate rankings with bounded cost have implemented system shout velocity which twitter like forum but items tweets Twitter are rated using comparisons For each new item the user who posts the item required compare two previous entries This ensures that over sequence posts get least comparisons requiring one review per item average Our mechanism uses this sequence comparisons obtain ranking estimate ensures that every item reviewed least once and winning entries are reviewed more often obtain better estimates top items 
11659 en Learning Concept Importance Using Weighted Dependence Model Modeling query concepts through term dependencies has been shown have significant positive effect retrieval performance especially for tasks such web search where relevance high ranks particularly critical Most previous work however treats all concepts equally important assumption that often does not hold especially for longer more complex queries this paper show that one the most effective existing term dependence models can naturally extended assigning weights concepts demonstrate that the weighted dependence model can trained using existing learning rank techniques even with relatively small number training queries Our study compares the effectiveness both endogenous collection based and exogenous based external sources features for determining concept importance test the weighted dependence model perform experiments both publicly available TREC corpora and proprietary web corpus Our experimental results indicate that our model consistently and significantly outperforms both the standard bag words model and the unweighted term dependence model and that combining endogenous and exogenous features generally results the best retrieval effectiveness 
11660 en Query Reformulation Using Anchor Text Query reformulation techniques based query logs have been studied method capturing user intent and improving retrieval effectiveness The evaluation these techniques has primarily however focused proprietary query logs and selected samples queries this paper suggest that anchor text which readily available can effective substitute for query log and study the effectiveness range query reformulation techniques including log based stemming substitution and expansion using standard TREC collections Our results show that log based query reformulation techniques are indeed effective with standard collections but expansion much safer form query modification than word substitution also show that using anchor text simulated query log least effective real log for these techniques 
11664 en Tagging Human Knowledge fundamental premise tagging systems that regular users can organize large collections for browsing and other tasks using uncontrolled vocabularies Until now that premise has remained relatively unexamined Using library data test the tagging approach organizing collection find that tagging systems have three major large scale organizational features consistency quality and completeness addition testing these features present results suggesting that users produce tags similar the topics designed experts that paid tagging can effectively supplement tags tagging system and that information integration may possible across tagging systems 
11665 en Precomputing Search Features for Fast and Accurate Query Classification Query intent classification crucial for web search and advertising known challenging because web queries contain less than three words average and provide little signal base classification decisions the same time the vocabulary used search queries vast thus classifiers based word occurrence have deal with very sparse feature space and often require large amounts training data Prior efforts address the issue feature sparseness augmented the feature space using features computed from the results obtained issuing the query classified against web search engine However these approaches induce high latency making them unacceptable practice nIn this paper propose new class features that realizes the benefit search based features without high latency These leverage occurrence between the query keywords and tags applied documents search results resulting significant boost web query classification accuracy precomputing the tag incidence for suitably chosen set keyword combinations are able generate the features online with low latency and memory requirements evaluate the accuracy our approach using large corpus real web queries the context commercial search 
11666 en  Tag You Tag Translating Tags for Advanced User Models Collaborative tagging services folksonomies have been among the stars the Web era They allow their users label diverse resources with freely chosen keywords tags Our studies two real world folksonomies unveil that individual users develop highly personalized vocabularies tags While these meet individual needs and preferences the considerable differences between personal tag vocabularies personomies impede services such social search customized tag recommendation this paper introduce novel user centric tag model that allows derive mappings between personal tag vocabularies and the corresponding folksonomies Using these mappings can infer the meaning user assigned tags and can predict choices tags user may want assign new items Furthermore our translational approach helps reducing common problems related tag ambiguity synonymous tags multilingualism evaluate the applicability our method tag recommendation and tag based social search Extensive experiments show that our translational model improves the prediction accuracy both scenarios 
11667 en Pairwise Interaction Tensor Factorization for Personalized Tag Recommendation Tagging plays important role many recent websites Recommender systems can help suggest user the tags might want use for tagging specific item Factorization models based the Tucker Decomposition model have been shown provide high quality tag recommendations outperforming other approaches like PageRank FolkRank collaborative filtering etc The problem with models the cubic core tensor resulting cubic runtime the factorization dimension for prediction and learning nnIn this paper present the factorization model PITF Pairwise Interaction Tensor Factorization which special case the model with linear runtime both for learning and prediction PITF explicitly models the pairwise interactions between users items and tags The model learned with adaption the Bayesian personalized ranking BPR criterion which originally has been introduced for item recommendation Empirically show real world datasets that this model outperforms largely run time and even can achieve better prediction quality Besides our lab experiments PITF has also won the ECML PKDD Discovery Challenge 2009 for graph based tag recommendation 
11668 en fLDA Matrix Factorization through Latent Dirichlet Allocation propose fLDA novel matrix factorization method predict ratings recommender system applications where “bag words” representation for item meta data natu ral Such scenarios are commonplace web applications like content recommendation targeting and web search where items are articles ads and web pages respectively Because data sparseness regularization key good predictive accuracy Our method works regularizing both user and item factors simultaneously through user features and the bag words associated with each item Specifically each word item associated with discrete latent factor often referred the topic the word item topics are obtained averaging topics across all words item Then user rating item modeled user’ affinity the item’ topics where user affinity topics user factors and topic assignments words items item factors are learned jointly supervised fashion avoid overfitting user and item factors are regularized through Gaussian linear regression and Latent Dirichlet Allocation LDA priors respectively nnWe show our model accurate interpretable and handles both cold start and warm start scenarios seamlessly through single model The efficacy our method illustrated benchmark datasets and new dataset from Yahoo Buzz where fLDA provides superior predictive accuracy cold start scenarios and comparable state the art methods warm start scenarios product fLDA also identifies interesting topics that explains user item interactions Our method also generalizes recently proposed technique called supervised LDA sLDA col laborative filtering applications While sLDA estimates item topic vectors supervised fashion for single regression fLDA incorporates multiple regressions one for each user estimating the item factors 
11697 en Coupled Semi Supervised Learning for Information Extraction consider the problem semi supervised learning extract categories academic fields athletes and relations PlaysSport athlete sport from web pages starting with handful labeled training examples each category relation plus hundreds millions unlabeled web documents Semi supervised training using only few labeled examples typically unreliable because the learning task underconstrained This paper pursues the thesis that much greater accuracy can achieved further constraining the learning task coupling the semi supervised training many extractors for different categories and relations characterize several ways which the training category and relation extractors can coupled and present experimental results demonstrating significantly improved accuracy result 
11698 en Data oriented Content Query System Searching for Data into Text the Web the Web provides rich data embedded the immense contents inside pages witness many hoc efforts for exploiting fine granularity information across Web text such Web information extraction typed entity search and question answering unify and generalize these efforts this paper proposes general search system Data oriented Content Query System DoCQS search directly into document contents for finding relevant values desired data types Motivated the current limitations start distilling the essential capabilities needed such content querying The capabilities call for conceptually relational model upon which design powerful Content Query Language CQL For efficient processing design novel index structures and query processing algorithms evaluate our proposal over two concrete domains realistic Web corpora demonstrating that our query language rather flexible and expressive and our query processing efficient with reasonable index overhead 
11699 en Corroborating Information from Disagreeing Views consider set views stating possibly conflicting facts Negative facts the views may come from functional dependencies the underlying database schema want predict the truth values the facts Beyond simple methods such voting typically rather accurate explore techniques based “corroboration” taking into account trust the views introduce three fix point algorithms corresponding different levels complexity underlying probabilistic model They all estimate both truth values facts and trust the views present experimental studies synthetic and real world data This analysis illustrates how and which context these methods improve corroboration results over baseline methods believe that corroboration can serve wide range applications such source selection the semantic Web data quality assessment semantic annotation cleaning social networks This work sets the bases for wide range techniques for solving these more complex problems 
11720 en GeoFolk Latent Spatial Semantics Web Social Media describe approach for multi modal characterization social media combining text features tags prominent example short unstructured text labels with spatial knowledge geotags and coordinates images and videos Our model based framework GeoFolk combines these two aspects order construct better algorithms for content management retrieval and sharing The approach based multi modal Bayesian models which allow integrate spatial semantics social media well formed probabilistic manner systematically evaluate the solution subset Flickr data characteristic scenarios tag recommendation content classification and clustering Experimental results show that our method outperforms baseline techniques that are based one the aspects alone The approach described this contribution can also used other domains such Geoweb retrieval 
11721 en Learning Influence Probabilities Social Networks Recently there has been tremendous interest the phenomenon influence propagation social networks The studies this area assume they have input their problems social graph with edges labeled with probabilities influence between users However the question where these probabilities come from how they can computed from real social network data has been largely ignored until now Thus interesting ask whether from social graph and log actions its users one can build models influence This the main problem attacked this paper addition proposing models and algorithms for learning the model parameters and for testing the learned models make predictions also develop techniques for predicting the time which user may expected perform action validate our ideas and techniques using the Flickr data set consisting social graph with nodes 40M edges and action log consisting 35M tuples referring 300K distinct actions Beyond showing that there genuine influence happening real social network show that our techniques have excellent prediction performance 
11722 en You Are Who You Know Inferring User Profiles Online Social Networks Online social networks are now popular way for users connect express themselves and share content Users today’ online social networks often post profile consisting attributes like geographic location interests and schools attended Such profile information used the sites basis for grouping users for sharing content and for suggesting users who may benefit from interaction However practice not all users provide these attributes nnIn this paper ask the question given attributes for some fraction the users online social network can infer the attributes the remaining users other words can the attributes users combination with the social network graph used predict the attributes another user the network answer this question gather fine grained data from two social networks and try infer user profile attributes find that users with common attributes are more likely friends and often form dense communities and propose method inferring user attributes that inspired previous approaches detecting communities social networks Our results show that certain user attributes can inferred with high accuracy when given information little the users 
11723 en TwitterRank Finding Topic sensitive Influential Twitterers This paper focuses the problem identifying influential users micro blogging services Twitter one the most notable micro blogging services employs social networking model called “following” which each user can choose who she wants “follow” receive tweets from without requiring the latter give permission first dataset prepared for this study observed that the users Twitter follow more than their followers and the users have users they are following follow them back Our study reveals that the presence “reciprocity” can explained phenomenon homophily Based this finding TwitterRank extension PageRank algorithm proposed measure the influence users Twitter TwitterRank measures the influence taking both the topical similarity between users and the link structure into account Experimental results show that TwitterRank outperforms the one Twitter currently uses and other related algorithms including the original PageRank and Topic sensitive PageRank 
11724 en Folks Folksonomies Social Link Prediction from Shared Metadata Web applications have attracted considerable amount attention because their open ended nature allows users create light weight semantic scaffolding organize and share content date the interplay the social and semantic components social media has been only partially explored Here focus Flickr and Last two social media systems which can relate the tagging activity the users with explicit representation their social network show that substantial level local lexical and topical alignment observable among users who lie close each other the social network introduce null model that preserves user activity while removing local correlations allowing disentangle the actual local alignment between users from statistical effects due the assortative mixing user activity and centrality the social network This analysis suggests that users with similar topical interests are more likely friends and therefore semantic similarity measures among users based solely their annotation metadata should predictive social links test this hypothesis the Last data set confirming that the social network constructed from semantic similarity captures actual friendship more accurately than Last ’ suggestions based listening patterns 
11725 en  Novel Click Model and Its Applications Online Advertising Recent advances click model have positioned attractive method for representing user preferences web search and online advertising Yet most the existing works focus training the click model for individual queries and cannot accurately model the tail queries due the lack training data Simultaneously most the existing works consider the query url and position neglecting some other important attributes click log data such the local time Obviously the click through rate different between daytime and midnight this paper propose novel click model based Bayesian network which capable modeling the tail queries because builds the click model attribute values with those values being shared across queries called our work General Click Model GCM found that most the existing works can special cases GCM assigning different parameters Experimental results large scale commercial advertisement dataset show that GCM can significantly and consistently lead better results compared the state the art works 
11726 en Adaptive Weighing Designs for Keyword Value Computation Attributing dollar value keyword essential part running any profitable search engine advertising campaign When advertiser has complete control over the interaction with and monetization each user arriving given keyword the value that term can accurately tracked However many instances the advertiser may monetize arrivals indirectly through one more third parties such cases typical for the third party provide only coarse grained reporting rather than report each monetization event users are aggregated into larger channels and the third party reports aggregate information such total daily revenue for each channel Examples third parties that use channels include Amazon and Google AdSense nnIn such scenarios the number channels generally much smaller than the number keywords whose value per click VPC wish learn However the advertiser has flexibility how assign keywords channels over time introduce the channelization problem how adaptively assign keywords channels over the course multiple days quickly obtain accurate VPC estimates all keywords relate this problem classical results weighing design devise new adaptive algorithms for this problem and quantify the performance these algorithms experimentally Our results demonstrate that adaptive weighing designs that exploit statistics term frequency variability VPCs across keywords and flexible channel assignments over time provide the best estimators keyword VPCs 
11727 en Translating Webpages into Bidphrases for Advertising One the most prevalent online advertising methods textual advertising produce textual advertiser must craft short creative the text the linking landing page which describes the product service being promoted Furthermore the advertiser must associate the creative set manually chosen bid phrases representing those Web search queries that should trigger the For efficiency given landing page the bid phrases are often chosen first and then for each bid phrase the creative produced using template Nevertheless campaign for large retailer might involve thousands landing pages and tens hundreds thousands bid phrases hence the entire process very laborious nnOur study aims towards the automatic construction online campaigns given landing page propose several algorithmic methods generate bid phrases suitable for the given input Such phrases must both relevant that reflect the content the page and well formed that likely used queries Web search engine this end use two phase approach First candidate bid phrases are generated number methods including monolingual translation model capable generating phrases not contained within the text the input well previously unseen phrases Second the candidates are ranked probabilistic framework using both the translation model which favors relevant phrases well bid phrase language model which favors well formed phrases nnEmpirical evaluation based real life corpus advertiser created landing pages and associated bid phrases confirms the value our approach which successfully generates many the human crafted bid phrases and performs significantly better than pure text extraction method 
11728 en Personalized Click Prediction Sponsored Search Sponsored search multi billion dollar business that generates most the revenue for search engines Predicting the probability that users click ads crucial sponsored search because the prediction used influence ranking filtering placement and pricing ads ranking filtering and placement have direct impact the user experience users expect the most useful ads rank high and placed prominent position the page Pricing impacts the advertisers’ return their investment and revenue for the search engine The objective this paper present framework for the personalization click models sponsored search develop user specific and demographic based features that reflect the click behavior individuals and groups The features are based observations search and click behaviors large number users commercial search engine add these features baseline non personalized click model and perform experiments offline test sets derived from user logs well live traffic Our results demonstrate that the personalized models significantly improve the accuracy click prediction 
11729 en Improving Relevance Sponsored Search describe machine learning approach for predicting sponsored search relevance Our baseline model incorporates basic features text overlap and then extend the model learn from past user clicks advertisements present novel approach using translation models learn user click propensity from sparse click logs nnOur relevance predictions are then applied multiple sponsored search applications both offline editorial evaluations and live online user tests The predicted relevance score used improve the quality the search page three areas filtering low quality ads more accurate ranking for ads and optimized page placement ads reduce prominent placement low relevance ads show significant gains across all three tasks 
11758 en Grammar meaning the law good behaviour
11759 en Optimizing Word Sketches for large scale lexicographic project
11768 en Besedna postaja pogovor pisateljem prevajalcem Yuyutsujem Sharma Gost tokratne postaje bil nepalski pesnik pisatelj prevajalec Yuyutsu Sharma njegovi poeziji pesnikom pogovarjal Evald Flisar prevajalec zbirke pesmi Jezero Fewa konj Sodobnost 2008 Yuyutsu Ramdass Sharma rodil Nakodarju Pand abu olal Batalu univerzi Rad astanu kjer spoznal ameri kega pesnika Davida Raya sre anje bilo klju njegovo literarno ustvarjanje Izdal deset pesni kih zbirk napisal roman Sicer anglist specialist sodobno ameri poezijo preteklosti ukvarjal tudi igralstvom akademsko kariero med drugim univerzi Katmanduju Leta 1995 celoti posvetil prevajanju pisanju Poezijo lanke kolumne objavlja asopisih ter revijah bere svojo poezijo povsod svetu tudi urednik leposlovje pri zalo Nirala angle ino aktivno prevaja sodobne nepalske pesnike nabralo antologij jih sestavil uredil med drugimi Roaring Recitals Five Nepali Poets bila nominirana laskavo priznanje azijske knjige leta 2001 Njegova poezija kateri kritiki tako doma kot tuji govorijo superlativih prevedena nem ino franco ino italijan ino hebrej ino nizozem ino ivi Katmanduju New Delhiju 
11782 en Experimental Techniques and Data for Systems Biology major challenge biology unravel the organisation and interactions cellular networks that enable complex life processes The underlying complexity arises from dynamic interactions among large numbers cellular constituents such genes proteins and metabolites The classical biochemistry and molecular biology approach has successfully identified most the components and some interactions but using such reductionist approach not possible comprehend how system properties emerge understand how cells function comprehensive and quantitative data components and interactions are required one hand coupled with rigorous data integration and modelling the other The aim this seminar explain the principles experimental techniques for study cell processes the level gene expression protein composition and metabolite profile addition studies interactions between different components The structure data well reliability the data obtained different techiques will discussed 
11875 en Living with Catastrophic Terrorism Can Science and Technology Make the Safer After the terrorists attack September three Academies the National Academy Sciences the National Academy Engineering and the Institute Medicine sponsored major study the role that science and technology might play countering the threat catastrophic terrorism the United States This study involved committee experts chaired Lewis Branscomb and Richard Klausner and was supported others specialized panels nnThe 400 page report was presented Congress and Governor Ridge President Bush choice for Director Homeland Security June 2002 was published the National Academies Press under the title Making America Safer The Role Science and Technology Countering Terrorism nnThis lecture summarizes the output this project addresses its influence legislation for Department Homeland Security and points the areas public policy that require the most urgent attention Professor Branscomb also presents his own expanded views some issues the report Link http mitworld mit edu video Lecture´ Homepage Host http mitworld mit edu host view Engineering Systems Division Series http mitworld mit edu series view Brunel Lecture Series Complex Systems 
11876 en The Columbia Tragedy System Level Issues for Engineering Among the “tragedy errors” that doomed the space shuttle Columbia perhaps the most damning were NASA’ organizational blunders Sheila Widnall served the board investigating Columbia’ destruction February 2003 and she can describe the technical failures that led moment moment the ghastly trail debris across the western United States But the investigation board traced the roots this disaster NASA’ “culture invincibility ” years the making Well intentioned people Widnall states became desensitized deviations from the norm NASA managers treated repeated anomalies such foam smashing into shuttle tiles take off “maintenance turnaround events ”nnFoam striking protective tiles the leading edge Columbia’ wing led the horrors entry gases excess 5000 degrees entered through possibly inch wide breech the wing melting sensors and internal structure sending the shuttle out control The failures that led this moment are both engineering system failures and human communication failures nnWidnall and the investigation board recommend independent safety oversight for shuttle flights NASA leadership that heeds minority points view and doesn’ let scheduling budget pressures define space missions and routine inclusion engineers who have the right address both technological and operational issues flight Link http mitworld mit edu video 171 Lecture´ Homepage Host http mitworld mit edu host view Engineering Systems Division Series http mitworld mit edu series view Brunel Lecture Series Complex Systems 
11877 en Engineering Engineering Systems The top engineering achievements the 20th century from the automobile and airplane telephone radio and computer all constitute “complex technical systems ” says Tom Magnanti certain that the next century’ top engineering challenges such “reconciling the inevitable growth world wide energy demand with potential environmental costs ” will involve complex solutions too Will engineering systems discipline play critical role educating engineers respond successfully these challenges Magnanti takes the slippery issue what constitutes field examines earlier MIT curricula such Systems Design and Management and the Conceptual model Mine Model Manipulate Measure for ways think about his topic “ single discipline the way sociology and psychology are ” ponders applies different architectural constructs engineering systems Should viewed intersection engineering management and social sciences and thus subset each borrowing components from technology economics human resources design and thus comprising “all engineering plus everything else ” Networking may prove central all work Magnanti says whether single discipline “field that has core focus … and draws upon multiple disciplines nnn Link http mitworld mit edu video 233 Lecture´ Homepage Host http mitworld mit edu host view Engineering Systems Division Series http mitworld mit edu series view Brunel Lecture Series Complex Systems 
11878 en The 21st Century about Engineering Systems and Society What’ “big complex and hairy ” and requires the efforts impassioned interdisciplinary team tackle The answer says Richard Newton the “one off problem” – the kind sprawling social scientific and engineering puzzle that increasingly challenges contemporary society Think about the conundrum affordable healthcare emergency preparedness How you address such enormous issues Newton’ answer CITRIS the Center for Information Technology Research the Interest Society This partnership among academia government and industry specializes attacking problems critical the quality life and whose solutions require “societal scale information systems ” Current CITRIS research includes designing information technology for the energy deprived developing world This demands says Newton “complete rethinking the architecture information and communication systems ” Work far points toward wireless technologies remote villages with communication antennas flying atop balloons anchored cables And the home front Newton points out that one third the total national outlay healthcare derives from lab tests about 500 billion dollars year Could reduce the tab coming with new kinds testing that don’ require visit the office and whose results could more efficiently communicated healthcare providers Newton wonders Cracking any these problems requires understanding information systems and benefits enormously from “passionate individuals” pulling together around shared vision – “like the moon shot ” Link http mitworld mit edu video 310 Lecture´ Homepage Host http mitworld mit edu host view Engineering Systems Division Series http mitworld mit edu series view Brunel Lecture Series Complex Systems 
11879 en Educating Engineers for 2020 and Beyond Though two years departed from the MIT President’ office Charles Vest has lost none his zeal for issues education and training Says Vest envy the next generation engineering students This without question the most exciting period human history science technology and engineering nnHe cites exponential advances knowledge instrumentation communication and computational capabilities which have created mind boggling possibilities cutting across traditional boundaries and blurring distinctions between science and engineering the same time globalization changing how engineers train and work well how nation resources are directed The entire nature the innovation ecosystem and business enterprise changing dramatically ways not yet fully understand says Vest These dizzying changes require accelerated commitment engineering research and education and compel research institutions simultaneously advance the frontiers fundamental science and technology and address the most important problems that face the world nnVest perceives two key frontiers engineering the intersection physical life and information sciences called bio nano info which offers stunning unexplored possibilities and the macro world energy food manufacturing communications which presents daunting challenges the future nnThe kind students Vest hopes will explore these new frontiers should reflect diverse society write and communicate well think about ethics and social responsibility conceive and operate systems great complexity within framework sustainable development and prepared live and work global citizens tall order admits Vest but there are men and women every day here who seem able all these things and more nnTo prepare this new generation engineering schools should focus creating environment that provides inspiration the long run offering exciting creative adventures rigorous demanding and empowering milieus more important than specifying details the curriculum says Vest Students are driven passion curiosity engagement and dreams Give them opportunities discover and – participate research teams perform challenging work industry gain professional experience other countries Vest says must ensure the best and brightest become engineers 2020 and beyond can afford fail Link http mitworld mit edu video 409 Lecture´ Homepage Host http mitworld mit edu host view Engineering Systems Division Series http mitworld mit edu series view Brunel Lecture Series Complex Systems 
11880 en Process Improvement the Rarefied Environment Academic Medicine Paul Levy says “medicine for the most part remains cottage industry ” then how can you impose system wide improvements especially you’ presiding over academic hospital where the culture rewards brilliant independent free thinking doctors nnThis has been Levy’ challenge since 2002 when took over ailing Beth Israel Deaconess Medical Center The result merger between two hospitals the late ‘90s BIDMC immediately fell into “downward spiral ” recounts Levy Doctors and nurses left and losses grew nearly million year The hospital burned 200 million 500 million endowment nnWhen arrived Levy recognized that the hospital’ problems had less with medicine than with management and organization For instance took 100 days for bill out after the actual service was performed and bills were often inaccurate based doctor’ hand scribbled note nnLevy set work enhancing the hospital’ routines such providing electronic billing system with pull down menus met with demoralized nurses address their concerns and succeeded reversing the turnover rate Then says Levy “ started focusing what really matters how well ’ taking care people how often are hurting and killing people and what stop ”nnHospitals notes “are very dangerous places ” with “bugs floating around and mistakes being made ” One common problem BIDMC ventilator associated pneumonia had mortality rate The fixes were simple raising beds better oral hygiene hand washing but accomplishing them required systemic compliance nnLevy identified doctors who could lead colleagues the new practices attached protractors beds nurses could raise them precisely degrees “Lots low tech solutions must institutionalized ” says Levy Mortality due this pneumonia dropped and Levy figures the hospital saves lives per year million expenses nnBy shadowing nurses and other staff Levy’ discovered that individuals often find workarounds problems but aren’ aware that others might benefit from their solutions Levy set blog post these solutions and focus the organization whole areas concern Supporting good performance sharing clinical results such “how many people hurt and kill” stimulates people hospital better believes Public exposure goes long way helping academic medical staff understand they must “held accountable for their actions particularly when comes harm ” Link http mitworld mit edu video 504 Lecture´ Homepage Host http mitworld mit edu host view Engineering Systems Division Series http mitworld mit edu series view Brunel Lecture Series Complex Systems Event Sponsor http mitworld mit edu host view Harvard MIT Division Health Sciences and Technology 
11881 en From Cleantech New Sources Innovation Imagine response oil dependence and climate change that offers people around the world new and improved version the car premised redesigning infrastructure top bottom with green technology way that recharges ailing national economies Applying both entrepreneurial spirit and systems engineering approach Shai Agassi has devised just such visionary plan for cracking these vexing global challenges nnA recent World Economic Forum asked participants how make the world better place 2020 Agassi felt engineer’ compulsion respond describes process “like fractal problem…opening cascade questions ” First came the notion running country without oil seized then dismissed the idea bio and hydrogen based fuels then experienced the seminal insight that “you need down from molecules electrons you want change the world ”nnThis realization meant addressing both economic and engineering problems ’ need offer consumers not vehicle limited two seats three wheels and mph speeds but one that could faster than gas cars with all the requisite bells and whistles move his plan along also determined use available electric car battery engineering This raised significant issues convenience where recharge and how frequently Agassi envisioned charging docks parking lots and home garages devised simple battery replacement method nnThen came the issue affordability which Agassi solved applying familiar business model though not one associated with cars cell phone minutes Sell consumers electric car with subscription for miles the longer the subscription the greater the discount rebate check Europe Agassi notes where gas costs gallon five year subscription pretty much gets you “ free electric car ”nnThe model’ complexity and infrastructure requirements imply government backing which Agassi has already secured Denmark there’ 180 tax gasoline and gas powered sedans costs thousand euros while electrics for thousand North Sea windmills will provide clean electricity for charge stations Israel’ building desert solar field “drive every car ” and smart grid monitor battery charging The hosting pilot programs Hawaii and the Bay Area nnHis not plan phase gradually The time now says “ must the right moral thing ” contend with climate change and brutal oil regimes and “ create the biggest expansion history ” Link http mitworld mit edu video 642 Lecture´ Homepage Host http mitworld mit edu host view Engineering Systems Division Series http mitworld mit edu series view Brunel Lecture Series Complex Systems 
11882 en Liberty Design Recalling lecture gave MIT 2005 Alan Davidson returns the questions the impact public policy the way technology evolving the Internet space nnInstead viewing lawyer for public policy interest group—his previous role— now approaches from his new perspective public policy advisor Google engineering design group counseling them how build products and run business encourages his fellow engineers think broadly … about their role the world … more than bench tied engineers and more involved the deep social debates the time nnThese questions remain What are the big issues facing the Internet and specifically Google and what are the lessons that have been learned The old Conventional Wisdom said censorship could not stopped only contained But Davidson believes that the last years there has been backlash from governments large institutions and influential economic actors The new Conventional Wisdom You don think can regulate the Internet Watch nnAs the Internet revolution advances processing and storage power the ability network with anyone anywhere the world and with device mobility—PCs remote devices Davidson uses half dozen real life examples from his experience Google illustrate their win win solutions Using screenshots describes the products and shows how the engineers and policy makers worked together create solutions dealing with privacy copyright intellectual property and censorship issues nnWhile the solutions lie building products that address these issues the challenges lie raising the issues proactively the engineering process being able influence regulation and business decisions The engineers build the product the public policy experts advise but they work partners balancing matters individual freedoms against government and economic interests Davidson certain that choices made today will define the kind Internet will have years Link http mitworld mit edu video 732 Lecture´ Homepage Host http mitworld mit edu host view Engineering Systems Division Series http mitworld mit edu series view Brunel Lecture Series Complex Systems 
11883 en Building Resilient Infrastructure Combat Terrorism Lessons from September 11th Building Resilient Infrastructure Combat Terrorism Lessons from September 11th Link http mitworld mit edu video Lecture´ Homepage Host http mitworld mit edu host view Engineering Systems Division Series http mitworld mit edu series view The Technology and Policy Program Homeland Security Technology and Policy Seminar Event Sponsors http mitworld mit edu host view MIT Technology and Policy Program http mitworld mit edu host view Engineering Systems Division 
11884 en Volvo Environmental Business Strategy With the global harmonization legislation rapid technical developments and increasing number customers with environmental awareness opportunities open for the transport related industry contribute sustainable society while maintaining favorable profitability one the world leading transportation companies the commercial field the Volvo Group seeks play important role achieving these objectives Link http mitworld mit edu video Lecture´ Homepage Host http mitworld mit edu host view 129 Laboratory for Energy and the Environment Series http mitworld mit edu series view The Wallenberg Lecture Sustainability and the Environment MIT 
11997 en Opening Address for the NIPS the Generative and Discriminative Learning Interface
11998 en Generative and Discriminative Models Statistical Parsing Since the earliest work statistical parsing constant theme has been the development discriminative and generative models with complementary strengths this work ’ give brief history discriminative and generative models statistical parsing focusing strengths and weaknesses the various models ’ start with early work discriminative history based models particular the SPATTER parser moving through early discriminative and generative models based lexicalized dependency representations through recent work conditional random field based models Finally ’ describe research semi supervised approaches that combine discriminative and generative models 
11999 en Generative and Discriminative Latent Variable Grammars Latent variable grammars take observed coarse treebank and induce more fine grained grammar categories that are better suited for modeling the syntax natural languages Estimation can done generative discriminative framework and results the best published parsing accuracies over wide range syntactically divergent languages and domains this paper highlight the commonalities and the differences between the two learning paradigms and speculate that hybrid approach might outperform either respectively 
12000 en Discriminative and Generative Views Binary Experiments consider Binary experiments supervised learning problems where there are two different labels and explore formal relationships between two views them which call “generative” and “discriminative” The discriminative perspective involves expected loss The generative perspective our sense involves the distances between class conditional distributions extend known results the class all proper losses scoring rules and all divergences distances between distributions also sketch how one can derive the SVM and MMD algorithms from the generative perspective 
12001 en Multi Task Discriminative Estimation for Generative Models and Probabilities Maximum entropy discrimination method for estimating distributions such that they meet classification constraints and perform accurate prediction These distributions are over parameters classifier for instance log linear prediction models log likelihood ratios generative models Many the resulting optimization problems are convex programs and sometimes just simple quadratic programs multi task settings several discrimination constraints are available from many tasks which potentially produce even better discrimination This advantage manifests itself some parameter tying involved for instance via multi task sparsity assumptions Using new variational bounds possible implement the multitask variants sequential quadratic programs sequential versions the independent discrimination problems these settings possible show that multi task discrimination requires more than constant increase computation over independent single task discrimination 
12002 en Generative and Discriminative Image Models Creating good probabilistic model for images challenging task due the large variability natural images For general photographs ideal generative model would have cope with scene layout occlusion variability object appearance variability object position and rotation and illumination effects like shading and shadows The formidable challenges creating such model have led many researchers pursue discriminative models which instead use image features that are largely invariant many these sources variability this talk will compare both approaches and describe some strengths and weaknesses each and suggest some directions which the best aspects both can combined 
12003 en Learning Feature Hierarchies Learning Deep Generative Models this paper present several ideas based learning deep generative models from high dimensional richly structured sensory input will exploit the following two key properties First show that deep generative models can learned efficiently from large amounts unlabeled data Second they can discriminatively fine tuned using the standard backpropagation algorithm Our results reveal that the learned high level feature representations capture lot structure the unlabeled input data which useful for subsequent discriminative tasks such classification regression even though these tasks are unknown when the deep generative model being trained 
12004 en Why Does Unsupervised Pre training Help Deep Discriminant Learning Recent research has been devoted learning algorithms for deep architectures such Deep Belief Networks and stacks auto encoder variants with impressive results obtained several areas The best results obtained supervised learning tasks involve unsupervised learning component usually unsupervised pre training phase with generative model Even though these new algorithms have enabled training deep models fine tuned with discriminant criterion many questions remain the nature this difficult learning problem The main question investigated here the following why does unsupervised pre training work and why does work well Answering these questions important learning deep architectures further improved propose several explanatory hypotheses and test them through extensive simulations empirically show the influence unsupervised pre training with respect architecture depth model capacity and number training examples The experiments confirm and clarify the advantage unsupervised pre training The results suggest that unsupervised pre training guides the learning towards basins attraction minima that are better terms the underlying data distribution the evidence from these results supports unusual regularization explanation for the effect pre training 
12005 en Unsupervised Learning Discriminating Data from Artificial Noise Noise contrastive estimation new estimation principle that have developed for parameterized statistical models The idea train classifier discriminate between the observed data and some artificially generated noise using the model log density function logistic regression function can proven that this leads consistent convergent estimator the parameters The method shown directly work for models where the density function does not integrate unity unnormalized models The normalization constant partition function can estimated like any other parameter compare the method with other methods that can used estimate unnormalized models including score matching contrastive divergence and maximum likelihood where the correct normalization estimated with importance sampling Simulations show that noise contrastive estimation offers the best trade off between computational and statistical efficiency The method then applied the modeling natural images 
12027 en Migratory Narratives Why Some Stories Replicate Across Media Cultures Historical Eras True stories and their fictional spin offs especially bloody ones occupy enduring spot western culture Thomas Pettitt’ specialty the “murdered sweetheart” tale emerged from medieval times seize hold the public imagination England and Scandinavia over several centuries The story involving seduced girl her murder lover and the lover’ death stems from some long lost actual case Publishers cranked out ballads based this story with helpfully lurid woodcut illustrations this “highly successful genre ” says Pettitt “marketing strategies” distilled the “shocking and juicy story” down the bare bones “ sometimes wonder the weapon choice was knife because rhymes conveniently with wife ” muses Pettitt nnThe sinking the Titanic sparked media frenzy all too familiar these days reporters rowed out meet survivors they could wire their newspapers first Richard Howells takes stock this tragedy and its media manipulation over time First the Edwardians “celebrated the heroism triumph Anglo Saxon pluck and courage” the voyagers with newsreels including one month after the tragedy postcards sheet music and records Later fiction films exploited the story fable about the emerging middle class our own times with the epic James Cameron film and assorted merchandise including Titanic software and beer Howells sees the Titanic “allegory for decline disaster decadence and doom …and finally kitsch entertainment ” modern myth the Titanic has become “ multimedia narrative ”nnJanet Staiger finds lots reasons for storytelling from the anthropological the psychoanalytical But she emphasizes “economic explanations the standardization stories for capitalist purpose ” know that murdered sweetheart ballad “will seller ” can premarketed and mass produced Some stories get yoked particular characters and others can wander more freely across formulas Staiger compares Barbie and Cinderella stuck their plot lines Batman who can show detective adventure parody melodrama form The “ability sell figures separate from formula enhances their capacity for capitalization ” says Staiger Link http mitworld mit edu video 281 Lecture´ Homepage Lecture Host http mitworld mit edu host view MIT Communications Forum Series http mitworld mit edu series view Media Transition The Work Stories 
12028 en Why Are Stories Violent Note Due copyright restrictions this video does not include the film clips screened Professor Sandler His presentation includes sufficient description and context make the argument clear nnYou wouldn’ ordinarily expect find Euripides Snow White Bruno Bettelheim and Rambo discussed the same event But they share the limelight this session violence intrinsic part human art and experience device exploited cynical producers lure consumers threat healthy child development natural means teaching and learning There consensus here but plenty provocative examples and scholarly insight David Thorburn sets the stage evoking the relentless tradition violence the Western literary canon from the eras the Bible and Greek tragedy nnKevin Sandler who dubs himself “political media economist ” fills out the contemporary end the continuum with analysis ratings handed out the film industry board Using “Eyes Wide Shut” and “Collateral Damage” evidence Sandler argues that major studios have positioned violence entertainment vehicle safely within the “cultural function” expect movies fulfill nnWhat about Snow White’ poisoned apple the cruelties Willy Wonka inflicts chocolate factory visitors Literary scholar Maria Tatar lays out three possible functions violence stories for children stimulating their imagination through surreal depictions “what might ” teaching them how behave through fear and giving them therapeutic outlet for primitive emotions series lively questioners try penetrate what Tatar calls the “mystery cultural effects ” speculating the psychological social and political consequences much violence children’ media Link http mitworld mit edu video 282 Lecture´ Homepage Lecture Host http mitworld mit edu host view MIT Communications Forum Series http mitworld mit edu series view Media Transition The Work Stories 
12029 en Narratives Science Robert Kanigel poses the central question this panel “The storytelling express leaving the station want jump aboard under some circumstances stay where are ” Science writing has matured discipline and genre and for many writers this means telling story with what Kanigel describes “ narrative arc cannon propelling you through text because readers’ eagerness know what’ happening next ” This implies some kind linear movement whether the writer focuses “the smallest atomic unit” larger canvas But Kanigel wonders “there are circumstances when don’ want stories ”nnThomas Levenson responds “You can long way down the path understanding science human activity without getting story ” offers the example writer who keeps diary year spent laboratory what Levenson describes “science travelogues ” But from his early experiences journalist Levenson has found that “Science produces certain kind knowledge but the activity science takes shape within and shaped the world beyond science ” brings historical interpretative method bear his subjects including Einstein Says Levenson “You get make meaning out the story you want rather than asking people extract meaning out happenstance facts ”nnAlan Lightman ponders the role science novels theatre and film offers several examples “gripping and suspenseful” discussions science within narratives such Michael Ondaatje’ novel The English Patient and Michael Frayn’ play Copenhagen These authors avoid the didactic with “motor that drives through discussion ” But the very popular genre science biography proves trickier propel successfully “ science ’ more challenge intertwine work with life because life deals with the inanimate ” says Lightman Link http mitworld mit edu video 284 Lecture´ Homepage Lecture Host http mitworld mit edu host view MIT Communications Forum Series http mitworld mit edu series view Media Transition The Work Stories 
12065 en Lecture Syllabus and Introduction
12069 en Triangular Numbers Part Elementary explanation triangular numbers and Gauss demonstration for the sum the first 100 natural numbers 
12070 en Triangular Numbers Part Using Gauss Idea find the sum Arithmetic progressions obtaining general formula for the sum arithmetic progression 
12071 en Triangular Numbers Part III Recursive Relation for triangular numbers Finding solution the recursive equation and another solution the Recursive equation 
12072 en  all Greek Sigma notation Sigma Notation Tetrahedral numbers Pyramidal Numbers Some relations between them 
12073 en Summation Telescoping property explain the summation telescoping property and apply finding two summations 
12074 en  infinity Mathematical Induction Explain the Method Mathematical Induction Francesco Maurolico Pascal and John Wallis Applying the method Induction prove the sum odd numbers square 
12075 en Mathematical Induction Part Prove Inequality using the Method Mathematical Induction 
12076 en Mathematical Induction Part III Recursive Relation for triangular numbers Finding solution the recursive equation and another solution the Recursive equation 
12077 en The well ordering principle Proving The Well Ordering Principle equivalent The Principle Mathematical Induction 
12078 en Weaving numbers Vedic multiplication weaving multiplication Fibonacci Sieve Lattice Multiplication John Napier Bones multiplication 
12079 en Are you having phun yet Introduction Phun The new entertaining and extreme fun educational computer program Using Phun explain Math 
12080 en Dimension Hipparchus explains how two numbers can describe the position point sphere then explains stereographic projection how can one draw picture the Earth piece paper 
12081 en Dimension three Escher tells the adventures two dimensional creatures who are trying imagine three dimensional objects 
12082 en The fourth dimension Mathematician Ludwig Schläfli talks about objects the fourth dimension and shows procession regular polyhedra dimension strange objects with 120 and even 600 faces 
12083 en The fourth dimension continued Mathematician Ludwig Schläfli talks about objects the fourth dimension and shows procession regular polyhedra dimension strange objects with 120 and even 600 faces 
12084 en Complex Numbers Mathematician Adrien Douady explains complex numbers The square root negative numbers explained simple terms Transforming the plane deforming pictures creating fractal images 
12085 en Complex Numbers Continued Mathematician Adrien Douady explains complex numbers The square root negative numbers explained simple terms Transforming the plane deforming pictures creating fractal images 
12086 en Fibration The mathematician Heinz Hopf describes his fibration Using complex numbers builds beautiful arrangements circles space 
12087 en Fibration Continued The mathematician Heinz Hopf describes his fibration Using complex numbers builds beautiful arrangements circles space 
12088 en Proof Mathematician Bernhard Riemann explains the importance proofs mathematics proves theorem stereographic projection 
12091 en Machine Learning Finding Patterns the World
12100 en Data Intensive Text Processing with MapReduce
12101 en Acquisition Lexical Knowledge from Grams
12103 en UBM based Acoustic Modeling for ASR
12104 en Lecture Bond Polarity Formal Charge Lewis Structures
12105 en Lecture Resonance Structures Skeletal Structures Bond Length
12106 en Lecture Orbital Models Structure and Bonding
12107 en Lecture Molecular Geometry Acids and Bases
12108 en Lecture Acid Strength and Equilibria
12109 en Lecture Lewis Acids Lewis Bases and Organic Reaction Mechanisms
12110 en Lecture Organic Compounds and Functional Groups
12111 en Lecture Hydrocarbons Alcohols Amines
12112 en Lecture Carbonyl Compounds Intermolecular Forces
12113 en Lecture Introduction Alkanes
12114 en Lecture Nomenclature Alkanes Conformations Ethane
12115 en Lecture Conformations Butane and Cycloalkanes
12117 en Lecture Introduction Stereochemistry
12118 en Lecture Assigning Tetrahedral Stereogenic Centers
12119 en Lecture Meso Compounds
12120 en Lecture Properties Chiral Compounds
12121 en Lecture Introduction Understanding Organic Reactions
12122 en Lecture Energy Diagrams Transition States and Reaction Rates
12123 en Lecture Energetics Reactions
12124 en Lecture Introduction Alkyl Halides and Nuceophilic Substitution
12125 en Lecture Mechanistic and Stereochemical Aspects SN2 Reactions
12126 en Lecture Elimination Reactions Introduction Reactions
12127 en Lecture Mechanistic and Stereochemical Aspects SN1 Reactions
12128 en Lecture Properties Electrophiles Nucleophiles and Leaving Groups
12129 en Lecture Regiochemical and Stereochemical Course Reactions
12130 en Lecture Reactions Comparison SN1 SN2 and Reactions
12148 en From the Mega the Nano Computer Modeling Engineering and Sciences mega nano unalni modeliranje enirstvu znanosti Computer Modeling Engineering Sciences CMES multi disciplinary enabling methodology fornan integrated process product simulation design devices which span the mega nano lengthscales nand which operate equally diverse time scales CMES engine for global economic growth nplays vital role reducing the product development time cost and assessing the longevity lifecycle ncosts and failure prevention various devices This lecture brief overview the past present nand the future CMES from the speaker’ perspective nnRa unalni modeliranje enirstvu znanosti ang Computer Modeling Engineering and Sciences CMES multidisciplinarna metodologija integrirano procesno produktno simuliranje ter rtovanje naprav delujejo dol inskih skalah mega nano enako raznolikih asovnih skalah CMES lahko gonilo globalne ekonomske rasti igra klju vlogo pri zmanj evanju razvojnega asa stro kov ter pri oceni ivljenjske dobe stro kov vzdr evanja prepre evanja okvar raznovrstnih naprav Predavanje kratek pregled preteklosti sedanjosti prihodnosti CMES predavateljeve perspektive 
12212 en Automatic Annotation Images using Ensembles Trees for Hierarchical Multi label Classification This research presents large scale system for detection visual nconcepts and annotation images The system composed two parts nfeature extraction and classification annotation The feature nextraction part provides global and local descriptions the images nthe form numerical vectors Using these numerical descriptions ntrain classifier predictive clustering tree PCT produce nannotations for unseen images PCTs are able handle target concepts nthat are organized hierarchy perform hierarchical nmulti label classification improve the classification performance nwe construct ensembles bags and random forests PCTs nnnWe evaluate our system two different databases IRMA database which ncontains medical images and the image database from the ImageCLEF ICPR n2010 photo annotation task which contains general images The extensive nexperiments conducted the benchmark databases show that our system nhas very high predictive performance and can easily scaled large namounts visual concepts and data addition our approach very ngeneral can easily extended with new feature extraction methods nand can thus easily applied other domains types images and nother classification schemes Furthermore can handle arbitrarily nsized hierarchies organized trees directed acyclic graphs 
12247 en  Translation from Logic English with Dynamic Semantics present procedure for translating standard predicate logic into English The procedure generates both referring expressions and non referring expressions including both referential and bound variable anaphora Non referring expressions correspond short term discoursenreferents which present special set challenges for natural language generation system they have limited ‘lifespans’ and the determiner with which they are introduced every some any sensitive the logical context Our system addresses these challenges usingndynamically updated information states 
12251 en Data information design and traffic injuries Podatki informacije oblikovanje prometne kodbe English The nature “information design” not determined what one does signage forms documents etc but how one does The users are the centre information design with all their differences possibilities needs and wants Data can absorbing but information design not about data about people reach people have know them Data without context not information Information difference that makes difference make difference there need for significance and significance comes from comparison comparison between one thing and another between one thing and its context between one thing and its consequences The presentation will outline the roles information and persuasion communication design provide example the possible importance the problems that design should address will present the social and economic costs traffic injuries discussing how turn data into information how contextualize information that its significance can perceived and how significance indispensable when there need promote action and change The central objective the paper contribute the lecture series’ main topic the relevance information design for things that matter society Slovensko »Informacijskega oblikovanja« dolo kar nekdo ozna evanje formularji dokumenti itd temve kako sredi informacijskega oblikovanja uporabniki vsemi razlikami nostmi potrebami zahtevami Podatki lahko mikavni vendar informacijsko oblikovanje namenjeno podatkom temve ljudem elimo ljudi dose jih moramo poznati Podatki brez konteksta niso informacije Informacije tisto kar naredi potrebni preskok potreben pomen izvira primerjave med razli nimi stvarmi med eno stvarjo njenim kontekstom ali med eno stvarjo njenimi posledicami Predavatelj predstavil vlogo informacij prepri evanja oblikovanju komunikacije Kot primer pomembnosti problemov jih oblikovanje lahko lotilo bodo prikazani dru beni gospodarski stro prometnih nesre bodo pokazali kako mogo podatke spremeniti informacije kako informacije postaviti kontekst lahko dojamemo njihov pomen ter kako nepogre ljiv pomen pojavi potreba spodbujanju delovanja sprememb Namen predavanja predvsem prispevati glavni temi serije predavanj pomenu informacijskega oblikovanja dru beno pomembnih podro jih 
12270 en From Microscopy Images Models Cellular Processes The advance fluorescent tagging and confocal microscopy allowing biologists image biochemical processes level detail that was unimaginable just few years ago However the analysis these images done mostly hand there severe bottleneck transforming these images into useful quantitative data that can used evaluate mathematical models nOne the inherent challenges involved automating this transformation that image data highly variable This requires recalibration the image processing algorithms for each experiment use machine learning methods enable the experimentalist calibrate the image processing methods without having any knowledge how these methods work This believe will allow the rapid integration computer vision methods with confocal microscopy and open the way the development quantitative spatial models cellular processes nFor more information see then http seed ucsd edu yfreund NewHomePage Applications Biomedical Imaging html Bio medical image analysis page 
12271 en Computational advertising business models technologies and issues CoAd Internet advertising revenues the United States totaled billion for 2007 percent versus 2006 revenues billion according the Interactive Advertising Bureau this represents approximately half the worldwide revenue from online advertising Fueled these growth rates and the desire provide added incentives and opportunities for both advertisers and publishers alternative business models online advertising are been developed This tutorial will review the main business models online advertising including the pay per impression model CPM and the pay per click model CPC relative new comer the pay per action model CPA where action could product purchase site visit customer lead email signup and dynamic CPM dCPM which optimizes campaign towards the sites and site sections that perform best for the advertiser nThis tutorial will also discuss detail the technology being leveraged automatically target ads within these business models this largely derives from the fields machine learning logistic regression online learning statistics binomial maximum likelihood information retrieval vector space model BM25 optimization theory linear and quadratic programming economics auction mechanisms game theory Challenges such click fraud the spam online advertising deception privacy and other open issues will also discussed Web applications such social networks and video photo sharing pose new challenges for online advertising These will also discussed 
12272 en Enterprise and Desktop search EDS The Enterprise and Desktop Search problems recently received considerable amount attention from academia mainly due the increasing demand industrial solutions supporting various search tasks intranets While challenges arising intranet search are not entirely new comparing those that web community has faced for years advanced web search technologies are often unable address them properly this course give research prospective distinctive features both Enterprise and Desktop Search typical search scenarios existing ranking techniques and algorithms First lecture gives general introduction reviews existing systems and outlines typical research challenges our next lecture plan summarize advanced ranking algorithms and personalization methods utilizing implicit and explicit feedback from users Third lecture provides overview exploratory search methods including search result clustering categorization faceted search well related techniques stimulating interaction with user Later discuss latest developments expert people search for example graph based and language model based methods Last lecture covers various aspects Desktop search state the art research prototypes advanced real world applications and recent break through ideas like just time retrieval and task context detection The course wrapped with discussion open problems and research directions Enterprise and Desktop search 
12273 en Information Retrieval Modeling IRM There such thing dominating model theory information retrieval unlike the situation for instance the area databases where the relational model the dominating database model information retrieval some models work for some applications whereas others work for other applications For instance vector space models are well suited for similarity search and relevance feedback many also non textual situations good weighting function available the probabilistic retrieval model naive Bayes model might good choice examples relevant and nonrelevant documents are available Google Pagerank model often used situations that need modelling more less static relations between documents region models have been designed search structured text and language models are helpful situations that require models language similarity document priors this tutorial carefully describe all these models exlpaining the consequences modelling assumptions address approaches based statistical language models great depth After the course students are able choose model information retrieval that adequate new situations and apply the model practical situations 
12275 en Modeling Web Searcher Behavior and Interactions Hundreds millions users search the web daily clicking the results submitting and refining queries and otherwise interacting with the search engines The vast amount information generated product these interactions can mined dramatically improve the effectiveness web search and information access general nThis course will survey the research modeling user behavior web search and how this information can improve web search effectiveness The emphasis will learning and analyzing the appropriate data mining and machine learning techniques for the user behavior and interaction data and the integration the behavioral models into the search engine operation 
12277 en Persistence based Clustering Clustering classical problem which looks for important segmentsnin unstructured data set general this ill posednproblem common approach consider the data set sample ofnan unknown probability distribution function some underlyingnspace Clustering then becomes problem understanding thenbehaviour the distribution function nnIn this talk will introduce persistence based clustering Undernsome mild assumptions the algorithm comes with variety strongntheoretical guarantees particular provably approximates thenstructure the underlying distribution function even when underlyingnspace only approximately known The approach based heavily onnpersistent homology also refered topological persistence anrelatively recent development the area computationalntopology precisely this framework which makes many thenproofs possible The talk will include general introduction tonpersistence prior knowledge expected the practical side nthe algorithm efficient both memory size and running time sonit can handle large high dimensional data sets quickly Finally itnprovides visual feedback addition the clusters something whichnis particularly useful when the data sets cannot visualized 
12305 en Welcome presentation Computer security Workshop presentation
12307 en Introduction Particle Physics for non particle physicists These lectures are introduction the ideas particle physics aimed students and teachers with little knowledge the subject They form broad basis that will developed more detail the subsequent lecturers the school nnPrerequisite knowledge Basic physics prior knowledge particle physics needed For cheap pocket sized guide see Particle Physics Very Short Introduction Frank Close published Oxford University Press 
12308 en Installation Commissioning and Startup Atlas CMS Experiments
12309 en Particle Detectors This lecture will serve introduction particle detectors and detection techniques nIn the first lecture historic overview particle detector development will given the second lecture some basic techniques and concepts for particle detection will discussed the third lecture the interaction particles with matter the basis particle detection will presented nThe fourth and fifth lectures will discuss different detector types used for particle tracking energy measurement and particle identification 
12311 en Accelerators Introduction and motivationn1b History and accelerator typesn2 Transverse beam dynamicsn3a Longitudinal beam dynamicsn3b Figure merit synchrotron collidern3c Beam controln4 Main limiting factorsn5 Technical challengesnnPrerequisite knowledge Previous knowledge accelerators not required 
12331 en The future energy and climate The talk will review some the basic facts about the history and present status the use energy and its climatic consequences clear that the world will have change its way energy production the sooner the better Because the difficulty storing electric energy far the best energy source for the future thermal solar from the deserts with overnight thermal storage will give some description the present status the technologies involved and end with pilot project for Europe and North Africa 
12332 en Visible and invisible modern Physics
12357 en Machine Learning Biological Network Models this talk survey work being conducted the Centre fornIntegrative Systems Biology Imperial College the use ofnmachine learning build models biochemical pathways nWithin the area Systems Biology these models providengraph based descriptions bio molecular interactions whichndescribe cellular activities such gene regulation metabolismnand transcription One the key advantages the approach taken nInductive Logic Programming the availability background knowledgenon existing known biochemical networks from publicly availablenresources such KEGG and Biocyc The topic has clear societal impactnowing its application Biology and Medicine Moreover objectndescriptions this domain have inherently relational structure thenform spatial and temporal interactions the molecules involved nThe relationships include biochemical reactions which one setnof metabolites transformed another mediated the involvementnof enzyme Existing genomic information very incompletenconcerning the functions and even the existence genes andnmetabolites leading the necessity techniques such asnlogical abduction introduce novel functions and inventnnew objects Moreover the development active learningnalgorithms has allowed automatic suggestion new experimentsnto test novel hypotheses The approach thus provides supportnfor the overall scientific cycle hypothesis generation andnexperimental testing 
12361 en ESA future projects and missions opportunity for Slovenia
12365 en Knowledge transfer and from clinical research
12377 en Compassion The Art Happiness One great question underlies our experience whether think about consciously not What the purpose life The Fourteenth Dalai Lama has considered this question and would like share his thoughts the hope that they may direct practical benefit those who read them believe that the purpose life happy From the moment birth every human being wants happiness and does not want suffering Neither social conditioning nor education nor ideology affect this From the very core our being simply desire contentment don know whether the universe with its countless galaxies stars and planets has deeper meaning not but the very least clear that humans who live this earth face the task making happy life for ourselves Therefore important discover what will bring about the greatest degree happiness 
12428 en VideoLectures Promo VideoLectures NET free and open access educational video lectures repository The lectures are given distinguished scholars and scientists the most important and prominent events like conferences summer schools workshops and science promotional events from many fields Science The portal aimed promoting science exchanging ideas and fostering knowledge sharing providing high quality didactic contents not only scientific community but also general public All lectures accompanying documents information and links are systematically selected and classified through the editorial process taking into account also users comments nnThe training materials are being developed within the FP5 FP6 and FP7 European Framework Programs where the web based portal VideoLectures NET being used educational platform for several funded research projects such PASCAL NoE ECOLEAD NoE SEKT and different organizations among others MIT OpenCourseWare and CERN The range countries involved and languages used varies from Europe USA Taiwan Australia Ukraine Russia and Brazil nnThe portal becoming major reference video training material repository and dissemination channel for academic researchers all around the world Following the ideas network with other similar initiatives new frameworks and plans are being prepared aiming boosting science video reference network combining universities and research institutes that provides qualitative stream scientific and training programs nnFor that purpose will continue film and provide services for major world scientific conferences and extend the coverage also non technical and natural science disciplines like Fine Arts Humanities Social studies and Law 
12436 en Visual information about medicines for patients designing for Don Quixote Vizualne informacije zdravilih bolnike oblikovanje Don Kihota English nSituation Information about medicines nIt very hard handle medicines properly without visual information Leaflets packaging websites and pharmacist labels provide patients with plethora texts and images that aim inform about dosage correct way taking side effects warnings and storage Unfortunately this visual information does not seem result ‘effective instructions and warnings’ and frequently leads confusion and anxiety Medical errors persistently increasing costs medicines and ineffective use are seen unavoidable and part this system nnIssue Four questionable assumptions nThe main practical task convince patients take medicines appropriately and effectively This problematic The reason might that some the assumptions that underlie the legal framework for the development visual information for patients are incorrect The first assumption that patients are helped standardization and strictly prescribing the information that required The second assumption that patients are not the main influential factor when information about medicines considered The third assumption that ‘medicines’ and ‘information’ must regulated governmental authorities the same manner The fourth assumption underestimates the ability patients recognize and interpret information about medicines These four assumptions lead view that only necessary ‘protect patients’ against ‘incorrect and incomplete’ information The result profusion guidelines and regulations about visual information nnConsequences are solving the wrong problems nThe current development process information about medicines diverts from the tried and tested processes developing appropriate arguments that could convince patients There are discrepancies the selection the contents the structure the argument and the style which the argument presented The result that the interpretation visual information about medicines unnecessarily difficult nnApproach Developing alternative prototypes nAn analysis shows that the four assumptions about ‘effective communication’ related information about medicines are malignant These assumptions hamper the development appropriate visual arguments that might support patients handle medicines appropriately Fighting these ‘windmills’ requires substantial efforts without benefitting patients nnThe development alternative genres that could provide patients with reliable and understandable information about medicines essential Novel prototypes that show what clear and understandable information really looks like are urgently required Slovensko nStanje Informacije zdravilih nBrez vizualnih informacij zelo pravilno ravnati zdravili Zgibanke embala spletne strani lekarni nalepke bolnikom ponujajo razli besedila podobe jih informirali odmerku pravilnem jemanju zdravil stranskih inkih opozorilih hranjenju zdravil vizualne informacije tvorijo » inkovitih navodil opozoril« temve pogosto vzrok zmedo preplah Zdravni napake rasto stro zdravil neu inkovita uporaba zdijo neizogibni del tega sistema nnZadeva tiri vpra ljive predpostavke nGlavna prakti naloga prepri ati bolnike naj ustrezno inkovito jemljejo zdravila problemati Razlog vsej verjetnosti napa predpostavke temelj pravnega okvira razvoja vizualnih informacij bolnike Prva predpostavka sta standardizacija strogo dolo anje potrebnih informacij pomo bolnikom Druga predpostavka bolniki niso glavni vplivni dejavnik pri informacijah zdravilih Tretja predpostavka morajo vladni organi enako nadzorovati »zdravila« »informacije« etrta predpostavka podcenjevanje sposobnosti bolnikov prepoznajo interpretirajo informacije zdravilih tiri predpostavke vodijo mnenju treba samo » ititi bolnike« pred »napa nimi nepopolnimi« informacijami Posledica tega mno ica navodil predpisov vizualnih informacijah nnPosledice ujemo napa probleme nTrenutni razvojni proces informacij zdravilih stran preizku enih procesov razvijanja ustreznih argumentov lahko prepri ali bolnike Obstajajo odstopanja izbiri vsebine ter strukturi slogu argumentiranja Posledica nepotrebno zapletena interpretacija vizualnih informacij zdravilih nnPristop Razvijanje alternativnih prototipov nAnalize ejo glavni krivec tiri predpostavke » inkoviti komunikaciji« predpostavke ovirajo razvoj ustreznih vizualnih argumentov bolnike lahko spodbudili pravilnem ravnanju zdravili Boj proti tem »mlinom veter« zahteva precej napor kar koristi bolnikom nnNujno treba razvijati alternativne oblike bolnikom ponudili zanesljive razumljive podatke zdravilih Nujno potrebujemo nove prototipe pokazali kak jasne razumljive informacije 
12444 en  Introduction Project Halo this talk will describe Project Halo large scale research program artificial intelligence sponsored Paul Allen’ Vulcan Inc Project Halo has three parts expert system called AURA for knowledge formulating and question answering science advanced reasoning system called SILK for default and higher order inference and social semantic web platform called Semantic MediaWiki SMW for effectively building the large basic knowledge base that necessary for the other two parts work will briefly describe the first two these parts but will spend most time describing Project Halo’ work SMW SMW combines semantic web technology and wiki based social mechanisms and marries the structure and flexibility database the crowd sourcing power wiki will show several examples SMW and conclude describing Vulcan’ Ultrapedia prototype which show what Wikipedia might look like was built with semantic wiki 
12617 en Optical Wireless Technologies for Broadband Communications Today information exchange depends the transmission data voice and multimedia across the telecommunication networks Optical wireless broadband communication represents one the most promising approaches for addressing the emerging broadband access market offers low start and operational costs high security rapid deployment high fibre like bandwidths where licence needed the other side optical wireless links can severely affected fog and atmospheric turbulence However the optical wireless communications also refered free space optical communications will play significant role future information superhighways nThe research group Optikom Graz deals with the research and development optical communications with special emphasis Free Space Optics FSO participates several national and international projects including Network Excellence SatNEx several ESA projects and COST IC0802 action related channel modelling for FSO systems The group currently investigating how increase the reliability FSO systems new hybrid FSO system design considering different weather and atmospheric conditions new modulation and coding schemes and different diversity techniques 
12690 en Forensic Statistics Where are and Where are Going will discuss the present situation Forensic statistics Rapid developments forensic science are putting statistics and probability more and more into the court room lime light often with apalling results Why this and where should Standard Bayesian and standard frequentist statistics are based the wrong paradigms Forensic statisticians have learn from the learning community But forensic statistics How can learn 
12691 en Approximate Bayesian Computation What Why and How Approximate Bayesian Computation ABC arose response the difficulty simulating observations from posterior distributions determined intractable likelihoods The method exploits the fact that while likelihoods may impossible compute complex probability models often easy simulate observations from them ABC its simplest form proceeds follows simulate parameter from the prior simulate observations from the model with this parameter iii accept the parameter the simulated observations are close enough the observed data The magic and the source potential disasters step iii This talk will outline what know and don about ABC and illustrate the methods with applications the fossil record and stem cell biology 
12693 en Boosted optimization for network classification this paper propose new classification algorithm designed for application complex networks motivated algorithmic similarities between boosting learning and message passing consider network classifier logistic regression where the variables define the nodes and the interaction effects define the edges From this definition represent the problem factor graph local exponential loss functions Using the factor graph representation possible interpret the network classifier ensemble individual node classifiers then combine ideas from boosted learning with network optimization algorithms define two novel algorithms Boosted Expectation Propagation BEP and Boosted Message Passing BMP These algorithms optimize the global network classifier performance locally weighting each node classifier the error the surrounding network structure compare the performance BEP and BMP logistic regression well state the art penalized logistic regression models simulated grid structured networks The results show that using local boosting optimize the performance network classifier increases classification performance and especially powerful cases when the whole network structure must considered for accurate classification 
12694 en Detecting weak but hierarchically structured patterns networks The ability detect weak distributed activation patterns networks critical several applications such identifying the onset anomalous activity incipient congestion the Internet faint traces biochemical spread sensor network This challenging problem since weak distributed patterns can invisible per node statistics well global network wide aggregate Most prior work considers situations which the activation non activation each node statistically independent but this unrealistic many problems this paper consider structured patterns arising from statistical dependencies the activation process Our contributions are three fold First propose sparsifying transform that succinctly represents structured activation patterns that conform hierarchical dependency graph Second establish that the proposed transform facilitates detection very weak activation patterns that cannot detected with existing methods Third show that the structure the hierarchical dependency graph governing the activation process and hence the network transform can learnt from very few logarithmic network size independent snapshots network activity 
12695 en Function class complexity and cluster structure with applications transduction relate function class complexity structure the function domain This facilitates risk analysis relative cluster structure the input space which particularly effective semi supervised learning particular quantify the complexity function classes defined over graph terms the graph structure 
12696 en Multiclass multilabel classification with more labels than examples discuss multiclass multilabel classification problems which the set possible labels extremely large Most existing multiclass multilabel learning algorithms expect observe reasonably large sample from each class and fail they receive only handful examples with given label propose and analyze the following two stage approach first use arbitrary perhaps heuristic classification algorithm construct initial classifier then apply simple but principled method augment this classifier removing harmful labels from its output careful theoretical analysis allows justify our approach under some reasonable conditions such label sparsity and power law distribution label frequencies even when the training set does not provide statistically accurate representation most classes Surprisingly our theoretical analysis continues hold even when the number classes exceeds the sample size demonstrate the merits our approach the ambitious task categorizing the entire web using the million categories defined Wikipedia 
12697 en Empirical Bernstein boosting Concentration inequalities that incorporate variance information such Bernstein Bennett inequality are often significantly tighter than counterparts such Hoeffding inequality that disregard variance Nevertheless many state the art machine learning algorithms for classification problems like AdaBoost and support vector machines SVMs extensively use Hoeffding inequalities justify empirical risk minimization and its variants This article proposes novel boosting algorithm based recently introduced principle sample variance penalization which motivated from empirical version Bernstein inequality This framework leads efficient algorithm that easy implement AdaBoost while producing strict generalization Experiments large number datasets show significant performance gains over AdaBoost This paper shows that sample variance penalization could viable alternative empirical risk minimization 
12698 en Sufficient covariates and linear propensity analysis Working within the decision theoretic framework for causal inference study the properties sufficient covariates which support causal inference from observational data and possibilities for their reduction particular illustrate the role propensity variable means simple model and explain why such reduction typically does not increase and may reduce estimation efficiency 
12699 en Dirichlet process mixtures generalised linear models propose Dirichlet Process mixtures Generalized Linear Models GLMs new method nonparametric regression that accommodates continuous and categorical inputs models response variable locally generalized linear model give conditions for the existence and asymptotic unbiasedness the GLM regression mean function estimate then give practical example for when those conditions hold evaluate GLM several data sets comparing modern methods nonparametric regression including regression trees and Gaussian processes 
12700 en Bayesian Gaussian process latent variable model introduce variational inference framework for training the Gaussian process latent variable model and thus performing Bayesian nonlinear dimensionality reduction This method allows variationally integrate out the input variables the Gaussian process and compute lower bound the exact marginal likelihood the nonlinear latent variable model The maximization the variational lower bound provides Bayesian training procedure that robust overfitting and can automatically select the dimensionality the nonlinear latent space demonstrate our method real world datasets The focus this paper dimensionality reduction problems but the methodology more general For example our algorithm immediately applicable for training Gaussian process models the presence missing uncertain inputs 
12701 en Factored way restricted Boltzmann machines for modeling natural images Deep belief nets have been successful modeling handwritten characters but has proved more difficult apply them real images The problem lies the restricted Boltzmann machine RBM which used module for learning deep belief nets one layer time The Gaussian Binary RBMs that have been used model real valued data are not good way model the covariance structure natural images propose factored way RBM that uses the states its hidden units represent abnormalities the local covariance structure image This provides probabilistic framework for the widely used simple complex cell architecture Our model learns binary features that work very well for object recognition the tiny images data set Even better features are obtained then using standard binary RBM learn deeper model 
12702 en Learning the structure deep sparse graphical models Deep belief networks are powerful way model complex probability distributions However difficult learn the structure belief network particularly one with hidden units The Indian buffet process has been used nonparametric Bayesian prior the structure directed belief network with single infinitely wide hidden layer Here introduce the cascading Indian buffet process CIBP which provides prior the structure layered directed belief network that unbounded both depth and width yet allows tractable inference use the CIBP prior with the nonlinear Gaussian belief network framework allow each unit vary its behavior between discrete and continuous representations use Markov chain Monte Carlo for inference this model and explore the structures learned image data 
12703 en Solving the uncapacitated facility location problem using message passing algorithms The Uncapacitated Facility Location Problem UFLP one the most widely studied discrete location problems whose applications arise variety settings tackle the UFLP using probabilistic inference graphical model approach that has received little attention the past show that the fixed points max product linear programming MPLP convexified version the max product algorithm can used construct solution with approximation guarantee for metric UFLP instances addition characterize some scenarios under which the MPLP solution guaranteed globally optimal evaluate the performance both max sum and MPLP empirically metric and non metric problems demonstrating the advantages the approximation construction and algorithm applicability non metric instances 
12704 en Dense message passing for sparse principal component analysis describe novel inference algorithm for sparse Bayesian PCA with zero norm prior the model parameters Bayesian inference very challenging probabilistic models this type MCMC procedures are too slow practical very high dimensional setting and standard mean field variational Bayes algorithms are ineffective adopt dense message passing algorithm similar algorithms developed the statistical physics community and previously applied inference problems coding and sparse classification The algorithm achieves near optimal performance synthetic data for which statistical mechanics theory optimal learning can derived also study two gene expression datasets used previous studies sparse PCA find our method performs better than one published algorithm and comparably second 
12705 en Focused belief propagation for query specific inference With the increasing popularity large scale probabilistic graphical models even lightweight approximate inference methods are becoming infeasible Fortunately often large parts the model are immediate interest the end user Given the variable that the user actually cares about show how quantify edge importance graphical models and significantly speed inference focusing computation important parts the model Our algorithm empirically demonstrates convergence speedup multiple times over state the art
12706 en Exploiting feature covariance high dimensional online learning Some online algorithms for linear classification model the uncertainty their weights over the course learning Modeling the full covariance structure the weights can provide significant advantage for classification However for high dimensional large scale data even though there may many second order feature interactions computationally infeasible maintain this covariance structure extend second order methods high dimensional data develop low rank approximations the covariance structure evaluate our approach both synthetic and real world data sets using the confidence weighted online learning framework show improvements over diagonal covariance matrices for both low and high dimensional data 
12707 en REGO Rank based estimation Renyi information using Euclidean graph optimization propose new method for non parametric estimation Renyi and Shannon information for multivariate distribution using corresponding copula multivariate distribution over normalized ranks the data the information the distribution the same the negative entropy its copula our method estimates this information solving Euclidean graph optimization problem the empirical estimate the distribution copula Owing the properties the copula show that the resulting estimator Renyi information strongly consistent and robust Further demonstrate its applicability the image registration addition simulated experiments 
12708 en Coherent inference optimal play game trees Round based games are instance discrete planning problems Some the best contemporary game tree search algorithms use random roll outs data Relying good policy they learn policy values propagating information upwards the tree but not between sibling nodes Here present generative model and corresponding approximate message passing scheme for inference the optimal off policy value nodes smooth AND trees given random roll outs The crucial insight that the distribution values game trees not completely arbitrary define generative model the policy values using latent score for each state representing the value under the random roll out policy Inference the values under the optimal policy separates into inductive pre data step and deductive post data part Both can solved approximately with Expectation Propagation allowing off policy value inference for any node the exponentially big tree linear time 
12709 en Nonlinear functional regression functional RKHS approach This paper deals with functional regression which the input attributes well the response are functions deal with this problem develop functional reproducing kernel Hilbert space approach here kernel operator acting function and yielding function demonstrate basic properties these functional RKHS well representer theorem for this setting investigate the construction kernels provide some experimental insight 
12710 en  the relation between universality characteristic kernels and RKHS embedding measures Universal kernels have been shown play important role the achievability the Bayes risk many kernel based algorithms that include binary classification regression etc this paper propose notion universality that generalizes the notions introduced Steinwart and Micchelli and study the necessary and sufficient conditions for kernel universal show that all these notions universality are closely linked the injective embedding certain class Borel measures into reproducing kernel Hilbert space RKHS exploiting this relation between universality and the embedding Borel measures into RKHS establish the relation between universal and characteristic kernels The latter have been proposed the context the RKHS embedding probability measures used statistical applications like homogeneity testing independence testing etc 
12711 en  combining graph based variance reduction schemes this paper consider two variance reduction schemes that exploit the structure the primal graph the graphical model Rao Blackwellised cutset sampling and AND sampling show that the two schemes are orthogonal and can combined further reduce the variance Our combination yields new family estimators which trade time and space with variance demonstrate experimentally that the new estimators are superior often yielding order magnitude improvement over previous schemes several benchmarks 
12712 en Convex structure learning log linear models beyond pairwise potentials Previous work has examined structure learning log linear models with regularization largely focusing the case pairwise potentials this work consider the case models with potentials arbitrary order but that satisfy hierarchical constraint enforce the hierarchical constraint using group regularization with overlapping groups and active set method that enforces hierarchical inclusion allows tractably consider the exponential number higher order potentials use spectral projected gradient method sub routine for solving the overlapping group regularization problem and make use sparse version Dykstra algorithm compute the projection Our experiments indicate that this model gives equal better test set likelihood compared previous models 
12713 en Modeling annotator expertise Learning when everybody knows bit something Supervised learning from multiple labeling sources increasingly important problem machine learning and data mining This paper develops probabilistic approach this problem when annotators may unreliable labels are noisy but also their expertise varies depending the data they observe annotators may have knowledge about different parts the input space That annotator may not consistently accurate inaccurate across the task domain The presented approach produces classification and annotator models that allow provide estimates the true labels and annotator variable expertise provide analysis the proposed model under various scenarios and show experimentally that annotator expertise can indeed vary real tasks and that the presented approach provides clear advantages over previously introduced multi annotator methods which only consider general annotator characteristics 
12714 en Fluid dynamics models for low rank discriminant analysis consider the problem reducing the dimensionality labeled data for classification Unfortunately the optimal approach finding the low dimensional projection with minimal Bayes classification error intractable most standard algorithms optimize tractable heuristic function the projected subspace Here investigate physics based model where consider the labeled data interacting fluid distributions derive the forces arising the fluids from information theoretic potential functions and consider appropriate low rank constraints the resulting acceleration and velocity flow fields show how apply the Gauss principle least constraint fluids obtain tractable solutions for low rank projections Our fluid dynamic approach demonstrated better approximate the Bayes optimal solution Gaussian systems including infinite dimensional Gaussian processes 
12716 en Half transductive ranking study the standard retrieval task ranking fixed set items given previously unseen query and pose the half transductive ranking problem The task transductive the set items fixed Transductive representations where the vector representation each example learned allow the generation highly nonlinear embeddings that capture object relationships without relying specific choice features and require only relatively simple optimization Unfortunately they have direct out sample extension Inductive approaches the other hand allow for the representation unknown queries describe algorithms for this setting which have the advantages both transductive and inductive approaches and can applied unsupervised either reconstruction based graph based and supervised ranking setups show empirically that our methods give strong performance all three tasks 
12762 en Building Structured Web Databases Midterm Report from the Cimple Project
12764 en DBToaster Aggressive Compilation Techniques for Online Aggregation
12765 en PrDB Increasing the Representational Power and Scaling Reasoning Probabilistic Databases
12766 en MCMC Inference Inside the for Extraction Resolution Alignment Provenance and Queries
12768 en WWT system for query driven relation extraction from the semi structured web
12769 en Query Driven Integration The System
12770 en Worth its Weight Gold Yet Another Resource — Comparative Study Wiktionary OpenThesaurus and GermaNet this paper analyze the topology and the content anrange lexical semantic resources for the German language constructedneither controlled GermaNet semi controlled OpenThesaurus orncollaborative community based manner Wiktionary For the firstntime the comparison the corresponding resources performed thenword sense level For this purpose the word senses terms are automaticallyndisambiguated Wiktionary and the content all resourcesnis converted uniform representation show that the resources’ntopology well comparable they share the small world property andncontain comparable number entries although differences theirnconnectivity exist Our study content related properties reveals thatnthe German Wiktionary has different distribution word senses andncontains more polysemous entries than both other resources identifynthat each resource contains the highest number particular type ofnsemantic relation finally increase the number relations Wiktionarynby considering symmetric and inverse relations that have beennfound usually absent this resource 
12771 en Combined Structured and Keyword Based Search Textually Enriched Entity Relationship Graphs present novel method combine simple nexible keyword based search with expressive structured queries assume thatnan entity relationship graph given wherensome the nodes are linked unstructuredntext documents The aim our approachnis efficiently search for relevant entities ornfacts about entities Using several examples nwe demonstrate the new types queryingnthat can realized our approach 
12772 en Aligning Sense Inventories Wikipedia and Wordnet this paper study the alignment ofnWikipedia articles and WordNet synsets Therefore nwe propose method convert Wikipedianto sense inventory show that alignednsense inventory both resources has two majornbenefits the coverage senses can increasednand enhanced information about aligned sensesncan obtained Our study and conclusions arenbased human annotations sense alignments 
12773 en ProbaMap scalable tool for discovering probabilistic mappings between taxonomies this paper investigate principlednapproach for defining and discovering probabilisticnmappings between two taxonomies nFirst compare two ways modelingnprobabilistic mappings which are compatiblenwith the logical constraints declared inneach taxonomy Then describe generatenand test algorithm called ProbaMap nwhich minimizes the number calls thenprobability estimator for determining thosenmappings whose probability exceeds certainnthreshold Finally provide experimentalnanalysis this approach 
12774 en Entity Disambiguation using Relations extracted from Wikipedia present approach for the disambiguation textual mentions ambiguous names ndisambiguation means here the identificationnof the true entity denoted name phrasenappearing query context through its assignment the corresponding Wikipedia article this article does not exist assign this query default entity Ambiguity names major problem information retrieval and causes uncertainty innthe assignment name phrases existingnknowledge base entries propose kernelnclassifier approach this problem and compare two Wikipedia structures construct anrich feature space The first approach reliesnon Wikipedia categories the second relations constructed from Wikipedia hypernlink structure nWe evaluate both approaches the Germannversion Wikipedia and show that both outperform baseline approach using simple cosine similarity 
12777 en Finding Frequent and Interesting Triples Text
12778 en Mining Commonsense Knowledge From Personal Stories Internet Weblogs Recent advances automated knowledge basenconstruction have created new opportunities tonaddress one the hardest challenges ArtificialnIntelligence automated commonsense reasoning nIn this paper describe our recent efforts innmining commonsense knowledge from thenpersonal stories that people write about theirnlives their Internet weblogs summarizenthree preliminary investigations that involve thenapplication statistical natural languagenprocessing techniques corpora millions ofnweblog stories and outline our current approachnto solving number outstanding technicalnchallenges 
12779 en Automatic Extraction Human Activity Knowledge from Method Describing Web Articles Knowledge daily human activities various domains invaluable for many customized user services that can benefit from context awareness activity predictions Past approaches constructing knowledge base this kind have been domain specific and not scalable recent attempt extract activities daily living ADL from Web resources deal with activities and objects involved achieving them but not the sequence actions activity This paper describes approach automatically extracting human activity knowledge from Web articles that describe methods for performing tasks variety domains The target knowledge base comprised activity goals actions and ingredients which are extracted with syntactic pattern based and probabilistic machine learning based methods The result evaluated for accuracy and coverage against some baselines 
12780 en Robust Web Extraction Principled Approach script generated web sites many documents share common HTML treenstructure allowing wrappers effectively extract information ofninterest course the scripts and thus the tree structure evolvenover time causing wrappers break repeatedly and resulting anhigh cost maintaining wrappers this paper explore novelnapproach use temporal snapshots web pages develop antree edit model HTML and use this model improve wrappernconstruction view the changes the tree structure asnsuppositions series edit operations deleting nodes insertingnnodes and substituting labels nodes The tree structures evolve bynchoosing these edit operations stochastically nnOur model attractive that the probability that source tree hasnevolved into target tree can estimated efficiently innquadratic time the size the trees making potentiallynuseful tool for variety tree evolution problems give annalgorithm learn the probabilistic model from training examplesnconsisting pairs trees and apply this algorithm collectionsnof web page snapshots derive HTML specific tree edit models nFinally describe novel wrapper construction framework that takesnthe tree edit model into account and compare the quality resultingnwrappers that traditional wrappers synthetic and real HTMLndocument examples 
12781 en Reinforcement Learning for Structured Data Labeling
12821 en Designing Online Communities from Theory Online communities are the fastest growing portion the Internet and provide members with information social support and entertainment While minority such Wikipedia MySpace Facebook and the Apache Server project are highly successful many others fail successful online communities must overcome challenges common almost all groups organizations and voluntary associations – solving problems start recruitment socialization commitment contribution coordination and regulation behavior The social sciences can tell lot about how create thriving online communities Social science theories can inform choices about how get community started integrate newcomers encourage commitment regulate behavior when there are conflicts motivate contributions and coordinate those contributions maximize benefits for the community nnThis talk focuses ways build members’ commitment online communities based theories social identity and interpersonal bonds provides overview the relevant theory describes results month field experiment which existing site was redesigned based principles derived from social identity and interpersonal bond theories and describes the results agent based model that examines how different approaches moderating the content group influence social identity and interpersonal bonds 
12822 en Behavioral Experiments Strategic Networks For four years now have been conductingn“medium scale” experiments how humannsubjects behave strategic and economic settingsnmediated underlying social networknstructure have explored wide rangenof networks inspired generative modelsnfrom the literature and diverse set collectivenstrategic problems including biased voting ngraph coloring consensus and networkedntrading These experiments have yielded anwealth both specific findings and emergingngeneral themes about how populations humannsubjects interact strategic networks nKearns will review these findings and themes nwith emphasis the many more questionsnthey raise than answer nMichael Kearns professor computernand information science the University ofnPennsylvania where holds the National CenternChair Resource Management and Technology nHe the founding director Penn Engineering’snnew Market and Social Systems Engineeringn MKSE program Kearns hasnsecondary appointments the Statistics andnOp erations and Information Managementn OPIM departments the Wharton School nand affiliated faculty member Penn’snApplied Math and Computational Science graduatenprogram Kearns also serves advisornto Yodle kaChing Invite Media and Kwedit nHis research interests include topics machinenlearning algorithmic game theory social networks ncomputational finance and artificial intelligence nMost recently has been conductingnhuman subject experiments strategic andneconomic interaction social networks Kearnsnreceived his mathematics and computernscience from the University California atnBerkeley 1985 and his computernscience from Harvard University 1989 Henhas served the program chair NIPS AAAI nCOLT and ACM member thenNIPS Foundation and the steering committeenfor the Snowbird Conference Learning andnserves the editorial board The MIT Pressnseries adaptive computation and machinenlearning 
12823 en Got Facebook Investigating What Social About Social Media Watkins has been researching young people’snmedia behaviors for more than ten years andnhe teaches the departments Radio Television nFilm and Sociology and the Center fornAfrican and African American Studies His recentnbook The Young and the Digital Whatnthe Migration Social Network Sites Games nand Anytime Anywhere Media Means for OurnFuture explores young people’ dynamic engagementnwith social media online games mobilenphones and communities like Facebooknand MySpace few short years ago Facebooknwas widely viewed site for college studentsnwho used the platform primarily for socialnpurposes making new friends stalkingneach other and posting pictures from weekendnof partying and drinking Watkins’ talk willnshow how young people’ participation innFacebook actually more complex than thenpopular images and myths suggests Drawingnfrom both survey data and depth interviewsnwith current college students and recent collegengraduates the talk considers how the usenof Facebook evolves across the young life cycle nThe talk also discusses the question what’snsocial about social media 
12824 en Words reflections psychological state Pennebaker’ research explores the links betweenntraumatic experiences expressive writing nnatural language use and physical andnmental health Across numerous real world contexts nhis studies have demonstrated that thenwords people use serve powerful reflectionsnof their personality and social worlds For example nhis analyses over 000 people whonwrote blogs the weeks before and afternSeptember terrorist attacks showed that thenjournal entries revealed pronounced psychologicalnchanges response the attacks His talknwill address the fact that most language basedncomputer programs analyze content heavynwords such nouns and regular verbs andnthrow out “junk” words such pronouns nprepositions and articles understand people’snthinking buying searching and other behaviors nAccording Pennebaker’ work analysesnof junk words can yield important insightsninto the social and psychological processes ofnpeople across cultures and languages willntalk about his recent studies which point thenrole junk words identifying personality ndepression status honesty group cohesiveness nand other individual and group behaviors 
12825 en Examining Online and Offline Communication Processes Online Dating and Social Network Sites Ellison’ research has been examining the waysnin which new information and communicationntechnologies shape social processes and vicenversa Her recent research has focused thensocial capital implications social network sitenuse and issues self presentation relationshipnformation and maintenance and impressionnformation online contexts Ellison’ talk willnpresent research examining how people usenthe Internet engage self presentation formnand maintain relationships and garner socialncapital benefits The talk will focus two newnstreams research one examining the ways innwhich people use Facebook connect withnothers and access social support and the othernexploring online dating participants’ perceptionsnregarding acceptable and unacceptablenmisrepresentation online dating profiles 
12826 en Sequential Influence Models Social Networks The spread influence among individuals social network can naturally modeled probabilistic framework but challenging reason about differences between various models well relate these models actual social network data Here consider two the most fundamental definitions influence one based small set snapshot observations social network and the other based detailed temporal dynamics The former particularly useful because large scale social network data sets are often available only snapshots crawls The latter however provides more detailed process model how influence spreads study the relationship between these two ways measuring influence particular establishing how infer the more detailed temporal measure from the more readily observable snapshot measure validate our analysis using the history social interactions Wikipedia the result the first large scale study exhibit direct relationship between snapshot and temporal models social influence 
12827 en Who Acquires Friends Through Social Media and Why “Rich Get Richer” versus “Seek and Shall Find” There ongoing debate not just among academics but popular culture about whether social media can expand people’ social networks and whether online friends can “real” friends The debate refuses die This paper addresses this question subjectively from the point view the user and examines the predictors acquiring new friends through social media use This multi method study with quantitative 617 and qualitative sections Some previous studies have found “rich get richer” effect where people who are socially active offline appear benefit most from online interactions This paper based the idea that whether online friends can real friends may subject self fulfilling prophecy those who not believe that online friendships can real friendships are not likely make such connections compare the “Rich Get Richer” and “Seek and Shall Find” models examining relationships between the amount offline socializing amount online social activity and the belief online friendships also qualitatively examine reasons cited respondents why online sociality not plausible route meaningful friendship The results show strong support for one the earliest theories computer mediated communication hyperpersonal interaction appears that sizable portion the young generation finds online interaction positive because perceived concentrate the conversation itself rather than appearances and seen freer social judgments African Americans are significantly more likely meet new friends online There also appear underlying personality traits apart from traditional demographic variables that divide the population terms their attitude towards online sociality 
12828 en  Star Not Only Metaphoric From Popularity Social Linkage The emergence online platforms allowing mix self publishing activities and social networking offers new possibilities for building online reputation and visibility this paper present method analyze the online popularity that takes into consideration both the success the published content and the social network topology First adapt the Kohonen self organizing maps order cluster the users online platforms depending their audience and authority characteristics Then perform detailed analysis the manner nodes are organized the social network Finally study the relationship between the network local structure around each node and the corresponding user’ popularity apply this method the MySpace music social network observe that the most popular artists are centers star shaped social structures and that exists fraction artists who are involved community and social activity dynamics independently their popularity This method based learning algorithm and network analysis appears robust and intuitive technique for rich description the online behavior 
12829 en ePluribus Ethnicity Social Networks propose approach determine the ethnic breakdown population based solely people names and data provided the Census Bureau demonstrate that our approach able predict the ethnicities individuals well the ethnicity entire population better than natural alternatives apply our technique the population Facebook users and uncover the demographic characteristics ethnicities and how they relate also discover that while Facebook has always been diverse diversity has increased over time leading population that today looks very similar the overall population also find that different ethnic groups relate one another assortative manner and that these groups have different profiles across demographics beliefs and usage site features 
12830 en The Social Dynamics Economic Activity Virtual World This paper examines social structures underlying economic activity Second Life massively multiplayer virtual world that allows users create and trade virtual objects and commodities find that users conduct many their transactions both within their social networks and within groups Using frequency chat proxy tie strength observe that free items are more likely exchanged the strength the tie increases Social ties particularly play significant role paid transactions for sellers with moderately sized customer base further find that sellers enjoying repeat business are likely selling niche markets because their customers tend contained smaller number groups But while social structure and interaction can help explain seller revenues and repeat business they provide little information the forecasting seller future performance Our quantitative analysis complemented novel method visualizing the transaction activity seller including revenue customer base growth and repeat business 
12831 en Your Brain Facebook Neuropsychological Associations with Social Versus other Media measured individuals’ mental associations between four types media books television social Facebook and general informational web pages and relevant concepts Addictive Story Interesting Frivolous Personal and Useful using three different measurements Likert scale questionnaire speeded Yes judgment task and electrical brain activity The three measures were designed capture associations different levels mental processing from very automatic electrical brain activity conscious and reasoned questionnaire more conscious levels cognitive processing Facebook was seen interesting addictive and highly personal Results for the electrical brain activity measure show that Facebook tells less story and surprisingly less personal than other forms media discuss differences results across the three measures and how our findings can inform the design future social media systems 
12832 en Towards Social Causality Analysis Interpersonal Relations Online Blogs and Forums this paper present encouraging preliminary results into the problem social causality causal reasoning used intelligent agents social environment online social interactions based model reciprocity every level social relationships are guided the shared understanding that most actions call for appropriate reactions and that inappropriate reactions require management Thus present analysis interpersonal relationships English reciprocal contexts Specifically rely here large and recently built database 882 reciprocal relation instances online media The resource analyzed along set novel and important dimensions symmetry affective value gender and intentionality action which are highly interconnected larger level automatically generate chains causal relations between verbs indicating interpersonal relationships Statistics along these dimensions give insights into people behavior judgments and thus their social interactions 
12833 en How Does the Data Sampling Strategy Impact the Discovery Information Diffusion Social Media Platforms such Twitter have provided researchers with ample opportunities analytically study social phenomena There are however significant computational challenges due the enormous rate production new information researchers are therefore often forced analyze judiciously selected “sample” the data Like other social media phenomena information diffusion social process– affected user context and topic addition the graph topology This paper studies the impact different attribute and topology based sampling strategies the discovery important social media phenomena–information diffusion nnWe examine several widely adopted sampling methods that select nodes based attribute random location and activity and topology forest fire well study the impact attribute based seed selection topology based sampling Then develop series metrics for evaluating the quality the sample based user activity volume number seeds topological reach spread and temporal characteristics rate additionally correlate the diffusion volume metric with two external variables–search and news trends Our experiments reveal that for small sample sizes sample that incorporates both topology and user context location activity can improve naive methods significant margin 
12834 en Photo Tagging Over Time Longitudinal Study the Role Attention Network Density and Motivations Along with the growth artifact sharing online communities such Flickr YouTube and Facebook comes the demand for adding descriptive meta information tags Tags help individuals organize and communicate the content and context their work for themselves and for others This longitudinal study draws research social psychology network theory and online communities explain tagging over time Our findings suggest that tagging increases contributor receives attention from others the community Further find that the more user network neighbors are connected each other directly the less the focal user will tend tag his photos However density interacts with attention such that those who are surrounded dense ego network respond more attention than others whose ego networks are sparsely interconnected Unexpectedly find direct correlation between tagging and the individual motivations enjoyment and commitment While commitment not directly associated with tagging there interaction effect such that the effect commitment tagging positive for users with low density ego networks and negative when user surrounded high density network Directions for future research well implications for theory and practice are discussed 
12835 en Microblogging Inside and Outside the Workplace Microblogging has recently generated lot research interest Yet very little known about how corporate employees use microblogging tools This study examined microblogging the workplace conducting content analysis comparing posts from individuals who were using internal proprietary tool and Twitter simultaneously both settings posts that provided information were directed others were more common than posts status Within these categories was more frequent provide information externally than internally but more common ask questions either through broadcast directed posts internally than externally Qualitative interviews explored users’ motivations regarding microblogging behavior The paper concludes with discussion the implications microblogging for business use 
12836 en Measuring User Influence Twitter The Million Follower Fallacy Directed links social media could represent anything from intimate friendships common interests even passion for breaking news celebrity gossip Such directed links determine the flow information and hence indicate user influence others — concept that crucial sociology and viral marketing this paper using large amount data collected from Twitter present depth comparison three measures influence indegree retweets and mentions Based these measures investigate the dynamics user influence across topics and time make several interesting observations First popular users who have high indegree are not necessarily influential terms spawning retweets mentions Second most influential users can hold significant influence over variety topics Third influence not gained spontaneously accidentally but through concerted effort such limiting tweets single topic believe that these findings provide new insights for viral marketing and suggest that topological measures such indegree alone reveals very little about the influence user 
12837 en The Directed Closure Process Information Networks with Analysis Link Formation Twitter has often been taken working assumption that directed links information networks are frequently formed short cutting two step path between the source and the destination — kind implicit link copying analogous the process triadic closure social networks Despite the role this assumption theoretical models such preferential attachment has received very little direct empirical investigation Here develop formalization and methodology for studying this type directed closure process and provide evidence for its important role the formation links Twitter then analyze sequence models designed capture the structural phenomena related directed closure that observe the Twitter data 
12838 en Characterizing Microblogs with Topic Models microblogging grows popularity services like Twitter are coming support information gathering needs above and beyond their traditional roles social networks But most users’ interaction with Twitter still primarily focused their social graphs forcing the often inappropriate conflation “people follow” with “stuff want read ” characterize some information needs that the current Twitter interface fails support and argue for better representations content for solving these challenges present scalable implementation partially supervised learning model Labeled LDA that maps the content the Twitter feed into dimensions These dimensions correspond roughly substance style status and social characteristics posts characterize users and tweets using this model and present results two information consumption oriented tasks 
12839 en Predicting Elections with Twitter What 140 Characters Reveal about Political Sentiment Twitter microblogging website where users read and write millions short messages variety topics every day This study uses the context the German federal election investigate whether Twitter used forum for political deliberation and whether online messages Twitter validly mirror offline political sentiment Using LIWC text analysis software conducted content analysis over 100 000 messages containing reference either political party politician Our results show that Twitter indeed used extensively for political deliberation find that the mere number messages mentioning party reflects the election result Moreover joint mentions two parties are line with real world political ties and coalitions analysis the tweets’ political sentiment demonstrates close correspondence the parties and politicians’ political positions indicating that the content Twitter messages plausibly reflects the offline political landscape discuss the use microblogging message content valid indicator political sentiment and derive suggestions for further research 
12840 en From Tweets Polls Linking Text Sentiment Public Opinion Time Series connect measures public opinion measured from polls with sentiment measured from text analyze several surveys consumer conﬁdence and political opinion over the 2008 2009 period and ﬁnd they correlate sentiment word frequencies contemporaneous Twitter messages While our results vary across datasets several cases the correlations are high and capture important large scale trends The results highlight the potential text streams substitute and supplement for traditional polling consumer conﬁdence and political opinion and can also pre dict future movements the polls ﬁnd that temporal smoothing critically important issue support successful model 
12841 en Information Contagion Empirical Study the Spread News Digg and Twitter Social Networks Social networks have emerged critical factor information dissemination search marketing expertise and influence discovery and potentially important tool for mobilizing people Social media has made social networks ubiquitous and also given researchers access massive quantities data for empirical analysis These data sets offer rich source evidence for studying dynamics individual and group behavior the structure networks and global patterns the flow information them However most previous studies the structure the underlying networks was not directly visible but had inferred from the flow information from one individual another result not yet understand dynamics information spread networks how the structure the network affects address this gap analyzing data from two popular social news sites Specifically extract social networks active users Digg and Twitter and track how interest news stories spreads among them show that social networks play crucial role the spread information these sites and that network structure affects dynamics information flow 
12842 en Tweeting from the Town Square Measuring Geographic Local Networks This paper examines tweets about two geographically local events shooting and building collapse that took place Wichita Kansas and Atlanta Georgia respectively Most Internet research has focused examining ways the Internet can connect people across long distances yet there are benefits being connected others who are nearby People close geographic proximity can provide real time information and eyewitness updates for one another about events local interest first show relationship between structural properties the Twitter network and geographic properties the physical world then describe the role mainstream news disseminating local information Last present poll 164 users’ information seeking practices conclude with practical and theoretical implications for sharing information local communities 
12843 en StepGreen org Increasing Energy Saving Behaviors via Social Networks Decades research have explored factors that can influence green behavior However much less known about how technology general and social technologies particular can motivate people participate green activities this paper describe the goals design and evaluation StepGreen org site intended promote energy saving behaviors present the results field study during which participants chose engage different actions and reported when they had completed them Our results suggest that motivating factors like public commitment and competition are effective and better leveraging these factors will likely lead even greater appeal and effectiveness Our contribution create understanding the impact different decisions the success StepGreen org that can benefit the designers other multifaceted online systems for behavior change 
12844 en Governance Social Media Case Study the Wikipedia Promotion Process Social media sites are often guided core group committed users engaged various forms governance crucial aspect this type governance deliberation which such group reaches decisions issues importance the site Despite its crucial — though subtle — role how number prominent social media sites function there has been relatively little investigation the deliberative aspects social media governance Here explore this issue investigating particular deliberative process that extensive public and recorded the promotion Wikipedia admins which determined elections that engage committed members the Wikipedia community find that the group decision making the heart this process exhibits several fundamental forms relative assessment First observe that the chance that voter will support candidate strongly dependent the relationship between characteristics the voter and the candidate Second investigate how both individual voter decisions and overall election outcomes can based models that take into account the sequential public nature the voting 
12846 en Responses Remixing Social Media Sharing Website this paper describe the ways participants the Scratch online community primarily young people engage remixing each others shared animations games and interactive projects particular try answer the following questions How users respond remixing social media environment where remixing explicitly permitted What qualities originators and their projects correspond higher likelihood plagiarism accusations there connection between plagiarism complaints and similarities between remix and the work based Our findings indicate that users have very wide range reactions remixing and that many users react positively accuse remixers plagiarism test several hypotheses that might explain the high number plagiarism accusations related original project complexity cumulative remixing originators integration into remixing practice and remixee remixer project similarity and find support for the first and last explanations 
12847 en ICWSM — Great Catchy Name Semi Supervised Recognition Sarcastic Sentences Online Product Reviews Sarcasm sophisticated form speech act widely used online communities Automatic recognition sarcasm however novel task Sarcasm recognition could contribute the performance review summarization and ranking systems This paper presents SASI novel Semi supervised Algorithm for Sarcasm Identification that recognizes sarcastic sentences product reviews SASI has two stages semi supervised pattern acquisition and sarcasm classification experimented data set about 66000 Amazon reviews for various books and products Using gold standard which each sentence was tagged annotators obtained precision and recall for identifying sarcastic sentences found some strong features that characterize sarcastic utterances However combination more subtle pattern based features proved more promising identifying the various facets sarcasm also speculate the motivation for using sarcasm online communities and social networks 
12849 en Star Quality Aggregating Reviews Rank Products and Merchants Given set reviews products merchants from wide range authors and several reviews websites how can measure the true quality the product merchant How remove the bias individual authors sources How compare reviews obtained from different websites where ratings may different scales stars etc How filter out unreliable reviews use only the ones with star quality Taking into account these considerations analyze data sets from variety different reviews sites the first paper our knowledge this These data sets include million product reviews and million merchant reviews explore statistic and heuristic based models for estimating the true quality product merchant and compare the performance these estimators the task ranking pairs objects also apply the same models the task using Netflix ratings data rank pairs movies and discover that the performance the different models surprisingly similar this data set 
12851 en Inverse Problem Solutions Heat Transfer Applications Development New Manufacturing Technologies for Ceramics and Glass and Studies Advanced Materials Thermophysical Properties The radiative and conductive heat transfer RCHT dominates lot modern machines and manufacturing technologies Bauman MSTU since the end 1970’ there have been worked out methods algorithms and software package “CAR” Conduction and Radiation for solving direct problems and inverse problems RCHT composite materials and constructions Numerical methods solving extreme statements numerical optimization residual functionals and iterative regularization methods form the theoretical base the package “CAR” approaches The package “CAR” was used for researches project reusable launch vehicles “Buran” “Hopper” large space frame “SOFORA” large deployable space antenna NPO EGS For today the software package “CAR” the base for the current studies advanced materials for aerospace applications and development new manufacturing technologies nIn the lecture two branches RCHT application are presented The first branch connected with studies advanced materials thermophysical properties The statements are formulated coefficient Short description experimental technique and some features combined heat transfer porous semitransparent material are given The second branch connected with designing new manufacturing technologies for ceramics and glass The statements are formulated boundary and assume the determination time variation incident heat flux the glass surface Mathematical modelling have been performed the frame development three heat treatment technologies infrared annealing thermal polishing and sintering glassceramic 
12934 en Haitian Creole Developing for Low Data Language
12935 en Translation Technology for Fighting World Poverty
12936 en Recent Progresses and Language Information Processing CCLIE BIT
12937 en TAUS Data Association News and Roadmap
12938 en META NET Towards the Multilingual Europe Technology Alliance
12939 en Evaluation Localization and Open Source Tools EuroMatrixPlus
12941 en Community Translation what when use how manage 
12942 en Welocalize Open Source efforts and integration
12943 en LetsMT – Towards Cloud Based Service for Generation
12948 en Asia Online Technology Platform Overview Vision
12949 en Free Open Source Machine Translation The Apertium Platform
12950 en Flexible and efficient management translation quality
12951 en The Evolution the European Machine Translation Programme the EPO
12952 en New Developments the European Commission
12953 en 2010 The Industrialisation 
12954 en Language Change and Linguistic Diversity – Future Challenges for 
12996 en Obama Imperialist Policies Following New York Peace Action Benefit viewing Karen Malpede new play Prophesy Noam Chomsky criticizes Obama rightwing policies war making medical care coziness with commercial interests warns the coming war Kandahar and Israel possible attack Iran that could nuclear the moderated Karen Chomsky comments Gulf Oil disaster the likely next financial crisis the Free Gaza Flotilla incident urges Guantanamo being returned Cuba and tortured detainees either being tried released 
12997 en Interview with Noam Chomsky Question nDo you currently see elephant room cognitive science just like you named one years ago— guess that reference critique radical behaviorism—something that needs addressing that gets too little attention nnQuestion nWhat are some your criticisms today anarchist movement How effective possible something many anarchists overlook and you perhaps the most prolific voice this topic your thoughts would very influential nnnQuestion nAs far favor stateless society the long run would mistake work for the elimination— said that would mistake work for the elimination the state the short run and should trying strengthen the state cause needed the check power large corporations Yet the tendency lot anarchist research— own too— show that the power large corporations derives from state privilege and governments tend get captured concentrated private interests That would seem imply that the likely beneficiaries more powerful state going the same corporate elite trying oppose business both derives from the state and good capturing the state why isn abolishing the state better strategy for defeating business power than enhancing the state power would nnQuestion guess the question that comes mind that just grows out these comments there very large number people who are committed sincerely and rightly the kind long term objectives that anarchists have always tried uphold And the question why can get together and decide —and instead you know condemning one another for not doing things exactly the way why can try formulate concrete proposals which combine two properties 
13232 en Liquid crystal nematic configurations thin films shall concerned with the influence surface geometry orientational ordering liquid crystal thin films will focus universal mechanisms such merging and splitting topological defects reshaping defect cores positioning defects and defect induced global system transformations All phenomena are analyzed the frame Landau Gennes theory terms tensorial order parameter For the cases studied discuss future research trends and possible applications first consider possible defect structures and merging defects thin nematic shells various geometries using approach which has been recently developed the Pavia group well known that the equilibrium texture spherical film exhibits four defects winding number sitting the vertices regular tetrahedron maximize their mutual distance varying the film geometry the position the defects and their structure could altered Among others things show that for sufficiently prolate ellipsoidal shells the four defects merge pairwise the poles leaving only two defects next consider external field induced transformations defect cores positioning defects and defect induced suppressed surface transitions For this purpose consider hybrid cylindrical cell where topologically stabilize boojum the center the upper confining plate external electric field applied the boojum could either stretched towards the cell interior expelled from the cell depending the sign the field anisotropy constant The stretching the boojum also accompanied substantial widening the defect core Depending conditions the presence the boojum could either substantially increase depress external field driven surface biaxial transition nFinally consider temperature driven surface wetting and dewetting transitions thin film show that for appropriate conditions the temperature difference between the surface and bulk phase transition could anomalously increased with respect already reported related phenomena 
13233 en Nearly Isostatic Periodic Lattices 1864 James Clerk Maxwell showed that system point particles dimensions mechanically stable only the number two point contacts between particles exceeds Systems with are isostatic Recent work confirms that randomly packed spheres are isostatic the point where the volume fraction phi reaches the critical value phi necessary support shear and that the mechanics this isostatic state determine behavior volume fractions above phi Infinite square and kagome lattices with nearest neighbor springs are isostatic but their finite counterparts have floppy modes zero frequency This talk will discuss the mechanical properties and phonon spectrum nearly isostatic versions these lattices which next nearest neighbor springs with variable spring constant are added either homogeneously randomly particular will show that these lattices exhibit characteristic lengths that diverge and frequencies that vanish agreement with general arguments the Chicago group The shear elastic modulus depends the geometry the isostatic network and not universal Response near the random case highly nonaffine This talk will also discuss isostatic variant the kagome lattice that has vanishing bulk modulus and negative Poisson ratio and whose floppy isostatic modes are not found the phonon spectrum with periodic boundary conditions Finally time permits the application some these ideas networks semi flexible polymers will discussed 
13234 en Optically and electrically controlled topological defect architectures confined chiral liquid crystals Liquid crystal defects have recently attracted great deal interest due their ability pre defining the symmetry colloidal interactions nematics and enabling the existence distinct thermodynamic phases such the twist grain boundary and blue phases confined nematic and cholesteric fluids defects appear result temperature quenching symmetry breaking phase transitions mechanical stresses etc These defects commonly annihilate minimize the free energy and are hard controlled utilized for applications reliable way This lecture will discuss the facile optical creation and multistable optical and electrical switching localized defect configurations confined chiral nematic LCs use focused Laguerre Gaussian vortex laser beams with different optical phase singularities generate topological defect architectures containing both point and line singularities bound each other the director twist and forming stable metastable configurations While being generated the defect architectures are probed multimodal labeling free nonlinear optical imaging that incorporates simultaneous study with three photon and two photon excitation self fluorescence microscopy second harmonic generation microscopy and broadband coherent anti Stokes Raman scattering polarizing microscopy addition the conventional fluorescence confocal polarizing microscopy chiral nematic LCs confined into homeotropic cells the laser generated topological defects embed the localized twist into the uniform background confinement untwisted director field forming localized chiro elastic particle like excitations dubbed “torons” that interact with each other via short range repulsive elasticity mediated interactions the field controlled cells with the plane director field one observes formation dipolar structures twist bound defects composed the torons and umbilics Similar the elastic dipoles formed colloidal particles accompanied hyperbolic point defects the toron umbilical pairs interact with each other via long range elastic interactions and form dipolar chains high densities the toron umbilical pairs these chains self organize into super lattices with toron umbilical pairs bound into antiferroelectric like two dimensional crystals dipolar colloidal chains demonstrate that the periodic lattices twist bound defects can used optically and electrically controlled diffraction gratings for optical data storage well the design all optical information displays This work was supported the Renewable and Sustainable Energy Initiative and Innovation Initiative Seed Grant Programs University Colorado International Institute for Complex Adaptive Matter and the NSF grants DMR0645461 DMR0820579 and DMR0847782 
13235 en The physics liquid crystals under confinement Porous media networks and the future Studies physical systems solid porous hosts date back several decades for example studies the helium superfluid transition jewelers rouge Research the superfluid properties porous media kept center stage until the nineties where they had share their supremacy with confined liquid crystal studies those working liquid crystals would like believe that Point case from applied perspective liquid crystal display arguably one the better known confined physical systems Their operation strongly depends the interaction between the liquid crystal molecules and the host solid surfaces From fundamental point view liquid crystals imbedded solid porous materials with dispersed nanoparticles are incredibly rich systems that allow the study variety physical phenomena including probing effects different order phase transitions These phenomena include dramatic changes phase transitions and particular size dependent critical exponents surface induced liquid crystal alignment bilayer bilayer smectic growth complete quasi complete and partial wetting and molecular configurational transitions among others should mentioned that much the above experimental work heavily relied the theoretical contributions Zumer and his workers Specifically some these effects were born out NMR and calorimetry studies with cyanobiphenyl liquid crystals embedded the well defined cylindrical cavities aluminum oxide Anopore polycarbonate Nucleopore membranes the randomly interconnected networks pores like Vycor and Aerogel glasses the Millipore filter cellulose voids dispersing spherical silica nanometer particles Aerosil the liquid crystal and course the original liquid crystals polymer networks After reviewing some the aforementioned studies will touch upon where future studies might These may range from confining networks formed from metallic nanoparticles nanowires photovoltaics drug delivery understanding trans cis photo isomerization transition porous media These studies would not have been possible without the many contributions Zalar and Zumer the University Ljubljana Slovenia and Iannacchione Jin Qian Zeng and Crawford Kent State University 
13236 en Recent advances nematic order reconstruction Investigations cell sandwich cell with the director rotating 180° are demonstrating the possibility obtain nematic transitions between two textures with different topologies for instance between untwisted state and twisted one Fast topological changes can observed means suitable electric fields micro nano confinement the nematic bulk close boundary surface strong frustration fact the case strong local distortion can induce transient and local biaxial states inside nematic calamitic phase and the resultant nematic dynamics demands full Landau Gennes tensor description this work present tensor numerical models capable describe the nematic order dynamics full details comparing theoretical results with experiments will also discuss nematic order reconstruction close boundary surface with strong infinite anchoring conditions can provide transitions equivalent anchoring breaking 
13237 en The power Poincare Elucidating the hidden symmetries focal conic domains Focal conic domains are typically the smoking gun which smectic liquid crystalline phases are identified The geometry the equally spaced smectic layers highly generic but the same time difficult work with this talk develop approach the study focal sets smectics which exploits hidden Poincare symmetry revealed only viewing the smectic layers projections from one higher dimension use this perspective shed light upon several classic focal conic textures including the concentric cyclides Dupin polygonal textures and tilt grain boundaries 
13238 en NMR Demixing and Phase Separation Liquid Crystals Demixing well known phenomenon present multi component liquids and polymer blends conventionally modeled the Flory Huggins free energy approach liquid crystals can result wide coexistence range nematic and isotropic phases Determination the respective temperature concentration phase diagram often rather tedious task due many varying parameters the relative volumes the phases the nematic order parameters the individual mesogens the nematic phase well the concentrations components the nematic and isotropic phases demonstrate that deuteron NMR particularly useful experimental tool for the study molecular segregation nematics providing for simultaneous measurement all the above parameters both bulk and confined systems liquid crystalline microemulsions doped liquid single crystal elastomers and photoisomerizable nematics 
13239 en Confinement effects two dimensions freely suspended liquid crystal films are studying the interactions and dynamics islands textures and topological defects onnfreely suspended smectic liquid crystal films Freely suspended smectic films are quantizednin thickness units single smectic layers and Islands studied here are thicker stacks ofnlayers thinner background film will report the following Diffusion islands smectic films revealing the distinct effects hydrodynamicndrag from liquid crystal flow and from airflow Interactions islands smectic films exploring the effects chirality thencollective behavior islands and their companion topological defects Dynamic behavior buckminsterfullerene nanospheres freely suspended films Effects polarization textures and defects two dimensions where dramaticntransformation textures found accompany the increase polarization changenwhich can produced increase the enentiomeric excess the Thenimages below show example where the textures are smooth with largenorientation fluctuations the 100 textures exhibit sharp discontinuities 
13245 en Carbon nanotube based liquid crystals Carbon nanotubes are promising anisotropic particles for variety applications such strong and lightweight composites sensors electronic devices conductive inks substrates for tissue engineering etc The dispersion behavior and spatial ordering carbon nanotubes are critical optimize the properties nanotube based materials Various approaches are currently explored achieve diverse structures such macroscopic alignment percolated isotropic networks solid liquid crystalline states present this talk the phase behavior nanotube suspensions stabilized surfactants amphiphilic polymers Those systems can form nematic liquid crystals Nevertheless achieving large values the order parameter well large mono domains remains challenging will discuss particular the effect processing conditions nanotube based liquid crystals Another approach for aligning carbon nanotubes consists dispersing the particles liquid crystalline medium Carbon nanotubes because their small dimensions don’ create distortions the liquid crystal host “weak anchoring” regime But they still align response the surface energy anisotropy will show some examples such materials made nanotubes embedded liquid crystals Routes for further improvements and future applications will discussed 
13246 en Monte Carlo Simulations Platelets Colloidal suspensions platelets are known experimentally show variety phenomena reflecting the interplay their Oseen Frank elastic constants and surface tension effects have previously determined the Frank elastic constants thin hard platelets Monte Carlo simulation and have recently extended this work non zero thickness both cases comparing with theoretical predictions expected the bend elastic constant least order magnitude smaller than the other two the results are reasonable agreement with experiment have also examined the phases thin hard platelets confined between hard flat walls observing surface induced ordering and capillary condensation the nematic phase 
13247 en Effect strong confinement defect structures cholesteric blue phases Cholesteric blue phases BPs found highly chiral liquid crystals are interesting examples three dimensional ordered structures soft materials They appear result frustrations between local preference double twist configuration over single twist and global topological constraint that double twist configuration cannot fill the whole space Though the structures bulk BPs with cubic symmetry are now well established not yet understood how the anchoring confining surfaces affects the order structures BPs Here discuss the structures topological defects strongly confined chiral liquid crystal nOur study based numerical calculations using Landau– Gennes theory which the orientational order described second rank tensor Defect structures planar cell imposing homeotropic anchoring the surfaces not resemble those bulk BPs and can indeed thermodynamically stable when the cell thickness the order the dimension the unit cell bulk BPs These novel defect structures can regarded consequence different frustration between the local preferred structure regular array disclinations and the constraint imposed the anchoring confining surfaces Our results indicate that there are still possibilities for unknown ordered structures liquid crystals arising from more complex frustrations nWe acknowledge financial support Slovenian Research Agency ARRS research program 0099 and project 2335 and KAKENHI Grant Aid for Scientific Research Priority Area “Soft Matter Physics” from the Ministry Education Culture Sports Science and Technology Japan 
13248 en Nematic Fluctuations Probe the Properties Liquid Crystal Elastomers recent experiments have shown that the director fluctuations nematic liquid crystal elastomers LCE measured dynamic light scattering are sensitive probe the properties LCE under strain particular with respect the semisoft behavior Semisoft elastic response originates symmetry breaking internal strain that was built into the material result the procedure obtain monodomain sample This strain coupled the nematic director locking into the orientation direction makes the relaxation rate the director finite and essentially independent the wave vector applied external strain perpendicular the orientation direction critical value corresponding the onset the semisoft plateau effectively cancels the anisotropy field acting the director that the relaxation rate zero wave vector goes zero reflecting the fact that ideal LCE the nematic director fluctuations are the Goldstone mode the system Our dynamic light scattering measurements the relaxation rate the nematic fluctuations function strain temperature are complete accordance with the theory semisoft elasticity Warner and Terentjev and combined with mechanical measurements allow determine all the parameters the theory nPhotosensitive LCE doped with azobenzene derivatives undergoing trans cis isomerization are particular interest Our experiments pure LCE have shown that the semisoftness parameter that measures the internal strain proportional the nematic order parameter photosensitive LCE under illumination the semisoftness parameter cannot determined from the stress strain curves due strong inhomogeneity the cis isomer concentration exploited the fact that the director fluctuations are coupled the anisotropy field and measured the change the nematic order parameter function illumination measuring the relaxation rate the director fluctuations with dynamic light scattering have also written holographic diffraction grating photosensitive LCE and determined the depth the layer that underwent cis trans isomerization measuring the angular width the diffraction peak around the Bragg angle 
13249 en Liquid crystal colloids functionalization inclusions and continuum Liquid crystal colloids combine orientational anisotropy liquid crystalline continuum phase and discrete ordering dispersed colloidal inclusions The long ranged orientational ordering liquid crystals generates structural forces between the inclusions which allows for assembly colloidal composites used advanced optical elements Fully the applicability and means for optimisation optical structures liquid crystal colloids revealed the variety possibilities for functionalizing the materials both inclusions and the continuum phase nHere present routes for functionalization colloidal particles and continuum liquid crystal For particles the role shape surface structure and Janus and higher Janus surface anchoring profile shown For bulk medium the role chirality and material activity demonstrated Novel flow profiles are shown active liquid crystal cells Combining confinement colloidal particles and active material flow microfluidic elements could assembled 
13250 en Nematic Colloid topological playground Particles dispersed nematic yield complex defect structures Beside structures where defects are localized close particles also structures where disclination lines entangle two more particles are found Here focus dimmers and show that simple geometrical description based local differences can used classify configurations and describe restructurings among possible forms The linking number disclination loop which tells how the director field defect line twists when following disclination help distinguish between topologically different classes Simple ring defects have zero linking number while entangled states exhibit fractional linking numbers 
4622 en Lecture The Origins the Space Shuttle
4623 en Lecture Space Shuttle History
4624 en Lecture Orbiter Sub System Design
4625 en Lecture The Decision Build the Shuttle
4626 en Lecture Orbiter Structure Thermal Protection System
4627 en Lecture Propulsion Space Shuttle Main Engines
4628 en Lecture Aerodynamics From Sub Hypersonic and Back 
4629 en Lecture Landing and Mechanical Systems
4630 en Lecture OMS RCS Fuel Cells Auxiliary Power Unit and Hydraulic Systems
4631 en Lecture The DoD and the Space Shuttle
4632 en Lecture Use Subsystems Function Flight Phase
4634 en Lecture Environmental Control Systems
4635 en Lecture Ground Operations Launching the Shuttle
4636 en Lecture Space Shuttle Accidents
4637 en Lecture Guidance Navigation and Control
4638 en Lecture Mission Control 
4639 en Lecture Mission Control 
4640 en Lecture Design Process Relates the Shuttle
4641 en Lecture EVA and Robotics the Shuttle
4642 en Lecture Systems Engineering for Space Shuttle Payloads
4643 en Lecture Test Flying the Space Shuttle
5022 en Welcome and introduction DEBATE
5023 en Welcome and introduction DEBATE
5027 en Research position women science
5034 en Experience women politics socialism and transition period
7160 en Lecture Introduction Sampling Theorem and Orthonormal PAM QAM Capacity AWGN Channels
7161 en Lecture Performance Small Signal Constellations
7162 en Lecture and Hard decision and Soft decision Decoding
7163 en Lecture and Introduction Binary Block Codes
7164 en Lecture and Introduction Finite Fields
7165 en Lecture and Reed Solomon Codes
7166 en Lecture and Introduction Convolutional Codes
7167 en Lecture and Trellis Representations Binary Linear Block Codes
7168 en Lecture and Codes Graphs
7169 en Lecture The Sum Product Algorithm
7170 en Lecture and Turbo LDPC and Codes
7171 en Lecture and Lattice and Trellis Codes
7172 en Lecture Introduction Basics Legal Research Legal Citations
7173 en Lecture LexisNexis® 1976 Copyright Act Here LexisNexis® handout you may find helpful PDF nnPlease read these cases discuss class http caselaw findlaw com scripts getcase court vol 499 invol 340 Feist Publications Inc Rural Telephone Service 499 340 1991 http ocw mit edu rdonlyres Electrical Engineering and Computer Science 912January IAP 2006 A7D69482 B8C0 4A1D 952E A58ADAC98216 feist pdf PDF http caselaw findlaw com scripts getcase court vol 000 invol U10426 Campbell Acuff Rose Music Inc 510 569 1994 http ocw mit edu rdonlyres Electrical Engineering and Computer Science 912January IAP 2006 1B8A67E3 1DC4 4E7C 8B56 E8C48E4056B3 campbell pdf PDF Command Video Corp Columbia Pictures Industries 777 Supp 787 Cal 1991 PDF http caselaw findlaw com scripts getcase court vol 464 invol 417 ony Corp America Universal City Studios Inc 464 417 1984 http ocw mit edu rdonlyres Electrical Engineering and Computer Science 912January IAP 2006 E631BDFB DF7D 4DA7 B6A7 1861AEF62A60 sony pdf PDF Remember just type the middle part the citation 499 340 into the Get Case citation field Lexis Nexis call the opinion 
7174 en Lecture Copyright applied Music Computers Napster® Peer Peer File Sharing LexisNexis® Legal Research then Federal Code and finally Guided Search That will take you this form nnSearch for uscs Cite This will pull the entire http www copyright gov title17 Copyright Act Alternately you can use the http www copyright gov Copyright Office file http ocw mit edu rdonlyres Electrical Engineering and Computer Science 912January IAP 2006 AEADEBD6 84C3 4568 8131 467C351748A1 copyright law pdf PDF nnRead the following sections the statute the section seems and just read the first few subsections You may find helpful look back the definitions section 101 106 Core Rights 106A Limited Moral Rights 107 Fair Use 109 First Sale 110 Exempt Performances 115 Only Read Subsections and Musical Covers 117 Computer Programs 302 Duration Copyright 401 Copyright Notice 411 Registration 504 Damages for Infringement 506 Criminal Violations including LaMacchia Law 
7175 en Lecture Software Licensing DVDs and Encryption Read http www4 law cornell edu uscode html uscode17 usc sec 00000512 000 html § 512 Remember Use uscs sec 512 nnRead http www law cornell edu copyright cases 180 F3d 1072 htm Recording Industry Ass America Diamond Multimedia Systems Inc 180 1072 9th Cir 1999 nnRead http caselaw findlaw com scripts getcase navby case court 2nd 9185 Universal City Studios Inc Corley 273 429 Cir 2001 http ocw mit edu rdonlyres Electrical Engineering and Computer Science 912January IAP 2006 10BD93D5 3B98 47E4 B1CB 20658542E0DC corley pdf PDF nnRead http caselaw findlaw com scripts getcase navby case court fed 1118 Chamberlain Group Inc Skylink Technologies Inc 381 1178 Fed Cir 2004 http ocw mit edu rdonlyres Electrical Engineering and Computer Science 912January IAP 2006 8732161B AF8C 44F2 B86D 8D32087A244C chamberlain pdf PDF nnRead Jonathan Zittrain essay The Copyright Cage http www legalaffairs org issues July August 2003 feature zittrain julaug03 msp legalaffairs magazine 
7304 en Lecture Derivatives slope velocity rate change
7305 en Lecture Limits continuity Trigonometric limits
7306 en Lecture Derivatives products quotients sine cosine
7307 en Lecture Chain rule Higher derivatives
7308 en Lecture Implicit differentiation inverses
7309 en Lecture Exponential and log Logarithmic differentiation hyperbolic functions
7310 en Lecture Hyperbolic functions cont and exam review
7327 en Lecture Determinants cross product
7328 en Lecture Matrices inverse matrices
7329 en Lecture Square systems equations planes
7330 en Lecture Parametric equations for lines and curves
7331 en Lecture Velocity acceleration Kepler second law
7500 en Lecture Level curves partial derivatives tangent plane approximation
7501 en Lecture Max min problems least squares
7503 en Lecture Second derivative test boundaries and infinity
7504 en Lecture Differentials chain rule
7505 en Lecture Gradient directional derivative tangent plane
7507 en Lecture Non independent variables
7508 en Lecture Partial differential equations review
7510 en Lecture Double integrals polar coordinates applications
7511 en Lecture Change variables
7512 en Lecture Vector fields and line integrals the plane
7513 en Lecture Path independence and conservative fields
7514 en Lecture Gradient fields and potential functions
7515 en Lecture Green theorem
7516 en Lecture Flux normal form Green theorem
7517 en Lecture Simply connected regions review
7518 en Lecture Triple integrals rectangular and cylindrical coordinates
7519 en Lecture Spherical coordinates surface area
7520 en Lecture Vector fields surface integrals and flux
7522 en Lecture Divergence theorem cont applications and proof
7523 en Lecture Line integrals space curl exactness and potentials
7524 en Lecture Stokes theorem
7525 en Lecture Stokes theorem cont review
7526 en Lecture Topological considerations Maxwell equations
7528 en Lecture Final review cont 
7722 en Photography African American cultural landscapes
7723 en Secret games collaborations with children
7724 en Photography and its role rebuilding New Orleans
7728 en  see the root idea
7746 en Session Heros Tolkien Lewis Beowolf 
7747 en Session Analyzing historical data making sense evidence Why history all 
7762 en Session Introduction the class and the aesthetics film explanation syllabus Discussion The Lady Eve 1941 film Sturges contemporary Orson Welles Film will shown this week class scholar Marian Keane commentary important example woman perspective the film will shown next week Looking movies art form and skill that requires training Prof Singer brings this course the perspective philosopher which not the case all film courses Singer philosophy teaching willing make himself available and put himself forward artist does teaching form self expression like art philosophy film and other media versus the philosophy film The idea that film respectable art with philosophical content not just entertainment fairly new within the academy within the last years How can films philosophical Singer book Reality Transformed addresses this looking the concepts formalism and realism together Formalists can characterized their use the camera techniques cinematography structural issues Hitchcock who was master technique Realists described French theorist Andre Bazin see the importance film part the human desire capture reality Singer argues that films can appreciated unless you savor what they mean without technique there meaning and without meaning technique has human importance Only when you see formalism and realism constant dialectic and interaction can you appreciate what film capable the role myths and mythmaking film How stories reach people Discussion various myths love and how they have been dealt with film Continuing overview syllabus and films screened throughout semester Review course expectations and requirements 
7763 en Session Review previous session How does one apply philosophical analysis any sort work art such movie What the meaning the tree knowledge the garden Eden How this philosophically important There overlap between science technology and art Mathematics can thought theoretical art Fundamental question Reality Transformed Formalists Realistsn Three Philosophical Filmmakers all filmmakers are both formalists and realists their own ways Are films the modern medium choice for myth making and disseminating philosophy Hitchcock emphasizes reality effect emphasis formalism but striving bring out realism Similar realism portrayed The Green Mile Assigning biblical characters The Lady Eve Which characters are Adam and Eve Who the snake The myth the whore virgin can the two harmonized The Lady Eve Jean journeys from one the other throughout the movie 
7764 en Session Edward Song comments the week reading and movie David Levinson comments the week reading and movie Film can focus attention different aspects the performance with more specificity than live performance This borne out the commentary for The Lady Eve Discussion camera work described Three Philosophical Filmmakers compared the camera work The Lady Eve Where how the character Charles The Lady Eve likely find love What the nature love between human beings Between humans and pets How this reflected the cinematic voice the filmmaker Discussion the quality the cinematography Amélie and the ideals romantic love Chekhov short story Did the character Eve The Lady Eve sell out the end the movie 
7765 en Session Discussion Miguel paper topics Rebel Without Cause and how teenagers deal with death Discussion Edward paper topics the ideological contrast presented the knight and his squire The Seventh Seal Discussion David paper topics Responding Heidegger position death and religion using The Seventh Seal Discussion Cathy paper topics Three main myths depicted Discussion Terry paper topics Theological representations The Seventh Seal Discussion Lauren paper topics How does the meaning life affect the outlook each character The Seventh Seal Discussion Phillip paper topics How imagination enhances meaning life seen Life Beautiful and Amélie Discussion Peter paper topics Contrast between self love and selfishness relation Pride and Prejudice 
8321 en Les super états superfluidité
8329 en The unexpected side the LHC
8386 en Class Planning and Realities Post war Iraq
8387 en Class Politics and Society Iraq the 20th Century
8388 en Class Comparative Insights Marshall Plan Japan and Iraq
8389 en Class Reconstructing New Liberal Iraq 
8390 en Class Consolidating Iraqi Democracy the Institutional Context
8391 en Class The Arab Discourse Iraq and the International Role
8392 en Class The Discourse Iraqis and Arabs the Reconstruction New Iraq Political Cartoons and Reflection Noam Chomsky Final presentation Professor Yosef Jabareen Arab political cartoons followed reflections Professor Noam Chomsky the Iraqi occupation and the hegemonizing agenda the the Middle East 
8393 en Lecture Newton Method
8394 en Lecture Duality Theory 
8395 en Lecture Semidefinite Optimization 
8420 en Lecture Who Develops Breakthrough New Products and Services Users Manufacturers Before thinking about how concept development will explore who does this activity Specifically the concept developer really manufacturer product service user 
8421 en Lecture Systematic Generation Ideas for Breakthrough New Products and Services the Lead User Method Users innovate when their interest But not all user innovations will make good product from product manufacturer standpoint Therefore manufacturers must identify and learn from lead users and other firms have learned network their way lead users and then combine lead user ideas with their own create breakthrough new products and services The reading for this lecture describes the experience 
8422 en Lecture Systematic Generation Incremental Improvements Existing Products and Services Traditional Marketing Research Concept Generation Techniques Traditional market research techniques are most advanced consumer products fields Here user needs are analyzed via multiattribute techniques marketing and personnel then use this data develop new product concepts Finally the market potential these ideas explored via focus groups representative consumers questionnaires etc 
8775 en Brains not Bullets From Terrorism Insurgencies and Drug Wars Street Gangs and World Warcraft previous work suggested that common dynamical patterns underlie the evolution irregular warfare and global terrorism offered simple model explain all these findings based common ’soup’ continually evolving attack units This talk updates this line research light new results addition confirming the robustness our model these results offer quantitative explanation why the insurgent war Iraq and the drug war Colombia have evolved the way that they have – and how the emerging wars Afghanistan and Mexico might evolve the future These findings strengthen our earlier hypothesis that the commonality observed dynamics are consequence how humans naturally ’ ’ conflict irrespective the individual conflict’ specific origin geographic location ideology and religious issues Having established the quantitative power our model use predict the duration wars and test out the consequences different intervention strategies then turn look the connection with transnational ’maras’ street gangs and online gangs which form around Internet role playing games such World Warcraft 
8776 en Growing Sovereignty Modeling the Shift from Indirect Direct Rule Drawing theories historical sociology model the emergence the territorial state early modern Europe Our modeling effort focuses systems change with respect the shift from indirect direct rule first introduce one dimensional model that captures the tradeoff between organizational and geographic distances second step present agent based model that features states with varying number organizational levels This model explicitly represents causal mechanisms conquest and internal state building through organizational bypass processes The computational findings confirm our hypothesis that technological change sufficient trigger the emergence modern direct state hierarchies Our theoretical findings indicate that the historical transformation from indirect direct rule presupposes logistical rather than the commonly assumed exponential form the loss strength gradient 
8777 en Dynamics Terrorist Groups The behavior terrorist groups may seem highly strategic and thus largely contingent unpredictable however taking comparative approach considering data terrorist attacks find that surprising patterns emerge this talk Ill describe recent work discovering and understanding the structure terrorist attacks over the past years and particular the regular behavior terrorist organizations These results shed new light the origin severe terrorist attacks and point fundamental constraints the dynamics terrorism 
8778 en Policy Informatics for Complex Systems Mental models are inadequate for coping with crises complex socioeconomic systems Modern information technology can support evidencebased policies using simulations synthesize data Synthetic data provide natural representation situations and hypothetical outcomes suitable for use policy makers This talk will explore issues arising the emerging science policy informatics distinctions between support for planning response efforts determining requirements for resolution fidelity precision and accuracy synthetic data communicating between model developers and stakeholders which includes designing informative experiments and interpreting outcomes and assessing adequacy models Examples will drawn from practical experiencesnwith the novel H1N1 influenza 
8779 en Cooperation and Conflict the Prisoner’ Dilemma and the Emergence Norms According Thomas Hobbes’ Leviathan ”the life man solitary poor nasty brutish and short” and would need powerful social institutions establish social order reality however social cooperation can also arise spontaneously based local interactions rather than centralized control The self organization cooperative behavior particularly puzzling for social dilemmas related sharing natural resources creating common goods Such situations are often described the prisoner’ dilemma Here report the sudden outbreak predominant cooperation noisy world dominated selfishness and defection when individuals imitate superior strategies and show success driven migration our model individuals are unrelated and not inherit behavioral traits They defect cooperate selfishly when the opportunity arises and they not know how often they will interact have interacted with someone else Moreover our individuals have reputation mechanism form friendship networks nor they have the option voluntary interaction costly punishment Therefore the outbreak prevailing cooperation when directed motion integrated game theoretical model remarkable particularly when random strategy mutations and random relocations challenge the formation and survival cooperation clusters Finally new results will presented the issue conflict the prisoner’ dilemma and the emergence norms when group dynamical effects are taken into account 
8780 en Explaining and Forecasting the Psychological Component Economic Activity develop methodology for estimating the parameters dynamic opinion expectation formation processes with social interactions study simple stochastic framework collective process opinion formation group agents who face binary decision problem The aggregate dynamics the individuals’ decisions can analyzed via the stochastic process governing the ensemble average choices Numerical approximations the transient density for this ensemble average allow the evaluation the likelihood function the base discrete observations the social dynamics This generic approach can used estimate the parameters various opinion formation processes from variety available aggregate data Our applications include identification interaction effects well known business climate index well analysis sentiment data from the German stock market both cases find strong evidence strong social interactions with the potential generating abrupt swings the average mood respondents this way the psychological component the imprints animal spirits economic data can identified 
8781 en Financially Constrained Business Fluctuations Evolving Network Economy explore the properties credit network characterized inside credit credit relationships connecting downstream and upstream firms and outside credit credit relationships connecting firms and banks The structure the network changes over time due the preferred partner choice rule The net worth firms turns out the driver growth and fluctuations production fact determined demand intermediate inputs the part firms The output simulations shows that business cycle the macroeconomic level can develop consequence the complex interaction the heterogeneous financial conditions the agents involved this context can study the emergence bankruptcy chains can alsonreproduce the main facts firms’ demography power law distribution firms’ size and Laplace ditribution growth rates 
8782 en Financial Regulation Attempt Regulate Complexity The talk reviews the main components the financial crisis 2007 from complexity perspective and argues that two decades ideology driven deregulation the surge securitization the spreading OTCnderivatives and off balance sheet items excessive leverage collaterized debt obligations and structured investment vehicles led the creation huge shadow banking system that became opaque and complex tonsuch degree totally unknowable Such system impossible regulate result massive government interventions partial complete nationalization and series collapses the system thenprocess deleveraging and large body new regulation the making The talk will give sketchy oversight what perhaps the most coherent set proposals for the new regulation due the Larosiere Committee Finally the idea adaptive regulatory regime will put forward 
8783 en Self Organization and Finite Size Effects Agent Models for Financial Markets The deviation from Random Walk behavior financial time series have been identified Stylized Facts and are common all markets The main ones are that fluctuations are much lager than those predicted from the standard economic theory gaussian fluctuations the clustering volatility and substantial non stationarity all properties Many Agent Based Models have been proposed explain these phenomena and several are indeed able reproduce some them However the situation still problematic becaus these models are typically rather complicated with various hoc assumptions This has prevented systhematic study these effects have tried therefore define workable Agent based Model which contains the essential elements but mathematically simple and well defined framework addition have considered some new important elements like the nonstationarity the process with respect the number agents and the question the self organization Namely why all markets evolve spontaneously towards the situation corresponding the considering that all models this restricted very narrow range parameters The are shown correspond finite size effects with respect time and the number agents which however can active different time scales This implies that strict universality cannot expected inndescribing these properties terms effecive critical exponents The introduction threshold the agents action small price movements lead action triggers the self organization towards the intermittentnstate corresponding the From these studies the herding phenomenon seems crucial one beyond the standard theory triggering element bubbles and crashs which develop spontaneously without cause effect relation The model can also used backwards derive the strategies the agents from the price time series Other applications are under consideration like the problem finite liquidity and the possibility that the reference fundamental price subject large fluctuations one cnsiders that all markets are linked into large network 
8785 en Financial Bubbles Real Estate Bubbles Derivative Bubbles and the Financial and Economic Crisis The financial crisis 2008 which started with initially well defined epicenter focused mortgage backed securities MBS has been cascading into global economic recession whose increasing severity and uncertain duration had led and continuing lead massive losses and damage for billions people Heavy central bank interventions and government spending programs have been launched worldwide and especially the USA and Europe the hope unfreeze credit and boltster consumption Here present evidence and articulate general framework that allows one diagnose the fundamental cause the unfolding financial and economic crisis the accumulation several bubbles and their interplay and mutual reinforcement has led illusion perpetual money machine allowing financial institutions extract wealth from unsustainable artificial process Taking stock this diagnostic conclude that many the intervention address the called liquidity crisis and encouragemore consumption are ill advised and even dangerous given the lack precautionary reserves that have been unaccumulated the good times and the huge liabilities The most interesting presents times constitute unique opportunities but also great challenges for which offer few recommendations 
8786 en Efficient Immunization Approaches Avoid Epidemic Spreading will show how methods based statistical physics and complex networks approaches may help predict the appearing crises such epidemics These methods also suggest efficient immunization strategies coop with such crises The epidemics could occur social systems well communication networks such computers cellphones The methods are based the percolation theory approach which extended complex networks include more realistic scenarios such the limited time epidemics the dynamical nature links Questions such how identify the most crucial spreaders and giving limited amount immunization doses how prioritize the recipients will also discussed 
8787 en Planning for Pandemic Outbreaks with Large Scale Computational Models present class computational epidemic models that integrate transportation and census data the worldwide scale The defined models allow the analysis the impact complex mobility networks the behavior emergent disease spreading and the general issue the predictive power offered computational approaches this framework possible tackle foundational issues using the particle network approach and provide new mathematical and computational tools for the study large scale epidemics will focus the discussion the analysis invasion thresholds and the definition epidemic pathways Based these results present the Global Epidemic Modeler GEM computational platform that can used the analysis intervention and mitigation policies for emerging disease outbreak 
8788 en Economic Fluctuations and Statistical Physics Quantifying Extremely Rare and Much Less Rare Events Recent analysis truly huge quantities empirical data suggests that classic economic theories not only fail for few outliers but that there occur similar outliers every possible size fact one analyzes only small data set say 104 data points then outliers appear occur “rare events ” However when analyze orders magnitude more data 108 data points find orders magnitude more outliers ignoring them not responsible option and studying their properties becomes realistic goal find that the statistical properties these “outliers” are identical the statistical properties everyday fluctuations For example histogram giving the number fluctuations given magnitude for fluctuations ranging magnitude from everyday fluctuations extremely rare fluctuations that occur with probability only perfect straight line double log plot Two unifying principles that underlie much the finance analysis will present are scale invariance and universality Mantegna HES Introduction Econophysics Correlations Complexity Finance Cambridge Press 2000 Scale invariance property not about algebraic equations but rather about functional equations which have their solutions not numbers but rather functional forms power laws nThe key idea universality that the identical set “scaling laws” hold across diverse markets and over diverse time periods demonstrate the principles scaling and universality describing very recent unpublished work HES Preis Schneider “New Laws Describing Trend Switching Processes Financial Markets” submitted For intriguing variety switching processes nature the underlying complex system abruptly changes specific “phase transition” point from one state another highly discontinuous fashion Examples phase transitions range from magnetism statistical physics physiology and macroscopic social phenomena Financial market fluctuations are characterized many abrupt switchings very short time scales from increasing “microtrends” decreasing “microtrends”—and vice versa ask whether these ubiquitous switching processes have quantifiable features analogous those present phase transitions and find striking scale free behavior the time intervals between transactions both before and after the switching occurs interpret our findings being consistent with time dependent collective behavior financial market participants test the possible universality our result performing parallel analysis transaction volume fluctuations 
8790 en Mechanisms Systemic Risk Contagion Reinforcement Redistribution The term ’systemic risk’ commonly denotes the risk that whole system consisting many interacting agents fails macroscopic property which emerges from the nonlinear interactions agents fact ’systemicnrisk’ already implies that the failure the system cannot fully explained the failure single agent Instead one has understand how such singular failures are able spread through the whole system affecting other agents Here addition network topology dynamic mechanisms such contagion similar epidemic processes herding behavior reinforcement prevailing trends and redistribution load stress debt play considerable role The talk aims categorizing some the existing models common framework first and discussing specific model financial networks afterwards elucidate the critical conditions for the breakdown system 
8791 en Two Models Collective Firm Bankruptcies Two models collective firm bankruptcies will presented The first one uses the Potts spin glass approach for firms rating evolution where two sources defaults are taken into account individual dynamics economic development and ordering interactions between firms show that such defined model leads phase transition which results collective defaults the case when the individual firm dynamics favors dumping rating changes there optimal strength firms interactions from the risk point view For small interaction strength parameters there are many independent bankruptcies individual companies For large parameters there are giant collective defaults firm clusters The second model represents defaults companies multi stage supply chain networks introduced modified approach that represents more details the real economic environment which firms are operating nWe focused the influence local processes the global economic behaviour the system and studied how the proposed modifications change the general properties the model realistically simulate the economic environment companies introduced the following features the model evolution supply chain network with the reconfiguration links price dispersion and the dynamics prices and costs production the certain point the system’ evolution the meta stable structures the network occur result the dynamics prices and costs production observed both the emergence highly profitable supply chains with the high market share and the avalanches bankruptcies 
8792 en Prediction and its Limits Socio Economic Systems Science recognizes number limitations its power predict the future physical systems Such limits typically stem from dynamical chaos the impracticability dealing with large numbers variables this talk will review recent work pertaining the limits predictability complex systems and novel features arising systems involving adaptive agents such humans The ”socio physics” approach often elicits the criticism from social scientists that ignores the ”reflexive” character social reality – that valid insights into individual human behaviour social patterns may quickly cause people alter their behaviour destroying the validity those insights will argue that reflexitivity real phenomenon but that ’ not fundamentalnbarrier socio economic prediction for two reasons First people under observation often become habituated their environment and exhibit stable behaviour Second science gaining ability model the reflexive process itself learning model the process human thinking ’ conclude reviewing studies political science which suggest that key reflexive feedback driving many the most recent financial crises has been the evolution ”triangles” power among government agencies regulators and special interests such the financial industry Any successful effort prevent such crises may need exert control over such feedbacks and produce regulatory framework that some sense ”lobby proof ”
8793 en Travel and Social Capital Some Empirical Evidence The presentation will present theoretical and empirical discussion the links between the generalized costs travel the use space and the spatial structure social networks the population After brief historical overview the changes the generalized costs travel and associated time space compression the industrialized countries the question will discussed what impact these changes should have the structure the social networks with respect the size overlap spatial location The second part the talk focuses the empirical work done far provide empirical evidence for the theoretical expectations formulated above The challenges inherent the survey work will presented well the key empirical results obtained far 
8794 en Microscopic Simulation Tsunami Related Evacuation the City Padang The evacuation whole cities even regions important problem demonstrated recent events such the evacuation Houston the case Hurricane Rita the evacuation coastal cities the case tsunamis robust and flexible simulation framework for such large scale disasters helps predict the evacuation process Furthermore possible recognize bottlenecks advance that elimination ofnthose bottlenecks possible This should lead better preparedness for cities regions that face high risk natural disasters Existing methods are either geared towards smaller problems Cellular Automatantechniques methods based differential equations are not microscopic methods based dynamic traffic assignment Our work uses technique that both microscopic and capable process large problems The simulation applied the Indonesian city Padang The city faces high risk being inundated earth quake triggered tsunami 
8795 en Macroscopic Modeling Traffic Congested Cities Empirical Evidence Analytical Derivations and Control Applications Various theories have been proposed describe vehicular traffic movement cities aggregate level They fall short create macroscopic model with variable inputs and outputs that could describe rush hour dynamically This work shows that Macroscopic Fundamental Diagram MFD relating production the product average flow and network length and accumulation the product average density and network length exists for neighborhoods cities the order km2 also demonstrates that conditional accumulation large networks behave predictably and independently their Origin Destination tables These results are based analysis using simulation large scale city networks and real data from urban metropolitan areas Regularity conditions under which MFD exists for different types networks are proposed and tested Further analysis real data shows that MFD not universal recipe that can describe any type large network For example MFDs for spatially inhomogeneous networks non redundant networks like freeway traffic systems are highly scattered analytical model based Variational Theory describes the connection between network structure and network’ MFD for urban neighborhoods controllednat least part traffic signals The MFD applied develop control strategies based neighborhood accumulation and speeds and improve accessibility without the uncertainty inherent forecast based approaches 
8796 en Statistical Physics and Social Systems Critical Perspective The Case Urban Mobility The application Statistical Physics social systems mainly related looking for macroscopic laws that are derived from experimental data average time space under the assumption that the averaged systemnis stationary state The final goal correlate the statistical laws the microscopic properties the system for example understand the nature the microscopic interactions point out the existence interaction networks However the probability theory suggests the existence few classes stationary distributions the thermodynamics limit that the question statistical physics approach could ablento point out the complex nature the social systems have analyzed GPS data base for individual mobility individual vehicles are monitored Italy for insurance reasons look for statistical laws path length distributions elapsed time the different activities related mobility flux distribution the road network and frequency rank distribution for the individual destinations show simple generic assumptions the microscopic behavior could explain the existence stationary macroscopic laws Our conclusion that the understanding the system complexity requires dynamical data base for the microscopic behavior large scale time dependent environment that allows study the evolution the transient states Theoretical results long range interacting systems suggest that the transient states may provide much more information the microscopic interaction nature Concerning human mobility the GPS data base will improved the next future enhancing the recording time sampling and increasing the sample size 
8797 en Spiraling Toward Complete Markets and Financial Instability The proliferation financial instruments provides more opportunities hedge risks reducing transaction costs and making markets more complete These predictions sharply contrasts with recent experience where asymmetric information and imperfect competition have played major role turning expanding credit derivative markets into ”financial weapons mass destruction” Here argue that the escalation market imperfections originates from the changes which take place the nature the market equilibria when the repertoire financial instruments expands This done the limit large random economy where set consumers invests financial instruments engineered banks order optimize their future consumption show that even the ideal case perfect competition where full information available all market participants markets approach completeness and transaction costs vanish the equilibrium develops marked vulnerability susceptibility market imperfections Therefore the onset instability does not require large shocks but rather arises from the intrinsic nature the equilibrium One particularly devastating effect that replicating portfolios used banks hedge new instruments require trading volumes within the financial sector which diverge the market approaches completeness Such interbank market itself develops divergent susceptibility the theoretical limit complete markets approached similar approach shows that the expansion derivative markets generates instability and large movements underlying markets These results suggest that the proliferation financial instrumentsnexacerbates the effects market imperfections order prevent escalation perverse effects markets may necessitate institutional structures which are more and more conspicuous they expand 
8798 en The Role Tie Strength the Cohesion the Society Tribute Mark Granovetter Electronic databases from phone emails logs currently provide detailed records human communication patterns offering novel avenues map and explore the structure social and communication networks examine the communication patterns millions mobile phone users allowing simultaneously study the local and the global structure society wide communication network observe coupling between interaction strengths and the networks local structure and conclude that social networks are robust the removal the strong ties but fall apart following phase transition the weak ties are removed show that this coupling significantly slows the diffusion process resulting dynamic trapping information communities and find that when comes information diffusion weak and strong ties are for different reasons both simultaneously ineffective Using the aggregate records mobile phone service provider about private voice calls more than million users construct over weeks weighted network interactions where the tie strength taken proportional the total duration the calls introduce measure the link overlap and show that nodes people with strong links have large friendship overlap This way prove for the first time the Granovetter hypothesis about the strength weak ties societal scale The network has strongly modular structure with highly wired communities with strong ties which are connected weak links global consequence this structure that the network connectedness resilient against removal strong links while falls apart whenthe weak links are cancelled The intimate relationship between link weights and topology has strong influence the dynamic properties the network Using the simplest diffusive spreading dynamics demonstrated that the probability getting new information alternatively getting infected via strong weak link low most cases links with intermediate strength play the role the transmitter order understand the peculiar interplay between topology and link weights constructed model the social network The model has strong simplifications and based elementary steps link formation and tie strengthening deal with constant number nodes order reach stationarity time time node eliminated and the same time new one without any connections born Links are created either random with very low probability using already existing links friends friends get friends important element the model that whenever link used there strengthening effect described parameter The resulting network describes well the qualitative features the call network including the strength the weak ties and the trapping effect 
8799 en The Weave Social Life How Social Interactions Shape the Individual One the deepest problems the social sciences concerns the causal impact society that properties the group the properties individuals This problem arises because individuals affect the properties groups and vice versa such that very difficult get causality Here take advantage the possibility affect the properties internet communities show that groups with higher density social interactions render their members generally more altruistic and trusting towards anonymous strangers Moreover higher density social interactions also causes boost trust towards those who reciprocate favours while diminishes trust towards those who fail reciprocate thus generating much stronger implicit punishment for untrustworthy individuals Finally increased social contact also enhances the strategic sophistication individuals and raises the prevalence Machiavellian strategies These results indicate that the density social interactions has deep impact individuals’ preferences beliefs and behaviors lending support sociological views society 
8800 en How Economies Grow How They Interract How They Fall and How They Recover The stochastic spatially extended generalized Lokta Volterra approach was introduced few years ago and was applied using analytical field theory and statistical mechanics methods numerically computer experiments and empirical gathering and processing real data techniques wide range natural biological economic and social systems this talk will describe its recent application the study interactions between economic sectors countries and blocks The theory predicts robustly very wide range conditions systematic regularities the growth rates evolution various subsystems The after shocks curve phenomenon economic decay and rebound induced the emergence singular growth centers revisited and more empirical support given the theory particular show that the data support the connection between the economic minimum and the crossover the new emergent leading sector with the old decaying one describe the Growth Alignment Effect GAE its theoretical basis and demonstrate empirically for numerous cases the international and intranational economies The GAE the concept that steady state the growth rates the GDP per capita the various system components align differentiate the GAE predictions from the usual convergence divergence conceptual framework that dominated economic studies until now 
8801 en Robustness Social Networks Networks typically cease operational when they fall apart disconnected pieces This can desired the case criminal networks should avoided for instance the case communication systems nDestruction can happen randomly due malicious attack will present various strategies optimizing the robustness networks preserving their degree distribution novel topology emerges Applications power networks botnets road systems and brain models will discussed 
8804 en Tutorial about Sociodynamics Sociodynamics intends provide integrated strategy for mathematical modelling collective dynamic processes the human society The approach far more general than catastrophe theory comprises the full dynamics key variables namely their chance behaviour well their quasi deterministic evolution connects the bottom and top down interaction between microlevel and macrolevel the social system The design principles start from the elementary dynamics the key variables terms socially interpretable probabilistic transition rates and end evolution equations for them The master equation for the probability distribution over key variables comprises mean behaviour and fluctuations well The quasi meanvalue equations derivable from the master equation describe the mean evolution only 
8805 en How Crime Bursts Can Occur with Minor Changes Retribution Policy model system interacting agents characterized given wealth and certain criminal propensity measured honesty coefficient This honesty related intrinsic factors like moral barriers and extrinsic ones the risk being imprisoned committing offense the simulation the honesty level the agents variable and function the level punition one hand and the contact with other agents learning contagion effect the other hand The number crimes per habitant measured function the probability being caught sharp phase transition observed function the probability punishment That means that once criminality has attained high level the probability retribution must considerably increase order come back state low criminality Also some precursor signals are observed that indicate possible bursts crime activity also analyze other consequences criminality the growth the economy the inequality the wealth distribution the Gini coefficient and other relevant quantities under different scenarios criminal activity and probabilities apprehension 
8806 en Commitment Unrewarded Behaviour The purpose presentation commitment show that its core resides unrewarded behaviour which rare but essential the conduct social communities Commitment defined unequivocal behaviour delivery carried out under the worst conditions when communities are unable reward Unrewarded commitment explored among 316 respondents The newly defined commitment mapped against conventional scales commitment and measures perceived organizational power perceived employment alternatives personal values Two types unrewarded behaviour are identified unrewarded commitment which not unrelated traditional measures commitment such affective and normative commitment and extreme Sisyphean unrewarded commitment which displays organizational behaviour even with affective normative instrumental attachment the community 
8808 en Cooperation and Conflict Wikipedia present model the collaborative process document authoring that takes place the free online encyclopedia Wikipedia consider the process editing Wikipedia page group agents with different opinions points view the topic the page which are continuous variables coupled with time inhomogeneous process for the WWW browsing the page which motivational factors for the participation the collaborative process affect the rate visits the page The model editing takes inspiration from response models biological neurons Social interactions between agents are thus mediatednby the content the page this original context opinion dynamics editors and regular users Wikipedia are seen actors having different objectives about what the point view expressed Wikipedia page should like and modify using simple greedy heuristic Interesting phenomena like the emergence shared neutral point view may then cast the light this dynamics opinions When the model opinion dynamics considered isolation simulations show that agents with opinions and rates activity that are fixed time converge pages opinion that reflect average shared point view between 
8809 en Measuring the Response Social System study the relaxation response social system after endogenous and exogenous bursts activity using the time series daily views for nearly million videos YouTube find that most activity can described accurately Poisson process However also find hundreds thousands examples which burst activity followed ubiquitous power law relaxation governing the timing views find that these relaxation exponents cluster into three distinct classes and allow for the classification collective human dynamics This consistent with epidemic model social network containing two ingredients power law distribution waiting times between cause and action and epidemic cascade actions becoming the cause ofnfuture actions This work conceptual extension the fluctuation dissipation theorem social systems and provides unique framework for the investigation timing complex systems 
8810 en Nature’ Solution the Problem Biological Logistics The ability cells survive and participate community such the human body requires logistical network that distributes nutrients cellular contents and information biologically reasonable time scales How does robust adaptable system emerge from the sum individual hard wired molecular agents operating noisy environment For example motor proteins deliver cargo along intracellular filaments appropriate sites network molecular compartments whose connectivity slowly becoming elucidated However surprisingly little known about what these motor proteins specifically where they cells what they transport and how their activity regulated address these basic questions modified motor proteins they could visualized live cells and recovered with their physical binding partners Individual motor proteins were also removed from cells determine the overall effect different cellular trafficking pathways found that different motor proteins are targeted unique sub cellular compartments and identified regulatory proteins resident these compartments that could serve molecular postal codes otherwise regulate the cycle cargo binding and release Overall this provides example biological solution managing complex systems using limited number components 
8811 en  some Value Risk Models Provoke Financial Market Destabilization Agent Based Financial Market Perspective The aim this paper explore the impact different Value Risk VaR models the stability financial markets Based numerical analysis test how simple and more sophisticated Value Risknmodels affect financial market stability This important implement effective regulations prevent financial market instability advance The Basel Committee Banking and Supervision BCBS does not stipulate that banks use special type VaR model Therefore practice many banks use methods with quite simple assumptions Testing the efficiency and reliability different VaR models with different underlying assumptions was and still important strand research Here mostly the accuracy estimating special quantile exploited this study explore the adequacy VaR models from another perspective adjust heterogeneous agent model integrating regulations Basel concerning market risk For this purpose use the financial market model Lux Marchesi 1999 2000 that can replicate stylized facts financial markets quite well First results indicate that the formula for calculating the level regulatory capital for market risk prescribed the BCBS prohibits more market stability the use more sophisticated models 
8812 en Clustering Dynamics Through Emerging Market Crash the Global Crisis 2007 2009 investigate the dynamics stock clustering the Johannesburg Stock Exchange JSE emerging market through the financial market crash 2008 particular apply the fully unsupervised parameter free data clustering technique pioneered Giada and Marsili 2002 investigate the changing correlation structure stocks well clustering daily market wide activity crisis compare our findings with identical analysis the London Stock Exchange through the same crisis period 
8813 en Early Signs Financial Crises For most diseases always better medically intervene earlier compared later This because treatment early stage generally more effective and less expensive The same probably true for economies and financial markets the current global financial crisis have seen billions dollars sunk into relief and stimulus packages with hardly any positive result show for the effort The reason clear these intervention measures are too late implement more effective and less costly economic and fiscal policies important detect the onset financial crisis early the same time not want excessive reactions when the market has merely caught ’cold’ this talk will describe recent work based the statistical segmentation and clustering analysis financial time series data that points characteristic early signs prior financial crises characteristic early signs prior true recovery and the characteristic time scales involved for bothnprocesses looking into period that covers both the current crisis well the most recent past crisis also hope learn lessons which intervention measures are effective and which intervention measuresnare not 
8817 en Contagion Norm Breaking the Number Righteous People The Norm Game introduced Axelrod investigated computer simulations carried out for agents distributed random network The agents are labeled sinners punishers after their first decision The stationary state shows bistable behaviour all become sinners all become punishers Here show how this bistability changes when some amount agents always break the norm always punish 
8832 en Welcome Speech the MLSS 2009
8833 en Kernel Methods and Support Vector Machines Kernel methods have become standard tool for pattern analysis during the last fifteen years since the introduction support vector machines will introduce the key ideas and indicate how this approach pattern analysis enables relatively easy plug and play application different tools The problem choosing and designing kernel for specific types data will also considered and overview different kernels will given 
8834 en Geometric Inference for Probability Distribution Data often comes the form point cloud sampled from unknown compact subset Euclidean space The general goal geometric inference then recover geometric and topological features Betti numbers curvatures this subset from the approximating point cloud data recent years appeared that the study distance functions allows address many these questions successfully However one the main limitations this framework that does not cope well with outliers nor with background noise this talk will show how extend the framework distance functions overcome this problem Replacing compact subsets measures will introduce notion distance function probability distribution nThese functions share many properties with classical distance functions which makes them suitable for inference purposes particular considering appropriate level sets these distance functions possible associate robust way topological and geometric features probability measure time permits will also mention few other potential applications this framework 
8835 en PAC Bayes Analysis Background and Applications
8836 en Cut Locus and Topology from Point Data cut locus point compact Riemannian manifold defined the set points where minimizing geodesics issued from stop being minimizing known that cut locus contains most the topological information Our goal utilize this property cut loci decipher the topology from point sample Recently has been shown that Rips complexes can built from point sample systematically compute the Betti numbers the rank the homology groups Rips complexes can computed easily and therefore are favored over others such restricted Delaunay alpha Cech and witness complex However the sizes the Rips complexes tend large Since the dimension cut locus lower than that the manifold subsample approximating the cut locus usually much smaller size and hence admits relatively small Rips complex nIn this talk explore the above approach for point data sampled from surfaces embedded any high dimensional Euclidean space present algorithm that computes subsample sample manifold where approximates cut locus Empirical results show that the first Betti number can computed from the Rips complexes built these subsamples The sizes these Rips complexes are much smaller than the one built the original sample 
8837 en Graphical Models and Applications Compressed sensing recent set mathematical results showing that sparse signals can exactly reconstructed from small number linear measurements Interestingly for ideal sparse signals with measurement noise random measurements allow perfect reconstruction while measurements based principal component analysis PCA independent component analysis ICA not the same time for other signal and noise distributions PCA and ICA can significantly outperform random projections terms enabling reconstruction from small number measurements this paper ask given training set typical the signals wish measure what are the optimal set linear projections for compressed sensing show that the optimal projections are general not the principal components nor the independent components the data but rather seemingly novel set projections that capture what still uncertain about the signal given the training set also show that the projections onto the learned uncertain components may far outperform random projections This particularly true the case natural images where random projections have vanishingly small signal noise ratio the number pixels becomes large Joint work with Hyun Sung Chang and Bill Freeman will give brief introduction questions representation learning and inference probabilistic graphical models and illustrate these ideas applications from our own work computational biology and computer vision 
8838 en Euler Calculus and Topological Data Management This talk covers the basic integral calculus based Euler characteristic and its utility data problems particularly aggregation redundant data and inverse problems over networks This calculus blend integral geometric and sheaf theoretic techniques and leads surprisingly practical algorithms and computations Qualitative versions integral transforms for signal processing will stressed 
8839 en Seeking Interpretable Models for High Dimensional Data Extracting useful information from high dimensional data the focus today statistical research and practice After broad success statistical machine learning prediction through regularization interpretability gaining attention and sparsity has been used its proxy With the virtues both regularization and sparsity Lasso penalized minimization has been very popular recently this talk would like discuss the theory and pratcice sparse modeling First will give overview recent research sparsity and explain what useful insights have been learned from theoretical analyses Lasso Second will present collaborative research with the Gallant Lab Berkeley building sparse models linear nonlinear and graphical that describe fMRI responses primary visual cortex area natural images 
8840 en Learning Dictionaries for Image Analysis and Sensing Sparse representations have recently drawn much attention from the signal processing and learning communities The basic underlying model consist considering that natural images signals general admit sparse decomposition some redundant dictionary This means that can find linear combination few atoms from the dictionary that lead efficient representation the original signal Recent results have shown that learning overcomplete non parametric dictionaries for image representations instead using off the shelf ones significantly improves numerous image and video processing tasks nIn this talk will first present our results learning multiscale overcomplete dictionaries for color image and video restoration will present the framework and provide numerous examples showing state the art results will then briefly show how extend this image classification deriving energies and optimization procedures that lead learning non parametric dictionaries for sparse representations optimized for classification will conclude showing results the extension this sensing and the learning incoherent dictionaries The work present this talk the result great collaborations with Mairal ENS Paris Rodriguez UofM Spain Martin Duarte UofM Kodak Ramirez UofM Lecumberry UofM Bach ENS Paris Elad Technion Israel Ponce ENS Paris and Zisserman ENS Oxford 
8842 en Examining the Relative Influence Familial Genetic and Environmental Covariate Information Flexible Risk Models present novel method for examining the relative influence familial genetic and environmental covariate information flexible nonparametric risk models Our goal investigating the relative importance these three sources information they are associated with particular outcome that end developed method for incorporating arbitrary pedigree information smoothing spline ANOVA ANOVA model expressing pedigree data positive semidefinite kernel matrix the ANOVA model able estimate log odds ratio multicomponent function several variables one more functional components representing information from environmental covariates and genetic marker data and another representing pedigree relationships report case study models for retinal pigmentary abnormalities the Beaver Dam Eye Study BDES Our model verifies known facts about the epidemiology this eye lesion found eyes with early age related macular degeneration AMD and shows significantly increased predictive ability models that include all three the genetic environmental and familial data sources The case study also shows that models that contain only two these data sources that pedigree environmental covariates pedigree genetic markers environmental covariates genetic markers have comparable predictive ability while less than the model with all three This result consistent with the notions that genetic marker data encodes least partly pedigree data and that familial correlations encode shared environment data well 
8843 en Vision and Hodge Theory general mathematical Hodge theory will presented together with its relationship spaces images 
8844 en Learning Deformable Models widely recognized that the fundamental building block high level computer vision the deformable template which represents realizations object class the image noisy geometric instantiations underlying model The instantiations typically come from subset some group centered the identity which act the model template Thus contrast some machine learning applications where one tries discover some unspecified manifold structure here entirely determined the group action and the model Given choice group action and family template models major challenge use sample images the object estimate the model and the distribution the group The primary obstacle that the instantiations group elements that produced each image are unobserved will describe general formulation this problem and then show some practical applications object detection and recognition 
8845 en Statistical Classification and Cluster Processes After introduction the notion exchangeable random partition continue with more detailed discussion the Ewens process and some its antecedents The concept exchangeable cluster process will described the main example being the Gauss Ewens process Some applications cluster processes will discussed including problems classification supervised learning and cluster analysis unsupervised learning second type probabilistic model based point processes also described contrast which the Gauss Ewes cluster process the domain associated with each class more diffuse and not localized the feature space For both models the classification problem interpreted the problem computing the predictive distribution for the class new object having given feature vector one case this conditional distribution given the observed features the other Papangelou conditional intensity 
8846 en Theory Methods and Applications Active Learning Traditional approaches machine learning and statistical inference are passive the sense that all data are collected prior analysis non adaptive fashion One can envision however more active strategies which information gleaned from previously collected data used guide the selection new data This talk discusses the emerging theory such active learning methods will show that feedback between data analysis and data collection can crucial for effective learning and inference The talk will describe two active learning problems First will consider binary valued prediction classification problems for which the prediction errors passive learning methods can exponentially larger than those active learning Second will discuss the role active learning the recovery sparse vectors noise will show that certain weak sparse patterns are imperceptible from passive measurements but can recovered perfectly using selective sensing 
8847 en Sparse Representations from Inverse Problems Pattern Recognition Sparse representations are the core many low level signal processing procedures and are used most pattern recognition algorithms reduce the dimension the search space Structuring sparse representations fro pattern recognition applications requires taking into account invariants relatively physical deformations such rotation scaling illumination Sparsity invariants and stability are conflicting requirements which source open problems Structured sparse representations with locally linear vector spaces are introduced for super resolution inverse problems and pattern recognition 
8848 en Optimization Algorithms Support Vector Machines This talk presents techniques for nonstationarity detection the context speech and audio waveforms with broad application any class time series that exhibits locally stationary behavior Many such waveforms particular information carrying natural sound signals exhibit degree controlled nonstationarity and are often well modeled slowly time varying systems The talk first describes the basic concepts such systems and their analysis via local Fourier methods Parametric approaches appropriate for speech are then introduced way time varying autoregressive models along with nonparametric approaches based variation time localized estimates the power spectral density observed random process along with efficient offline bootstrap procedure based the Wold representation Several real world examples are given 
8849 en Unsupervised Learning for Stereo Vision consider the problem learning estimate depth from stereo image pairs This can formulated unsupervised learning the training pairs are not labeled with depth have formulated algorithm which maximizes conditional likelihood the left image given right image model that involves latent information depth This unsupervised learning algorithm implicitly trains shape from texture and shape from shading monocular depth cues The talk will present pragmatic results the stereo vision problem well general formulation models and methods for maximizing conditional likelihood latent variable model where wish interpret the latent information labels 
8851 en Theory and Applications Boosting Boosting general method for producing very accurate classification rule combining rough and moderately inaccurate rules thumb While rooted theoretical framework machine learning boosting has been found perform quite well empirically This tutorial will introduce the boosting algorithm AdaBoost and explain the underlying theory boosting including explanations that have been given why boosting often does not suffer from overfitting well some the myriad other theoretical points view that have been taken this algorithm Some practical applications and extensions boosting will also described 
8852 en Generative Models for Image Analysis probabilistic grammar for the grouping and labeling parts and objects when taken together with pose and part dependent appearance models constitutes generative scene model and Bayesian framework for image analysis the extent that the generative model generates features opposed pixel intensities the inverse posterior distribution interpretations given images based incomplete information feature vectors are generally insufficient recover the original intensities will argue for fully generative scene models meaning models that principle generate actual digital pictures will outline approach the construction fully generative models through extension context sensitive grammars and formulation the popular template models for image fragments Mostly will focus the problem learning template models from image data Since the model fully specified generative the pixel level the templates can learned maximum likelihood training set eyes for example yields ensemble left and right eyes familiar and natural character but not actually coming from any particular individuals the training set The upshot mixture distribution image patches consisting set templates and set conditional patch distributions one for each template One way test the model examine samples will show how sample from the mixture distribution and will show sample sets eyes mouths and generic background Another way test the model use for detection recognition classification will show the results test ethnic classification based the eye region faces 
8853 en  Surrogate Loss Functions Divergences and Decentralized Detection 1951 David Blackwell published seminal paper widely cited economics which link was established between the risk based loss and class functionals known divergences The latter functionals have since come play important role several areas signal processing and information theory including decentralized detection Yet their role these fields has largely been heuristic show that extension Blackwell´ programme provides solid foundation for the use divergences decentralized detection well more general problems experimental design Our extension based connection between divergences and the class called surrogate loss funcions computationally inspired upper bounds loss that have become central the machine learning literature classification Joint work with XuanLong Nguyen and Martin Wainwright 
8854 en Similarity Based Classifiers Problems and Solutions Similarity based learning assumes one given similarities between samples learn from and can considered special case graph based learning where the graph given and fully connected Such problems arise frequently computer vision bioinformatics and problems involving human judgment will review the field similarity based classification and describe the main problems encountered adapting standard algorithms for this problem including different approaches approximating indefinite similarities kernels will motivate why local methods lessen the indefinite similarity problem and show that kernelized linear interpolation and local kernel ridge regression can profitably applied such similarity based classification problems framing them weighted nearest neighbor classifiers Eight real datasets will used compare state the art methods and illustrate the open challenges this field 
8855 en What Unique Games Structural Biology and the Low Rank Matrix Completion Problem Have Common will formulate several data driven applications MAX2LIN and games and show how approximately solve them using efficient spectral and semidefinite program relaxations The relaxations perform incredibly well the presence large number outlier measurements that cannot satisfied use random matrix theory prove that the algorithms almost achieve the information theoretic Shannon bound The underlying group structure the different applications like etc heavily exploited Applications include cryo electron microscopy and NMR spectroscopy for protein structuring low rank matrix completion clock synchronization and surface reconstruction computer vision and optics Partly joint with Yoel Shkolnisky Ronald Coifman and Fred Sigworth Yale Mihai Cucuringu and Yaron Lipman Princeton and Yosi Keller Bar Ilan 
8883 en Bounding Excess Risk Machine Learning will discuss general approach the problem bounding the excess risk learning algorithms based empirical risk minimization possibly penalized This approach has been developed the recent years several authors among others Massart Bartlett Bousquet and Mendelson Koltchinskii based powerful concentration inequalities due Talagrand well variety tools empirical processes theory comparison inequalities entropy and generic chaining bounds Gaussian empirical and Rademacher processes etc provides way obtain sharp excess risk bounds number problems such regression density estimation and classification and for many different classes learning methods kernel machines ensemble methods sparse recovery also provides general way construct sharp data dependent bounds excess risk that can used model selection and adaptation problems 
8891 en OSS Tools Support Collaborative Mobile Work Practices This lecture aims better understanding the way currently mobile professionals work remotely collaboration with others both within and beyond the company and matching these current ways working with the most appropriate open source software OSS collaboration tools This achieved through addressing the current state art the mobility challenges and identifying what working well inefficiently remote collaboration across four case studies Evidences from the cases show that there currently little tool support for mobile work practices and better integration the tools with companies existing internal systems may improve the productivity the mobile workers For researchers research lens proposed open discussions and further concepts development with respect mobile collaboration For practitioners set technical requirements and list corresponding OSS tools are presented further elaborate the mobile working concept from their own context with specific focus the scenario manager business trip The paper concludes discussing open problems and proposing the research themes within the context mobile collaboration 
8894 en Productivity Collaboration intensive Knowledge Work The Collaboration Management Imperative Collaboration hot issue and increasing extent recognised key driver overall business performance innovation capabilities and productivity However few companies methodically evaluate how well they perform the area collaboration and few companies have implemented management and leadership principles systematically improve collaborative performance This article describes the commonly occurring mismatch between the potential impact collaboration business performance and the attention given collaboration Furthermore the article explains why companies should approach collaboration strategically and identify new ways fostering and facilitating collaboration structured manner The article proposes value perspective collaboration and provides framework for classifying and managing different factors related collaboration and concludes with list specific action points for organisations that are interested improving their collaborative performance and obtaining higher Return Investment ROI their collaboration initiatives 
8895 en Collaborative Working Environments Globalised Inquiry for All With this lecture are sharing our practical findings the eSangathan Project interpreted from the theoretical perspectives Inquiring Communities and Collaborative Working Environment CWE start investigating the use and CWE support Inquiring Communities among seniors working create social innovations identify five different forms Inquiring Communities the Realistic the Analytic the Idealistic the Dialectic and the Pragmatic These communities take basic and essential for communication and sharing knowledge among human beings there are not very much evidence the CWE support all these five communities use theories Knowledge Management stepping stone because there are substantial evidence support for Knowledge Management CWE even though Knowledge Management lacks sound theoretical foundation Knowledge Management only can illustrate the Realistic the Analytic and the Idealistic types Inquiring Communities see lack support CWEs for the most crucial aspects communication and knowledge sharing that among differences opinion the Dialectical and Pragmatic communities Finally explicate findings good practice CWE have experienced them the eSangathan project together with some important dilemmas for further investigations 
8896 en Achieving Interoperability Grid Enabled Virtual Organisation Grid computing introduces new paradigm for the realisation efficient collaborative ICT infrastructures for VOs that has many advantages comparison other known approaches However due some shortcomings with regard industry requirements practical uptake still quite low despite the potential benefits this paper focus three important issues regarding the achievement efficient interoperability grid enabled VOs the appropriate handling authorisation and authentication the role based access resources and services and the gridification existing applications suggest approach extend Grid functionality addition nal semantic service layer top the basic Grid middleware services The services this layer are grounded three inter related ontologies specified OWL alignment with the Semantic Web paradigm Reported are findings from the recently finished European project InteliGrid and the ongoing German project BauVOGrid 
8897 en How the idea Single European Electronic Market turning into reality The idea Single European Electronic Market SEEM described the European Union and further elaborated within the European Project SEEMseed seems good chance for Small Medium and Micro Enterprises seamlessly participate the electronic market today and the future Even individuals may take advantage the SEEM idea actively benefit from electronic business within Europe The overall goal realizing Single Electronic European Market not easy attainable because high complexity and fragmentation the areas interest Under patronage and sponsorship European Commission above all 6th and 7th Framework Programme several project are currently running soon started order foster the SEEM idea Similar this CEN ISSS has developed the project eCAT this paper will describe and analyze the current efforts this area and will describe meta project called Simple Line Catalog connect results the existing projects initiatives and studies and cover them with integral user interface accessible SME and Individuals across the borders and languages 
8898 en Validation architectural targets business components identification Component identification one decisive task designing software architectures for large component based information systems and especially the quality business components identification plays important role concurrent enterprising Methods that have been developed for this task yield component architectures that conform these methods target functions This paper validates the soundness architectures resulting from systematic component identification with the BCI business components identification method could derive our results from real life industry project where show that architecture qualities required stakeholders are directly covered from target architecture generated through BCI application 
8899 en  intelligent system business and enterprise management IDEA IDEA system assists all the specific processes enterprise from the meat processing industry support decision makers manage performances implementing the concepts Business Performance Management BPM and Business Intelligence IDEA system transforms data into information and then into knowledge being focused business technological and economical aspects specific the meat processing enterprises helping them realise efficient use their business policies financial human and material resources IDEA system integrates solutions implemented the software components decision processes management customer relation management and enterprise resources planning components IDEA integrates the BPM organisation processes with its CRM components and ERP components IDEA system offers support for intelligent management business processes manufacture flows and the enterprise resources The tools considered the development IDEA system are oriented business management business workflow analysis business performance management OLAP Online Analytical Processing data modelling data visualisation report servers AJAX Asynchronous JavaScript and XML technology 
8900 en The effects various forms inter organizational trust competitiveness CIOPS Cognitive Inter organizational Production System agent based simulation model integrating structural and cognitive aspects industry competitiveness The model links firms profitability the quality their suppliers thus firms purpose manage their cognitive space order find out the best supplier This work analyses performance firms using different decision making patterns which define the way clients select their suppliers Four decision making patterns are observed when firms make decisions using only their own past experiences when they consider also others experiences when they rely reputations assigned suppliers and finally when they make decision randomly Results show that decision making patterns based others experiences and reputation are more profitable but that they are extremely sensitive opportunist behaviours 
8901 en inContext Coupling and Sharing Context for Collaborative Teams Present team members have difficulties keeping the relations between their various concurrent activities due the lack suitable tools supporting context coupling and sharing Furthermore collaboration services are hardly aware related context team members and their activities Such awareness required adapt the dynamics collaborative teams this paper discuss the context coupling techniques provided the inContext project Utilizing the concept activity based context and Web services techniques can couple individual and team contexts runtime thus improving the context awareness and adaptation collaboration services such email shared calendars instant messaging and document management 
8902 en Introduction the Session This session will show the results the work the project project Integrated Project funded the IST programme the European Commission 6th Framework with budget EUR million and project partners aims boost the use ICT promote rural development According this strategic goal will identify develop and validate technological responses actual barriers jeopardizing the sustainable development rural areas The project works Living labs different countries and manages different kind activities the rural environment including traditional and new economic activities rural areas The project developing products and services different sectors This session will present the results and findings the framework the project the products and services developed but also the methodologies developed the project 
8903 en Enhancing Open Service Oriented Architecture with Collaborative Functions for Rural Areas Development rural European areas face many barriers The Collaboration Rural project aims remove these barriers through Collaborative Technologies adopted among Rural Living Labs across Europe and substantially contribute the definition user centric Open Collaborative Architecture The paper presents the threefold Open Service Oriented Architecture approach System Software Architecture and Practical Implementation levels show that collaborative functions can orchestrated and instantiated tailored process using service broker that can register and manage them introducing control and data planes and domain concept the architecture easily addresses different business models more natural way compared other software platforms service architectures also illustrate how the Software Architecture principles and specific components discussed are instantiated the Spanish and South African Rural Living Labs 
8905 en The multiple side collaborative working Foscati Living Lab
8906 en Living Labs Fostering Open Innovation and Rural Development Methodology and Results Rural living labs constitute new and not yet validated approach enabling user driven ICT based innovation initiatives geared towards economic and social development rural areas the same time living labs provide context for open innovation based partnerships between all stakeholders This paper discusses methodologies and strategies for developing launching and operating rural living labs for innovative collaborative working environments and presents initial results from the Integrated Project Three living labs cases are presented and compared Homokháti Hungary Sekhukhune South Africa and Cudillero Spain The process establishing the living lab the involvement users the experimentation and innovation processes and the technical and business innovations and their impacts the rural environment are being discussed order conclude about effective methodologies and strategies Such methodologies and strategies include the establishment stakeholder platforms the creation user communities the cyclic and spiral approach innovation and the action research style participative development Initial results indicate that order successful such methodologies and strategies must strongly tailored the local situation 
8915 en Introduction the workshop Concurrent enterprising and especially the new waves innovation collaborative networks are the key issues the ICE conference 2008 The education related aspects essential topic prepare the future professionals the increasing cooperative dimension every business fields This workshop addresses the issues related cooperation collective design education methods tools sociological aspects and The papers relate different design experiments performed across Architecture students France Portugal Germany and Canada The workshop aims bring together discuss and improve the innovative pedagogical scenarios and stimulate pedagogical network innovative cooperation teaching methods 
8916 en Collaborative and Virtual Architectural Design Second Life FINC experiment
8918 en Stimulating Collaborative Behaviour Design Education
8919 en Critical Success Factors and Challenges develop new Sustainable Supply Chains India based Swiss Experiences
8920 en COIN Project Introduction 2020 enterprise collaboration and interoperability services will become invisible pervasive and self adaptive knowledge and business utility disposal the European networked enterprises from any industrial sector and domain order rapidly set efficiently manage and effectively operate different forms business collaborations from the most traditional supply chains the most advanced and dynamic business ecosystems nThe COIN project developing ICT integrated solution order make enterprise collaboration and interoperability services available business utility for European networked enterprises The objective the COIN workshop present Enterprises Interoperability and Enterprise Collaboration scenarios selected among the most promising cases Europe with the aim collecting additional use requirements and initial implementation roadmaps based real industrial and socio economic contexts 
8921 en The COIN Metaphore for Industry
8922 en COIN Results Market Context Targets
8923 en Coin end user VEN Healthcare
8924 en Collaboration and Interoperability the Andalusian Aeronautical Cluster
8925 en COIN business needs from the perspective Innovative Cluster the Hungarian Association Companies IVSZ 
8926 en Early requirements collected from the end users
8928 en Increased Efficiency Customer Involvement Configuration Processes The SWOP Approach Besides higher complexity products and services trends and tendencies nowadays industries show also growing customer demand for reliable fast and cheap well individual solutions for existing problems Nevertheless optimised engineering and production processes involving multidisciplinary input dynamic working environments and multi stakeholder interests across the life cycle and supply chain products and services still have not been achieved yet Especially for complex products the configuration process getting more and more important for successful and efficient sales process addition essential for company store its technical know how centrally but make available cross departmentally Ulmer 2005 
8929 en Expected project results and use scenarios
8957 en Living Labs new ways enhance innovativeness public sector services The public sector seen play important role facilitator innovativeness and competitiveness the private sector Besides this important role the innovativeness the public sector must also promoted new ways because the new challenges facing public sector service production This paper introduces the ideas the emerging open innovation paradigm the public sector context presenting case for user involvement the public sector service development context the Lahti region Finland This paper also discusses more wider terms the emerging role the public sector not only facilitator innovativeness the private sector organisations but also target innovation policies and especially highlights new ways involve the end users public sector services producing innovations The implications for the regional innovation system RIS are also discussed 
8958 en Best Practices Innovation and Development Experiences from Five Living Lab Innovation Environments The Living Lab concept based open innovation and serves platform for different stakeholders the innovation system cities companies universities There strong emphasis user participation The aim this paper study depth the experiences Living Lab innovation environment platform qualitative case study method gain more understanding the best practices they have found their activities areas that need improvement and innovations coming out these Living Labs From the Living Labs existing Finland today five were chosen for this stud These represent different areas industry and have University Applied Sciences involved 
8959 en Supporting innovative SME innovation processes The role regional intermediaries Innovation crucial for growth highly developed regions Still remains challenge foster innovation deliberately Regional intermediaries can play important role and provide platforms that induce networks and conversations Analysis examples from Central Switzerland and from Extremadura Spain shows three patterns typical for the most innovative SME take time for creative thought break and play effect mix people with different backgrounds and ideas diverse people effect and support open and trustful communication conversation effect These effects can summarized the known cafeteria effect and used the regional level Organizations like the Lucerne University Applied Sciences Fundecyt Extremadura many other organizations can use these effects ingredients for creating innovation supportive environments where SME can experience the power break and play diverse people and open and trustful conversations 
8960 en Adaptability through open innovation complexity view selectivity Today world characterized increasing complexity uncertainty and change Several authors have found Complex Adaptive Systems CAS the basis for more suitable management models that should allow firms adapt and survive under highly complex uncertain and changing environments The incorporation external capabilities and knowledge through open innovation can increase organization adaptability because amplifies significant differences and increases the number transforming exchanges through higher interaction with external system agents However too much difference can generate large number possibilities reducing momentum for action and too many exchanges limits individual behaviour Therefore important selective that organizations pursuit adaptability through open innovation don fall into chaos using the example the Engineering and Tooling sector this paper explores the impact open innovation adaptability and the importance selectivity and knowledge brokers 
8961 en Increased Efficiency Customer Involvement Configuration Processes The SWOP Approach Besides higher complexity products and services trends and tendencies nowadays industries show also growing customer demand for reliable fast and cheap well individual solutions for existing problems Nevertheless optimised engineering and production processes involving multidisciplinary input dynamic working environments and multi stakeholder interests across the life cycle and supply chain products and services still have not been achieved yet Especially for complex products the configuration process getting more and more important for successful and efficient sales process addition essential for company store its technical know how centrally but make available cross departmentally Ulmer 2005 
8962 en Monitoring and Control Collaborative Innovation Small Firms’ networks Collaborative innovations may generated and well driven strong visions and the progresses can optimised adequate monitoring and control The paper specifies verified framework for collaborative innovation for the case small firms Using the criticality concept narrows down the attributes observed minimum set The quantifications these attributes provide for reliable base for control and decision procedures ensuring the progress well the optimisation collaborative innovations The value bundles all observable result characteristics for control interventions that allow the set efficient process control for collaborative innovation 
8963 en Context recognition the wearIT work project
8964 en The next big things mobile computing
8965 en  Approach Systemic Innovation Information Technology for Emergency Response
8966 en Does Wearable Computing Really Empower the Mobile Worker – findings from ethnographic studies
8969 en The Role Collaborative Working Environments Enabling Global Business Tukej treba dodat folder gareis rcw kot part dva videa noter Sta dva avtorja eno predavanje delov nnnnnThe objective this paper based early results the New Global study explore how globalisation markets and industries affects the way companies are operating and collaborating and investigate the opportunities which global networking and global collaborative working opens for market players including Europe large number SMEs core focus how ICT enabled collaborative working environments CWE enable global operations and working Based investigation current trends and developments this paper explores various types collaboration settings which CWEs enable new forms global collaboration teams networks and communities Initial results case studies are presented identify policies and strategies which could applied promote global collaboration European companies 
8984 en Semantic Web Services Foundation for Enterprise Interoperability
8987 en What sustainable innovation and why emerging markets 
8989 en Applying Serious Games for Supporting Idea Generation Collaborative Innovation Processes The ideation process often called the fuzzy front end innovation one the most crucial steps when starting industrial and especially collaborative innovation processes There are numerous creativity techniques like brainstorming used this early phase This paper introduces another approach based Serious Gaming game structure the ideation process refQuest has been developed and briefly described Two early evaluations have been performed the University Bremen order verify that the approach supports idea generation structured approach and get overview strengths and weaknesses for further enhancements The approach used for this early evaluation the refQuest game prototype was based three different types input the observation and the exchange information between the facilitator and the player questionnaires comprising questions the functionality the utility and the usability the software well questions dealing with the idea generation process and direct observations during the game 
8990 en Computer Related Inventions particular Business Methods Examination the European Patent Office
8991 en “Experiences projects with Emerging Markets for Sustainable Innovation
8996 en How European SMEs use ICT engage Global Virtual Collaboration
9020 en Automated detection electrocardiographic diagnostic features through interplay between Spatial Aggregation and Computational Geometry Within the medical domain Functional Imaging providesnmethods for effectual visualization diagnostically relevantnnumeric fields spatially referenced measurements ofnvariables related organ functions Unveiling the salientnphysical events that underly functional image most appropriatelynaddressed feature extraction methods that exploitnthe domain specific knowledge combined with spatialnrelations multiple abstraction levels and scales The identificationnof specific patterns that are known characterizenclasses pathologies provides important support thendiagnosis disturbances and the assessment organ functions nIn this work focus Electrocardiographic diagnosisnbased epicardial activation fields This kind data nwhich can now obtained non invasively from body surfacendata through mathematical model based reconstruction methods ncan hit electrical conduction pathologies that routine surfacenECGs may miss However their analysis interpretationnstill requires highly specialized skills that belong few experts nGiven epicardial activation field the automated detectionnof salient patterns grounded the existing interpretationnrationale would represent major contributionntowards the clinical use such valuable tools whose diagnosticnpotential still largely unexplored focus epicardialnactivation isochronal maps which convey informationnabout the heart electric function terms the depolarizationnwavefront kinematics approach grounded the integrationnof Spatial Aggregation method with conceptsnborrowed from Computational Geometry provides computationalnframework extract from the given activation data few basic features that characterize the wavefront propagation nas well more specific set diagnostic featuresnthat identify important class heart rhythm pathologies nnamely reentry arrhythmias due block conduction nKeywords Biomedical imaging functional imaging imagenbased diagnosis spatial aggregation computational geometry nelectrocardiography cardiac electrical function 
9021 en Computing Human Like Qualitative Topological Relations via Visual Routines core problem spatial reasoning finding appropriate set relationships compute This paper proposes that humans represent topological relationships between regions using three basic qualitative relations contains intersects and overlaps with show how these relations can computed from sketched inputs using model mid level perception Results from pilot experiment indicate that these three relationships suffice explain people judgments four English spatial terms “intersects” “overlaps” “connects ” and “contains” although combination the three generally required for each term 
9022 en Commonsense Inference Dynamic Spatial Systems “Phenomenal and Reasoning Requirements” Spatial changes within environment are typicallyna result interaction— actions and events—noccurring within Reasoning about such changes nwhen dealt with formally within the context ofnqualitative spatial calculi and logics action andnchange poses several difficulties along multiple dimensions phenomenal requirements stemmingnfrom the dynamic nature the spatial system nappearing and disappearing objects reasoningnrequirements abductive explanation ndomain independent epistemological persistence nramification and aspects concerningnthe need satisfy the intrinsic axiomatic propertiesnof the spatial calculi compositional consistency nbeing modelled This paper encompassingnthe phenomenal and reasoning aspects nand respectively presents some instances thatndemonstrate the role commonsense reasoningnand the non monotonic inference patterns necessitatesnwhilst representing and reasoning about dynamicnspatial systems general 
9023 en Factored Envisioning Envisioning has been used extensively model behaviornof physical systems Envisioning generatesnthe qualitatively distinct possible behaviors withoutnnumerically simulating every possible set ofninput conditions and model parameters This papernapplies envisioning analyze course actionn COA diagrams determine the qualitativelyndistinct outcomes military operations ordernto avoid the combinatorial explosion possiblenstates this envisioner factors non interactingnunits into separate envisionment threads The envisionernuses Assumption Based Truth Maintenancento further limit combinatorial explosion and estimatenprobability outcomes illustrate the performancenof the factored envisioner variety ofnexamples provided military experts analyzenits scaling performance and demonstrate its abilitynto track operations from sparse observations 
9024 en Automated Critique Sketched Designs Engineering Designers often use series sketches explain how their design goes through different states modes achieve its intended function Learning how create such explanations turns out difficult problem for engineering students tomated crash test dummy let students practice explanations would desirable This paper scribes how carry out core piece the reason ing needed such system show how open domain sketch understanding system can used enter many aspects such explanations and how qualitative mechanics can used check the plausibility the intended state transitions The system evaluated using corpus sketches based designs from engineering school sign communications course 
9025 en Learning and Reasoning with Qualitative Models Physical Behavior Building models the physical world from examples important challenge for qualitative reasoning systems describe system that can learn intuitive models physical behaviors from corpus multimodal multi state stimuli consisting sketches and text The system extracts and temporally encodes exemplars from the stimuli and uses analogical generalization abstract prototypical behaviors Using statistical analysis the system parameterizes these abstractions into qualitative representations for reasoning show that the explanations the system provides for new situations are consistent with those given naïve students Keywords Cognitive modeling conceptual change misconceptions naïve physics qualitative reasoning
9026 en Intelligent Authoring ’Graph Microworlds’ for Adaptive Learning with Microworlds science education important sequence set ofnmicroworlds which means system and its model limitednfrom educational viewpoint various complexitynadaptively the context learning previouslynproposed Graph Microworlds GMW frameworknfor indexing set microworlds based their models nBy using GMW possible adaptively selectnthe microworld student should learn next and assistnhim transferring between microworlds However nit isn’ easy describe GMW because author mustnhave the expertise the process modeling thisnresearch propose method for semi automating thendescription GMW introducing the compositionalnmodeling mechanism Our method assists authornin generating set indexed microworlds and also innconsidering educational meanings the relations betweennthem present how design such functionnand also illustrate how works preliminary testnwith prototype system showed the effectiveness ournmethod 
9027 en Application qualitative reasoning models the scientific education deaf students Regarding the education deaf students Brazil threenconditions have met order bring qualitativenreasoning models into the classroom bilingualneducation should provided the Brazilian Sign Languagen LIBRAS being the first and Portuguese the secondnlanguage the absence scientific vocabulary innLIBRAS has created given the auralnimpairment which cognitively compensated through annover developed visual ability visually oriented pedagogynis needed This paper describes how qualitative reasoningnmay provide adequate scenario create vocabulary innsign language for representing scientific concepts whilenoffering support for the integration visually orientednmodels and simulations and written Portuguese inneducational activities nKey words qualitative models deaf science education
9028 en Closeness and Distance Relations Order Magnitude Qualitative Reasoning via PDL The syntax semantics and axiom system for extensionnof Propositional Dynamic Logic PDL for order magnitudenqualitative reasoning which formalizes the concepts ofncloseness and distance introduced this paper doingnthis use some the advantages PDL firstly exploitnthe possibility constructing complex relations fromnsimpler ones for defining the concept closeness and othernprogramming commands such while and repeat nuntil secondly employ its theoretical support order tonshow that the satisfiability problem decidable Moreover nthe specific axioms our logic have been obtained from thenminimal set formulas needed our definition qualitativensum small medium and large numbers also presentnsome the advantages our approach the basis annexample 
9029 en Incorporating Qualitative Equations Process Based Models This paper explores the possibility extending Processbasednmodels with Qualitative differential equations nProcess based modeling modeling technique that usesntwo level approach for modeling dynamical systems Itnmodels systems purely qualitative level terms ofnentities and processes that involve those entities onenhand and quantitative level which all entities andnprocesses are given quantitative formulation which thatnautomatically translated into set ordinary differentialnequations This paper aims illustrate that this formalismncan extended with intermediate level modelingnwhich consists qualitative equations 
9030 en Using Qualitative Reasoning Modelling Consensus Group Decision Making Ordinal scales are commonly used rating and evaluationnprocesses These processes usually involve group decisionnmaking means experts’ committee this paper anmathematical framework based the qualitative model ofnthe absolute orders magnitude considered The entropynof qualitatively described system defined this framework nOn the one hand this enables measure the amountnof information provided each evaluator and the othernhand the coherence the evaluation committee The newnapproach capable managing situations where the assessmentngiven experts involves different levels precision nThe use the proposed measures within automatic systemnfor group decision making will contribute towards avoidingnthe potential subjectivity caused conflicts interestsnof the evaluators the group 
9031 en Model Building Experiences using Garp3 Problems Patterns and Debugging Capturing conceptual knowledge models becomingnof interest larger audience domain experts nConsequently have been training severalngroups effectively create models during the lastnfew years this paper describe our teaching experiences nthe issues the modellers encountered and thensolutions solve them the form reusable patterns nand finally structured way debug models 
9032 en Dark Knowledge Qualitative Reasoning Call Arms While people qualitative reasoning there amplenevidence that they not always well Two currentncrises human induced climate change and the financialnmeltdown can traced part faulty mental models nThe community has formalisms that can potentially helpnwith public education about such problems but far wenhave not been very successful doing claim thatnpart the reason that current accounts notnadequately incorporate experiential knowledge arguenthat important find better ways improve publicnqualitative reasoning abilities part helping peoplenenlist their experience based models via analogy 
9033 en Order Magnitude Based Link Analysis for False Identity Detection Combating identity fraud crucial and urgent false identitynhas become the common denominator all seriousncrime including mafia trafficking and terrorism Typical approachesnto detecting the use false identity rely thensimilarity measure textual and other content based characteristics nwhich are usually not applicable the case deceptivenand erroneous description This barrier can overcomenthrough link information presented communicationnbehaviors financial interactions and social networks Quantitativenlink based similarity measures have proven effectivenfor identifying similar problems the Internet and publicationndomains However these numerical methods only concentratenon link structures and fail achieve accurate andncoherent interpretation the information Inspired thisnobservation this paper presents novel qualitative similaritynmeasure that makes use multiple link properties refinenthe underlying similarity estimation process and consequentlynderive semantic rich similarity descriptors The approachnis based order magnitude reasoning Its applicabilitynand performance are experimentally evaluated over anterrorism related dataset and further generalized with publicationndata 
9034 en QCM Based Concept Map System Qualitative representations have proven usefulnformalisms for capturing human mental models result nqualitative modeling could become important tool forncognitive science Specifically environment whichnqualitative representations can used explore mentalnmodels and different type reasoning and simulations cannbe performed these models can useful tool forncognitive scientists this paper introduce thenQualitative Concept Map system designed for cognitivenscientists for building and simulating qualitative andnBayesian models using qualitative process theory andnBayesian inference 
9035 en Qualitative approximation Dynamic TimeWarping similarity between time series data Dynamic time warping DTW method for calculatingnthe similarity between two time series which cannoccur different times speeds Although its effectivenessnmade very popular several disciplines itsntime complexity makes useful only fornrelatively short time series this paper proposena qualitative approximation Qualitative Dynamic TimenWarping QDTW DTW QDTW reduces time seriesnlength transforming qualitative time series nDTW later calculated between qualitative time series nAs qualitative time series are normally much shorternthan their corresponding numerical time series time toncompute their similarity significantly reduced Experimentalnresults have shown improved running time upnto three orders magnitude while prediction accuracynonly slightly decreased 
9036 en  qualitative model the salmon life cycle the context river rehabilitation qualitative model was developed Garp3 capture andnformalise knowledge about river rehabilitation and thenmanagement Atlantic salmon population The modelnintegrates information about the ecology the salmon lifencycle the environmental factors that may limit the survivalnof key life stages and links with human activities such asnagriculture habitat rehabilitation and fishing The overallnaim the model was explore the effects rehabilitationnin the context complete life cycle scenario Thenscenarios and simulations produced were able explorenthese processes the context complete life cycle but atnthis scale the simulations were time consuming Therefore nin addition these scenarios series smallerndemonstrator scenarios were developed that succinctlynexplored individual concepts within the system 
9037 en Evaluating the potential Qualitative Reasoning capture and communicate knowledge sustainable catchment management This paper presents the potential use QualitativenReasoning capture and communicate knowledge onnsustainable catchment management Based case study nqualitative models dealing with issues sustainablendevelopment riverine landscapes were developed andnimplemented using the Garp3 software following generalnmodeling framework The evaluation the models and thenQR approach students and experts revealed the highnpotential models capture and communicatencomplex knowledge understandable and interestingnmanner mainly due the ability the presented approachnto capture qualitative system dynamics and integrate ‘hard’nand ‘soft’ facts structured way the future library ofnexpert models might serve important source ofninformation for both education and management 
9038 en Assessing the Ecological Impacts Agriculture Intensification Through Qualitative Reasoning How feed the world without loosing what left ofnbiodiversity Two answers for this question are found thenliterature the one hand the “Land Sparing” paradigmnsuggests that increasing yield means intensive agriculturalnsystems would fulfill the needs human population and savennatural landscapes the other hand “Biodiversity FriendlynFarming” argues that agricultural intensification has deep impactsnon both biodiversity and ecosystem properties and suggests thatnnon intensive farming practices keep the ecological balance andnstill may produce large quantities high quality food foodnsecurity This work presents Qualitative Reasoning modelnthat compares the impacts intensive and non intensivenagriculture water resources biodiversity and productivity Thensimulations show the inefficiency intensive agriculture innprotecting water resources and biodiversity and the efficiency ofnnon intensive approach terms food production andnecosystem conservation 
9082 en Learning Hierarchical Architectures from Neuroscience Derived Kernels Understanding the processing information our cortex significant part understanding how the brain works arguably one the greatest problems science today particular our visual abilities are computationally amazing computer science still far from being able create vision engine that imitates them Thus visual cortex and the problem the computations performs may well good proxy for the rest the cortex and for intelligence itself will briefly review our work developing hierarchical feedforward architecture for object recognition based the anatomy and the physiology the primate visual cortex These architectures compete with state the art computer vision systems they mimic human performance specific but difficult natural image recognition task will sketch current work aimed extending the model the recognition behaviors time sequences images and accounting for attentional effects inhuman vision will then describe new attempt with Smale Rosasco and Bouvrie develop mathematics for hierarchical kernel machines centered around the notion recursively defined derived kernel and directly suggested the model and the underlying neuroscience the visual cortex 
9083 en More Data Less Work Runtime Monotonically Decreasing Function Data Set Size are used studying runtime increasing function the data set size and are happy when this increase not bad when the runtime increases linearly even polynomiall with the data set size Traditional runtime analysis learning also viewed this way and studies how training runtime increases more data available However considering the true objective training which obtain good predictor will argue that training runtime should actually studied decreasing function training set size Focusing training Support Vector Machines SVMs and combining ideas from optimization statistical learning theory and online methods will then present both theoretical and empirical results demonstrating how simple stochastic subgradient descent approach indeed displays such monotonic decreasing behavior will also discuss similar phenomena the context Gaussian mixture clustering where appears that excess data turns the problem from computationally intractable computationally tractable Joint work with Shai Shalev Shwartz Karthik Sridharan Yoram Singer Greg Shakhnarovich and Sam Roweis 
9084 en  Finding Low Error Clusterings There has been substantial work approximation algorithms for clustering data under distance based objective functions such median means and min sum objectives This work fueled part the hope that approximating these objectives well will indeed yield more accurate solutions That for problems such clustering proteins function clustering images subject there some unknown correct target clustering and the implicit assumption that clusterings that are approximately optimal terms these distance based measures are also approximately correct terms error with respect the target this work show that make this implicit assumption explicit that assume that any approximation the given clustering objective Phi epsilon close the target then can produce clusterings that are epsilon close the target even for values for which obtaining approximation hard particular for the median means and min sum objectives show that can achieve this guarantee for any constant Our results shows how for these clustering objectives one can get much better guarantees accuracy than those implied results obtained far the approximation literature wisely using all the available information for the problem hand 
9086 en Analysis Clustering Procedures Clustering procedures are notoriously short rigorous guarantees this tutorial will cover some the types analysis that have been applied clustering and emphasize open problems that remain Part Approximation algorithms for clustering Two popular cost functions for clustering are center and means Both are hard optimize exactly Algorithms for approximately optimizing these cost functions Hierarchical versions such clusterings Clustering when data arriving streaming online manner Part Analysis popular heuristics How good means How fast Probabilistic analysis What approximation ratio achieved agglomerative heuristics for hierarchial clustering Part III Statistical theory clustering What aspects the underlying data distribution are captured the clustering finite sample from that distribution Consistency means The cluster tree and linkage algorithms Rates for vector quantization 
9087 en The Stability the Contour Orientable Manifold Think the view the boundary solid shape projection manifold Its apparent contour the projection the critical points Generalizing the projection smooth mappings manifold get the contour the image the points which the derivative not surjective Measuring difference with the erosion distance the Hausdorff distance between the complements prove that the contour stable Along the way introduce the now well established method persistent homology including the stability its diagrams well extension using zigzag modules Joint work with Dmitriy Morozov and Amit Patel 
9088 en  Theory Similarity Functions for Learning and Clustering Kernel methods have become powerful tools machine learning They perform well many applications and there also well developed theory what makes given kernel useful for given learning problem However this theory requires viewing kernels implicit and often difficult characterize maps into high dimensional spaces this talk will describe work developing theory that just views kernel measure similarity between data objects and describes the usefulness given kernel more general similarity function terms fairly intuitive direct properties how the similarity function relates the task hand without need refer any implicit spaces will also talk about extension this framework learning from purely unlabeled data clustering particular one can ask how much stronger the properties similarity function should terms its relation the unknown desired clustering that can used cluster well learn well without any label information all find that are willing relax the objective bit for example allow the algorithm produce hierarchical clustering that will call successful some pruning close the desired clustering then this question leads number interesting graph theoretic and game theoretic properties that are sufficient cluster well This work can viewed defining kind PAC model for clustering This talk based work joint with Maria Florina Balcan Santosh Vempala and Nati Srebro 
9089 en  Bahadur Type Representation the Linear Support Vector Machine and its Relative Efficiency The support vector machine has been used successfully variety applications Also the theoretical front its statistical properties including Bayes risk consistency have been examined rather extensively Taking another look the method investigate the asymptotic behavior the linear support vector machine through Bahadur type representation the coefficients established under appropriate conditions Their asymptotic normality and statistical variability are derived the basis the representation Furthermore direct theoretical comparison made with likelihood based approach classification such linear discriminant analysis and logistic regression terms the asymptotic relative efficiency where the efficiency classification procedure defined using the excess risk from the Bayes risk 
9090 en Fitting Graph Vector Data ask What the right graph fit set vectors propose one solution that provides good answers standard Machine Learning problems that has interesting combinatorial properties and that can compute efficiently Joint work with Jonathan Kelner and Samuel Daitch 
9091 en  Overview Compressed Sensing and Sparse Signal Recovery via Minimization many applications one often has fewer equations than unknowns While this seems hopeless the premise that the object wish recover sparse nearly sparse radically changes the problem making the search for solutions feasible This lecture will introduce sparsity key modeling tool together with series little miracles touching many areas data processing These examples show that finding that solution underdetermined system linear equations with minimum norm often returns the right answer Further there now well established body work going the name compressed sensing which asserts that one can exploit sparsity compressibility when acquiring signals general interest and that one can design nonadaptive sampling techniques that condense the information compressible signal into small amount data fewer data points than were thought necessary will survey some these theories and trace back some their origins early work done the Because these theories are broadly applicable nature the tutorial will move through several applications areas that may impacted such signal processing bio medical imaging machine learning and Finally will discuss how these theories and methods have far reaching implications for sensor design and other types designs 
9092 en Spectral Graph Theory Linear Solvers and Applications discuss the development combinatorial methods for solving symmetric diagonally dominate linear systems Over the last fifteen years the computer science community has made substantial progress fast solvers for SDD systems For general SDD systems the upper bound log for some constant where the number non zero entries due Spielman and Teng Newer methods combinatorial multigrid have linear time guarantee for the planar case and work very well practice Critical the use these new solvers has been the reduction problems the solution SDD systems present some these reductions including several from image processing 
9093 en Cheeger Cuts and Spectral Clustering Spectral clustering has become recent years one the most popular clustering algorithm this talk discuss generalized version spectral clustering based the second eigenvector the graph Laplacian non linear generalization the graph Laplacian The clustering obtained for can seen interpolation the relaxation the normalized cut and the Cheeger cut However the main motivation for spectral clustering the fact that one can show that the cut value obtained thresholding the second eigenvector the Laplacian converges towards the optimal Cheeger cut tends will also present efficient implementation which allows spectral clustering for large scale datasets 
9094 en Multiscale Geometry and Harmonic Analysis Data Bases describe method for geometrization databases such questionnaires lists sensor outputs Interlacing multiscale diffusion geometries rows and columns data matrix results pair language ontologies which are mutually supportive certain words are used certain contexts This mutual geometry serves structure Harmonic Analysis and signal processing the database will illustrate databases audio music psychological questionnaires science documents images and many others Joint work with Mata Gavish Yale University 
9095 en Graphical Models for Speech Recognition Articulatory and Audio Visual Models Since the 1980s the main approach automatic speech recognition has been using hidden Markov models HMMs which each state corresponds phoneme part phoneme the context the neighboring phonemes Despite their crude approximation the speech signal and the large margin for improvement still remaining HMMs have proven difficult beat the last few years there has been increasing interest more complex graphical models for speech recognition involving multiple streams states will describe two such approaches one modeling pronunciation variation the result the sloppy behavior articulatory variables the states the lips tongue etc and the other modeling the audio and visual states audio visual speech recognition recognition enhanced lipreading 
9096 en Semi Supervised Learning This tutorial covers classification approaches that utilize both labeled and unlabeled data will review self training Gaussian mixture models training multiview learning graph transduction and manifold regularization transductive SVMs and PAC bound for semi supervised learning then discuss some new development including online semi supervised learning multi manifold learning and human semi supervised learning 
9097 en Matrix Completion via Convex Optimization Theory and Algorithms This talk considers problem considerable practical interest the recovery data matrix from sampling its entries partially filled out surveys for instance would like infer the many missing entries the area recommender systems users submit ratings subset entries database and the vendor provides recommendations based the user preferences Because users only rate few items would like infer their preference for unrated items this the famous Netflix problem Formally suppose that observe entries selected uniformly random from matrix Can complete the matrix and recover the entries that have not seen show that perhaps surprisingly one can recover low rank matrices exactly from what appear highly incomplete sets sampled entries that from minimally sampled set entries Further perfect recovery possible solving simple convex optimization program namely convenient semidefinite program surprise that our methods are optimal and succeed soon recovery possible any method whatsoever matter how intractable this result hinges powerful techniques probability theory Time permitting will also present very efficient algorithm based iterative singular value thresholding which can complete matrices with about billion entries matter minutes personal computer 
9098 en Drifting Games Boosting and Online Learning Drifting games provide new and useful framework for analyzing learning algorithms this talk will present the framework and show how used derive new boosting algorithm called RobustBoost and new online prediction algorithm called NormalHedge will present two sets experiments using these algorithms synthetic and real world data The first set demonstrates that RobustBoost can learn from mislabeled training data The second demonstrating application NormalHedge the tracking moving objects 
9099 en Recent Progress Combinatorial Statistics will discuss some recent progress combinatorial statistics particular will describe progress the areas reconstructing graphical models estimation the Mallows model and diagnostics MCMC 
9100 en MAP Estimation with Perfect Graphs Efficiently finding the maximum posteriori MAP configuration graphical model important problem which often implemented using message passing algorithms and linear programming The optimality such algorithms only well established for singly connected graphs such trees Recently along with others have shown that matching and matching also admit exact MAP estimation under max product belief propagation This leads consider generalization trees matchings and matchings the fascinating family called perfect graphs While MAP estimation general loopy graphical models for perfect graphs particular form the problem This result leverages recent progress defining perfect graphs the strong perfect graph theorem which has been resolved after decades linear programming relaxations MAP estimation and recent convergent message passing schemes particular convert any graphical model into called nand Markov random field This model straightforward relax into linear program whose integrality can established general testing for graph perfection This perfection test performed efficiently using polynomial time algorithm Alternatively known decomposition tools from perfect graph theory may used prove perfection for certain graphs Thus general graph framework provided for determining when MAP estimation any graphical model has integral linear programming relaxation and exactly recoverable message passing 
9101 en Inference for Networks great deal attention has recently been paid determining sub communities the basis relations corresponding edges between individuals corresponding vertices out unlabelled graph Neman SIAM Review 2003 Airoldi JMLR 2008 Leskovec Kleinberg SIGKDD 2005 for probabilistic ergodic models infinite unlabelled graphs drive consistency properties the Newman Girvon index and develop index with better consistency properties and better performance simulated data sets This joint work with Aiyou Chen 
9102 en Cocktail Party Problem Binary Classification Speech segregation the cocktail party problem has proven extremely challenging Part the challenge stems from the lack carefully analyzed computational goal While the separation every sound source mixture considered the gold standard argue that such objective neither realistic nor what the human auditory system does Motivated the auditory masking phenomenon have suggested instead the ideal time frequency binary mask main goal for computational auditory scene analysis Ideal binary masking retains the mixture energy units where the local signal noise ratio exceeds certain threshold and rejects the mixture energy other units Recent psychophysical evidence shows that ideal binary masking leads large speech intelligibility improvements noisy environments for both normal hearing and hearing impaired listeners The effectiveness the ideal binary mask implies that sound separation may formulated case binary classification which opens the cocktail party problem variety pattern classification and clustering methods example discuss recent system that segregates unvoiced speech supervised classification acoustic phonetic features 
9103 en Machine Learning Acoustic Signal Processing This tutorial presents framework for understanding and comparing applications pattern recognition acoustic signal processing Representative applications will delimited two binary features regression classification inferred variables are continuous discrete instantaneous dynamic Regression problems include imaging and sound source tracking using device with unknown properties and inverse problems articulatory estimation from speech audio Classification problems include the detection syllable onsets and offsets speech signal and the classification non speech audio events Instantaneous inference performed using universal approximator neural network Gaussian mixture kernel regression constrained regularized necessary reduce generalization error resulting support vector machine shrunk net pruned tree boosted classifier combination Dynamic inference methods apply prior knowledge state transition probabilities either the form regularization term using Bayesian inference the form set constraints using linear programming both examples include speech text transcription acoustic articulatory inversion using switching Kalman filter and computation the query presence probability audio information retrieval task 
9104 en Nonlinear Dimension Reduction Spectral Connectivity Analysis and Diffusion Coarse Graining For naturally occurring data the dimension the given input space often very large while the data themselves have low intrinsic dimensionality Spectral kernel methods are non linear techniques for transforming data into coordinate system that efficiently reveal the geometric structure particular the connectivity the data this talk will focus one particular technique diffusion maps and diffusion coarse graining the construction based Markov random walk the data and offers general scheme simultaneously reorganizing and quantizing graphs and arbitrarily shaped data sets high dimensions using intrinsic geometry show that clustering embedding spaces equivalent compressing operators and that the quantization distortion diffusion space bounds the error compression the operator thus giving rigorous justification and precise measure performance means clustering spectral embedding spaces will discuss two particular applications diffusion coarse graining One application choosing appropriate set prototype similar stellar population SSP spectra for parameter estimation star formation history galaxies The other example texture discrimination novel geometry based metric distributions Part this work joint with Coifman Lafon Richards and Schafer 
9314 en Warm for BCI Physiology Basic Concepts the Transition from Cellular Microrecordings Noninvasive Large Scale EEG MEG Signals Macroscopic brain sigals the noninvasively measured scalp EEG MEG correlate with mental states such movement intentions This opens new communication channel for paralyzed patients their intentions can read computers and utilised for triggering technical devices This entry level tutorial will provide intuitive introduction into the relevant brain anatomy and physiology and describe typical procedures well potential pitfalls when obtaining and analysing multichannel EEG MEG data 
9315 en Machine Learning and Signal Processing Tools for BCI will first provide brief overview Brain Computer Interface from machine learning and signal processing perspective particular showing the wealth the complexity and the difficulties the data available truly enormous challenge real time multi variate very strongly noise contaminated data stream processed and neuroelectric activities are accurately differentiated will then detail discuss the components the data analysis chain employed modern BCI systems spanning all aspects from preprocessing and feature extraction adaptive fixed classification and feedback design 
9316 en About Learning Predictions and Adaptivity Brains and Machines Using useful signals from the brain and useful computer algorithms improve brain machine interfaces will talk about the physiology motor cortex and the nature activity population neurons motor cortex during Sensorimotor learning movement preparation and execution will present the approach internal models the brain the basis for learning and perception and use all the above show how our current knowledge can facilitate approaches adaptive brain machine interfaces 
9317 en Theory and Application Electrocorticographic ECoG Signals Humans Brain computer interfaces BCIs convert brain signals into outputs that communicate user intent BCIs can used people communicate and interact with their environment However the prevailing non invasive and invasive sensor methods have important limitations Electrocorticographic ECoG recordings from the surface the brain could robust and high fidelity alternative existing sensor methods This tutorial will provide overview the history ECoG recordings describe the types signals present ECoG and their relationship signals detected using EEG and intracortical microelectrodes and finally give examples successful use these signals real time for BCI purposes and also for diagnosis 
9318 en What the Plan Movement Goal Representations the Frontoparietal Reach Network When planning goal directed arm movements the sensorimotor system needs integrate the current behavioral context with given spatial constraints define and maintain motor goals are interested how this integration achieved within the sensorimotor network Specifically tested the respective roles the dorsal premotor cortex PMd and the parietal reach region PRR defining and planning context specific reach goals 
9319 en Brain Machine Interfaces Based Neuronal Ensemble Recordings Brain machine interfaces BMIs have experienced explosive development during the last decade Current state the art BMIs convert neuronal ensemble activity recorded nonhuman primates human subjects into reaching and grasping movements performed artificial actuators BMIs that enact movements lower extremeties are less explored Additionally most BMI implementations not have somatosensory feedback from the actuator will review our recent experiments which extracted bipedal locomotion patterns from monkey cortical activity and used spatiotemporal patterns intracortical microstimulation deliver information back the brain These results bring closer building clinical neuroprosthetic devices for restoration both sensory and motor functions paralyzed people 
9320 en Plasticity the Brain Computer Interface Next generation recurrent Brain Computer Interfaces will not only extract signals from cortical activity but also deliver feedback the nervous system via electrical stimulation For example stimulation cervical spinal segments can produce functional arm and hand movements such reaching and grasping are developing new technologies including chronic electrodes and implantable electronic circuitry control stimulation from cortical recordings constituting artificial corticospinal connection which could replace injured motor pathways will present evidence that the motor system can readily acquire the novel neuromotor transformations required incorporate these connections into motor system function separate experiments have shown that operation artificial connections can potentiate new motor pathways via activity dependent plasticity mechanisms Together these results suggest that recurrent BCIs have application not only prostheses replace function but also tools for manipulating plastic reorganisation restore nervous system function following injury 
9321 en BCI Paralysis Unfulfilled Promise EEG and ECoG Electrocorticogram can used successfully initiate direct brain communication with locked patients but fail completely locked patients Possible reasons are explained and some new solutions with first data presented chronic stroke the author team together with Cohen group NIH have shown motor restoration paralysed hand chronic stroke without residual movement using non invasive MEG BCI However generalization from the BCI clinic the social reality was poor new strategy for invasive and non invasive BCI chronic stroke demonstrated and first data presented 
9322 en The Hybrid BCI There are several different BCI approaches which may may not depend external stimulation Slow cortical potential SCP event related desynchronisation ERD and sensorimotor rhythm SMR BCIs not require external stimulation while P300 BCIs and steady state visual evoked potential SSVEP BCIs Dependent means this respect that the user has focus attention and gaze flickering flashing lights and can therefore not completely freely decide perform action Each type BCI system has advantages and disadvantages SSVEP BCIs need minimal training time and can achieve high information transfer rate ITR but have relatively high false positive rate during rest contrast asynchronous brain switch based the post imagery beta ERS has low ITR but can set quickly and easily with low false position rate Pfurtscheller and Solis Escalante Clin Neurophysio 2009 therefore challenge use the advantages different BCI systems and create “hybrid” BCI system switching battery flickering lights SSVEP BCI off using brain switch ERD BCI Another type “hybrid” BCI can analyse motor imagery related EEG changes and SSVEP amplitudes simultaneously was shown recently that such “hybrid” strategy results better classification accuracy relative either ERD SSVEP classification alone Allison submitted 2009 
9323 en Feedback Regulated Mental Imagery BCI Applications Using Non Invasive EEG and NIRS Signals important issue brain computer interface BCI development detect changes brain signals that are related specific intentions thought processes For example mental motor imagery modulates the sensorimotor brain activity and the detected changes can used operate computer controlled device Clinical applications this technology include the restoration movement such control grasping with the help neuroprosthesis severely paralyzed individuals The motor imagery based BCI training may further useful complementary therapeutic tool facilitate functional recovery after stroke date the majority BCI systems rely EEG recordings However near infrared spectroscopy NIRS has recently attracted attention BCI researchers due its noninvasiveness portability short preparation time and relatively low cost this talk will shortly introduce the NIRS technique for BCI development and present data how characteristic hemodynamic responses during motor imagery can modulated real time NIRS feedback Based recent results will finally discuss how simultaneous NIRS and EEG recordings might combine advantages both approaches 
9324 en EEG Based Brain Computer Interface for Communication and Control Independent Home Use People affected severe motor disorders such amyotrophic lateral sclerosis ALS brainstem stroke cerebral palsy and spinal cord injury need alternative methods for communication and control They may not able use even the most basic conventional assistive technologies which all rely one way another muscles Studies from this and other laboratories have shown that humans including those with severe motor disabilities can learn control sensorimotor rhythms and other features scalp recorded electroencephalographic EEG activity and that they can use this control select letters icons move cursor three dimensions Such multidimensional control could used control prosthesis robotic arm Currently are showing that people with ALS can use EEG based brain computer interfaces BCIs for communication and control independently their homes 
9325 en Tackling Increasing Opthalmologic Problems Patients with New Auditory Multi Class BCI Paradigm Most P300 BCI approaches use the visual modality for stimulation and feedback Due increasing sight deterioration this might not the preferable choice for ALS patients late stages tackle this general problem multi class brain computer interface paradigm proposed that uses fast spatially distributed auditory cues for ERP paradigms 
9328 en  Robust Spelling Device for Locked Patients Based Real Time fMRI Several medical conditions brain injury stroke progressive neurological diseases can lead complete paralysis while largely preserving sensory and cognitive functions and associated brain activation investigated whether healthy subjects are able write solely the basis voluntary control the fMRI BOLD signal Using guided display technique show that subjects can learn less than half hour produce reliably any letter the alphabet single trial achieve this performance subjects use three mental strategies modulate spatio temporal properties the fMRI signal three different brain areas While the transmitted information BOLD time courses from regions interest has been initially decoded offline human raters have recently implemented fully automatized real time brain reading technique The developed paradigm and decoding technique might applied locked patients let them communicate their wishes and thoughts reliably without extensive pre training 
9330 en Modeling fMRI Dynamics Functional MRI modeling challenged long range coupling non linearity and lack detailed physiological information will review our progress modeling the spatio temporal dynamics fMRI including hemodynamic deconvolution blind deconvolution and brain state decoding based spatio temporal kernel methods 
9332 en Bernstein Focus Neurotechnology Berlin The Bernstein Focus Neurotechnology Berlin BFNT posits that neuroscientific results can exploited for developing robust ‘real world’ applications that have major potential for also non medical industry Similar the new paradigm medical research ‘from bench bedside and back’ the center brings together multidisciplinary faculty with the aim directly applying insights from basic neuroscience relevant applications ‘from bench desktop and back’ The major aim the BFNT foster novel noninvasive ‘brain reading’ techniques enhance man machine interactions Their contributions will evaluated the future oriented field usability studies for telecommunications systems and services driver assisted measures for vehicle safety 
9333 en Bernstein Focus Neurotechnology Freiburg spite considerable progress towards prosthetic devices controlled neuronal signals brain machine interfaces and other neurotechnological devices however user friendly neurotechnical devices for everyday use remain vision the future with numerous fundamental biological technical computational clinical and ethical problems still solved The aim the BCNT consortium the development bidirectional hybrid neurotechnical devices for human usage This will implemented three research clusters each consisting projects organized around common goal understand the principles advance technology and explore and extend clinical applications Each project addresses issues central neurotechnology from basic questions decoding neuronal signals interfacing biological neuronal networks technical devices actuators and real time feedback systems via the stable recording and interpretation neuronal signals the clinical testing and application new technologies Research the BCNT will supported matching interdisciplinary training program for neurotechnology collaboration with industrial applied and clinical partners neuroprosthetical devices for biomedical application will developed 
9490 en Business Cases for Enterprise Interoperability The Andalusian Aeronautics Business Case
9492 en eBIZ TCF Initiative Improve eAdoption European Textile Clothing and Footwear Industry
9493 en Debate Business Cases for Enterprise Interoperability
9494 en Business Cases for Enterprise Interoperability Collaborative Demand Capacity Planning CDCP 
9495 en iSURF – Piacenza Knitwear Business Case
9496 en Collaboration and Interoperability Production Management Ship Building Industry
9497 en The eGov Financial Reporting Business Case
9498 en Welcome the COIN4LL Workshop Unleashing Open Innovation with Enterprise Collaboration Interoperability Services the Living Lab Way 
9499 en Unleashing Open Innovation potential Living Labs Enterprise Interoperability and Collaboration Services the COIN project
9500 en Living Labs Open Innovation Functional Regions
9502 en Methodologies for Engaging Users into Research Innovation The Living Lab way Open Innovation Ecosystem
9504 en  Science Base initiative state play from the Commission
9505 en Task Force Enterprise Interoperability Science Base
9506 en  the Scientific Basis Enterprise Interoperability
9507 en Towards Semantic Interoperability Evolving Environment
9508 en Dealing with Interoperability Agent Oriented Perspective
9510 en System Theory support Enterprise Interoperability Science Base
9511 en Towards science Considerations and points view
9512 en Breeding Business Success West midlawos collaborative commerce marketplace
9533 en Multi Strategy Trading Utilizing Market Regimes This video considers the problem dynamically allocating capital portfolio trading strategies nThe allocation should robust and the capital allocated trading strategy should reflectnthe confidence the expected profit that the strategy will make current market conditions nGood trading strategies exploit recurring market dynamics that can more prevalent some timenperiods than others Indeed the concept regimes fundamental financial markets and muchnresearch has focused the detection regime shifts this paper consider regime definednby set trading strategies that exhibit similar performance given time period nWe consider different parameterizations the same strategy distinct our ground set strategies nThe trading problem pick distribution over the ground set that will achieve good performancenin the current time period That typically choose distribution support greater thannone reflects uncertainty many levels and allows diversification risk and return drivers nWe provide simple algorithm that empirically picks distributions that often approximate the performancenof oracle that picks the best trading strategy each period from the ground set Tonthis end explicitly define regimes subsets strategies initial phase rule out largennumber regimes irrelevant counter the combinatorial explosion dealing with subsets nIn the training phase our algorithm pick random time windows and learn two functions thenfirst classifyMarket for probabilistic regime classification and takes input the market datanand produces distribution over regimes the second stFuncDist produces for each regime distributionnover strategies where strategies believed good that regime are assigned highernprobability The main tools use are Monte Carlo permutation tests and incremental weightingnof probabilities the trading phase use standard “walk forward” approach the samplenperiod use the trading results for regime classification and the out sample period allocatencapital according the combination classifyMarket determined from the sample period andnthe current stFuncDist This simple algorithm but empirically successful one indicationnof which report The approach bears some similarity Sequential Monte Carlo methods innthat sequentially weights hypotheses our case regarding suitability strategies nIn the final section discuss approach modelling the time evolution strategy fitnessesnwith view towards characterizing regimes This could used guide our choice samplenof out sample periods the existing setup present preliminary results this direction Inncurrent work are trying extend the basic algorithm such way that can more directlynmake use the Sequential Monte Carlo method such particle filter based estimation strategynfitness that might parsimoniously accomplish what done above with permutation tests 
9534 en The More Rating New Model comparative analysis different companies from different countries This video discusses specific model for assessing credit risk Industrialncompanies using financial statement data and industry specific information nIn particular the model permits each enterprise associate fundamental creditnrating giving indication the creditworthiness industrial companies 
9537 en Dynamic Portfolio Management with Transaction Costs develop recurrent reinforcement learning RRL system that directly inducesnportfolio management policies from time series asset prices and indicators nwhile accounting for transaction costs The RRL approach learns direct mappingnfrom indicator series portfolio weights bypassing the need explicitlynmodel the time series price returns The resulting policies dynamically optimizenthe portfolio Sharpe ratio while incorporating changing conditions and transactionncosts key problem with many portfolio optimization methods includingnMarkowitz discovering ”corner solutions” with weight concentrated just anfew assets dynamic context naive portfolio algorithms can exhibit switchingnbehavior particularly when transaction costs are ignored this work extendnthe RRL approach produce better diversified portfolios and smoother assetnallocations over time The solutions propose are include realistic transactionncosts and shrink portfolio weights toward the prior portfolio The methodsnare assessed global asset allocation problem consisting the Pacific NorthnAmerica and Europe MSCI International Equity Indices 
9538 en Modelling decimalisation the Nasdaq stockmarket
9540 en The Effect Reinforcement Learning Agents Double Auction Markets Several time series models such ARCH and GARCH have been developed forecast volatilitynusing asset returns data However these methods ignore one key source market volatility financialnnews Similarly asset pricing models often describe the arrival novel information jumpnprocess but the characteristics the underlying jump process are only coarsely all related tonthe underlying news source Our objective this paper show that recent advances statisticalnlearning allow much more refined analysis the impact news asset prices nIn this paper demonstrate that information from press releases can used predict intradaynabnormal returns with relatively high accuracy form text classification problem wherenpress releases are labeled positive the absolute return jumps some fixed time after the newsnis made public First abnormal returns are predicted using support vector machines similar fashionnto Given press release predict whether not abnormal return will occur thennext 250 minutes using either text past absolute returns Our experiments analyze predictabilitynat many horizons and demonstrate significant initial intraday predictability that decreasesnthroughout the trading day Second optimally combine text information with asset price timenseries significantly enhance classification performance using multiple kernel learning MKL Wenuse analytic center cutting planemethod ACCPM solve the resultingMKL problem ACCPMnis particularly efficient problems where the objective function and gradient are hard evaluatenbut whose feasible set simple enough that analytic centers can computed efficiently Furthermore nbecause does not suffer from conditioning issues ACCPM can achieve higher precisionntargets than other first order methods 
9541 en Machine Learning Based Prediction Financial Markets Forecasting models generally very poor job predicting future returns financial markets whichnare characterized high levels noise commonly known that predictions typical autoregressiventime series forecasting models for example are usually very conservative – meaning close the mean –nbecause the inherent difficulty making accurate forecasts This situation particularly discouragingnsince the large future values that especially care about predicting accurately Machine learningnmethods provide potential solution this problem providing multiple models that each whichnmakes forecasts different magnitudes The obvious problem with this approach overfitting nespecially the learner has constraints how complex its models can this talk present thentradeoffs between increased the model complexity and forecast accuracy based mix trading resultsnand current research 
9542 en Modelling Financial Time Series using Grammatical Evolution The traditional models price and its statistical signatures are often based onnlimiting assumptions such linearity Moreover the model developer facednwith the model selection problem and model uncertainty this paper introducena method based Grammatical Evolution evolve models fornpredicting financial returns and examine the profitability these models Ournempirical analysis demonstrates that for some securities our method able producenmodels return that are lead more profitable trading compared with annAutoregressive model picked using Aikake Information Criterion AIC under thenassumption frictionless markets 
9544 en Modeling Dependence Financial Data with Semiparametric Archimedean Copulas Copulas are useful tools for the construction multivariate models because theynallow link univariate marginals into joint model with arbitrary dependencenstructure While non parametric copula models can have poor generalization performance nstandard parametric copulas often lack expressive capacity capturenthe dependencies present financial data this work propose novelnsemiparametric bivariate Archimedean copula model that expressed termsnof latent function This latent function approximated using basis naturalnsplines and the model parameters are selected maximum penalized likelihood nExperiments financial data are used evaluate the accuracy the proposednestimator with respect other benchmark methods Two flexible estimators ofnArchimedean copulas previously introduced the literature two approaches forncopula estimation that allow for more general dependencies and three parametricncopulas models The proposed semiparametric copula model has excellent andnout sample performance which makes useful tool for modeling multivariatenfinancial data 
9548 en Empirical Portfolio Selection Dark pools are relatively recent type equities exchange whichntransparency deliberately limited order minimize the marketnimpact large volume trades The success and proliferation dark npools has also led challenging and interesting problem innalgorithmic trading namely optimizing the distribution large ntrade over multiple competing dark pools this work formalizenthis problem multi venue exploration from censored data andnprovide provably efficient and near optimal algorithm for its solution nThis algorithm and its analysis has much common with well studiednalgorithms for exploration exploitation reinforcement learning andnis evaluated dark pool execution data from large brokerage 
9549 en Dynamic Asset Allocation for Bivariate Enhanced Index Tracking using Sparse PLS Index tracking popular portfolio management strategy which involves creating portfolio whosenreturns track very closely those achieved benchmark index There are two interconnected problemsnassociated with index tracking asset selection and asset allocation Asset selection involvesnselecting subset out available assets whereas asset allocation involves investing proportionnof the total available capital each one the assets with the objective reproducing thenperformance the index The capital invested asset proportion the total capital thatnPpni These portfolio weights are generally estimated minimzing the tracking error thatnis the error between the index returns and the portfolio returns ˆy given 1PTnt ˆyt nFollowing this setting the problem asset allocation becomes standard regression problem withnthe portfolio weights being the parameters estimated nIn the literature only few attempts have been made tackle both the asset selection and allocationnproblems the same time for instance use quadratic programming approach and the methodnin based genetic algorithms Our interest lies taking unified approach which simultaneouslynselects subset assets the available basket and minimizes the tracking error take anregularized regression approach full index replication scenario asset selection can thoughtnof assigning certain assets zero weight that those assets are not included the portfolio nwhereas the selected one should able reproduce the index These ideas have recently beennexploited the context minimum variance portfolios and penalized least squares have beennproved promising method for creating robust portfolios see also the related work nWe extend these ideas three main ways Firstly consider multivariate version the indexntracking problem where the selected portfolio expected reproduce the performance multiplenindices Secondly are interested enhanced versions the indices tracked that thenportfolio also expected overperform each index given annual percentage return say plusn15 Thirdly propose methodology that works well real time and fully adaptive thensense that both the asset allocation and optimization solutions can updated recursive manner nkeeping the number computations low every time new data points are made available Thisnlast feature makes the methodology more robust against non stationarities presented the data andnyelds superior tracking results before transaction costs 
9551 en Are markets efficient view from micro structural data Efficient market theory posits that market prices reflect any instant time the fundamental value assets and can only change because unpredictable news other information items that affect this fundamental value true well systematic quantitative strategies should not work But course this picture cannot strictly hold – for one thing someone should process information and push the price towards its putative true value There should least some kind tatonnement and arbitrage opportunities high frequencies order dissect these possible mispricing mechanisms and devise profitable high frequency trading and execution models the detailed study order flow and order books has become mandatory nnMuch physics where the detailed understanding the microscopic world provides invaluable insight macroscopic phenomena believe that consistent picture the microstructure mechanisms will help put perspective some the traditional questions about markets and prices such “Are prices equilibrium ” “What the information content these prices ” “Why the volatility high ” will also allow one optimize execution costs which for large AUMs mostly due impact nnEmpirical data reveals unexpectedly subtle price formation mechanism Order flow turns out highly persistent long memory process both sign and volume This reflects the fact that even very liquid markets the revealed liquidity fact extremely small typically 001 the market cap stock Large orders buy sell can only traded incrementally over periods time long months Hence prices cannot instantaneously equilibrium and cannot instantaneously reflect all available information There nearly always substantial offset between latent offer and latent demand that only slowly gets incorporated prices nnMaintaining compatibility with market efficiency has profound consequences price formation the dynamics liquidity and the nature impact anonymous electronic markets there cannot any distinction between “informed” trades and “uninformed” trades The average impact all trades must the same which means that impact must have mechanical origin everything otherwise held constant the appearance extra buyer seller must average move the price down nnnA body theory that makes detailed quantitative predictions about the volume and lag dependence market impact the bid ask spread order book dynamics nand volatility has been recently put forth This framework allows one make quantitative models execution costs terms time dependent non local friction kernel nnIt also suggests novel interpretation financial information The theory rational expectations and efficient markets has increasingly emphasized information and belittled the role supply and demand contradiction with the intuition traders and the layman Our recent work the role news price jumps also shows that information the traditional sense not the main driver market volatility Rather highlight the role fluctuations supply and demand which may may not exogenous and may may not informed – does not really matter Attempts estimate post the fraction truly informed trades actually leads very small numbers least judged short time basis meaning that the concept informed trades not very useful understand what going markets high frequencies But still prices manage almost perfectly unpredictable even very short time scales The conclusion that any useful notion information must internal the market trades order flow cancellations are information whatever the final cause these events may 
9553 en Predicting Abnormal Returns From News Using Text Classification
9554 en Modeling the 500 Index using the Kalman Filter and the LagLasso This video introduces method predict upward and downward monthly variationsnof the 500 index using pool macro economic and financialnexplicative variables The method based the combination denoisingnstep performed Kalman filtering with variable selection step performednby Lasso type procedure particular propose implementation thenLasso method called LagLasso which includes selection lags for individual factors nWe provide promising backtesting results the prediction model based annaive trading rule 
9579 en QCA and fuzzy sets This course examines the family configurational comparative methods CCM First the course spells out the fundamental concepts that underlie the configurational comparative approach the framework the general literature comparative empirical social research participants are made familiar with issues such concept formation truth tables basic Boolean algebra ideal types and property spaces Then participants are trained use the most widely used the CCM far dichotomous Qualitative Comparative Analysis csQCA The practical steps and best practices csQCA including software use TOSMANA and QCA are taught first the basic procedures then various refinements The course concluded with overview linked developments such fuzzy set QCA fsQCA and multi value QCA mvQCA and the combination QCA with other methods Real life published applications are used throughout the course participants are also encouraged bring their own data available Some basic quantitative qualitative methodological training probably useful get more out the course but participants with little methodological training should find major obstacles follow the course Above all participants should motivated engage rigorous comparative analysis 
9580 en Multiple regression analysis The course starts with discussion the logic the multivariate regression model and the central assumptions underlying the ordinary least squares approach Then proceeds with testing for the adequacy the assumptions and suitable corrections and extensions the estimation techniques the context cross sectional data Particular emphasis will laid multicollinearity and heteroskedasticity The second part the course focuses functional form Models that are nonlinear variables but linear parameters dummy variables and interaction terms will covered the third part various topics arising with special data are covered Firstly the analysis binary dependent variables introduced Secondly problems involved with the analysis longitudinal data time series and panel data are discussed with special emphasis autocorrelation The course assumes proficiency with descriptive and inferential statistics the level test theory and bivariate regression analysis 
9581 en Mixed methods research This interactive course provides new and seasoned researchers with framework step step manner for using quantitative and qualitative research approaches within the same study The instructor will provide many published examples and illustrate how conduct mixed methods research using both statistical software such SPSS and qualitative software such QDA Miner Participants will able understand the historical underpinnings mixed methods research define and explain mixed methods research its current form describe the major steps the mixed methods research process identify goals and objectives for mixed methods research studies identify mixed methods techniques for conducting literature reviews identify the rationale and purpose for mixing quantitative and qualitative approaches design mixed methods research questions describe the role sampling the mixed methods research process compare and contrast several mixed methods research designs describe several ways collecting data mixed methods research studies conduct mixed methods data analyses link research questions mixed methods data analysis techniques identify how make quality meta inferences explain the major legitimation types mixed methods research and understand issues and standards involved conducting reporting and publishing mixed methods research 
9582 en Creative Environment and Young Researchers Performance The Keys PhD Students Success The results the study also conducted Hajdeja Igli Franc Mali Uro Mateli nand Petra Ziherl presented this lecture confirm other empirical results obtained bynsociological research the activities research groups Hemlin Allwood Martinn2004 creativity research productivity young researchers strongly influenced intrasocialnfactors such autonomy flexibility cooperation etc More precisely this studynconfirms that the micro level the relationships among the researchers especially betweennthe young researcher and his her mentor play important role for the young researcher snscientific performance This especially true the phase the socialisation andnprofessionalisation young scientists during the research 
9583 en ‘Creative Environment and Young Researchers’ Performance The Keys PhD After the lecture and reaction from the discussant open debate will held with thenaudience both substantive and methodological issues 
9586 en Computer Verified Exact Analysis This tutorial will illustrate how use the Coq proof assistant implement effective and provably correct computation for analysis Coq provides dependently typed functional programming language that allows users specify both programs and formal proofs nnWe will introduce dependent type theory and show how can used develop both mathematics and programming will show how use dependent type theory implement constructive analysis Specifically will cover how implement effective real numbers and effective integration nnThis work will done using the Coq proof assistant The tutorial will cover how use the Coq proof assistant Attendees are encouraged download and install Coq from http coq inria download and also download and make the full system CoRN from http corn download html beforehand 
9664 en The Evolutions Cybercrime the Email the Species still more Deadlier than the Mail This talk will discuss the implications technology for criminal behaviour and its control The first part will briefly outline how networked technology has transformed transforming crime crime control policing and surveillance will chart the development cybercrime through three generational changes from discrete computers systems dial modem access broadband will then map out the significant transformations and the challenges they create especially the need deal with informationalized networked and globalised small impact bulk victimisations that not fall within the routine activities and experiences criminal justice systems and the professionals who work within them nnThe second part will explore recent developments cybercrimes that are continuing challenge criminal justice systems For example dial computer networking became common place during the late 1990s the practice bulk spamming through their content and also attachments were arguably the most prevalent form online victimisation The prevalence spamming proliferated dramatically from mid 2003 onwards following the advent broadband and the growth botnets robot networks remotely administered infected computers However more recent years have experienced the emergence new forms victimization online which are showing interesting and distinct signs evolution from their predecessors nnBotnets and the threats from spams remain prevalent but the explosion social networking sites has added potential opportunities for online victimisation Not only are the there now many more opportunities for obtaining personal information about individuals who live out large parts their lives online but these social networks can also exploited socially engineering persuading participants pass information the various nodes their personal networks These information flows can used perform more advanced forms phishing expeditions deed the worst case scenario they can contribute mass panics through the intentionally accidental flow misinformation Not only email being surpassed the primary form threat but will suggested this talk that these new victimisations are potentially more invasive nnThe third part the talk will seek identify some the new developments networked technology that could used initiate future online attacks the future These include ambient technologies new generations Radio Frequency Identity Tags but also the impact governmental and commercial policies which increase our reliance upon technology Whilst some these predictions may speculative one thing remains certain cybercrime not absolute concept – will not eradicated rather relative online business and social opportunities and therefore function that opportunity consequence cybercrime will never eradicated the best that can hope achieve that can prevented through social information quickly potential exploits operating and financial systems can identified this end need develop new methodologies for understanding change happens and also explore the various relationships between technology and law the process regulating harmful behaviour online 
9672 en Online Child Pornography European and Hungarian Perspective
9824 en Privacy Web Search Query Log Mining Web search engines have changed our lives enabling instant access information about subjects that are both deeply important well passing whims The search engines that provide answers our search queries also log those queries order improve their algorithms nAcademic research search queries has shown that they can provide valuable information diverse topics including word and phrase similarity topical seasonality and may even have potential for sociology well providing barometer the popularity many subjects the same time individuals are rightly concerned about what the consequences accidental leaking deliberate sharing this information may mean for their privacy this talk will cover the applications which have benefited from mining query logs the risks that privacy can breached sharing query logs and current algorithms for mining logs way prevent privacy breaches 
9825 en Theory Practice Interplay Machine Learning – Emerging Theoretical Challenges Theoretical analysis has played major role some the most prominent practical successes statistical machine learning However mainstream machine learning theory assumes some strong simplifying assumptions which are often unrealistic the past decade the practice machine learning has led the development various heuristic paradigms that answer the needs vastly growing range applications Many useful such paradigms fall beyond the scope the currently available analysis Will theory play similar pivotal role the newly emerging sub areas machine learning nIn this talk will survey some such application motivated theoretical challenges particular will discuss recent developments the theoretical analysis semi supervised learning multi task learning “learning learn” privacy preserving learning and more 
9826 en Highly Multilingual News Analysis Applications The publicly accessible Europe Media Monitor EMM family applications http press jrc overview html gather and analyse average 000 100 000 online news articles per day languages Through the extraction meta information these articles they provide aggregated view the news they allow monitor trends and navigate the news over time and even across languages EMM NewsExplorer additionally collects historical information about persons and organisations from the multilingual news generates occurrence and quotation based social networks and more All EMM applications were entirely developed and are being maintained the European Commission’ Joint Research Centre JRC Ispra Italy nnThe applications make combined use variety text analysis tools including clustering multi label document classification named entity recognition name variant matching across languages and writing systems topic detection and tracking event scenario template filling and more Due the high number languages covered linguistics poor methods were used for the development these text mining components See the site http langtech jrc for technical details and list publications nnThe speaker will give overview the various applications and will then explain the workings selected text analysis components 
9827 en The Growing Semantic Web From its beginnings 2004 the data available the web Semantic Web formats has typically been both eclectic and relatively small and closely linked the interests particular researchers the past year however the quantity and scope data published the public semantic web has exploded and the size the semantic web now measured the billions assertions significant and growing resource for applications which depend web based resources for some all their knowledge With this massive increase quantity and scope come many opportunities well the usual issues scale the web inconsistency mapping problems incompleteness and data variability This talk will cover the history and current state the Semantic Web and the Linked Data Cloud describe some the uses which web based semantic data currently put and discuss prospects for the ECML PKDD community leverage this growing web data 
9828 en Are There Yet Statistical approaches Artificial Intelligence are behind most success stories the field the past decade The idea generating non trivial behaviour analysing vast amounts data has enabled recommendation systems search engines spam filters optical character recognition machine translation and speech recognition celebrate the spectacular achievements this line research need assess its full potential its limitations and its position within the larger scheme things What are the next steps take towards machine intelligence 
9983 en Artificial Business Intelligence Scaling Beyond the Real World with Cyc and LarKC the last few years significant advancement has been achieved semantic knowledge and context technologies well methods for knowledge management These technologies are becoming especially effective when applied the capture formalization and automated reuse knowledge particular these techniques have been demonstrated Cycorp specific intelligence and medical domains Equally though they may applied problems managing business complexity provide ABI Artificial Business Intelligence nThe explosion availability free and open information resources following the emergence the Web2 paradigm has widened the prospects for constructing real Artificial Intelligence solutions that are able learn reason and speculate nnIn talk discuss the general class problems that should solvable the near term part exploiting available knowledge and part collaboration between people and machines show some examples partial solutions and describe some detail the components more complete solution The discussion will focus the issue scaling techniques real applications both terms very large inferentially sophisticated knowledges bases like Cyc and terms techniques for web scale inference the goal the FP7 LarKC project 
9984 en Link Mining Statistical machine learning the midst relational revolution After many decades focusing independent and identically distributed iid examples researchers are now studying problems which the examples are linked together into complex networks These networks can simple sequences and meshes such those arising part speech tagging and remote sensing complex the collaboration structures produced knowledge workers performing variety tasks different contexts within enterprise this talk will give overview this newly emerging research focusing specifically link mining tasks and algorithms 
9985 en Text Mining and Light Weight Semantics
9986 en Informal Knowledge Processes The Long Tail Business Processes
9987 en Lizzon Professional Messaging Utility for Distributing Relevant Information within Enterprise Real Time
9988 en Taking Anysite com the Next Level with SEO Web Analytics Testing Data Mining Targeting Forecasting and Web Personalization
9989 en Introduction the ACTIVE Knowledge Workspace SDK This session will provide short introduction into the ACTIVE knowledge workspace with online demonstration the basic Workspace features nWorkspace software architecture will overviewed and then the ACTIVE Software Developer Kit will presented SDK usage example the scenario for developing ACTIVated application will explained 
9990 en  Cabinet Web Scientific Curiositics
9991 en  Future Internet Cloud Computing and Semantics You Name This presentation will present various developments the Internet Services Research the Internet Services put the context ongoing research the Future Internet The role semantics this research domain will also illustrated addition this presentation will consider industry relevance focusing well known business models based Software Service and Cloud Computing number business strategies will discussed well Some glimpses future research will also given 
9992 en Semantic Technology Business Systems Status and Prospects
9994 en Research Directions Enterprise Knowledge Management
9995 en The Intelligent Cargo Concept the European Project EURIDICE
9996 en  the Customer Front Line The Case Study ACTIVE
10001 en Opening speech Pozdravni nagovor
10005 en The Emergence Life Earth Mystery Scientific Problem Nastanek ivljenja Zemlji misterij ali znanstveni problem Until the end the 19th century the origin life Earth was explained either the creative act god the result spontaneous generation – the repeated formation complete organisms from inanimate matter Only within evolutionary conception following Darwin theory could the origin life the ancient Earth begin studied scientifically Scientists still didn find empirical answer this difficult question and are divided the nature the first systems emerge They agree however that natural selection was actively involved the process They are also united rejecting the creationistic claims and supporting the naturalistic worldview nIzvor ivljenja vse konca stoletja razlagali ali kot stvarstvo ali kot rezultatnspontanega nastanka torej kot ponovni nastanek celotnih organizmov ive snovi ele znevolucijskim konceptom sledil Darwinovi teoriji eli preu evati znanstveno nRaziskovalci vedno niso empiri nega odgovora vpra anje delijo glede nanprepri anje pojavu prvih sistemov Kljub vsemu strinjajo bil naravni izbor aktivno vklju ennv proces Enakega mnenja tudi pri zavra anju kreacionisti nih razlag pri podpiranjunnaturalisti nega svetovnega nazora 
10006 en The Major Transitions Evolution Veliki prehodi evoluciji Some major transitions evolution such the origin multicellular organisms that social animals occurred number times whereas others the origin the genetic code language seem have been unique events One must cautious with the word ‘unique’ however Due lack the ‘true’ phylogeny all extinct and extant organisms one can give only operational definition all the extant and fossil species which possess traits arising from particular transition share last common ancestor after that transition then the transition said unique Obviously quite possible that there had been independent “trials” were but not have comparative fossil evidence for them 
10010 en The Gene Context from Developmental Plasticity Plastic Heredity Gen kontekstu razvojne plasti nosti plasti nega dedovanja The gene centered view according which genes are the most important determinants development the sole stuff biological heredity and the guide for the understanding all aspects evolution has dominated biological thinking for the last years This view now changing this lecture point the perils “genetic astrology” – predicting the future and analyzing personality the basis DNA sequencing present developmental approach biology and evolution which stresses the importance phenotypic plasticity and which incorporates epigenetic inheritance This approach points the many sources developmental and hereditary variations answers some the puzzles that the gene centered approach failed solve and leads more satisfying and fertile biological outlook and research nZadnjih petdeset let biolo kem razmi ljanju prevladuje genocentri pogled kateremnso geni najpomembnej dejavnik vpliva ontogenetski razvoj organizmov edina osnova zanbiolo dedovanje vodilo razumevanje vseh vidikov evolucije pogled zadnjem asunspreminja tem prispevku bom izpostavila nevarnosti genetske astrologije napovedujenprihodnost analizira osebnost podlagi zaporedja DNA Predstavila bom razvojni pogled nanbiologijo evolucijo poudarja pomen fenotipske plasti nosti vklju uje epigenetsko dedovanje nTak pristop poka mnogo vzrokov ontogenetske dedne raznolikosti odgovori nekaterenuganke jih genocentri pogled obeta zadovoljivej plodnej raziskovanje vnprihodnosti biologije 
10011 en Cooperation – Successful Principle the Living World Sodelovanje med organizmi kot princip ivih sistemih dana njega zornega kota lahko emo nobena ival pre ivi brez posebnih sodelujo ihnpartnerjev nekaterih primerih taka sodelovanja celo spremenila Zemljo prinesla novenpokrajine Torej niso bile vpletene samo populacije vrste temve veliko sistemi biocenoze nekosistemi pokrajine vklju obse nimi obmo oceanskega dna nNadalje sodelovanje omogo tudi prebavo sodelovanje posebno izrazito pri termitih jihnnaseljujejo enoceli karji nahajajo posebnem delu revesja karji sodelovanju znbakterijami omogo ajo razgradnjo lignina umrejo karji tudi termiti pre ivijo Podobnonpre vekovalci razgrajujejo celulozo hrani Migetalkarji ivijo njihovih elodcih omogo ajo – snpomo bakterij – prebavljivost hrane Danes splo znano prehranjevalnem traktu lovekan ivi prokariontov kot vseh celic telesu Lahko teli veliko podobnih primerov nSklenemo lahko vse ivali prebavlajnje potrebujejo prisotnost sodelovanje drugihnorganizmov njihovih prebavilih mnogih primerih sodelovanje vodi isto nov razvoj Najbolj prepri ljiv primer aji sonsestavljeni gliv enoceli nih alg ali cianobakterij aji ivijo skoraj vseh kopenskihnekosistemih vklju Antarktiko uspevajo morski obali lahko tudi vodni nRaznolikost dana njih cvetnic bila mogo brez opra itve posebno elkami kot tudi pti inin sesalci Cvet opra evalec sta skozi dolgo skupno evolucijo Veliko cvetov potrebuje zelonposebne opra evalce teh opra evalcev lahko rastline izumrejo nPrenos transport primer obse sodelovanje Mrtva telesa iztrebki morajo razkrojiti kon nega produkta minerali tako ekosistemi ostanejo nepo kodovani Mrtva telesa iztrebki privla ijo mnogo elk imajo druge pomembne organizme nujno potrebni razkroj obenem jih pripeljejo naslednjega izvora hrane Hro prena ajo gliste ice kot tudi bakterije tako omogo ajo zaprtje biokemijskega kroga nNa koncu podmena Nobena ival vklju dana njim lovekom sposobna pre iveti breznmedvrstnega sodelovanja kriti nem stanju vsi lahko soo imo globalnimi okoljskiminproblemi 
10014 en Evolution and How Microbes See Evolucija vidika mikrobov With the beginning life under early Earth condition the microorganisms developed metabolic pathways for energy regeneration and carbon assimilation Due stepwise improvements new developments were introduced resulting finally microbial life forms today more less stable geochemical cycles and remarkable changed world For humankind very minor fraction today’ microorganisms can cause medical problems Most them are essential members the ecosystem World and for human beings directly indirectly great importance Nevertheless there are several new habitats introduced which are invaded them and where they cause major problems etkom ivljenja pogojih zgodnji Zemlji mikroorganizmi razvili metabolnenpoti pridobivanje energije asimilacijo ogljika postopnimi izbolj avami razvijali novenlastnosti emur sledili razmah mikrobnih oblik ivljenja kot poznamo danes bolj ali manjnstabilni geokemi cikli spremenjen svet zdravje love tva nevaren zelo majhenndel dana njih mikroorganizmov ina jih pomembnih gradnikov svtovnega ekosistema sonneposredno ali posredno izjemno pomembni loveka nazadnje naselili nekatera novanprebivali smo jih razvili tam lahko povzro ajo resne ave
10020 en Urban Ecology Why Increasingly Important Topic Urbana ekologija – zakaj njen pomen pove uje Land use changes due rapidly increasing urbanization pose major threat ecosystems and their functions worldwide the end this decade more than half the world human population will living cities and other urbanized areas Human induced habitats loss and fragmentation the landscape well accumulation trace gases and other pollutants serve the best known examples negative impacts dense human population the surrounding environment Land use changes can seen analogous soil use well developed old soils are replaced functionally altered soils even completely new substrates called “made lands” Such conversion land and soils urban use likely translate into changes soil biota thereby distorting life supporting ecosystem services such decomposition organic matter cycling nutrients and detoxification harmful substances Urban soils are traditionally described being highly artificial and disturbed although soils urban parks and gardens can share many features typical agricultural even natural soils One the key factors distinguishing urban soils from natural soils their high spatial heterogeneity the various ecological patterns and processes This high heterogeneity manifests parks cemeteries vacant lots streams and lakes gardens and yards campus areas golf courses bridges air ports and landfills These habitats are highly dynamic influenced both biophysical and ecological drivers the one hand and social and economic drivers the other Active management green spaces vital but seldom sufficient there also need protect restore and manage surrounding ecosystems order maintain ecosystem services value for human well being and build resilience the urban landscape nRecent climate models predict precipitation increase under various climatic conditions especially heavily urbanized areas Combined with increasing proportion sealed impermeable surfaces urban settings the growing trend rain events are likely cause anomalies hydrological cycles typical example the increased quantity and worsened quality urban runoff waters “street waters” this presentation urban runoff waters will dealt indicator the ecological health urbanized habitats Furthermore the typicalities urban natural ecosystems are compared and some examples the ongoing urban ecological studies Finland will presented nZaradi hitro nara ajo urbanizacije prihaja sprememb rabi zemlji kar predstavljanpomembno gro njo ekosistemom njihovemu delovanju irom svetu konca tega desetletja bonve kot polovica svetovne populacije ivela mestih drugih urbaniziranih obmo jih Habitati jihnspreminja lovek izguba fragmentacija pokrajine kot tudi spro anje plinov sledovih drugihnonesna evalcev slu ijo kot najbolj znani primeri negativnih vplivov goste love populacije nanokolje Spremembe rabi zemlji lahko gledamo kot izrabo tal dobro razvita stara prstnnadome funkcionalno spremenjeno prstjo ali celo povsem novim substratom tako imenovanon umetno zemljo Tak spreminjanje zemlji potrebe urbane uporabe najverjetneje vodi vnspremembe ivljenju prsti tako poru ivljenjske podporne mehanizme ekosistema kot sonrazgradnja organskih snovi kro enje hranil razstrupljanje kodljivih snovi Zemljo urbanihnobmo jih navadi opisujejo kot umetno prizadeto vendar prst mestnih parkih innvrtovih lahko zelo podobna kmetijski ali celo naravni prsti Eden glavnih dejavnikov katerih senzemlja mestih tiste naravi zunaj mest velika prostorska heterogenost razli nih ekolo kihnvzorcev procesov Visoko heterogenost ejo okolja kot parki pokopali gradbi potoki innjezera vrtovi dvori univerzitetna naselja igri golf mostovi letali smeti Tinhabitati zelo dinami nanje eni strani vplivajo biofizikalni ekolo dejavniki druginstrani socialne ekonomske nje Aktivno upravljanje zelenih prostorov zelo pomembno nvendar redko zadostuje treba ititi obnavljati upravljati tudi okoli nje ekosisteme zato senvzdr ujejo podporne storitve ekosistemih pomembne blagostanje ljudi omogo ajonpro nost urbane krajine nZadnji klimatski modeli napovedujejo pove anje koli ine padavin razli nih klimatskih pogojih enposebno urbaniziranih obmo jih povezavi vedno jim dele zatesnjenih nneprepustnih povr urbanih okoljih zelo verjetno nara ajo trend povzro ilnanomalije hidrolo kih ciklih Tipi primer tega pove ana koli ina poslab ana kakovostnurbanih povr insko odtekajo voda uli vode tej predstavitvi bodo urbane odto vodenuporabljene kot kazalnik ekolo kega zdravja urbanih ivljenjskih okolij Nadalje bodo predstavljeninprimerjava zna ilnosti urbanih naravnih ekosistemov ter nekaj primerov potekajo urbanihnekolo kih tudij Finskem 
10022 en The Young Charles Darwin Student Naturalist and Gardener Mladi Charles Darwin – tudent naravoslovec vrtnar Charles Darwin was one the most important scientists who ever lived was born 1809 200 years ago Shrewsbury Shropshire England was fortunate have wealthy father who was doctor and part intelligent and educated family lived large house called ‘The Mount’ with servants and large garden the edge the town and open countryside had developed strong interest natural history before attended his first school the age eight having been taught previously his mother brother and sisters Many poor children his age never had the opportunity attend school However was unfortunate because his mother died soon after started day school was sent Shrewsbury Grammar School boarder for seven years where studied Latin and Greek but little that interested him Science was not taught schools that time but Charles developed his knowledge collecting natural history specimens and helping his older brother with Chemistry experiments home was not exceptional child school but his father taught him about observation recording and analysis information the garden and surgery assisting with his patients and diagnosing illnesses This prepared him for Edinburgh University where studied become doctor but ‘dropped out’ because did not like operations dissections and was sent Cambridge University train for The Church become priest However both Edinburgh and Cambridge disliked lectures preferring read about the subjects books and spent most his time having good time with his friends and collecting beetles However worked hard enough pass examinations and achieved good Bachelor Arts Degree first step becoming clergyman That career path was cut short because had impressed influential professors and lecturers who admired his scientific prowess time when the study natural history studying the wonders God’ Creation was considered appropriate pastime for clergyman was recommended for the role ship’ naturalist the survey ship ‘The Beagle’ because his natural history skills and because was ‘ gentleman’ the right social background the captain’ companion His self motivated study plants animals and rocks commenced child Shrewsbury and encouraged last perceptive teachers propelled him into new direction However his five year voyage The Beagle around the world and his subsequent life research would have been impossible his father had not supported him financially and later when married invested large sum money the income from which supported his research wife and family had been raised one parent family and did not well school where his interests were dismissed waste time However had the support his family and eventually university found the support teachers who recognised his potential nCharles Darwin bil eden najpomembnej znanstvenikov zgodovine Rodil letan1809 pred 200 leti Shrewsburyju okraju Shropshire Angliji Dobro popotnico munpredstavljali premo poklicu zdravnik ter izobra ena razgledana dru ina iveli nanobrobju mesta veliki imenovani »The Mount« Gora slu abniki velikim vrtom nNaravoslovje Charlesa elo zanimati pou evali mati brat sestre preden prinosmih letih obiskovati olo Mnogi revnej otroci tedaj olanja sploh niso pri tudinmalemu Charlesu bilo lahko saj kmalu vstopu olo umrla mati Sedem let prebil nangimnaziji Shrewsburyju kjer bival internatu Tam latin ino ino ninpreve zanimalo Naravoslovnih predmetov tedaj olah niso pou evali Charles svojennaravoslovno znanje razvijal sam med drugim tudi tem doma starej emu bratu pomagal prinkemijskih poizkusih oli bil izjemen enec doma vrtu ter ordinaciji prinkirur kih operacijah diagnosticiranju bolezni opazovati bele iti analizirati podatke Tako senje pripravil tudij medicine Edinbur univerzi Ker maral operacij seciranja tudija nindokon Poizkusil Cambridgeu tudijem teologije Tako kot Edinburgu tudi ugotovil nda zelo odbijajo vsa predavanja raje tudiral knjig veliko asa posvetil tudi zabavi snprijatelji zbiranju hro Kljub vsemu uspe opravil izpite bil pravi poti donduhovni kega poklica vplivne profesorje svojim naravoslovnim znanjem naredil vtis nin asu veljalo naravoslovje ali »preu evanje udes jega stvarjenja« primernonprosto asno dejavnost duhovnikov Njegova nesojena duhovni kariera bila prekinjena nzaradi naravoslovnega znanja ker izhajal »primerne« dru ine predlagali »ladijskegannaravoslovca« kapitanovega spremljevalca raziskovalni ladji Beagle Vztrajno samostojnonprou evanje rastlin ivali kamnin eto otro tvu nazadnje vzpodbujeno strani dojemljivihnu iteljev pognalo novo smer Vendar njegovo petletno potovanje ladjo Beagle okoli sveta innnjegovo kasnej raziskovalno delo bila brez etove izdatne finan pomo Tudi ponCharlesovi poroki vlo veliko denarja investicije prihodki katerih Charles pla eval svojenraziskovalno delo vzdr eval dru ino Odrasel enostar evski dru ini olah kjer njegovonzanimanje naravoslovje ozna ili izgubo asa bil preve uspe Kljub temu vselej imelnpodporo dru ine kasneje univerzi vendarle tudi razumevanje podporo iteljev sonprepoznali njegove zmo nosti 
10026 en Biological Education for the 21st Century Educating the Next Generation for Tomorrow’ Society Biolo izobrazba stoletje Izobra evanje nove generacije dru prihodnosti Against the background changing world and major developments biological sciences this paper addresses two overarching questions What can biological education contribute the general education young people 21st Century and How might approach biological education order meet the future demands society argues that teaching about and through biology can contribute the general education young people enabling them become successful learners confident individuals and responsible citizens Furthermore outlines some principles guide the development the biology curriculum emphasises the importance young peoples’ own ideas teaching and learning and highlights the key role formative assessment considering biological education for 21st Century the paper emphasises the need for different sectors government education science and industry work together the need develop creative approaches pedagogy and importantly the need hold high expectations for quality and achievement nOb spreminjajo svetu velikem napredku biolo znanosti lanku zastavljamnkrovni vpra anji Kaj lahko biolo izobra evanje prispeva splo izobrazbi mladih stoletju nin Kako naj zasnujemo biolo izobra evanje ustrezalo prihodnjim potrebam dru Snpou evanjem biologiji skozi biologijo lahko prispevamo splo izobrazbi mladih bodonuspe ili ter postali samozavestne osebe odgovorni avljani Poleg tega predstavljam nekaterensmernice razvoj nih rtov biologijo pomen lastnih predstav mladih pri pou evanju enjunter klju vlogo sprotnega preverjanja znanja biolo izobra evanje stoletju pomembninsodelovanje med razli nimi sektorji vlado izobra evanjem znanostjo industrijo razvojnustvarjalnih pristopov pedagogiki ter visoka pri akovanja kakovosti dose kih encev 
10096 en Crime Conflict and the Racialization Criminal Law The scars from riots American cities the late 1960s remain visible today not onlynin the physical landscape few stubbornly poor cities but philosophy and jurisprudencenof criminal law that has instantiated the disparate fates racial minoritiesnin the criminal justice system The riots took place the midst profound social andneconomic restructuring the nation’ cities and the outset epidemic risingnrates crime and disorder that framed both new political order and profoundntransformation American criminal law and criminal procedure Within the decade anpolitical and legal mobilization – fueled racial and cultural conflict – led abruptnreversal the substance and philosophy criminal law The ceding rights criminalndefendants and the increasing regulation police the early 1960s gave way throughna series cascading court decisions and new laws punitive regime that over threendecades has expanded the authority police curtailed the procedural rights criminalndefendants and supported policies that have sustained widening racial gap innincarceration new body criminal laws though facially race neutral have had profoundnracial consequences that are durable and sustainable even low crime era PartnI this paper discusses the antecedents contexts and dynamics this turn criminalnlaw focusing the racial dynamics that exploded wave riots Part examinesnthe development the new legal order analyzing the reversal law through series ofncourt decisions over two decades Part III examines how the use race neutral laws tonachieve crime control the absence complementary models social regulation hasnproduced disparate racial impacts that have become endogenous the political order nPart discusses the challenges legal and institutional reform restore racial equalitynin criminal justice The American experience cautionary tale the limits and dangersnof criminal law manage diversity and social conflict 
10097 en Slovenia Crime Policy Time Change Traditionally Slovenia had comparatively low level violent and organized crime andncomparatively low imprisonment rate addition successfully resisted punitivenessnin all its aspects starting the level prescribed sentences and incarcerationnrates Recently however can witness several new developments its crime policy nFirst can observe the growing interest populist politics the crime policy issues nThe fear and the fight against crime has risen higher among the priorities the electionsncampaigns and every day politics Connected that the potential academianand research institutions influence crime policy decision making has been declining nas has been notably demonstrated the haste passing the new Criminal Code inn2008 Finally the becoming more and more interested harmonizing criminalnlaw and crime policy the extending criminal law powers the erode Slovenia’ sovereigntynin this respect presentation will discuss the relevance these developmentsnfor the future 
10098 en Redeeming Redemption Criminological Concept the past two decades the science criminology has focused considerable attentionnon the topic desistance from crime how and why individuals active crime “gonstraight ” This research has been instrumental the design and assessment strategiesnfor reducing recidivism through resettlement reintegration support Criminologists nhowever have had little say about the issue “redemption” what should requirenfor individuals officially forgiven their crimes and have their “good names” restored nIn this talk will outline the need for discussion secular redemption societynand discuss the implications criminological research this regard 
10099 en Slovenian Criminology Its Beginnings Development and State the Art The early beginnings the literature Slovenian Criminology back the earlyn1920s when Fran Mil inski judge with enough literary talent depict complex issuesnof law and crime published the first Slovenian novel juvenile delinquency Innthe 1930s Aleksander Vasiljevi Maklecov Russian criminal lawyer and refugee fromnRussia joined the Faculty Law Ljubljana and became well known for his reflectionsnupon several criminological issues and problems which many are still topicalntoday alcohol abuse and juvenile delinquency prevention women and crime crimenin newspapers etc also the author the first Slovenian textbook criminology ‘Introduction criminology’ 1948 1950 the Secretariat the Internal Affairs nhaving established research unit study crime and delinquency started publishingn‘Criminal Investigation Topics’ professional journal gradually evolve into ‘Journal ofnCriminal Investigation and Criminology’ now SSCI journal addition there are twonmore recent journals dealing with criminological topics ‘Social Education’ and ‘Journalnof Criminal Justice and Security’ The Institute Criminology was established 1954 nand its first director was Hinko ovnik The first research project finished 1957 hasnso far been followed more than 150 research projects The most fertile developmentnera the Institute’ positivistic research endeavours was that under Katja Vodopivec nMaklecov’ PhD graduate 1943 and the second director the Institute She establishednSlovenian criminology science equal footing with other disciplines and headedna huge number research projects Her successors directors the Institute werenJanez Alenka elih and Matja Jager addition the Institute Criminology nother institutions have developed this field expertise studying crime delinquency nsafety and security issues and other crime related problems Social Education Depart72nment the Faculty Education Faculty Law and Faculty Criminal Justicenand Security Slovenian criminology developed several stages making significantncontributions and enjoying international recognition The leading perspectives thisndiscussion relate crime control and prevention the impact Slovenian criminologicalnthought policy making international projects publications well contributionsnto global criminology 
10100 en Caught between crime control and human rights The fall the Berlin wall November 1989 has not brought the “end history” butnthe beginning new era instability uncertainty and conflict One the outputsnof the opening the borders Europe has been the rapid increase trafficking humannbeings the 1990s coupled with the rise research the phenomenon humanntrafficking Despite all research done remains very difficult get good grip onnthe phenomenon Albrecht using variety sources mentions estimates betweenn200 000–500 000 women who are trafficked Western Europe for the purpose prostitutionnon annual basis many them coming from the former socialist countries ofnCentral and Eastern Europe Since the 1990s well the issue trafficking has becomenthe object systems crime control worldwide both through criminal legislation andncriminal justice system enforcement Both national states and international organisationsnhave adopted variety legal instruments that make trafficking criminal offencenand have reinforced the investigation and the prosecution such offences Enforcement nhowever remains problem most countries partly because the close relationshipnwith organised crime partly because victims are not always willing testify outnof fear for revenge the same time interesting note shift from conceiving humanntrafficking law enforcement problem relating offenders understanding itnas serious violation human rights and putting the emphasis the human dignity ofnthe victims This shift has also facilitated the development protection mechanisms fornvictims including access justice for them which the same time may strengthen thenmodel law enforcement this contribution will focus both the phenomenon ofntrafficking its antecedents and its manifestations well the policies designed toncombat trafficking doing will also highlight fundamental conceptual paradigmsnused view the phenomenon such ‘moral panics’ Cohen left realism Young nand crime and human rights Parmentier and Weitekamp 
10101 en Smuggling and Trafficking Human Beings the Balkan Area The paper intends give and overview and critical analyses causes and recent trendsnin smuggling and trafficking human beings the Balkan area well criminalnpolicies and mechanisms for protection victims First the problems related definitionsnand distinction between smuggling and trafficking will analysed relation tongeographical position Balkan and attention will drown the scarce serious academicnresearch this field well overall low quality data about victims perpetratorsnand policies Then main contributing factors and recent trends will explored nsuggesting large parts population being involved smuggling and trafficking “business” nwhile large portions victims are invisible and stay out any support system nParticular attention will paid both victims and perpetrators coming from marginalisedngroups well victims who are invisible because they not fit widespread stereotypes about victims illegal migrants men sexual workers street children childrennused organised crime for guiding victims etc Criminal policies and mechanisms fornprotection victims will then analysed relation the role and social position ofnperpetrators and socio economic status social visibility and stereotypes related bothnvictims and perpetrators will argue that spite obvious positive developmentsnrecent years comprehensive and holistic approach smuggling and trafficking humannbeings which goes beyond stigmatization “otherness” and social exclusion notnestablished neither Balkan nor Western countries the concluding part the papernwill suggest possible directions toward policy which would oriented toward preventionnand social inclusion both victims and perpetrators with more victims assistednand human rights both protected 
10102 en Crime and Globalisation Post industrial societies are facing changes the way people internalize social norms nwhat they feel guilty about when they experience shame and how they perceive punishment nIdentification with traditional authorities which have the past transmittednsocial norms has been declining for some time Individualism has been pushed itsnlimits And transgression norms which comes from global capital international financialninstitution and state governments has often been cherished matter progress nUnder the veil ideology perpetual economic growth the societal level and advancementnof self fulfilment the individual level the definition what counts asntransgression has been globally altered Redefinition what counts limit what isnthe nature the prohibition and what are publicly acceptable forms remorse wellnas individually experienced anxieties regard prohibitions also underwent change nFeeling guilt and shame often accompanies individual’ striving towards creating annimage perfect life and not much transgression moral rules and the legal order Innthis context the definition crime has radically changed too How can criminology respondnto these changes interdisciplinary discipline needs new way assessnthe way malaise the civilization affects the malaise the individual and vice versa Inntrying understand this connection some lessons from contemporary psychoanalyticnknowledge might help especially the reasoning that utilitarianism ultimately failed its perception that people work towards advancement their well being and minimalizationnof pain Current economic crisis for example cannot explained throughnthis framework – rather need look through the prism enjoyment selfdestructionnwhich has always been the hidden underside progress 
10103 en Crime Policy between Effective Crime Control and Human Rights Protection Crime policy has been facing the dilemma whether human rights standards shouldnbe upheld the effectiveness strengthened for quite some time For the Central andnEast European countries this dilemma particular importance because human rightsnhave been the motivating factor the processes the 1990ies democratization Socialnchanges that occurred after the 1990ies have coincided with ongoing change crimenpolicy the “free world” the liberal and humane crime policy has been slowly replacednby just desert law and order and other more punitive policies this field Crime policyndevelopments the last decade especially after have been especially orientedntowards achieving greater effectiveness – also the cost human rights Crime policiesnin different European countries have adopted measures that either diminished humannrights standards some cases zone criminality has been extended beyond criminalnoffences others law enforcements measures can applied persons very remotelynconnected not connected all the criminal offence Policies and measures clearlyndisregarding human rights standards have been taken legislative well executivenauthorities the European well national levels The economic crisis may thentesting point for future orientation crime policy going into fully punitive direction nor may oriented towards its earlier goals – effectiveness respecting humannrights standards – new ways 
10105 en What Are Patterns Disclaimer Videolectures Net emphasises that the audio quality this video could not improved ndue poor audio quality conditions provided the lecture auditorium 
10106 en Pattern Analysis and Scientific Method Privacy and Intelligent Machines Disclaimer Videolectures Net emphasises that the audio quality this video could not improved ndue poor audio quality conditions provided the lecture auditorium 
10110 en Three Hours Multiple Classififier Systems Motivations and basic concepts Motivationsnof multiple classifier systems The “worst” case and “best” case motivations nPractical and theoretical motivations Basic concepts Architectures fornmultiple classifier systems Ensemble types combiner types The concept ofnclassifier “diversity” The design cycle multiple classifier system nnCreating multiple classifiers Systematicnmethods for creating classifier ensembles Methodsnbased training data manipulation data splitting methods Bagging andnBoosting Methodsnbased input and output feature manipulation feature selection the RandomnSubspace method noise injection and error correcting codes nnCombining multiple classifiers Methodsnfor combining multiple classifiers the “abstract” level voting methods thenBehaviour Knowledge Space method etc Methodsnfor combining multiple classifiers the “rank” level the Borda count method netc Methodsnfor combining multiple classifiers the “measurement” level linearncombiners the product rule etc Basicnconcepts dynamic classifier selection methods 
10111 en Statistical Significance and Stability Analysis for Patterns
10112 en Pattern Analysis over Graphs and Bioinformatics Applications Classification and regression over graphs Overview npositive definite graph kernels based walk subtrees etc wellnas other non similarity functions from graph matching thatncan used compare graphs and classification regression withnkernel methods Applications QSAR chemistry image classificationnn2 Detecting patterns the context regression classification with graph prior knowledge over the features nOverview nin classical regression classification problem over high dimensionalnvectors Control the complexity using priors that can derivednfrom the graph over the vectors and how they can used penaltynfunctions for classification and regression This will cover diffusionnkernels and other kernels over graphs fused lasso structured groupnlasso Application bioinformatics 
10114 en Patterns Significant Accidental
10116 en Analysis Patterns for Computer Security
10118 en IFA for the Diagnosis Railway Infrastructure Device Semi Supervised Learning
10783 en Welcome and Introduction Organizer and Partners
10784 en Leveraging New Technologies for Process Flexibility Logistics Service Providers
10785 en ICT Enabler for Efficient and Sustainable Transport Logistics
10786 en ICT Research Support Freight and Logistics
10787 en The Intelligent Cargo Concept the European Project EURIDICE
10789 en Panel Discussion Challenges Met the Logistic Sector
10790 en Hardware and Related Software Technologies Track and Trace Monitoring Data Aquisition 
10791 en Frameworks for Cargo Centric Approach
10792 en The Unexploited Potential Savings the European Road Transport Industry
10793 en Impact Current and Future Technologies – Visions Beyond Existing
10794 en Results the KOMODA Delphi Survey Logistics
10796 en Impact Assessment Study Intelligent Cargo
11099 en Furniture scenario Delocalisation with production networks countries with cheaper human efforts skill competencies
11141 en Relative Entropy overview relative entropy aka Kulback Leibler divergence etc and its multiple appearances information theory probability and statistics including recent results the speaker 
11142 en Deep Learning with Multiplicative Interactions Deep networks can learned efficiently from unlabeled data The layers representation are learned one time using simple learning module that has only one layer latent variables The values the latent variables one module form the data for training the next module The most commonly used modules are Restricted Boltzmann Machines autoencoders with sparsity penalty the hidden activities Although deep networks have been quite successful for tasks such object recognition information retrieval and modeling motion capture data the simple learning modules not have multiplicative interactions which are very useful for some types data The talk will show how third order energy function can factorized yield simple learning module that retains advantageous properties Restricted Boltzmann Machine such very simple exact inference and very simple learning rule based pair wise statistics The new module contains multiplicative interactions that are useful for variety unsupervised learning tasks Researchers the University Toronto have been using this type module extract oriented energy from image patches and dense flow fields from image sequences The new module can also used allow the style motion blend auto regressive models motion capture data Finally the new module can used combine eye position with feature vector allow system that has variable resolution retina integrate information about shape over many fixations 
11143 en The Rat Vibrissal Array Model Sensorimotor System The rat whisker vibrissal system has neural processing pathways that are analogous human tactile pathways through the spinal cord Rats use rhythmic movements their whiskers actually extract object features including size shape orientation and texture this talk will describe our efforts characterize whisker mechanical properties and determine the set mechanical variables that could potentially sensed the rat have also developed hardware array artificial whiskers that makes use these variables successfully extract dimensional object features the behavioral side have developed laser light sheet visualize whisker object contact patterns during natural exploratory behavior and have used this technique examine the relative roles head and whisker movements generating patterns mechanosensory input across the array during natural exploratory sequences Finally are developing simulation environment that integrates our knowledge whisker mechanics with our knowledge head and whisker motion enable the user model the rat interactions with various objects the environment Our goal predict the contact patterns – and resulting forces and moments – each whisker base for given exploratory sequence and then predict the resulting responses trigeminal ganglion neurons 
11144 en Learning and Inference Low Level Vision Low level vision addresses the issues labeling and organizing image pixels according scene related properties such motion contrast depth and reﬂectance will describe our attempts understand low level vision humans and machines optimal inference given the statistics the world time permits will discuss favorite NIPS rejected papers nYair Weiss Associate Professor the Hebrew University School Computer Science and Engineering received his from MIT working with Ted Adelson motion analysis and did postdoctoral work Berkeley Since 2005 has been fellow the Canadian Institute for Advanced Research With his students and colleagues has authored award winning papers NIPS 2002 ECCV 2006 UAI 2008 and CVPR 2009 nnSlide presentation contains animation videos which can found http www huji yweiss movies tar 
11145 en Bayesian Analysis Markov Chains Suppose observe data and want test comes from Markov chain does may want estimate the transition operator Working Bayesian way have specify priors and compute posteriors Interesting things happen want put priors reversible Markov chains There are useful connections with reinforced random walk work with Silke Rolles large scale application protein folding will described More generally these problems arise approximating dynamical system Markov chain For continuous state spaces the usual conjugate prior analysis breaks down Thesis work Wai Liu Stanford gives useful families priors where computations are easy These seem work well test problems and can proved consistent 
11147 en Making Very Large Scale Linear Algebraic Computations Possible Via Randomization The demands software for analyzing data are rapidly increasing ever larger data sets are generated medical imaging analyzing large networks such the World Wide Web image and video processing and range other applications handle this avalanche data any software used must able fully exploit modern hardware characterized multiple processors and capacious but slow memory The evolution computer architecture currently forcing shift algorithm design away from the classical algorithms that were designed for single processor computers with all the data available Random Access Memory RAM towards algorithms that aggressively minimize communication costs This tutorial will describe set recently developed techniques for standard linear algebraic computations such computing partial singular value decomposition matrix that are very well suited for implementation multi core other parallel architectures and for processing data stored disk streamed These techniques are based the use randomized sampling reduce the effective dimensionality the data Remarkably randomized sampling does not only loosen communication constraints but does while maintaining even improving the accuracy and robustness existing deterministic techniques 
11148 en Understanding Visual Scenes One remarkable aspect human vision the ability understand the meaning novel image event quickly and effortlessly Within single glance can comprehend the semantic category place its spatial layout well identify many the objects that compose the scene Approaching human abilities scene understanding current challenge for computer vision systems The field scene understanding multidisciplinary involving growing collection works computer vision machine learning cognitive psychology and neuroscience this tutorial will focus recent work computer vision attempting solve the tasks scene recognition and classification visual context representation object recognition context drawing parallelism with work psychology and neuroscience Devising systems that solve scene and object recognition integrated fashion will lead towards more efficient and robust artificial visual understanding systems 
11149 en Model Based Reinforcement Learning model based reinforcement learning agent uses its experience construct representation the control dynamics its environment can then predict the outcome its actions and make decisions that maximize its learning and task performance This tutorial will survey work this area with emphasis recent results Topics will include Efficient learning the PAC MDP formalism Bayesian reinforcement learning models and linear function approximation recent advances planning 
11150 en Sparse Methods for Machine Learning Theory and Algorithms Regularization the norm has attracted lot interest recent years statistics machine learning and signal processing the context least square linear regression the problem usually referred the Lasso basis pursuit Much the early effort has been dedicated algorithms solve the optimization problem efficiently either through first order methods through homotopy methods that leads the entire regularization path the set solutions for all values the regularization parameters the cost single matrix inversion well known property the regularization the norm the sparsity the solutions leads loading vectors with many zeros and thus performs model selection top regularization Recent works have looked precisely the model consistency the Lasso know that the data were generated from sparse loading vector does the Lasso actually recover the sparsity pattern when the number observations grows Moreover how many irrelevant variables could consider while still being able infer correctly the relevant ones The objective the tutorial give unified overview the recent contributions sparse convex methods machine learning both terms theory and algorithms The course will divided three parts the first part the focus will the regular norm and variable selection introducing key algorithms and key theoretical results Then several more structured machine learning problems will discussed vectors second part and matrices third part such multi task learning sparse principal component analysis multiple kernel learning and sparse coding 
11151 en Deep Learning Natural Language Processing This tutorial will describe recent advances deep learning techniques for Natural Language Processing NLP Traditional NLP approaches favour shallow systems possibly cascaded with adequate hand crafted features constrast are interested end end architectures these systems include several feature layers with increasing abstraction each layer Compared shallow systems these feature layers are learnt for the task interest and not require any engineering will show how neural networks are naturally well suited for end end learning NLP tasks will study multi tasking different tasks new semi supervised learning techniques adapted these deep architectures and review end end structured output learning Finally will highlight how some these advances can applied other fields research like computer vision well 
11152 en Sequential Monte Carlo Methods Over the last fifteen years sequential Monte Carlo SMC methods gained popularity powerful tools for solving intractable inference problems arising the modelling sequential data Much effort was devoted the development SMC methods known particle filters PFs for estimating the filtering distribution the latent variables dynamic models This line research produced many algorithms including auxiliary variable PFs marginal PFs the resample move algorithm and Rao Blackwellised PFs also led many applications tracking computer vision robotics and econometrics The theoretical properties these methods were also studied extensively this period Although PFs occupied the center stage significant progress was also attained the development SMC methods for parameter estimation online particle smoothing and SMC techniques for control and planning Various SMC algorithms were also designed approximate sequences unnormalized functions thus allowing for the computation eigen pairs large matrices and kernel operators Recently frameworks for building efficient high dimensional proposal distributions for MCMC using SMC methods were proposed These allow design effective MCMC algorithms complex scenarios where standard strategies failed Such methods have been demonstrated number domains including simulated tempering Dirichlet process mixtures nonlinear non Gaussian state space models protein folding and stochastic differential equations Finally SMC methods were also generalized carry out approximate inference static models This typically done constructing sequence probability distributions which starts with easy sample from distribution and which converges the desired target distribution These SMC methods have been successfully applied notoriously hard problems such inference Boltzmann machines marginal parameter estimation and nonlinear Bayesian experimental design this tutorial will introduce the classical SMC methods and expose the audience the new developments the field 
11179 en Towards Brain Computer Interfacing Algorithms for line Differentiation Neuroelectric Activities Brain Computer Interfacing BCI aims making use brain signalsnfor the control objects spelling gaming and This talknwill first provide brief overview Brain Computer Interfacenfrom machine learning and signal processing perspective Innparticular shows the wealth the complexity and the difficulties ofnthe data available truly enormous challenge real time anmulti variate very strongly noise contaminated data stream benprocessed and neuroelectric activities are accuratelyndifferentiated real time nnFinally report more detail about the Berlin Brain Computern BBCI Interface that based EEG signals and take the audiencenall the way from the measured signal the preprocessing and filtering nthe classification the respective application Â BCI newnchannel for man machine communication discussed clinicalnsetting and for gaming 
11180 en Machine Learning for Brain Computer Interfaces Brain computer interfaces BCI aim the ultimate assistive technology ndecoding user intentions directly from brain signals without involving any nmuscles peripheral nerves Thus some classes BCI potentially offer hope nfor users with even the most extreme cases paralysis such late stage nAmyotrophic Lateral Sclerosis where nothing else currently allows communication nof any kind Other lines BCI research aim restore lost motor function nnatural way possible reconnecting and some cases training motor cortical nareas control prosthetic previously paretic limbs Research and development nare progressing both invasive and non invasive fronts although BCI has yet nmake breakthrough widespread clinical application nnThe high noise high dimensional nature brain signals particularly non invasivenapproaches and patient populations make robust decoding techniques necessity nGenerally the approach has been use relatively simple feature extraction techniques nsuch template matching and band power estimation coupled simple linear classifiers nThis has led prevailing view among applied BCI researchers that sophisticated nmachine learning irrelevant since doesn matter what classifier you use once you ndone your preprocessing right and extracted the right features shall show few examples nof how this runs counter both the empirical reality and the spirit what needs done nto bring BCI into clinical application Along the way highlight some the interesting nproblems that remain open for machine learners 
11181 en  Efficient P300 based Brain Computer Interface with Minimal Calibration Time Brain Computer Interfaces BCI are communication systems that enable subjects send commandsnto computers using only their brain activity Most existing BCI are based ElectroEncephaloGraphyn EEG the measure brain activity far BCI have been proven benvery promising communication and control tools for disabled people promising brain signalsnused the design assistive BCI for disabled people the P300 positive waveform occuringnroughly 300 after rare and relevant stimulus order use P300 based BCI subjectsnhave focus their attention given stimulus randomly appearing among many others eachnstimulus corresponding given command The appearance the desired stimulus being rare andnrelevant expected trigger P300 the subject’ brain activity such detecting the P300nenables the system identify the desired stimulus and hence the desired command Interestinglynenough P300 based BCI have been successfully used control wheelchair see tonenable severely disabled users spell words nnHowever current P300 based BCI well other BCI systems still suffer from several limitationsnwhich prevent them from being widely used One these limitations that use BCI manynexamples the subject’ EEG signals must recorded order calibrate the BCI which isnunconvenient and time consuming Moreover this calibration process generally has repeatednat regular intervals from one day the other order accomodate sources variationsnsuch changes electrode positions changes the subject’ mental state and fatigue level nTherefore the calibration time should maintained brief possible Until now reducing thencalibration time P300 based BCI has been scarcely addressed the literature Exceptions arenthe works and suggested use initially BCI calibrated withnfew training samples and then incrementally adapt this BCI online thanks semi supervisednlearning proposed use subject independent BCI previously learnt from the datanof many other subjects also followed online adaptation However the main limitiation ofnthese two approaches that such BCI would have initially poor detection performances becomingnefficient only after adaptation ideal P300 based BCI would have initially high performances neven trained with very few examples this paper propose new P300 based BCI designnwhich can trained using much fewer examples than current BCI designs without sacrifying thendetection performances 
11182 en Extracting Gait Spatiotemporal Properties from Parkinson Disease Patients The Parkinson’ disease frequent chronic progressive syndrome the elderly population nCurrent available treatments either stimulate brain dopamine receptors increase dopaminensynthesis the long term especially from the fifth year disease onset motor complicationsnis often observed Such motor complications arise consequence reduction the durationnof the effect the medication This motor complications affects spatiotemporal properties duringnthe gait patients Length and speed the steps change due the effects known dyskinesianand akinesia thus and line measurement these properties during gait may help predictnthese situations and therefore warn the patient minimizing risk falling remote healthncare system Recently several approaches using inertial sensors have been developed with the aimnof measure these types gait properties The gait characteristics may obtainednusing gyroscopes tied legs using double inverted pendulum model nevertheless wearingnthese devices the legs during daily life activity seems drawback leaving the application scopenof this method clinical environments the case accelerometers they are usually positionednat the dorsal side the trunk near the region the subject since the CoM location thisnposition CoM acceleration velocity and displacement can estimated However thenbest our knowledge there user friendly wearable device location that patients may usenoutside the hospital Here propose method based SVM regression extract spatiotemporalnproperties from accelerations obtained from single accelerometer positioned the lateral side ofnthe waist with the advantage being wearable system the patients may use during their daily life nwithout danger hurt damaging the device 
11183 en Machine Learning Applied Multi Modal Interaction Adaptive Interfaces and Ubiquitous Assistive Technologies The presentation will describe the challenge eInclusion the technological designnprocess which impedes the complete integration people with disabilities and elderlynin Information Society face this challenge the INREDIS project aims face nindividual needs users instead addressing the needs the average user nproposing basic technologies that enables the creation personalized channels forncommunication and interaction with the technological environment For this purpose nMachine Learning can help constructing effective methods reflect user needs npreferences and expectations and their evolution over time user interfaces nconsequently improving satisfaction and performance particular academia and nindustry within the INREDIS consortium explore together the potential Machine nLearning multimodal services and ubiquitous assistive technologies well nadaptive user interfaces according user and technological capabilities 
11185 en Human Centered Machine Learning Social Interaction Assistant for Individuals with Visual Impairments Over the last couple decades the increasing focus accessibility has resulted the design andndevelopment several assistive technologies aid people with visual impairments their dailynactivities Most these devices have been centered enhancing the interaction user whonis blind visually impaired with objects and environments such computer monitor personalndigital assistant cellphone road traffic grocery store Although these efforts are very essentialnfor the quality life these individuals there also need which has far not been seriouslynconsidered enrich the interactions individuals who are blind with other individuals nnNon verbal cues including prosody elements the physical environment the appearance communicatorsnand physical movements account for much the information communicatednduring social interactions However more than million individuals the who are legallynblind and million worldwide have limited experience this fundamental privilege socialninteractions These individuals continue faced with fundamental challenges coping withneveryday interactions their social lives The work described this paper based the designnand development Social Interaction Assistant that intended enrich the experience socialninteractions for individuals who are blind providing real time access information aboutnindividuals and their surrounds The realization Social Interaction Assistant device involvesnsolving several challenging problems pattern analysis and machine intelligence such personnrecognition tracking head body pose estimation gesture recognition expression recognition etc onna wearable real time platform list eight significant daily challenges faced these individualsnwas identified our initial focus group studies conducted with individuals who are blind visuallynimpaired Each these problems raises unique machine learning challenges that need tonbe addressed 
11186 en Toward Text Picture Synthesis estimated that more that million people the United States have significant communicationnimpairments that result them relying methods other than natural speech alone for communicationn One type commonly used augmentative and alternative communication AAC system isnpictorial communication software such SymWriter which uses lookup table transliterateneach word common phrase sentence into icon This example converting informationnbetween modalities However the resulting sequence icons can difficult understand nWe have been developing general purpose Text Picture TTP synthesis algorithms tonimprove understandability using machine learning techniques Our goal help users with specialnneeds such the elderly those with disabilities rapidly browse documents through pictorialnsummaries Figure Our TTP system targets general English This differs from other pictorialnconversion systems that require hand crafted narrative descriptions scene models nor special domains Instead use concatenative “collage” approach this talk wendiscuss how machine learning enables the key components our TTP system 
11187 en Fast and Flexible Selection with Single Switch single switch communication user input consists repeated clicks distinguished only timingninformation these clicks might generated pressing button blinking For instance thenrange movement individuals with severe motor impairments may limited single muscle nAlternatively crowded jostled mobile technology user may able click precisely whilenother actions are difficult sloppy single switch may also useful when information conveyed nsuch PIN sensitive and hand location normal keyboard might betray this content Ournmethod “Nomon” Figure expands the application scope existing methods and facilitatesnfaster writing than the most common single switch writing interface nnExisting single switch communication methods include scanning and One Button Dasher Morse Code contrast requires either click duration information multiple switches Thesenmethods require options arranged particular configuration contrast traditional operatingnsystems web browsers and free form applications such drawing place options arbitrarynpoints the screen seek single switch selection method that not limited certain forms ofnoption placement want our method work for any number options able effectivelynreorder the set selections without imposing additional cognitive load and allow the user tonattend only the desired target Our method Nomon accomplishes these objectives can furthernautomatically adapt individuals’ clicking abilities and incorporate prior beliefs about optionnselection frequency nnTo test our method developed writing application the Nomon Keyboard Figure and comparednits performance with popular commercial scanning interface The Grid Figure Wenexamined study participants’ writing speeds error rates and number clicks made per character asnwell the subjective ratings their experiences found that novice users wrote faster withnthe Nomon interface than with the scanning interface experienced user author with 10nhours practice wrote speeds words per minute with Nomon using clicks per characternand making errors the final text 
11188 en Data Mining Based User Modeling Systems for Web Personalization Applied People with Disabilities This position paper tackles the problem automatic web personalization using machine learningntechniques model the users behavior The target population people with physical sensory orncognitive restrictions this paper present our plans study the possibility creating usernmodels using the information extracted from web navigation logs means data mining methods nWe discuss the expected advantages adopting data mining generate information about the user nin comparison with traditional methods 
11189 en Perspective the Goals and Complexities Inclusive Design This presentation will discuss goals methodology and research for creating accessible user experiences today cutting edge software technology Using framework for mapping user requirements technology solutions will discuss the complex market for accessible technology and the opportunity for innovation technology solutions Demos will given new accessibility solutions Windows and the Internet The presentation will highlight the complexities the accessible technology space with the hope inspiring research and application machine learning 
11191 en Granger Causality and Dynamic Structural Systems Using generally applicable dynamic structural system equations give natural definitions direct and total structural causality applicable both structural VARs and recursive structures representing time series natural experiments These concepts enable forge previously missing link between Granger causality and structural causality showing that given corresponding conditional form exogeneity causality holds and only corresponding form structural causality holds importance for applications the structural characterization finite order causality which forms the basisfor most empirical work show that conditional exogeneity necessary for valid structural inference and prove that the absence structural causality conditional exogeneity equivalent non causality provide practical new causality and conditional exogeneity tests and describe their use testing for structural causality 
11192 en Time Series Causality Inference Using the Phase Slope Index method recently introduced Nolte Phys Rev Lett 100 23401 2008 estimates the causal direction interactions robustly with respect instantaneous mixtures independent sources with arbitrary spectral content observations which are dominated non white spatially correlated noise and which dynamic structural interaction plays little part The method named Phase Slope Index PSI unlikely assign causality the case lack dynamic interaction among time series unlike Granger causality for linear systems Results show that PSI does not yield false positives even the case nonlinear interactions The meaning instaneous noise mixtures different data domains will discussed the context correct correlation causation inference and the theoretical relationship PSI other time series causality inference methods will expanded upon 
11193 en Causality Brain Connectivity Studies Using Functional Magnetic Resonance Imaging fMRI Data This talk will discuss the application Granger causality fMRI data the form Granger causality mapping GCM which used explore directed influences between neuronal populations effective connectivity fMRI data The method does not rely priori specification model that contains pre selected regions and connections between them This distinguishes from other fMRI effective connectivity approaches that aim testing contrasting specific hypotheses about neuronal interactions Instead GCM relies the Granger causality concept define the existence and direction influence from temporal information the data The problems limited temporal resolution fMRI and the hemodynamic source the signal that makes direct interpretation fMRI Granger causality neuronal influence difficult will discussed 
11194 en Graphical Causal Models for Time Series Econometrics Some Recent Developments and Applications Structural vector autoregressive models are potentially very useful tools for guiding economic policy present recently developed method estimate and identify the causal structure underlying the data generating process The method which based graphical models exploits conditional independence tests among estimated VAR residuals infer the causal relationships among contemporaneous variables first show how this method works the Gaussian linear setting Then present some developments for both the linear non Gaussian and nonlinear settings 
11195 en Open Access Datasets for Time Series Causality Discovery Validation The Causality Workbench project provides environment test causal discovery algorithms Via web portal http clopinet com causality provide number resources including repository datasets models and software packages and virtual laboratory allowing users benchmark causal discovery algorithms performing virtual experiments study artificial causal systems regularly organize competitions Our repository already includes several time dependent datasets from variety domains system biology neurosciences physics manufacturing and marketing will invite new contributions and present our plan for upcoming evaluations causal models for time series applications 
11196 en Understanding Gene Regulatory Networks and Their Variations key biological question uncover the regulatory networks cellular system and understand how this network varies across individuals cell types and environmental conditions this talk will describe work that uses machine learning techniques reconstruct gene regulatory networks from gene expression data Specifically exploit novel forms Bayesian regularized regression enable transfer between multiple related learning problems such between different individuals between different cell types demonstrate applications two domains understanding the effect individual genetic variation gene regulation and its effect phenotypes including human disease and understanding the regulatory mechanisms underling immune system cell differentiation 
11197 en Time Varying Graphical Models Reverse Engineering and Analyzing Rewiring Networks plausible representation the relational information among entities dynamic systems such social community living cell stochastic network that topologically rewiring and semantically evolving over time While there rich literature modeling static temporally invariant networks until recently little has been done toward modeling the dynamic processes underlying rewiring networks and recovering such networks when they are not observable this talk will present new formalism for modeling network evolution over time based time evolving probabilistic graphical models such GGM MRF and DBN and several new algorithms for estimating the structure such models underlying nonstationary time series nodal attributes will show some promising results recovering the latent sequence evolving social networks the Senate based voting history and the gene networks over more than 4000 genes during the life cycle Drosophila melanogaster from microarray time course time resolution only limited sample frequency will also sketch some theoretical results the asymptotic sparsistency the proposed methods 
11198 en Novel Applications Computational Biology Infectious Disease Interventions Interventions infectious diseases are increasingly relying computational biology and genomic methods Estimating changes viral genetic diversity population could new potential method evaluate vaccination strategies populations Transgenic mosquitoes immune pathogen are being developed replace the native mosquito vector number vector borne diseases High throughput methods are being used elucidate mechanisms immune memory with the promise developing better vaccines Large scale computer simulation models are useful for exploring interventions and could benefit from input from network and graph theory this talk discuss few novel applications computational biology understanding infectious diseases and interventions 
11205 en Direct Maximization Protein Identifications from Tandem Mass Spectra
11206 en Exploiting Physico Chemical Properties String Kernels
11207 en  Bayesian Method for Reconstruction Macromolecular Structure Using Class Averages from Single Particle Electron Microscopy
11208 en vbFRET Bayesian Approach Single Molecule Forster Resonance Energy Transfer Analysis
11209 en Leveraging Joint Test Status Distribution for Optimal Significance Testing
11210 en Statistical Methods for Ultra Deep Pyrosequencing Fast Evolving Viruses
11211 en  Machine Learning Pipeline for Phenotype Prediction from Genotype Data
11212 en Association Mapping Traits over Time Using Gaussian Processes
11213 en Learning Graphical Model Structure with Sparse Bayesian Factor Models and Process Priors
11214 en Scalable Hierarchical Multitask Learning Sequence Biology
11268 en Geostatistics for Gaussian Processes Gaussian process methodology has inspired number stimulating new ideas the area machine learning Kriging has been introduced statistical interpolation method for the design computer experiments twenty years ago However some aspects the geostatistical methodology originally developed for natural resource estimation have been ignored when switching this new context This talk reviews concepts geostatistics and particular the estimation components spatial variation the context multiple correlated outputs 
11269 en Gaussian Processes and Process Convolutions from Bayesian Perspective
11270 en Prior Knowledge and Sparse Methods for Convolved Multiple Outputs Gaussian Processes One approach account for non trivial correlations between outputs employs convolution processes Under latent function interpretation the convolution transform possible establish dependencies between output variables Two important aspects this framework are how can introduce prior knowledge and how can perform efficient inference Relating the convolution operation with dynamical systems can specify richer covariance functions for multiple outputs also present different sparse approximations for dependent output Gaussian processes the context structured covariances Joint work with Neil Lawrence David Luengo and Michalis Titsias 
11271 en Multi Task Learning and Matrix Regularization Multi task learning extends the standard paradigm supervised learning multi task learning samples for multiple related tasks are given and the goal learn function for each task and also generalize well transfer learned knowledge new tasks The applications this paradigm are numerous and range from computer vision collaborative filtering bioinformatics while also relates vector valued problems multiclass multiview learning etc will present framework for multi task learning which based learning common kernel for all tasks will also show how this formulation connects the trace norm and group Lasso approaches Moreover the proposed optimization problem can solved using alternating minimization algorithm which simple and efficient can also kernelized virtue multi task representer theorem which holds for large family matrix regularization problems and includes the classical representer theorem special case 
11272 en Learning Vector Fields with Spectral Filtering present class regularized kernel methods for vector valued learning which are based filtering the spectrum the kernel matrix The considered methods include Tikhonov regularization special case well interesting alternatives such vector valued extensions boosting While preserving the good statistical properties Tikhonov regularization some the new algorithms allows for much faster implementation since they require only matrix vector multiplications discuss the computational complexity the different methods taking into account the regularization parameter choice step The results our analysis are supported numerical experiments 
11273 en Borrowing Strength Learning Vector Valued Functions and Supervised Dimension Reduction study the problem supervised dimension reduction from the perspective learning vector valuednfunctions and multi task hierarchical modeling regularization framework algorithm speci ednand empirical results are provided the second part the talk the same problem supervised dimensionnreduction for hierarchical model revisted from non parametric Bayesian perspective 
11274 en Approximate Inference Natural Language Processing start out presenting idealized version the natural language processing problem parsing will brazenly suggest that most NLP reducible variations parsing problems show how dynamic programming solves the idealized version the problem both for calculating modes and marginals over parse trees exploiting some key independence assumptions about the structure natural language sentences nnI will then discuss two approximate inference methods that let build more powerful models parsing Neither comes with strong theoretical guarantees but both are demonstrated perform strongly experiments real NLP data The first method builds the dynamic programming representation combining max product and sum product methods produce approximately the best parses and residual sum over the rest the parses useful when incorporating features that violate the usual independence assumptions Experiments validate the approach with discriminative model for machine translation nnThe second method turns parsing problem instance into concise integer linear program Approximate inference then accomplished using well known linear program relaxation This embedded new online learning algorithm that tries penalize uninterpretable fractional solutions and therefore inference cost evaluation time show that this approach leads state the art parsing performance seven languages with improved speed for both exact and approximate inference and significant performance loss 
11276 en Joint Max Margin and Max Entropy Learning Graphical Models Inferring structured predictions based correlated covariates remains central problem many fields including NLP computer vision and computational biology Popular paradigms for training structured input output models include the maximum conditional likelihood estimation which leads the well known CRF and the max margin learning which leads the structured SVM M3N each enjoys some advantages well weaknesses this talk present new general framework called Maximum Entropy Discrimination Markov Networks MEDN which integrates the margin based and likelihood based approaches and combines and extends their merits This new learning paradigm naturally facilitates integration the generative and discriminative principles under unified framework and the basic strategies can generalized learn arbitrary graphical models such the generative Bayesian networks models with structured hidden variables will discuss number theoretical properties this model and show applications MEDN learning fully supervised structured model max margin structured models with hidden variables and max margin LDA model for jointly discovering discriminative latent topic representations and predicting document label score text documents with compelling performance each case 
11277 en Large Scale Learning and Inference What Have Learned with Markov Logic Networks Markov logic allows very large and rich graphical models compactly specified Current learning and inference algorithms for Markov logic can routinely handle models with millions variables billions features thousands latent variables and strong dependencies this talk will give overview the main ideas these algorithms including weighted satisfiability MCMC with deterministic dependencies lazy inference lifted inference relational cutting planes scaled conjugate gradient relational clustering and relational pathfinding will also discuss the lessons learned developing successive generations these algorithms and promising ideas for the next round scaling 
11278 en Parameter Learning Using Approximate MAP Inference recent years machine learning has seen the development series algorithms for parameter learning that avoid estimating the partition function and instead rely accurate approximate MAP inference Within this framework consider two new topics nnIn the first part discuss parameter learning semi supervised scenario Specifically focus region based scene segmentation model that explains image terms its underlying regions set connected pixels that provide discriminative features and their semantic labels such sky grass foreground While easy obtain partial ground truth labeling for the pixels training image not possible for human annotator provide with the best set regions those that result the most discriminative features address this issue develop novel iterative MAP inference algorithm which selects the best subset regions from large dictionary using convex relaxations use our algorithm complete the ground truth labeling infer the regions which allows employ the highly successful max margin training regime compare our approach with the state the art methods and demonstrate significant improvements nnIn the second part discuss new learning framework for general log linear models based contrastive objectives contrastive objective considers set interesting assignments and attempts push the probability the correct instantiation the expense the other interesting assignments contrast our approach related methods such pseudo likelihood and contrastive divergence compare the correct instantiation only nearby instantiations which can problematic when there high scoring instantiation far away from the correct one present some the theoretical properties and practical advantages our method including the ability learn log linear model using only approximate MAP inference the theoretical properties and practical advantages our method including the ability learn log linear model using only approximate MAP inference also show results applying our method some simple synthetic examples where significantly outperforms pseudo likelihood 
11279 en Training Structured Predictors for Novel Loss Functions motivation consider the PASCAL image segmentation challenge Given image and target class such person the challenge segment the image into regions occupied objects that class person foreground and regions not occupied that class non person background the present state the art the lowest pixel error rate achieved predicting all background However the challenge evaluated with intersection over union score with the property that the all background prediction scores zero This raises the question how one incorporates particular loss function into the training structured predictor standard approach incorporate the desired loss into the structured hinge loss and observe that for any loss the structured hinge loss upper bound the desired loss However this upper bound quite loose and far from clear that the structured hinge loss appropriate useful way handle the PASCAL evaluation measure nnThis talk reviews various approaches this problem and presents new training algorithm call the good label bad label algorithm prove that the data rich regime the good label bad label algorithm follows the gradient the training loss assuming only that can perform inference the given graphical model The algorithm structurally similar but significantly different from stochastic subgradient descent the structured hinge loss which does not follow the loss gradient 
11280 en Some Machine Learning Problems that the Computer Vision Community Would Like See Solved From user perspective describe what solutions like see regarding the learning large scale graphical models Also recent vision workshop asked one one numerous leading researchers computer vision what results they would like see from computer scientists machine learning folks present those responses 
11281 en Covariate Shift Kernel Mean Matching Given sets observations training and test data consider the problem weighting the training data such that its distribution more closely matches that the test data achieve this goal matching covariate distributions between training and test sets high dimensional feature space specifically reproducing kernel Hilbert space This approach does not require distribution estimation Instead the sample weights are obtained simple quadratic programming procedure nWe first describe how distributions may mapped reproducing kernel Hilbert spaces Next review distances between such mappings and describe conditions under which the feature space mappings are injective and thus distributions have unique mapping Finally demonstrate how transfer learning algorithm can obtained reweighting the training points such that their feature mean matches that the unlabeled test distribution Our correction procedure yields its greatest and most consistent advantages when the learning algorithm returns classifier regressor that simpler than the data might suggest the other hand even ideal sample reweighting may not practical benefit given sufficiently powerful classifier available 
11284 en Kernel Learning and Meta Kernels for Transfer Learning
11286 en  Free Lunch Theorems for Transfer Learning will present formal framework for transfer learning and investigate under which conditions possible provide performance guarantees for such scenarios will address two key issues Which notions task similarity suffice provide meaningful error bounds target task for predictor trained different source task Can better than just train hypothesis the source task and analyze its performance the target task Can the use unlabeled target samples reduce the target prediction error 
11319 en Learning Region based Scene Segmentation Model recent years machine learning has seen the development series algorithms for parameter learning that avoid estimating the partition function and instead rely accurate approximate MAP inference Within this framework consider two new topics nnIn the first part discuss parameter learning semi supervised scenario Specifically focus region based scene segmentation model that explains image terms its underlying regions set connected pixels that provide discriminative features and their semantic labels such sky grass foreground While easy obtain partial ground truth labeling for the pixels training image not possible for human annotator provide with the best set regions those that result the most discriminative features address this issue develop novel iterative MAP inference algorithm which selects the best subset regions from large dictionary using convex relaxations use our algorithm complete the ground truth labeling infer the regions which allows employ the highly successful max margin training regime compare our approach with the state the art methods and demonstrate significant improvements nnIn the second part discuss new learning framework for general log linear models based contrastive objectives contrastive objective considers set interesting assignments and attempts push the probability the correct instantiation the expense the other interesting assignments contrast our approach related methods such pseudo likelihood and contrastive divergence compare the correct instantiation only nearby instantiations which can problematic when there high scoring instantiation far away from the correct one present some the theoretical properties and practical advantages our method including the ability learn log linear model using only approximate MAP inference the theoretical properties and practical advantages our method including the ability learn log linear model using only approximate MAP inference also show results applying our method some simple synthetic examples where significantly outperforms pseudo likelihood 
11337 en SINDBAD and SiQL Inductive Database and Query Language the Relational Model The speaker presented the concepts and implementation SINDBAD prototype inductive database proposed Imielinski and Mannila the relational model The goal support all steps the knowledge discovery process the basis queries database system The query language SiQL structured inductive query language SQL extension offers query primitives for feature selection discretization pattern mining clustering instance based learning and rule induction 
11351 en Retrospective Change point Approaches and Sequential Modelling propose for the analysis array CGH data new stochastic segmentation model and associatednestimation procedure that has attractive statistical and computational properties important bene fit ofnthis Bayesian segmentation model that yields explicit formulas for posterior means which can usednto estimate the signal directly without performing segmentation Other quantities relating the posteriorndistribution that are useful for providing confi dence assessments any given segmentation can also benestimated using our method propose approximation method whose computation time linear innsequence length which makes our method practically applicable the new higher density arrays Simulationnstudies and applications real array CGH data illustrate the advantages the proposed approach 
11352 en  Dynamic HMM for Online Segmentation propose novel method for the analysis sequential datanthat exhibits inherent mode switching particular the datanmight non stationary time series from dynamical systemnthat switches between multiple operating modes Unlike other approaches our method processes the data incrementally and withoutnany training internal parameters use HMM with dynamically changing number states and line variant thenViterbi algorithm that performs unsupervised segmentation andnclassification the data the the method able process incoming data real time The main idea the approach isnto track and segment changes the probability density the datanin sliding window the incoming data stream The usefulnessnof the algorithm demonstrated application switchingndynamical system 
11353 en Distributed Detection and Localization Network Anomalies using Rank Tests propose efficient and decentralized method for detecting change points high dimensional data This issue growing concern the network security community since this context network anomalies such denial service DoS attacks are likely lead statistical changes Internet traffic Our method proposes way distributing centralized approach called TopRank which consists data reduction stage based record filtering followed nonparametric change point detection test based statistics The key point aggregate censored time series built locally and perform nonparametric test for doubly censored time series resulting from this aggregation With this new approach called distributed TopRank the following can address massive data streams and perform network anomaly detection and localization the fly while limiting the quantity data exchanged within the network 
11354 en Product Partition Models for Modelling Changing Dependency Structure Time Series show how apply the efficient Bayesian changepoint detection techniques Fearnhead thenmultivariate setting model the joint density vector valued observations using undirected Gaussianngraphical models whose structure estimate show how can exactly compute the MAPnsegmentation well how draw perfect samples from the posterior over segmentations simultaneouslynaccounting for uncertainty about the number and location changepoints well uncertainty about thencovariance structure illustrate the technique applying financial data and bee tracking data 
11356 en Hierarchical Dirichlet Process based Hidden Markov Models consider the problem speaker diarization the problem segmenting audio recording meetingninto temporal segments corresponding individual speakers The problem rendered particularly cultnby the fact that are not allowed assume knowledge the number people participating the meeting nTo address this problem take Bayesian nonparametric approach speaker diarization that builds onnthe hierarchical Dirichlet process hidden Markov model HDP HMM Teh 2006 Although thenbasic HDP HMM tends over segment the audio data creating redundant states and rapidly switchingnamong them describe augmented HDP HMM that provides eff ective control over the switching rate nWe also show that this augmentation makes possible treat emission distributions nonparametrically nTo scale the resulting architecture realistic diarization problems develop sampling algorithm thatnemploys truncated approximation the Dirichlet process jointly resample the full state sequence ngreatly improving mixing rates Working with benchmark NIST data set show that our Bayesiannnonparametric architecture yields state the art speaker diarization results 
11357 en Quickest Change Detection This work examines the problem sequential change detection the constant drift Brownian motion the case multiple alternatives performance measure extended Lordenas criterion proposed nWhen the possible drifts assumed after the change have the same sign the CUSUM rule designed detectnthe smallest absolute value drift proven the optimum the drifts have opposite signs thenna specifi CUSUM rule shown asymptotically optimal the frequency false alarms tends tonin finity 
11359 en Adaptive Sequential Bayesian Change point Detection Nonstationarity changes the generative parameters are often key aspect real world timenseries which comprise many distinct parameter regimes inability react regime changesncan have detrimental impact predictive performance Change point detection CPD attemptsnto reduce this impact recognizing regime change events and adapting the predictive model appropriately nAs result can useful tool diverse set application domains includingnrobotics process control and finance CPD especially relevant finance where risk resultingnfrom parameter changes often neglected models For example Gaussian copula models used innpricing collateralized debt obligations CDOs had two key flaws assuming that subprime mortgagendefaults have fixed correlation structure and using point estimate these correlation parametersnlearned from historical data prior the burst the real estate bubble Bayesian change pointnanalysis avoids both these problems assuming change point model the parameters andnintegrating out the uncertainty the parameters rather than using point estimate 
11360 en Temporal Segmentation with Kernel Change point Detection introduce kernel based method for change point analysis within sequencenof temporal observations Change point analysis unlabeled sample observationsnconsists first testing whether change the distribution occurs withinnthe sample and second change occurs estimating the change point instantnafter which the distribution the observations switches from one distribution tonanother different distribution propose test statistic based upon themaximumnkernel Fisher discriminant ratio measure homogeneity between segments nWe derive its limiting distribution under the null hypothesis change occurs nand establish the consistency under the alternative hypothesis change occurs nThis allows build statistical hypothesis testing procedure for testing the presencenof change point with prescribed false alarm probability and detectionnprobability tending one the large sample setting change actually occurs nthe test statistic also yields estimator the change point location Promisingnexperimental results temporal segmentation mental tasks from BCI data andnpop song indexation are presented 
11408 en Presentation Global port cities
11409 en Presentation Decorative brickwork global history
11410 en Presentation Before the scramble for Africa tracing African architecture through trade
11411 en Presentation 20th century African urbanism three vignettes
11412 en Presentation global history pilgrimage introduction
11413 en Presentation The temple the cave rock cut architecture
11414 en Lecture The importance chemical principles
11415 en Lecture Discovery electron and nucleus need for quantum mechanics
11417 en Lecture Wave particle duality matter SchrÃ¶dinger equation
11418 en Lecture Hydrogen atom energy levels
11419 en Lecture Hydrogen atom wavefunctions orbitals 
11421 en Lecture Multielectron atoms and electron configurations
11423 en Lecture Periodic trends continued Covalent bonds
11425 en Lecture Exceptions Lewis structure rules Ionic bonds
11426 en Lecture Polar covalent bonds VSEPR theory
11427 en Lecture Molecular orbital theory
11428 en Lecture Valence bond theory and hybridization
11429 en Lecture Determining hybridization complex molecules Thermochemistry and bond energies bond enthalpies
11430 en Lecture Entropy and disorder
11431 en Lecture Free energy and control spontaneity
11433 en Lecture Chatelier principle and applications blood oxygen levels
11434 en Lecture Acid base equilibrium MIT water safe drink 
11435 en Lecture Chemical and biological buffers
11436 en Lecture Acid base titrations
11437 en Lecture Balancing oxidation reduction equations
11439 en Lecture Chemical and biological oxidation reduction reactions
11440 en Lecture Transition metals and the treatment lead poisoning
11441 en Lecture Crystal field theory
11442 en Lecture Metals biology
11443 en Lecture Magnetism and spectrochemical theory
11445 en Lecture Nuclear chemistry and elementary reactions
11447 en Lecture Temperature and kinetics
11732 en The Black Hole the Center Our Galaxy The Nobel Prize winning physicist talks about various aspects our galaxy and discusses new methods astronomy and astrophysics that make possible explorations deep into the heart the Milky Way Link http mitworld mit edu video 603 Lecture´ Homepage Host http mitworld mit edu host view Ford MIT Nobel Laureate Lecture Series 
11734 en Bose Einstein Condensates The Coldest Matter the Universe What happens when gas cooled absolute zero new door the quantum world opens because all the atoms start marching lockstep forming one giant matter wave the Bose Einstein condensate This was predicted Einstein 1925 but only realized 1995 laboratories JILA Boulder and MIT Since then many properties this mysterious form matter have been revealed including matter wave amplification and quantized vortices Bose condensates have been used realize basic atom laser intense source coherent matter waves Link http mitworld mit edu video Lecture´ Homepage Series http mitworld mit edu host view Physics Department Host http mitworld mit edu series view 2001 Physics Colloquium 
11735 en The Philosophy Conflict Resolution Link http mitworld mit edu video Lecture´ Homepage Host http mitworld mit edu host view Ford MIT Nobel Laureate Lecture Series Event Sponsors http mitworld mit edu host view Graduate Student Council http mitworld mit edu host view Undergraduate Association http mitworld mit edu host view Community Services Office MIT http mitworld mit edu host view Office the Chancellor 
11738 en 2002 Nobel Prize Physiology Medicine Nobel Lecture October 2002 The Nobel Prize Physiology Medicine was awarded Robert Horvitz Sydney Brenner and John Sulston for their discoveries concerning genetic regulation organ development and programmed cell death Link http mitworld mit edu video Lecture´ Homepage Host http mitworld mit edu host view McGovern Institute for Brain Research MIT Event Sponsor http mitworld mit edu host view MIT School Science 
11801 en New Frontiers with Ultracold Gases Better bring sweater when you visit Wolfgang Ketterle’ laboratories This master cool has managed reduce temperatures his vacuum chambers below those found interstellar space “The colder are the more have the potential make new discoveries ” says Ketterle won the 2001 Nobel Prize Physics for generating Bose Einstein condensates atoms that clump together briefly gas frigid temperatures Now Ketterle manipulating these transient events novel ways Using magnetic field can generate Bose Einstein condensates and transport them potentially microchips envisions supersensitive chips that will help measure rotation and gravity aid navigation and geological exploration the decades ahead And his latest triumph Ketterle actually formed ultracold molecules after bringing two atoms together the chilliest manmade conditions ever generated flouted chemists’ predictions and achieved heat release “ ’ holding atoms laser beam turn down the laser power and those atoms turn into molecules… nature had knocked door and said you have one free wish wish for something you want science wouldn’ have been bold enough ask for that ” Link http mitworld mit edu video 192 Lecture´ Homepage Host http mitworld mit edu host view Physics Department 
11802 en Progress the Study the Ray Background Riccardo Giacconi has probably seen deeper into the universe than any other human being has conducted his explorations not with the naked eye but with series increasingly sensitive detectors relentlessly searching for the source cosmic ray radiation this first person account pursuing one question for years what emerges most clearly the kind focus determination and invention required make discoveries the Nobel Prize league Giacconi confesses that “ ray astronomy not easy” – admirable understatement – but succeeds proving three key points from the Uhuru satellite the Hubble and Chandra telescopes the success experiments depends much brilliant instrument design data analysis individual identifiable galaxies are the source the universe’ ray radiation background and are now “looking objects whose nature not know” – objects that the next generation astronomers will understand only they have the resources build new instruments Link http mitworld mit edu video 197 Lecture´ Homepage Host http mitworld mit edu host view Massachusetts Space Grant Consortium 
11803 en The Origin Mass and the Feebleness Gravity stunning roster awards all identify Frank Wilczek one the most profound and influential theoretical physicists alive today This lecture proves the point Wilczek goes after one the deepest questions science What the origin mass Rewriting Einstein’ famous equation dramatizes that energy the source mass energetic but massless quarks and gluons Wilczek argues give rise mass finding quasi stable equilibrium states better know protons and neutrons nnHaving reinterpreted the theory quantum chromodynamics brisk half hour Wilczek plunges into another brain straining question What makes gravity feeble Here the more tentative answer derives from the unimaginably tiny dimensions the Planck scale Fundamental forces make sense that realm gravity weak only relative the enormously larger scales live Wilczek looks forward testing some these speculations via experimental results early 2009 Link http mitworld mit edu video 204 Lecture´ Homepage Host http mitworld mit edu host view Physics Department 
11804 en 2004 Nobel Colloquium There’ magic formula for winning the Nobel Prize But you can’ find more classic model than the career Frank Wilczek Feshbach Professor Physics and 2004 Nobel laureate nnWilczek was year old graduate student Princeton when made his breakthrough discovery High energy physics was baffled the “strong force ” which binds the quarks that make protons and neutrons Wilczek with two colleagues who share the prize was brave enough entertain really startling idea the strong force works just the opposite way from the more familiar forces nature – the closer together the particles are the weaker the force becomes idea Wilczek captured the phrase asymptotic freedom ” This profound insight into the fundamental forces nature has astonishing explanatory power not only for physics but also for cosmology now understand the early universe – the first few minutes existence – better than understand the universe around today nnFar from resting his Nobel laurels Wilczek still working the most puzzling frontiers his science – for example struggling explain The Origin Mass and the Feebleness Gravity the subject his previous Physics Colloquium Link http mitworld mit edu video 237 Lecture´ Homepage Host http mitworld mit edu host view Physics Department 
11806 en Ending Global Poverty Imagine bank that loans money based borrower’ desperate circumstances where Muhammad Yunus says “the less you have the higher priority you have ” Turning banking convention its head has accomplished world good for millions impoverished Bangladeshis the pioneering economist Yunus has demonstrated the last three decades What began modest academic experiment has become personal crusade end poverty Yunus reminds that for two thirds the world’ population “financial institutions not exist ” Yet “ ’ created world which goes around with money you don’ have the first dollar you can’ catch the next dollar ” was Yunus’ notion the face harsh skepticism give the poorest the poor their first dollar they could become self supporting “ ’ not talking about people who don’ know what with their lives… They’ good enterprising smart anybody else ” His Grameen Bank spread from village village lender tiny amounts money microcredit primarily women Yunus heard that “all women can raise chickens cows make baskets said ‘Don’ underestimate the talent human beings ’ ” collateral required nor paperwork—just effort make good and pay back the loan Now the bank boasts million borrowers receiving half billion dollars year has branched out into student loans health care coverage and into other countries Grameen has even created mobile phone company bring cell phones Bangladeshi villages Yunus envisions microcredit building society where even poor people can open “the gift they have inside them ” Link http mitworld mit edu video 289 Lecture´ Homepage Host http mitworld mit edu host view 124 Poverty Action Lab Event Sponsors http mitworld mit edu host view Economics Department http mitworld mit edu host view MIT School Humanities Arts and Social Sciences 
11807 en Leadership Complex Technology Driven World Sometimes the best way achieve leadership pursuing vision meeting some personal goals these three top flight technologists suggest nnRobert Langer admits “ don’ tend think myself leader have simple ideas just want see can some good and get satisfaction out that ” counts himself lucky have gotten job Harvard Medical School which allowed him apply engineering medical problems “ wanted see could make things that might help improve people’ health ” attributes some his leadership learning years struggle acquiring grant money— one case year battle with the NIH back novel drug delivery system for which Langer was awarded the Charles Stark Draper Prize 2002 nnSays Robert Metcalfe “ have idealization innovative leadership—that ’ lovely But the enemy the status quo and ’ resourceful and determined defeat innovation ” Metcalfe’ personal style figures his successes went war against IBM the 1980s “when had invention that was better than what they had and they threw all their monopoly resources against was alone and surrounded and beat them ” make progress against the status quo Metcalfe states “you have obnoxious ”nnDon’ forget schmoozing and team playing reminds Nobel Laureate Phillip Sharp who acquired much his savvy moving through academic ranks MIT and partnering with outside firms “ like set goal – that ’ like see this technology that this scientific question answered ” While you must set goals and seize opportunities says you also need attract optimal talents your environment and “get others play the game ” These are skills Sharp says learned high school sports Link http mitworld mit edu video 304 Lecture´ Homepage Host http mitworld mit edu host view 131 MIT Leadership Center Series http mitworld mit edu series view The Passion Action Summit The MIT Leadership Center Launch 
11818 en How Would Climate Change Influence Society the 21st Century Panel Rajendra Pachauri leads fellow members the Nobel Prize winning IPCC remarkable public session soul searching Now that the IPCC has helped make climate change signal issue our times what next nnJohn Reilly wonders whether the IPCC should celebrating any success given that greenhouse gas emissions continue rise spite all the comprehensive study Given the “dismal outcome far ” ’ important that the IPCC “avoid the complacency that comes with big awards ” and that “much all the work still there done ” “ ’ probably time for sunset Michael Golay suggests ” Now that the IPCC has succeeded establishing climate change “ reality among least the chattering classes ” the next step actually social question one that much more difficult than coming with new technologies “ ’ really talking about interfering with markets and doing this way that doesn’ become simply another vehicle for creating profits for special interests… ”nnWilliam Moomaw believes IPCC reports have made possible policy and corporate innovations that would have been unthinkable only decade ago and the IPCC should continue serve advisory capacity the world laying out the technological and economic possibilities Says Moomaw “ got off bad start talked about global warming being environmental issue when fact global warming symptom maldevelopment nnThe IPCC “should continue the voice science and help well informed society make tough decisions ” declares Andreas Fischlin This will mean “facing the issue sustainability the context climate change extent many won’ like ” Research challenges developing nations may impede efforts “optimize the IPCC’ work and help the whole issue moving toward more sustainable world ”nnAkimasa Sumi believes IPCC should continue have powerful role the future because the “climate change issue driven science ” proposes refining climate models the hope reducing uncertainty around such matters the role aerosols and clouds says the focus must now adaptation and mitigation particularly over year time scale nnThe IPCC established its relevance because drew line between being policy relevant and policy prescriptive says Adil Najam Now “ need claim victory understanding the mechanics the science and stop debating ” The next step must mean “focusing not the scope the problem but potential for solutions ”nnShould the IPCC attempt become more prescriptive believes Howard Herzog “ would lose respect ” his years with the organization “anytime got into policy prescriptive areas when got close the line tensions rose arguments intensified lost consensus ” thinks ’ important continue the IPCC’ work because the science will change and need “broker out there summarize where science critical issues ” Link http mitworld mit edu video 551 Lecture´ Homepage Host http mitworld mit edu host view 158 MIT Energy Initiative Series http mitworld mit edu series view 123 Alliance for Global Sustainability Conference 
11824 en The Energy Problem and the Interplay Between Basic and Applied Research The situation facing our planet could hardly more dire There’ increasingly dangerous competition among nations for ever scarce energy resources and climate change racing ahead predictions Although Steven Chu believes “ are getting close where ’ very nervous time ” also sees “reason for hope ”nnJust science the 1970s produced “green revolution” agricultural productivity preventing mass starvation swelling global population Chu counting transformative scientific and engineering ideas achieve sustainable energy and cap climate change nnAs chief architect new policy and with tens billions dollars pump into his vision Chu targeting key areas Number one his list energy efficiency and conservation Since buildings use the nation’ total energy designing more efficient homes and offices will make big difference There are “tune ups” possible for existing buildings and software that can direct lighting heating and cooling where ’ needed that can achieve plus energy savings and won’ break the bank Says Chu “This truly low hanging fruit but have build the tools that allow architects and structural engineers get with ”nnOn the supply side Chu has his heart set transformative technologies such nanotech breakthroughs solar power ’ looking for ways scale biomass fuel production now that synthetic biology can make microbes manufacture gas like fuels Noting particular the work MIT’ Dan Nocera Chu says “wants use nature inspiration but beyond nature ” performing artificial photosynthesis create new hydrocarbons And the and China continue dependence coal figuring out how capture and sequester carbon from these plants figures “high the list things must ” ’ again hoping researchers will find some analog nature’ ability grab and neutralize CO2 nnThe ideal environment for jumpstarting such urgent scientific efforts believes Chu something like Bell Labs where Chu himself worked The Labs performed “mission driven research” around communications and for war efforts but along the way also developed the transistor information theory radio astronomy and lasers among many examples These scientist led labs emphasized exchange ideas and rapid infusion research funds the most promising work This led inventions that turn transformed the economy Chu envisions energy lab equivalents that “deliver the goods” along with fundamental science “ you can have the Nobel Prize and save the world the same time ” Link http mitworld mit edu video 683 Lecture´ Homepage Host http mitworld mit edu host view The Office the President MIT Series http mitworld mit edu series view 108 Karl Taylor Compton Lecture 
11825 en Challenges Nation Building times humorous and other times defiant José Ramos Horta describes nurturing the 21st century’ first sovereign state through its formative years The journey East Timor from brutal Indonesian rule fragile self governance has involved Ramos Horta conflict and debate from the halls the the smallest villages this tiny Southeast Asian island nnHe describes the scene 2002 after two years supervised transition when Indonesia handed off nation had governed force for decades “ human calamity close 200 thousand people lost their lives ” Another 200 thousand were forcibly displaced into West Timor departed “ anger and frustration ” Indonesia’ military orchestrated the destruction the nation’ cities roads schools and clinics “The economy was standstill ” says Ramos Horta “ received barely sketch state skeleton ”nnThe challenge rebuilding East Timor all the more daunting given “the psychological emotional trauma years violence ” There are bitter disputes involving how conduct national process reconciliation Western ambassadors recently called Ramos Horta “representatives two countries most notorious…for providing weapons and the red carpet treatment the dictatorship Indonesia ” They advocated establishing international tribunal pursue crimes against humanity during Indonesian rule Says Ramos Horta “Had been bad mood would have said ‘Excuse the two you are lecturing human rights and justice ’”nnDespite warnings from the that “lack justice encourages impunity ” believes East Timor must travel its own path toward reconciliation East Timor set such tribunal “Who would start with Indonesia the which provided weapons Suharto Australia all them once ” states “ you pursue justice any cost without being sensitive the challenges and complexities the ground you undermine the incipient nation democracy and justice ”nnToday when Ramos Horta travels the countryside people don’ want discuss security and unity Recounts Ramos Horta “They joke with ‘ President really like your road peace but prefer road our village ’” ’ now focused providing his people with such essentials clean water and electricity and shoring the nation’ fragile social and economic institutions “Let’ put all the past behind Look after the victims the wounded their minds bodies and souls build country that deserving much sacrifice Chasing the ghosts the past leads nowhere ” says Ramos Horta Link http mitworld mit edu video 714 Lecture´ Homepage Host http mitworld mit edu host view 175 Legatum Center for Development and Entrepreneurship Series http mitworld mit edu series view 151 The Legatum Pericles Lecture Series 
11826 en America Leadership Clean Energy welcoming President Obama MIT PresidentnSusan Hockfield summarizes the vast array energy innovation MIT including the MIT Energy Initiative and the student led 1700 member Energy Club and declares share President Obama view that clean energy the defining challenge this era nnIn his introduction President Obama Professor Ernest Moniz Director the MIT Energy Initiative MITEI and member the President Council Advisors Science and Technology PCAST discusses global issues clean energy science and innovation and credits Obama for expanding the nation energy vision nnBarack Obama came MIT not just praise the Institute leading edge energy research but encourage all America’ “heirs legacy innovation” their pursuit discovery The nation owes much its prosperity risk takers and entrepreneurs Obama said and now given the linked challenges energy and climate change need such pioneers more than ever nnAfter visiting MIT labs working more efficient solar cells and lighting batteries “that aren’ built but grown ” and offshore wind plants that function even when the air still Obama told large crowd that the nation inevitably transitions from fossil fuels renewable energy ’ counting the kind “innovative potential display MIT ”nnObama acknowledges the great challenges facing energy researchers and entrepreneurs traditional energy supplies become more precious and energy demands grow nations are competing develop new ways produce and use energy said Obama and the winner will lead the global economy “ want America that nation ’ that simple ”nnHis administration’ response has been make massive investments both clean energy and basic science Obama aims these efforts both the current recession and the nation’ future economic health Clean energy jobs today and research “ produce the technologies tomorrow” will “lay new foundation for lasting prosperity ” hopes this comprehensive approach will culminate legislation that will transform America’ entire energy system nnBut Obama under delusion that all will embrace his plan “The closer get ” says Obama the “more ’ hear from those whose interest ideology run counter that much needed action ’ engaged ” What worries the president more though dangerous pessimism shared many “that our politics are too broken and our people too unwilling make hard choices for actually deal with this energy issue ” Implicit this argument says that America has lost its fighting spirit nnObama rejects this argument “because what ’ seen here MIT … and because what know are capable achieving when called upon … ” The nation that harnessed electricity and the atom one that has always sought out new frontiers “and this generation different ” Obama invokes the achievements the past call arms “ what sure difficult fight the months and years ahead” ensure that “ are the energy leader that need ” Link http mitworld mit edu video 716 Lecture´ Homepage Host http mitworld mit edu host view The Office the President MIT 
11870 en  Beautiful Mind Genius Madness Reawakening Sylvia Nasar the author Beautiful Mind tells the extraordinary story mathematician John Nash drama about the mystery the human mind and shares some her experiences writing her prize winning biography Link http mitworld mit edu video Lecture´ Homepage Lecture Host http mitworld mit edu host view Department Mathematics MIT Series http mitworld mit edu series view Applied Mathematics Colloquium 
11871 en  New Kind Science Wouldn’ exciting Stephen Wolfram wonders have little computer program that could function precise ultimate model our universe you ran the program long enough would reproduce every single thing that happens ’ not out the question according Wolfram’ lecture which somehow encapsulates his 200 page opus New Kind Science single hour nnWolfram’ vast and penetrating research uses simple computations generate complex computer models that resemble designs found nature embraces the really big subjects and the really small ones—from patterns mollusk shells and the shapes leaves and snowflakes free will evolution and extra terrestrial life This new kind thinking might provide alternatives evolution explaining how different forms life emerged Wolfram believes his work already transforming the study science well making possible host new technologies Link http mitworld mit edu video 149 Lecture´ Homepage Host http mitworld mit edu host view Department Mathematics MIT Series http mitworld mit edu series view Applied Mathematics Colloquium 
11872 en Space Shuttle Discovery Mission the International Space Station STS 121 The sign sheet for astronaut school likely grow even longer after viewing Stephanie Wilson’ reality video about her days space Wilson self described “robo chick ” served specialist July 2006 one NASA’ return flight test missions following the Columbia accident She narrates video account day day diary – the work and fun she and fellow astronauts engaged nnMuch Wilson’ job involved using robotic arm help unload supplies onto the International Space Station which the shuttle Discovery was docked for several days When she wasn’ helping transfer 000 pounds food gear and experiments she was assisting crew members space walks during which they assembled another piece the space station and tested putty like material for repairing cracks and holes the shuttle delicate heat tiles Wilson who was operating foot long robotic boom arm for these jobs describes the challenge functioning “ minutes day and minutes night ” the astronauts swiftly circled the earth “ got very cold and dark and colleagues said was very lonely the end bendy stick ”nnWilson’ video clearly demonstrates the awesome solitude these spacewalkers well the mundane almost household nature their chores Astronauts used tools resembling cordless drills assemble new hardware onto the space station Her footage also reveals the camaraderie and joy life above earth She takes spinning like fish through the submarine narrow chambers the attached shuttle and space station and view astronauts zero gravity play with floating balls water containing air bubbles and attempt catch myriad their mouths Wilson herself performs flipping sequence admitting “There’ child all ”nnTo Wilson’ clear regret this may her last shuttle flight After mission astronaut goes the bottom long list flight aspirants But more the point NASA facing budget cuts and the mandate lunar and Mars missions will retire the shuttles 2010 with the goal sending new vehicle 2014 During the interim years Russia’ Soyuz space ships will exclusively bear the burden transport the space station Link http mitworld mit edu video 391 Lecture´ Homepage Host http mitworld mit edu host view Department Mathematics MIT Series http mitworld mit edu series view Applied Mathematics Colloquium 
11873 en The Politically Correct Atomic Reactor With energy emerging issue domestic and international importance the Nuclear Engineering Department MIT has been quietly working technology that hopes will meet the challenge providing clean safe and reliable source electricity What started January 1998 Independent Activities Period IAP project has blossomed into full design effort whose goal build nuclear plant that can compete with natural gas meltdown proof and have waste form that can disposed without reprocessing nnThe technology chosen was high temperature helium cooled gas turbine powered modular pebble bed reactor which was originally developed Germany the late and The MIT design team taking fresh look all aspects the technology from factory manufacture and site assembly advanced fuel designs safety analyses modularity features that allow the entire plant shipped truck and advanced instrumentation and control systems This technology was mentioned the current Bush national energy plan example the type fresh thinking that needed nnThe colloquium will describe the technology and identify opportunities for other departments contribute the design this plant which might actually built consortium product collaboration with other universities national laboratories and industry Link http mitworld mit edu video Lecture´ Homepage Host http mitworld mit edu host view Electrical Engineering and Computer Science Department Series http mitworld mit edu series view EECS Colloquium Series 
11874 en Cryptography Science Magic Examples the tricks that can performed with modern cryptographic techniques will presented and each trick explored see whether science can proved what seems magic what seems may only illusion The tricks considered will include break cryptography leak secret sharing key cryptography see signatures watch coin tossing and knowledge proofs Link http mitworld mit edu video Lecture´ Homepage Host http mitworld mit edu host view Electrical Engineering and Computer Science Department Series http mitworld mit edu series view EECS Colloquium Series 
11925 en Space Exploration The Next 100 Years High hopes meet high frustration this panel whose participants collectively yearn for new vision guide our space program Andrew Chaikin recommends three step self help regimen move the program forward lowering the cost access space the going rate thousand dollars per pound embracing “outside the box” ideas and engaging national conversation about space Supriya Chakrabarti predicts that around years NASA will deploying robotic terrestrial planet finders and using the moon for both tourism and commercial development like mining This will possible the short term space scientists look for low cost launch options which might include exploiting existing missile technology Richard Binzel puts the odds civilization threatening asteroid impact the next 100 years one million but believes the odds are whole lot better that human beings will exploring asteroids space ’ got leg since ’ already sent robot reconnaissance the moons Jupiter ’ worried about catastrophic asteroid strikes Binzel says should start taking incremental steps such putting nuclear reactors space power vehicles for long inter planetary journeys Link http mitworld mit edu video 167 Lecture´ Homepage Lecture Host http mitworld mit edu host view Technology and Culture Forum Series http mitworld mit edu series view 100th Anniversary Flight 
11926 en Flight The Next 100 Years This panel delves into both the fabled and likely future air travel boy Joseph Corn treasured the Popular Mechanics issue whose cover featured man parking helicopter the garage America’ romance with aviation which started soon after the Wright Brothers’ flight wasn’ just about hardware transportation says Corn but about utopian dream Air travel would bring about world peace and brotherhood – dream says Corn shattered the dropping the nuclear bomb Jane Garvey reminisces about Y2K knuckle biting – she was bravely aloft New Year’ Eve 1999 The tremendous growth regional jet travel and urban hub congestion will shift aviation rural communities Garvey projects but believes new runways will built without strong local commitment nnAllen Haggerty says that with only five airplane manufacturers left expect streamlined plane travel you get your desired destination more directly but without amenities Some new and different planes are the works the Airbus 380 will carry 555 passengers with less noise than 747 Boeing designing cargo plane called “The Pelican ” which will have 500 foot wing span and length greater than football field Link http mitworld mit edu video 174 Lecture´ Homepage Lecture Host http mitworld mit edu host view Technology and Culture Forum Series http mitworld mit edu series view 100th Anniversary Flight 
11940 en Organizational Economics and Management Education less than hour Robert Gibbons not only gets through 200 years economic history but outlines new curriculum organizational research planned the Sloan School Gibbons recounts some classic business stories – for instance how Birds Eye’ success with frozen peas made the frozen food market “thick ” opening scores smaller players Management students must master the basics economics says Gibbons but Sloan must also help them train their sights the current economy The planned course offerings will knit together such traditional studies economic theory markets and competition with the latest the fields corporate governance and culture technology and innovation Link http mitworld mit edu video 144 Lecture´ Homepage Lecture Host http mitworld mit edu host view MIT Sloan School Management Series http mitworld mit edu series view Back the Classroom 2003 
11941 en Innovation Are You Predator Are You Prey seems well established truth that new technologies drive out older established ones this lecture MIT Sloan Professor James Utterback demonstrates just the opposite that symbiotic relationship can evolve between new “predator” and older “prey” industries that can sustain both Using such vivid historical examples the lightbulb safety match and mousetrap describes how the original companies that created these products thrived even they were challenged newer firms that harnessed automated manufacturing different distribution methods Playing remarkable film shot 1927 Utterback shows how the transition from ice harvesting mechanical refrigeration expanded the market for both – exemplifying the idea that new and old business ideas can and often reinforce each other Link http mitworld mit edu video 142 Lecture´ Homepage Lecture Host http mitworld mit edu host view MIT Sloan School Management Series http mitworld mit edu series view Back the Classroom 2003 
11956 en Responding the environment Epigenetic variations heredity and evolution Odgovor razmere okolju Epigenetska variabilnost pri dedovanju evoluciji his theory evolution Darwin recognized that thenconditions life play role the generation hereditarynvariations well their selection However nsince the mid 20th century the Modern Synthesis versionnof Darwinism expelled developmental responses environmentalnchanges from the study heritable variation nIt identifi heredity with genetics with hereditary variationnbeing seen terms combinations randomly generatedngene mutations This view has dominated evolutionaryntheorizing for the last sixty years Since the 1990s ndata coming from developmental biology particularlynthe molecular aspects differentiation and morphogenesis nfrom ecology particular ideas about niche constructionnand studies symbiosis from behavior wherenthe transmission information through social learning isna major focus and from cultural studies where the relationnbetween cultural evolution and genetic evolution isnunder scrutiny challenging the modern synthesis view nMarion Lamb and devoted our recent book Evolutionnin Four Dimensions this challenge and identifi fourntypes inheritance genetic epigenetic behavioral andnsymbol based each which can provide variations which natural selection will act Some these variationsnarise response developmental and environmentalnconditions developmentally induced reconstructednheritable variations can selected and lead changesnin the nature and frequency phenotypes populations nFurthermore under certain conditions the mechanismsnunderlying epigenetic inheritance can also lead the reorganizationnof the epigenome this lecture reviewnthe challenge that comes from the work epigeneticsncarried out since the late 1980s discuss different types ofnepigenetic inheritance mechanisms examine the prevalence nstability and inducibility cellular epigenetic variants nand point some the ways which epigeneticnmechanisms have affected micro and macro evolution svoji teoriji evoluciji Darwin izpostavil vlogo ivljenjskihnrazmer nastanku dednih razlik njihovinselekciji sredine stoletja dalje moderna sintezandarvinizma izklju ila razvojne odgovore okoljskenspremembe tudij dednih razlikah Dedovanjenje izena ila genetiko dedne razlike opisovala kotnkombinacije naklju nih genskih mutacij pogled jenprevladoval evolucijskih polemikah zadnjih estdesetnlet devetdesetih let dalje novi podatki razvojnenbiologije predvsem molekularni vidiki diferenciacije innmorfogeneze ekologije ustvarjanje raziskave simbioze nraziskav vedenja prenos informacij prek socialneganu enja kulturolo kih raziskav povezave medngenetsko kulturno evolucijo spreminjajo pogled modernensinteze Marion Lamb sva teh izzivih pisali vnnajini knjigi Evolution Four Dimensions kateri svandolo ili tiri tipe dedovanja genetsko epigenetsko vedenjskonin simbolno katerih lahko vsak predstavljanvir razlik katerih deluje naravni izbor Nekatere odnteh razlik izvirajo razvojnih okoljskih razmer karnvodi spremembe naravi frekvenci fenotipov vnpopulaciji Nadalje lahko mehanizmi odgovorni epigenetsko dedovanje pod dolo enimi pogoji vodijo vnreorganizacijo epigenoma tem predavanju bom predstavilanpregled epigenetskih raziskav poznih osemdesetihnlet naprej nadalje bom predstavila razli tipenoz mehanizme epigenetskega dedovanja prevalenco nstabilnost inducibilnost razli nih epigenetskih variantnin izpostavila nekatere ine katerimi epigenetskinmehanizmi vplivali mikro makroevolucijo 
11970 en The ecosystem concept Koncept ekosistema The Convention Biological Diversity CBD defi nesnan “ecosystem” “dynamic complex plant animalnand micro organism communities and their non livingnenvironment interacting functional unit” see alsonTansley 1935 Christopherson 1996 The basic idea isnthat living and dead organisms are permanently involvednin the exchange energy material and informationnwith their environment Ecosystem function governednby organisms acting various stages within the system nPrimary producers green photosynthetically activenplants and bacteria form the base the system Theynhave the unique ability and conserve the energynof extraterrestrial radiation and produce digestible carbohydrates nlipids and proteins They are hierarchicallynfollowed herbivorous phytophagous organisms feedingnon them The rst order consumers are the preynfor second order consumers carnivores which huntnand feed herbivores There may further levels andnsteps carnivorous consumers depending the ecosystemsnselected Finally decomposers destruents andnreducers are mineralizing dead organic material thusnplaying their role organic material recycling – prerequisitenfor plant growth There broad spectrum ofnecosystems including terrestrial and aquatic ones Deepnsee coral reefs sea shores ponds rivers and creeks arenaquatic ecosystems are tundra taiga deserts grassnlands the terrestrial side But also anthropogenicallyninfl uenced systems may called ecosystems like urbannareas gardens waste land Ecosystems can threatenednby various stressors The toxicity introducednelements toxic gases heavy metals pesticides thenaggressiveness newly introduced invasive speciesn global warming economic globalization are only fewnexamples gradually unbalancing existing ecosystems konvenciji biolo raznolikosti CBD ekosistemnopredeljen kot dinami kompleks zdru rastlin ivalinin mikroorganizmov ter njihovega ivega okolja kinskupaj delujejo kot funkcionalna enota glej tudi Tansley n1935 Christopherson 1996 Osnovna ideja son ivi odmrli organizmi stalno vklju eni izmenjavonenergije snovi informacij svojim okoljem Delovanjenekosistema poganjajo organizmi svojim delovanjem nanrazli nih stopnjah sistema Primarni producenti zelene nfotosintetsko aktivne rastline bakterije baza ekosistema nker lahko sprejmejo zadr ijo energijo zunajzemeljskegansevanja proizvedejo razgradljive ogljikovenhidrate obe beljakovine Naslednjo stopnjo predstavljajonrastlinojedi organizmi potro niki prveganreda predstavljajo plen potro nike drugega redan mesojedci rastlinojedce lovijo njimi hranijo izbranem ekosistemu lahko zaporednih stopenjnmesojedih potro nikov Kon razkrojevalci razgradijonmrtev organski material igrajo klju vlogo recikliranjunsnovi potrebnih rast rastlin Obstaja mnogonekosistemov vklju kopenskimi vodnimi globokonmorje koralni grebeni obale ribniki reke potoki sonprimeri vodnih ekosistemov tako kot tundra tajga npu ava travi primeri kopenskih Med ekosistemenlahko pri tevamo tudi antropogene kot urbane povr ine nvrtovi odlagali odpadkov ekosisteme lahkonvplivajo razli stresni dejavniki strupeni plini kenkovine pesticidi ali agresivnost novih invazivnihnvrst globalno segrevanje ekonomska globalizacija 
11975 en Molecular markers and their application biogeography Molekulski markerji njihova uporaba biogeografiji The application molecular tools DNA sequences nDNA fingerprinting has revolutionized biogeographicnresearch over the last two decades Molecular biogeographyncan summarized under “phylogeography” anterm coined John Avise twenty years ago describingnthe branch science that explores and interprets thengeographical distribution genealogical lineages mynpresentation going discuss the following issues Why should use molecular markers bio geographicalnresearch Which types molecular markers are being used nhow are the data generated and how they looknlike Which questions can answered with molecularndata and which ones not nTo illustrate the above points will present studies thatnexplored the effect the glaciations the ice ages onnthe flora the Alps well the 6th framework projectn“INTRABIODIV” example for the integrationnof molecular data habitat data and species distributionndata starting point for that project was that species richnessnis the most widely used measure for biodiversity assessment nHowever intraspecific diversity geneticnpolymorphism that represents the evolutionary andnadaptive potential each species changing environments nThe main point the project was study possible correlationsnbetween intraspecific diversity and species richnessnor habitat variation The objectives were and explain possible relationships among inter nand intraspecifi plant diversity and habitat variation elaborate modeling approach predict intraspecific plant diversity using more efficiently accessiblensurrogates large scale iii establish tools for the design network protectednareas effectively ensure the sustainable managementnof natural genetic resources nThe following questions were asked using the Alps andnthe Carpathians model systems there congruence between intra interspecific biodiversity areas high endemism often coinciding withnglacial refugia harbour great degree intraspecificndiversity iii habitat variation characterized environmentalnparameters good surrogate for intra and interspecific diversity nIn order accomplish the aims intraspecific diversity wasnmapped using molecular markers model species nthe species richness was mapped the same area usingnmainly existing data plant distributions Furthermore nenvironmental data were compiled for map habitatndiversity and finally these maps were compared findnpossible correlations among these variables nUporaba molekularnih orodij zaporedje DNA prstninodtis DNA zadnjih dvajsetih letih prevetrila biogeografskenraziskave Molekularno biogeografi lahkonpovzamemo kot filogeografijo izraz skoval JohnnAvise predstavlja tisto znanost odkriva razlagangeografsko raz irjenost genealo kih linij Predstavil bomnnaslednja vpra anja Zakaj uporabljati molekularne markerje biogeografskihnraziskavah Tipe molekularnih markerjev ine pridobivanjanin vrste podatkov katera vpra anja lahko odgovorimo molekularniminpodatki katera moremo nKot primer povezovanja molekularnih habitatnih podatkovno raz irjenosti vrst bom predstavil raziskavo onposledicah poledenitev med ledenimi dobami alpskonfloro evropski program okvira INTRABIODIV Izhodi entega projekta bilo dejstvo pestrost vrstnnajpogostej kazalnik biodiverzitete Vendar intraspecifin raznolikost genetski polimorfizem predstavljanevolucijsko prilagoditveno vsake vrst vnspreminjajo okoljih Glavni poudarek projekta jenbila nost povezave med intraspecifi raznolikostjonin pestrostjo vrst ranolikostjo habitatov Cilji bili poiskati razlo iti razmerja med inter intraspecifin raznolikostjo rastlin ter habitatno raznolikostjo izdelati model napoved intraspecifi raznolikostinrastlin velikem obsegu uporabo bolj dostopnih nadomestkov dolo iti orodja izdelavo mre itenih obmo ijnin tem zagotoviti inkovito trajnostno upravljanjennaravnih genetskih virov eleli smo odgovoriti naslednja vpra anja pri emernsmo uporabili Alpe Karpate kot modelna sistema Ali obstaja skladnost med intra interspecifi raznolikostjo Ali imajo obmo veliko pojavnostjo endemitov innobenem tudi ledenodobnih reliktov visoko stopnjo intraspecifi raznolikosti Ali habitatne razlike jih dolo ajo okoljski parametri ndober pribli intra interspecifi raznolikost nDa dosegli namen smo pregledali intraspecifi nonraznolikost molekularnimi markerji pri modelnihnvrstah istih obmo jih smo ocenili vrstno pestrost izndostopnih podatkov raz irjenosti rastlin Okoljske podatkensmo vklju ili kot kazalnike habitate raznolikosti nNa koncu smo vse tri vrste podatkov primerjali binna morebitne povezave med vsemi spremenljivkami 
12173 en Lecture The Cognitive Architecture 
12174 en Lecture The Cognitive Architecture 
12175 en Lecture The Cognitive Architecture 
12176 en Lecture The Cognitive Architecture 
12177 en Lecture The Cognitive Architecture 
12178 en Lecture The Cognitive Architecture 
12179 en Lecture Theories Knowledge 
12180 en Lecture Theories Knowledge 
12181 en Lecture Theories Knowledge 
12182 en Lecture Theories Knowledge 
12183 en Lecture Theories Knowledge 
12184 en Lecture Complex Cognition 
12185 en Lecture Complex Cognition 
12186 en Lecture Complex Cognition 
12187 en Lecture Complex Cognition 
12188 en Lecture Emotion Motivation and Volition 
12189 en Lecture Emotion Motivation and Volition 
12190 en Lecture Emotion Motivation and Volition 
12191 en Lecture Emotion Motivation and Volition 
12192 en Lecture Emotion Motivation and Volition 
12193 en Lecture Emotion Motivation and Volition 
12194 en Lecture Cognitive Development Through the Life Span 
12195 en Lecture Cognitive Development Through the Life Span 
12196 en Lecture Cognitive Development Through the Life Span 
12197 en Lecture Cognitive Development Through the Life Span 
12198 en Lecture Cognitive Development Through the Life Span 
12199 en Lecture Cognitive Development Through the Life Span 
12200 en Lecture The Brain and Cognition 
12201 en Lecture The Brain and Cognition 
12248 en The Cyc Lexicon The Cyc knowledge base formalized representation vast quantity fundamental human knowledge facts rules thumb and heuristics for reasoning about the objects and events everyday life The medium representation the formal language CycL described below The consists terms which constitute the vocabulary CycL and assertions which relate those terms These assertions include both simple ground assertions and rules Cyc not frame based system the Cyc team thinks the instead sea assertions with each assertion being more about one the terms involved than another nnThe Cyc divided into many currently thousands microtheories each which essentially bundle assertions that share common set assumptions some microtheories are focused particular domain knowledge particular level detail particular interval time etc The microtheory mechanism allows Cyc independently maintain assertions which are prima facie contradictory and enhances the performance the Cyc system focusing the inferencing process nnAt the present time the Cyc contains nearly five hundred thousand terms including about fifteen thousand types relations and about five million facts assertions relating these terms New assertions are continually added the through combination automated and manual means Additionally term denoting functions allow for the automatic creation millions non atomic terms such LiquidFn Nitrogen and Cyc adds vast number assertions the itself product the inferencing process 
12290 en PAC Bayes Theory Supervised Learning
12293 en Incompatibilities between PAC Bayes and Exploration
12294 en Bounding the Gaussian Process Information Gain Applications PAC Bayes and Bandit Optimization
12296 en PAC Bayes Sample Compress and Kernel Methods
12297 en PAC Bayes Analysis Links Luckiness and Applications
12299 en Expectation prior PAC Bayes Bounds for SVMs
12300 en Data dependent Prior PAC Bayes Bounds Empirical Study
12301 en PAC Bayesian Analysis Unsupervised Learning
12302 en Bayes Average Case Performance PAC Bayes Bounds
12303 en PAC Bayesian Bounds for Spare Regression Estimation with Exponential Weights
12304 en Efficient Mixture Modeling with RKHS Embeddings PAC Bayesian Analysis
12339 en Reconstructing networks from experimental and natural genetic perturbations Functional genomics has demonstrated considerable success inferring the inner working cell through analysis its response various perturbations Perturbations can take the form experimental interventions like gene deletions RNA interference natural perturbations like SNPs copy number alterations talk will describe methods lab has developed reconstruct networks from the phenotypic effects gene perturbations particular will describe Nested Effects Models class probabilistic graphical reconstruct signaling pathways from downstream effects and introduce methods correlate the impact copy number variation gene expression with different sub types breast cancer 
12340 en Networking genes and drugs Understanding gene function and drug mode action from large scale experimental data gene regulatory network where two genes are connected they are directly functionally regulating each other can reverse engineered from large scale experimental data such gene expression profiles Here used simple but effective reverse engineering approach using all the available gene expression profiles mammals solving along the way the problems handling normalizing and analysing such massive dataset reverse engineered coexpression network for Homo Sapiens Mus Musculus from set 255 8895 gene expression profiles The human mouse network characterized set 22283 45101 nodes genes and set 817 629 641 095 edges where the edge weighted the Mutual Information measure between the two genes nnnWe show how the resulting network can then used understand the function gene the modularity gene regulation well tool analyse gene signatures identify the mode action drug nnnWe will also show how possible use gene expression profile build drug network where drugs can automatically grouped subnetworks communities drugs sharing similar mode action 
12342 en Estimating the contribution non genetic factors gene expression using Gaussian process latent variable models Thanks the recent increase the amount genetic profiling data available and the ability characterize disease activity through gene expression possible understand more detail the multitude causal factors linked with each disease This challenging task because the integration different sources biological data not straightforward and because non genetic factors such differences the experimental setting individual characteristics such gender and ethnicity are not always artificially controlled Since these non genetic factors may cause most the variation gene expression reducing the accuracy genetic studies there’ pressing need for models that take them explicitly into account present model which non genetic factors are unobserved latent variables the gene expression levels can described linear functions both these latent variables and Single Nucleotide Polymorphisms SNPs From generative point view can see the gene expression levels nnY epsilon nnWhere the matrix containing the SNPs are the latent variables and are mapping matrices Gaussian distributed isotropic error model and allows the model have non zero mean nnThe model inspired the one proposed Stegle but instead optimizing parameters and marginalising latent variables Probabilistic PCA marginalise the parameters and optimize the latent variables For particular choice prior over the mapping matrices and the two approaches are equivalent nnThis kind model called dual Probabilistic PCA and belongs wider class models called Gaussian Process Latent Variable Models Indeed dual PPCA the special case where the output dimensions are assumed linear independent and identically distributed Each these assumptions can relaxed obtaining new probabilistic models Many extensions this model are possible but even its simplest form the eQTL study results are extremely promising terms number significant associations found 
12343 en Using sequential Monte Carlo approaches design tool synthetic biology many engineering contexts easy state what want but hard achieve our desired outcomes The more potential solutions exist the harder becomes identify optimal solutions Here show how this problem can approached approximate Bayesian computation framework Our approach has the advantage that builds the powerful Bayesian model selection formalism includes sensitivity and robustness analysis extra cost and flexibly incorporates diverse design objectives illustrate the performance this approach the context bacterial two component systems TCS These systems enable prokaryotes and some simple eukaryotes and plants sense their environments and adapt their internal state changing circumstances present detailed analysis orthodox and unorthodox TCSs and show how can rationally construct TCS that show robust and optimal response characteristics different stimuli encountered during bacterial infections biotechnological biofuels production and bioremediation applications conclude elaborating the connections between our approach and maximum entropy procedures and the advantages over traditional engineering strategies 
12345 en Decoding underlying behaviour from destructive time series experiments through Gaussian process models major problem for biological time series that often experiments such gene expression measurements using microarrays RNA seq require the organism cells destroyed This means that particular time series often series measurements different organisms batches cells different times Biological replicates normally consist separate biological sample measured the same time With the advent single cell expression experiments where not currently conceivable make genome wide gene expression measurements without destroying the cell expect such set ups sustained nnMany existing approaches modelling transcriptional data postulate differential equation model for continuous time expression profiles from which the repeated observations arise Two ways modelling repeat experiments would either handle repeated observations being from shared profile from completely independent profiles The former approach assumes that gene expression profile for each experiment does not vary whilst the latter approach assumes relationship between the gene expression profiles For many experimental set ups might expect something between these two extremes where whilst each individual measurement comes from different collection cells different organism the experimental set broadly the same therefore expect some shared affects and some independent affects for the experiments nnIn this work propose integrated Gaussian process framework for analysis such experiments our approach independent aspects the experiments are modelled independent Gaussian process draws while the common profile across the experiments modelled separate Gaussian process The method adds power through sharing replicates for the common profile while being robust outliers from individual rogue experiments 
12347 en Identifying interactions the time and frequency domains local and global networks Reverse engineering approaches such Bayesian network inference ordinary differential equations ODEs and information theory are widely applied deriving causal relationships among different elements such genes proteins metabolites neurons brain areas and based upon multi dimensional spatial and temporal data Here focused the Granger causality approach both the time and frequency domains local and global networks and applied our approach experimental data genes and proteins For small gene network Granger causality outperformed all the other three approaches mentioned above global protein network from 812 proteins was reconstructed using novel approach The obtained results fitted well with known experimental findings and opened many experimentally testable predictions addition interactions the time domain interactions the frequency domain were also recovered Our approach general and can easily applied other types temporal data 
12349 en Deterministic and stochastic models bicoid protein gradient formation Drosophila embryos Modelling maternal mRNA degradation Passive diffusion class molecules known morphogens mechanism that helps establish spatial patterns gene expression during embryonic development was proposed Turing This mechanism usually modelled passive diffusion morphogen proteins translated from maternally deposited messenger RNAs Such diffusion models assume constant supply morphogens the source throughout the establishment the required profile steady state Working with the bicoid morphogen which establishes the anterior posterior axis the Drosophila embryo note that this constant source assumption unrealistic since the maternal mRNA known decay after certain time since egg laying have incorporated more realistic model the morphogen source since the maternal mRNA should expected decay explicitly model the source constant supply followed exponential decay and solve the reaction diffusion equation numerically for one dimensional morphogen propagation minimising the squared error between model outputs and measurements published the FlyEx database show how parameters diffusion rate mRNA and protein decay constants and the onset maternal mRNA decay can assigned sensible values also extend this work further show how such realistic source model may combined with recently published flow model that takes into account advective transport Moreover stochastic simulation based model which includes Bicoid molecule reactions has also been implemented with new source model our work 
12350 en Statistical analysis protein patternation cell membranes during immunological synapse statistical analysis two different experiments considered Both them are related understanding the mechanism behind the distribution molecules involved formation organized patterns protein complexes and molecules the contact interface between the membranes immune cell and antigen presenting cell Such patterns are called immunological synapses nnIn the first experiment cell adhering the flat surface lipid bilayer There are molecules two types the surface the bilayer They are fluorescently labelled with different colours their distribution can observed using microscope During the contact molecules one type are binding while second type molecules stay unbound This results segregation different type molecules and forming synapse pattern that can observed and scanned using confocal microscopy the case lipid bilayer the contact interface flat and the whole contact interface can scanned single image nnThe second experiment deals with cells forming synapses with target antigen presenting cells Two colour fluorescent labelling used again and similar protein patternation the cell cell contact interface can observed using confocal microscopy The main difference with the first experiment imaging technique instead single image series confocal images made along the same axis which approximately parallel the synapse interface result stack cross section fluorescence images the interacting cells considered for the quantitative analysis nnIn both experiments possible observe the segregation labelled molecules during the formation the synapse pattern terms fluorescence intensity values this expressed strong negative correlation between different colour fluorescence introduce model based the hypothesis exclusion size which explains the mutual segregation molecules result elastic properties single molecules and bonds combined with the properties the cell membrane Based this model computational algorithm for the Bayesian statistical analysis fluorescence images developed order estimate relevant physical parameters that cannot measured explicitly 
12351 en Machine learning methods for effective proteomics image analysis Two dimensional gel electrophoresis 2DGE remains the most widely used method for proteins identification and differential expression analysis due its lower cost and the existence mature commercial software tools for 2DGE image analysis despite the fact that non gel based methods are gaining popularity Although there are several software packages that promise automation the whole protein spot detection and quantification process the hard reality remains today that Fey and Larsen stated 2001 There program that remotely automatic when presented with complex images most programs require often more than day user hands time edit the image before can fully entered into the database‚ nnTo address these limitations and develop automated 2DGE image analysis workflow have developed previous works effective image analysis methodology that first denoises the 2DGE image based the Controurlet transform and then separates effectively the parts the denoised image which include true protein spots called Regions Interest ROIs from the background only areas using Active Contours without edges this work complete the image analysis workflow adding well tuned pipeline operations based unsupervised machine learning methods for analyzing further each isolated ROI order fish the centers and estimate the quantities the individual hidden spots One dimensional mixture modeling the ROI pixel intensities histogram applied first identify and remove any remaining background pixels Then the surviving ROI pixels are used molecules generators order convert random sampling the processed ROI image isomorphic dataset through appropriate random sampling representing the distribution molecules the underlying protein species that are projected spots the gel image This reverse engineering action rooted machine learning constitutes unique innovation this work that the best our knowledge has not been applied before 2DGE image analysis The candidate protein spot centers are then located applying hierarchical clustering Finally the individual spot boundaries are delineated fitting Gaussian models the data using generalized mixture modeling and the Minimum Message Length MML criterion control the best model complexity extensive evaluation this novel spot modeling methodology using both real and synthetic 2DGE images reveals that more precise and more specific than PDQuest terms spot detection while both methods achieve comparable high sensitivity Furthermore can estimate more reliably the volumes the extracted spots even the presence substantial noise and areas the image where faint and overlapping saturated spots are located close each other should noted that the end end workflow that have developed for 2DGE image analysis does not require any calibration parameters every time new gel image presented for analysis This desirable characteristic makes suitable candidate for the automatic processing image stacks needed for highthroughput proteomics analysis support systems biology projects 
12355 en Ethics for the New Millennium Ethics for the New Millennium addressed general audience presents moralnframework based universal rather than religious principles rests the observationnthat those whose conduct ethically positive are happier and more satisfied and the beliefnthat much the unhappiness humans endure actually our own making Itsnultimate goal happiness for every individual irrespective religious belief nThough the Dalai Lama himself practicing Buddhist his approach life and the moralncompass that guides him can use each and every one – Muslim Christian nJew Buddhist atheist – our quest lead happier more fulfilling life nAccording the Dalai Lama our survival has depended and will continue depend ournbasic goodness human beings the past the respect people had for their religionnhelped maintain ethical practice through majority following one religion another nToday with the growing secularization and globalization society must find waynthat transcends religion establish consensus what constitutes positive and negativenconduct what right and wrong and what appropriate and inappropriate nnLink http www dalailama com The Office His Holiness the Dalai Lama nLink http www dalailamafoundation org dlf index jsp The Dalai Lama Foundation 
12378 en Lecture The Brain and Cognition 
12379 en Lecture The Brain and Cognition 
12380 en Lecture The Brain and Cognition 
12381 en Lecture Assessment and Individual Differences 
12382 en Lecture Assessment and Individual Differences 
12383 en Lecture Assessment and Individual Differences 
12384 en Lecture Assessment and Individual Differences 
12437 en Cholera Canker Rash and Consumption Historical epidemiology and nosology Massachusetts 1850 1920
12438 en Leadership Regulatory Agencies and Public Health
12439 en California Department Public Health and Pandemics All Hands Deck 
12440 en Health Under Siege The Gazan Model
12441 en Rural Hypertension China Growing Epidemic
12469 en Course introduction the first lecture introduction solar cells given Simple examples illustrate the relevance this topic The question Why solar cells Will answered more than one way 
12470 en Solar radiation this session solar radiation reviewed Spectralconsiderations and its relation improve the performance solar cells isaddressed 
12471 en Semiconductor properties this lecture the semiconductor physics thatare involved the generation photovoltaic energy are studied Theabsorption separation and collection concepts are explained
12472 en  junction After the study the physics principles this session deeper review the topic carry the lecture the junction covered Part presents the basics used Part 
12473 en Losses and Optimization this lecture the cell performance limits are explained Techniques improve the performance the solar cells end with the record solar cells Topics related losses Part and optimization Part are shown 
12474 en Crystalline Technology this lecture crystalline silicon technology reviewed two parts Part and Part 
12475 en  system design Practical use solar cells important understand therefore design strategy for systems made this lecture systems are studied two parts Part and Part 
12476 en Organic solar cells Organic solar cells are excellent option continue with the research solar cells this lecture the last principles and advances organic solar cells are presented Part and Part 
12479 en Why users need semantic search While users dependence search continues increase user satisfaction not improving This partly because search hard and partly because users are becoming more demanding and pushing search beyond the traditional scope information retrieval Our research reveals three key problems search imprecise results need for query refinement and need support complex tasks and decisions Semantic technologies can help address these problems providing improvements core search results and also through enabling richer user experiences such faceted navigation entity centered experiences and task completion and decision tools 
12480 en Paraphrasing Invariance Coefficient Measuring Para Query Invariance Search Engines Paraphrasing the restatement reuse text which preserves its meaning another form para query paraphrase search query Humans easily recognize paraqueries but search engines are still far away from claim that order for search engine called semantic necessary that recognizes para queries returning the same search results for all para queries given query nRecognizing para queries important and desired ability search engine can relieve users the burden rephrasing queries order improve the relevance results 
12481 en Using BM25F for Semantic Search Information Retrieval approaches for semantic web search engines have become very popular the last years Popularization different libraries like Lucene that allows implementations almost out the box have make easier integration Semantic Web search engines However one the most important features Semantic Web documents the structure since this structure allow represent semantic machine readable format this paper analyze the specific problems structured and how adapt weighting schemas for semantic document retrieval 
12482 en Distributed Indexing for Semantic Search this paper describe the process building indices for semantic search using MapReduce compare the two most straightforward representations RDF data the horizontal index structure using parallel indices and the vertical index structure using elds measure the cost building indices and also compare retrieval performance keyword queries and queries restricted particular properties 
12483 en Dear Search Engine What’ your opinion about Sentiment Analysis for Semantic Enrichment Web Search Results Search Engines have become the main entry point Web content and large part the visible Web consists what presented them top retrieved results Therefore would desirable the rst few results were representative sample the entire result set This paper provides preliminary study about opinions contained search engine results for controversial queries such cloning immigration this end extract sentiment metadata from web pages and compare search engine results for several queries Furthermore compare opinions expressed the top results those other retrieved results examine whether the top ranked pages are good sample all results from opinion perspective preliminary empirical analysis compare results from commercial search engines controversial queries study the relation between sentiments topics and rankings 
12484 en Automatic Modeling User Real World Activities from the Web for Semantic have been developing task based service navigation system that offers the user services relevant the task the user wants perform The system allows the user concretize his her request the task model developed human experts this study reduce the cost collectingna wide variety activities investigate the automatic modeling users’ real world activities from the web extract the widest possible variety activities with high precision and recall investigate the appropriate number contents and resources extract Our results show that not need examine the entire web which too time consuming limited number search results 900 from among 000 000 search results from blog contents are needed addition estimate the hierarchical relationships present the activity model with the lowest possible error rate propose method that divides the representation activities into noun part and verb part nand calculates the mutual information between them The result shows almost the hierarchical relationships can captured the proposed method 
12485 en The Wisdom Tweetonomies Acquiring Latent Conceptual Structures from Social Awareness Streams Although one might argue that little wisdom can conveyed messages 140 characters less this paper sets out explore whether the aggregation messages social awareness streams such Twitter conveys meaningful information about given domain research community know little about the structural and semantic properties such streams and how they can analyzed characterized and used This paper introduces network theoretic model social awareness stream called tweetonomy together with set stream based measures that allow researchers systematically defi and compare diff erent stream aggregations apply the model and measures dataset acquired from Twitter study emerging semantics selected streams The network theoretic model and the corresponding measures introduced this paper are relevant for researchers interested information retrieval and ontology learning from social awareness streams Our empiricalnfi ndings demonstrate that fferent social awareness stream aggregations exhibit interesting differences making them amenable for different applications 
12486 en  Large Scale System for Annotating and Querying Quotations News Feeds this paper describe system that automatically extracts quotations from news feeds and allows efficient retrieval the semantically annotated quotes APIs for real time querying over million quotes extracted from recent news feeds are publicly available addition each day add around thousand new quotes extracted from around thousand news articles blogs apply computationalnlinguistic techniques such reference resolution entity recognition and disambiguation improve both precision and recall the quote detection support faceted search both speakers and entities mentioned the quotes 
12487 en Entity Search Building Bridges between Two Worlds consider the task entity search and examine which extent state art information retrieval and semantic web technologies are capable answering information needs that focus entities also explore the potential combining with technologies improve the end end performance specfii entity search task arrive and motivate proposal combine text based entity models with semantic information from the Linked Open Data cloud 
12488 en Methodology and Campaign Design for the Evaluation Semantic Search Tools The main problem with the state the art the semantic search domain the lack comprehensive evaluations There exist only few fforts evaluate semantic search tools and compare the results with other evaluations their kind nIn this paper present systematic approach for testing and benchmarking semantic search tools that was developed within the SEALS project Unlike other semantic web evaluations our methodology tests search tools both automatically and interactively with human user the loop This allows test not only functional performance measures such precision and recall but also usability issues such ease use and comprehensibility the query language The paper describes the evaluation goals and assumptions the criteria and metrics the type experiments will conduct well the datasets required conduct the evaluation the context the SEALS initiative our knowledge the first eff ort present comprehensive evaluation methodology for Semantic Web search tools 
12489 en Discussion the Entity Search Track
12490 en Predicting Positive and Negative Links Online Social Networks study online social networks which relationships can both positive indicating friendship and negative indicating opposition antagonism Such mix positive and negative links arise variety online settings study datasets from Epinions Slashdot and Wikipedia Despite the diversity settings considered find that the signs links the underlying social networks can predicted with high accuracy using models that generalize across the different domains These models provide insight into some the fundamental principles that drive the formation signed links networks and also shed light theories balance and status from social psychology 
12491 en Empirical Comparison Algorithms for Network Community Detection Detecting clusters communities large real world graphs such large social information networks problem considerable interest practice one typically chooses objective function that captures the intuition network cluster set nodes with better internal connectivity than external connectivity and then one applies approximation algorithms heuristics extract sets nodes that are related the objective function and that “look like” good communities for the application interest this paper explore range network community detection methods order compare them and understand their relative performance and the systematic biases clusters they identify evaluate several common objective functions that are used formalize the notion network community and examine several different classes approximation algorithms that aim optimize such objective functions addition rather than simply fixing objective and asking for approximation the best cluster any size consider size resolved version the optimization problem Considering community quality function its size provides much finer lens with which examine community detection algorithms since objective functions and approximation algorithms often have non obvious size dependent behavior 
12492 en Statistical Models Music listening Sessions Social Media User experience social media characterized rich interaction with the media content and other participants within the online community use statistical models describe the patterns music listening online communities different levels model complexity First adapt the LDA model capture the users’ taste songs and identify the corresponding clusters media and users Second define graphical model that takes into consideration the listening sessions and captures the listening mood users Our session model yields clusters media and users that capture the behavior exhibited across listening sessions and allows faster inference when compared the LDA model Our experiments with the data from online media site Zune Social music community demonstrate that the session model better terms the perplexity the music genre occurrence compared the LDA based taste model that does not incorporate cross session information and baseline model that does not use latent clusters 
12493 en Video Search Are Algorithms All Need During the 1990s search technology improved sufficiently handle large volumes textual material without the need for manual abstracting indexing and cataloging Taking professional cataloguers out the process text indexing created enormous value analogous set advances underway with video the 2010s But how and when will possible take professionals out the process cataloging video manually How can expect different approaches video search and search evolve and which ones will prove most useful What kind societal value can reap making making all our broadcast history readily accessible books journal articles and newspapers are now How can the W3C help with the development appropriate standards for video description and search Answers and debate about these questions will the focus this panel which has representatives from some the largest most viewed and carefully indexed collections digital video available online 
12618 en Machine learning for cognitive science What machine learning 
12619 en Cognitive science for machine learning What cognitive science 
12620 en Machine learning for cognitive science Bayesian methods and statistical learning theory
12621 en Cognitive science for machine learning Empirical methods
12622 en Machine learning for cognitive science Kernel methods and Bayesian methods
12623 en Cognitive science for machine learning Models and theories cognitive science
12626 en Bayesian modeling action and perception and some other stuff
12629 en Language acquisition and Kolmogorov complexity Why language acquisition possible
12631 en Machine learning and the cognitive science natural language
12633 en Neuroscience cognitive science and machine learning
12634 en How could networks neurons learn carry out probabilistic inference 
12636 en Reinforcement learning Tutorial Rethinking State Action Reward
12719 en Building the Knowledge Base for Environmental Governance Perspectives
12720 en Teaching Climate Change and the System Southeast Europe
12721 en The Role UNESCO Climate Change Education and Education for Sustainable Development Southeast Europe
12722 en Regional Coordination Nationale Climate Change Strategies and the Role Human Scientific Capacity Building
12723 en Climate Change Capacity Building United Nations Environment Programme
12725 en Teaching Climate Change the multiple relationships between climate change related education climate sustainability business sector and civil society
12726 en Innovative Diplomatic Training Climate Change Harnessing the Potentials Modern Information and Communication Technologies
12727 en UNITAR Approach Capacity Building and Development for Climate Change
12728 en Innovative Funding Scientific Capacity Building Climate Change the IPCC Scholarship Programme
12729 en  Studies Portal and Preparation SEE specific Subportal
12730 en Practical Experience with Regional Climate Change related Capacity Building CEE and SEE
12731 en Belgrade Initiative Climate Change for Scientific Capacity Building and Policy Development the SEE Region
12732 en Building the Knowledge base for Climate Change Governance the SEE
12733 en How achieve Interministerial and International Cooperation related Climate Change Capacity Building SEE
12736 en International and Crosssectoral Cooperation Climate Change Scientists Slovenian Experience and Issues for SEE region
12737 en Graz Climate Change research SEE networking expiriences and outlook
12738 en Teaching Climate Change The Role Tertiary Education Institutions and Barriers Effective Curriculum Transformation
12739 en Climate Change and United Nations Studies the Context SEE Regional Inter University operation
12741 en Global Challenges and the Need for International Cooperation SEE
12742 en Global Climate Change Situation Room Innovative Way Global Knowledge Collaboration zdruzi videom pride
12745 en Technology Park Ljubljana and Tech SME development Slovenia The current situation and perspectives for new High tech SMEs are presented The basic steps needed for the commercialization idea are listed emphasizing the concrete procedures and experiences from the Technological park Ljubljana 
12746 en From Wireless Sensor Networks Internet Things and Future Internet this presentation first overview the main PROSENSE project goals and achievements presented The main wireless sensor networks topics well the application addressed are described Building this view the further technological development the domain towards Internet Things and Future Internet given Finally the main research topics visions and activities the Europe level the Internet Things domain are overviewed 
12747 en Smart Grids and WSN Slovenia New concepts smart electricity networks SmartGrids represent the evolution the production and efficient use electricity the one hand the developed system oriented solutions will allow high penetration distributed energy resources and the other consumer oriented solutions will allow the efficient use energy for end users 
12748 en Antennas and electromagnetic simulators for demanding wireless applications complex environments Antennas for wireless sensor applications need extremely versatile small adaptive low cost mobile “smart” Efficient and versatile software tools for antenna analysis and simulation are presented Modeling approaches for electromagnetic radiation layered structures biological tissues are introduced with practical realizations adequate antennas Some antenna applications wireless sensor networks WSN human animal body are also addressed 
12749 en Sensor networks telemedicine and telecare The development information technology and telecommunications has reached level where its usefulness can applied for health care needs Telemedicine and telecare rely two extensive and interconnected professional fiels Information and Communication Technology ICT and medicine approach for use sensors for data capture along with telecommunication connections and program tools harmonized with the biomedical profession and the organization health care activities will proposed 
12750 en Applying integrated sensor networks public distribution systems Experiences with integration various WSNs single global sensor network with possibilities for alerting and subscribing sensor data interested users could efficiently used public distribution systems today’ public distribution systems regardless water gas public heat distribution there are large number installed sensor nodes with accompanying software for monitoring and alerting provided usually from single vendor making the network very homogeneous Our solution tries provide more flexible system with integration various installed sensors from different vendors which enable scalability the system with facilitated installation new sensors the future the same time the unified functions alerting subscribing and monitoring are still preserved 
12751 en Enhancing fitness with WSN systems From the laboratory the market Personal WSN systems have targeted individual users The system can offered the market package the necessary devices and software for monitoring Another approach would target groups users providing them with the entire exercise environments and competitive exercising Finally with the Smart Running Track SRT equipment already use and collected sensor data digital image the person’ level fitness can maintained Future Internet technology can used provide various services the users WNS supported fitness systems 
12752 en Versatile Sensor Node Platform for the Sensor Service Concept Versatile Sensor Node VSN high performance sensor network platform with modular structure long life autonomy and flexible radio Wireless interface spans over several industrial scientific and medical frequency bands and supports multiple communication technologies including ZigBee 6LoWPAN Bluetooth and WiFi Various sensors and actuators can connected via digital and analog peripherals which makes VSN adaptable diverse application requirements supporting semantic technologies and intelligent machine learning algorithms provides transparent infrastructure which sensors are offered service nnn
12753 en APSIS Autonomous surface vehicle for measurements and logistic miniature boat designed perform hydrographic surveys line measurements and sample collection shallow waters The boat light weight measuring 220 and easy handle two persons 
12754 en DIONIS Efficient monitoring system for vineyards novel vineyard monitoring WSN based application currently under development joint collaboration between FEEIT – Skopje and ECS – Skopje presented The application named DIONIS incorporates various sensors temperature humidity and chemical substances sensors for data gathering wireless communication devices for data dissemination relevant entities database for storing the acquired data and Graphical User Interface GUI for user friendly data statistics monitoring Based the extracted field parameters DIONIS able detect abnormal situations and alarm local and remote authorities DIONIS can enhance the grape growing process and provide higher wine quality well exhibit water savings and more efficient pesticide use 
12755 en Power and Energy Management with Energy Control Modules Future households requirements for demand side management are auto demand response AutoDR function and full control over distributed power sources Existing solutions feature direct link between power meters and appliances new concept called Smart Distribution Box SmartDB provides complete energy and power management solution represents intermediate layer extending smart grid power meter functionality support AutoDR with fast and guaranteed response times distributed power sources and full control over energy management with extra safety functions Demo implementation Smart Distribution Box composed Energy Control modules and management applications running mobile phones and Linux Windows systems 
12756 en Application biosensors sport and medicine dynamics muscles rapid development low power electronic biosensors enabling production devices that are small enough not constrain the measured subject thus providing the scientists with whole new insight both dynamical and electrical properties muscles The usage biosensors can applied medicine sport industry any field where work output quality depends any kind muscle activity Knowledge obtained through biosensors will lead development both medicine sport and other related fields 
12757 en Harvesting Wireless Sensor Solutions and Networks EnOcean technology Most wireless sensors which are connected standalone into network are battery driven the last time new batteryless and wireless sensors are use based new approaches with extremely small amount energy for sending information that even harvesting from environment energy can sufficient The environment energy can present mechanical thermal photonic form Sensors which are harvesting environment energy are result EnOcean technology that spreading very successfully for example the field electrical installations and industry 
12758 en Wireless sensor network measurements high density wind dynamics the region Vipavska dolina Slovenia with embedded real time algorithm for prediction the wind conditions will demonstrate case intelligent wireless sensor network algorithm for prediction wind conditions the region Vipavska dolina The system was developed for traffic security the highway during the periods evolution high density wind energy Detection wireless sensor network communicate with host super computing system for real time computation fluid dynamics based boundary condition from discrete nodes and GPU technology apply self organized neural network dynamics attractor space sensor nodes and fuzzy network prediction for detection the threshold for traffic security 
12759 en Examples WSN applications through funded projects this talk overview given different applications wireless sensor networks developed the framework recent founded projects and cooperating industrial partners These success stories illustrate how WSN can lead the development new services 
12854 en Hands Working with existing LarKC workflow
12855 en Hands Building LarKC decider plug create workflow from existing plug ins
12856 en Introduction Distributed Processing LarKC
12857 en Hands Building LarKC plug and integrating into existing workflow
12858 en Hands Understanding and Manipulating the Urban Computing workflow
12860 en Real time processing intensive web streams
12861 en Logic based hoc business process management Concepts and challenges
12862 en From Web Web using Data Mining Web applications such Flickr offer rich set data with huge potential for exploitation the human users nUnfortunately the sifting through such data far from easy and rewarding due lack semantics the one side and anlack rich data description the other side For instance most photos Flickr have very little description attached that could used for retrieving exploring the photos this talk demonstrate how the enrichment Web data automatically discovered more less semantic relationships improves the user experience 
12863 en  XML Schema and Topic Map Ontology for Formalization Background Knowledge Data Mining Background sometimes referred domain knowledge extensively used data mining for data pre processing and fornnugget oriented data mining tasks essential for constraining thensearch space and pruning the results Despite the costs eliciting background knowledge from domain experts there has been far little effortnto devise common exchange standard for its representation This paper proposes the Background Knowledge Exchange Format BKEF anlightweight XML Schema for storing information features and patterns and the Background Knowledge Ontology BKOn its semantic abstraction The purpose BKOn allow reasoning over andnintegration analysed data with existing domain ontologies shownan elicitation interface producing BKEF and discuss the possibilities fornintegration such background knowledge with domain ontologies 
12864 en Importing Knowledge Fragments CMS Enabled Data Mining Analytical Reports Descriptive data mining only brings its fruits when the results are providednto the end user palatable form The vehicle for end user delivery miningnresults and associated information such data schema task settings and domain background knowledge are called analytical reports order managena huge number reports referring different mining sessions designed andata mining web portal based content management system together callednSEWEBAR CMS One the requirements the CMS was the ability interact with semantic knowledge sources and other structured data see nThe data analyst who authors analytical report the CMS has differentnpossibilities semi automatically entering structured data into the text nFirst for locally stored data such mining task result data descriptionsnexported from mining tools PMML Predictive Model Mark Language anCMS plugin can pick marked segments HTML code produced from PMMLnusing XSLT and insert them into the report indicated the analyst nSecond sophisticated support for remote data knowledge has been newlynadded The infrastructure for this functionality allows persistently specifyn– Links queriable resourcesn– Template queries for these resources which can paramatrized thenend user runtime – XSLT transformations allowing insert the results queries HTMLnfragments either static dynamically updated from the resources nCurrently experiment with queriable resources the form native XMLndatabase Berkeley queried via XQuery which stores PMML data and semantic knowledge bases both the form SPARQL endpoint and Ontopia Knowledge Suite Topic Maps tool queried via Prolog like language called tolog nInclusion further types resources such Lucene indices progress 
12865 en Towards semantic foundation for bioinformatics With two and half thousand year tradition logic the best understood way ofnrepresenting scientific knowledge Only logic provides the semantic clarity necessarynto ensure the comprehensibility reproducibility and free exchange knowledge nThe use logic also necessary enable computers play full part sciencen The semantic web transforming the dissemination science making for thenfirst time making large amount scientific knowledge available expressed logic nBioinformatics one the undoubted successes stories the semantic web withnbioinformatic knowledge making large percentage the scientific semantic web nMany the problems that make semantic web reasoning difficult don apply tonbioinformatics ground truth scientific knowledge exists top level ontologiesnhave been agreed BFO many other ontological standards exist and thenbioinformatic semantic web large but not too large nThe use bioinformatic software essential modern biology However therenis clear mismatch between the increasing use the semantic web and logic and thenway bioinformatic systems utlilise and make inferences with this knowledge This isnbecause almost all computer based bioinformatic reasoning done using hocnprograms From formal point view these programs are invariably making logicalninferences deductions abductions inductions with perhaps probabilistic element nHowever what exactly these inferences exactly are generally unclear nThe aim research make these inferences clear and express them innlogic and make them executable across the semantic web 
12868 en From Disasters WoW Using Web Science understand and enable 21st century multidimensional networks Recent advances Web Science provide comprehensive digital traces social actions interactions and transactions These data provide unprecedented exploratorium model the socio technical motivations for creating maintaining dissolving and reconstituting multidimensional social networks Multidimensional networks include multiple types nodes people documents datasets tags etc and multiple types relationships authorship citation web links etc Using examples from research wide range activities such disaster response public health and massively multiplayer online games WoW the World Warcraft Contractor will argue that Web Science serves the foundation for the development theories and methods help advance our ability understand and enable multidimensional networks 
12869 en Linked Data Now what Since the Linked Data principles were first outlined have witnessed outstanding growth and heterogeneity linked data publicly available the Web which has even managed trigger the interest large companies and governmental bodies world wide the light this evolution and given the current take and expectations raised believe now time reflect about the progress thus far and plan for the future challenges and opportunities that the Web Data will bring this panel shall discuss what has worked and what has not far and shall try identify what should and what should not the future 
12870 en The Semantic Product Memory Interactive Black Box for Smart Objects semantic product memory stores diary individual physical object persistent way embedded sensor system that networked wireless communication smart environment The product monitors itself and its environment Semantic technologies based OWL ontologies guarantee interoperability the product memory across the complete supply chain and lifecycle smart objects and enable end user access the product’ lifelog nIn this talk present the layered architecture together with the representation and inference formalisms used our SemProM project funded the German Ministry Education and Research BMBF with Million Euro SemProM goes well beyond traditional RFID technology and the basis for intelligent automation smart factories event driven logistics well smart retail and after sales Collecting information logs about objects such smart environments and making available for example about object’ origin location movements physical properties environmental conditions usage history well warranty and maintenance data can help enterprises improve their business processes and create new ones Existing business process models become more accurate since information taken directly from the point action can used manage adapt processes real time for the emerging Internet Things nWe show how such embedded “black box” event recorders can transform everyday objects like cars circuit boards pizzas and drug blister packs into smart products show how consumers smart products can access the lifelogs products NFC enabled smartphones using SemProM’ browser and track the complete history product multimodal dialogues role based access control mechanism ensures privacy and security the SemProM product memories will discuss fully operational pilot implementations semantic product memories developed the SemProM consortium together with major German companies like SAP BMW Siemens DHL Globus Retail and Kohl Pharma 
12871 en  Pattern Science for the Semantic Web will present the current state play with respect collecting finding classifying and using design patterns the semantic web The talk will compare historically related work highlight some successful stories and curious unexpected bottlenecks and will envision some charming research and development directions from the Web Data 
12872 en SKOS Past Present Future and little bit history architecture and engineering SKOS Simple Knowledge Organisation System common data model for sharing and linking knowledge organization systems via the Web Many knowledge organization systems such thesauri taxonomies classification schemes and subject heading systems share similar structure and are used similar applications SKOS captures much this similarity and makes explicit enabling data and technology sharing across diverse applications nThe SKOS data model provides standard low cost migration path for porting existing knowledge organization systems the Semantic Web SKOS also provides light weight intuitive language for developing and sharing new knowledge organization systems may used its own combination with formal knowledge representation languages such the Web Ontology language OWL SKOS was published W3C Recommendation August 2009 and seeing growing take number fields including among others cultural heritage economics astronomy and local government SKOS also looks set play key role providing vocabularies for the Data Web through its use Open Linked Data 
12984 en Verbmobile machine translation story
13008 en Object Graphs for Context Aware Category Discovery How can knowing about some categories help dis ncover new ones unlabeled images Unsupervised visualncategory discovery useful mine for recurring objectsnwithout human supervision but existing methods assumenno prior information and thus tend perform poorly forncluttered scenes with multiple objects propose lever nage knowledge about previously learned categories nable more accurate discovery introduce novel object ngraph descriptor encode the layout object level noccurrence patterns relative unfamiliar region andnshow that using model the interaction betweennan image’ known and unknown objects can better ntect new visual categories Rather than mine for all cat negories from scratch our method identifies new objectsnwhile drawing useful cues from familiar ones eval nuate our approach benchmark datasets and demonstratenclear improvements discovery over conventional purelynappearance based baselines 
13009 en Grouplet Structured Image Representation for Recognizing Human and Object Interactions Psychologists have proposed that many human object interactionnactivities form unique classes scenes Recognizingnthese scenes important for many social functions Tonenable computer this however challenging task nTake people playing musical instrument PPMI example nto distinguish person playing violin from personnjust holding violin requires subtle distinction characteristicnimage features and feature arrangements that differentiatenthese two scenes Most the existing image representationnmethods are either too coarse BoW orntoo sparse constellation models for performing thisntask this paper propose new image feature representationncalled “grouplet” The grouplet captures thenstructured information image encoding numbernof discriminative visual features and their spatial configurations nUsing dataset different PPMI activities nwe show that grouplets are more effective classifying andndetecting human object interactions than other state theartnmethods particular our method can make robustndistinction between humans playing the instruments and humansnco occurring with the instruments without playing 
13010 en Modeling Mutual Context Object and Human Pose Human Object Interaction Activities Detecting objects cluttered scenes and estimating articulatednhuman body parts are two challenging problems inncomputer vision The difficulty particularly pronouncednin activities involving human object interactions playingntennis where the relevant object tends small ornonly partially visible and the human body parts are oftennself occluded observe however that objects and humannposes can serve mutual context each other – recognizingnone facilitates the recognition the other this papernwe propose new random field model encode the mutualncontext objects and human poses human object interactionnactivities then cast the model learning task anstructure learning problem which the structural connectivitynbetween the object the overall human pose and differentnbody parts are estimated through structure searchnapproach and the parameters the model are estimatednby new max margin algorithm sports data set sixnclasses human object interactions show that ournmutual context model significantly outperforms state theartnin detecting very difficult objects and human poses 
13011 en The chains model for detecting parts their context Detecting object part relies two sources informationn the appearance the part itself and the contextnsupplied surrounding parts this paper considernproblems which target part cannot recognized reliablynusing its own appearance such detecting lowresolutionnhands and must recognized using the contextnof surrounding parts develop the ‘chains model’nwhich can locate parts interest robust and precisenmanner even when the surrounding context highly variablenand deformable the proposed model the relationnbetween context features and the target part modeled annon parametric manner using ensemble feature chainsnleading from parts the context the detection target Thenmethod uses the configuration the features the imagendirectly rather than through fitting articulated modelnof the object addition the chains are composable meaningnthat new chains observed the test image can composednof sub chains seen during training Consequently nthe model capable handling object poses which areninfrequent even non existent during training test thenapproach different settings including object parts detection nas well complete object detection The results shownthe advantages the chains model for detecting and localizingnparts complex deformable objects 
13013 en Multimodal semi supervised learning for image classification image categorization the goal decide imagenbelongs certain category not binary classifier cannbe learned from manually labeled images while using morenlabeled examples improves performance obtaining the imagenlabels time consuming process nWe are interested how other sources informationncan aid the learning process given fixed amount labelednimages particular consider scenario wherenkeywords are associated with the training images asnfound photo sharing websites The goal learn anclassifier for images alone but will use the keywordsnassociated with labeled and unlabeled images improventhe classifier using semi supervised learning first learnna strong Multiple Kernel Learning MKL classifier usingnboth the image content and keywords and use scorenunlabeled images then learn classifiers visual featuresnonly either support vector machines SVM leastsquaresnregression LSR from the MKL output values onnboth the labeled and unlabeled images nIn our experiments classes from the PASCALnVOC’ set and from the MIR Flickr set demonstratenthe benefit our semi supervised approach over only usingnthe labeled images also present results for scenarionwhere not use any manual labeling but directly learnnclassifiers from the image tags The semi supervised approachnalso improves classification accuracy this case 
13014 en What Helps Where And Why Semantic Relatedness for Knowledge Transfer Remarkable performance has been reported recognizensingle object classes Scalability large numbers classesnhowever remains important challenge for today’ recognitionnmethods Several authors have promoted knowledgentransfer between classes key ingredient address thisnchallenge However previous work the decision whichnknowledge transfer has required either manual supervisionnor least few training examples limiting the scalabilitynof these approaches this work explicitly addressnthe question how automatically decide which informationnto transfer between classes without the need any humannintervention For this tap into linguistic knowledgenbases provide the semantic link between sources what nand targets where knowledge transfer provide rigorousnexperimental evaluation different knowledge basesnand state the art techniques from Natural Language Processingnwhich goes far beyond the limited use languagenin related work also give insights into the applicabilityn why different knowledge sources and similarity measuresnfor knowledge transfer 
13015 en Towards Semantic Embedding Visual Vocabulary Visual vocabulary serves fundamental componentnin many computer vision tasks such object recognition nvisual search and scene modeling While state the artnapproaches build visual vocabulary based solely visualnstatistics local image patches the correlative image labelsnare left unexploited generating visual words thisnwork present semantic embedding framework integratensemantic information from Flickr labels for supervisednvocabulary construction Our main contribution anHidden Markov Random Field modeling supervise featurenspace quantization with specialized considerations tonlabel correlations Local visual features are modeled asnan Observed Field which follows visual metrics partitionnfeature space Semantic labels are modeled HiddennField which imposes generative supervision the ObservednField with WordNet based correlation constraints asnGibbs distribution simplifying the Markov property innthe Hidden Field both unsupervised and supervised labelnindependent vocabularies can derived from our framework nWe validate our performances two challengingncomputer vision tasks with comparisons state the arts Large scale image search Flickr 000 database Object recognition the PASCAL VOC database 
13017 en Common Visual Pattern Discovery via Spatially Coherent Correspondences
13018 en Unsupervised Detection and Segmentation Identical Objects address unsupervised object detection and segmentationnproblem that goes beyond the conventional assumptionsnof one one object correspondences modeltestnsettings between images Our method can detect andnsegment identical objects directly from single image anhandful images without any supervision detect andnsegment all the object level correspondences from the givennimages novel multi layer match growing method proposednthat starts from initial local feature matches and exploresnthe images intra layer expansion and inter layernmerge estimates geometric relations between object entitiesnand establishes ‘object correspondence networks’ thatnconnect matching objects Experiments demonstrate robustnperformance our method challenging datasets 
13019 en  Novel Riemannian Framework for Shape Analysis Objects this paper introduce novel Riemannian framework for shape analysis parameterized surfaces Wenderive distance function between any two surfaces thatnis invariant rigid motion global scaling and reparametrization the last part that presents the mainndifficulty Our solution this problem twofold wendefine special representation called map represent each surface and develop gradient based algorithm optimize over different parameterizations ofna surface The second step akin deforming the meshnon fixed surface optimize its placement This different from the current methods that treat the given meshes asnfixed Under the chosen representation with the metric the action the parametrization group isometries This results our knowledge the first Riemannian distance between parameterized surfaces have allnthe desired invariances demonstrate this frameworknwith several examples using some toy shapes and real datanwith anatomical structures and cropped facial surfaces Wenalso successfully demonstrate clustering and classificationnof these objects under the proposed metric 
13020 en Global and Efficient Self Similarity for Object Classification and Detection Self similarity attractive image property which has recentlynfound its way into object recognition the form ofnlocal self similarity descriptors thisnpaper explore global self similarity GSS and its advantagesnover local self similarity LSS make three contributions propose computationally efficient algorithmsnto extract GSS descriptors for classification Thesencapture the spatial arrangements self similarities withinnthe entire image show how use these descriptorsnefficiently for detection sliding window frameworknand branch and bound framework experimentallyndemonstrate Pascal VOC 2007 and ETHZ ShapenClasses that GSS outperforms LSS for both classificationnand detection and that GSS descriptors are complementarynto conventional descriptors such gradients color 
13022 en Object Recognition Discriminative Combinations Line Segments and Ellipses
13023 en  Detection Multiple Object Instances using Hough Transforms detect multiple objects interest the methods basednon Hough transform use non maxima supression modenseeking order locate and distinguish peaks Houghnimages Such postprocessing requires tuning extra parametersnand often fragile especially when objects interestntend closely located the paper develop annew probabilistic framework that many ways related tonHough transform sharing its simplicity and wide applicability nAt the same time the framework bypasses the problemnof multiple peaks identification Hough images andnpermits detection multiple objects without invoking nonmaximumnsuppression heuristics result the experimentsndemonstrate significant improvement detectionnaccuracy both for the classical task straight line detectionnand for more modern category level pedestrian detectionnproblem 
13024 en Cascade Object Detection with Deformable Part Models describe general method for building cascade classifiersnfrom part based deformable models such pictorialnstructures focus primarily the case star structurednmodels and show how simple algorithm based partialnhypothesis pruning can speed object detection bynmore than one order magnitude without sacrificing detectionnaccuracy our algorithm partial hypotheses arenpruned with sequence thresholds analogy probablynapproximately correct PAC learning introduce thennotion probably approximately admissible PAA thresholds nSuch thresholds provide theoretical guarantees thenperformance the cascade method and can computednfrom small sample positive examples Finally outlinena cascade detection algorithm for general class ofnmodels defined grammar formalism This class includesnnot only tree structured pictorial structures but alsonricher models that can represent each part recursively anmixture other parts 
13025 en Food Recognition Using Statistics Pairwise Local Features Food recognition difficult because food items are deformablenobjects that exhibit significant variations appearance nWe believe the key recognizing food exploitnthe spatial relationships between different ingredientsn such meat and bread sandwich propose annew representation for food items that calculates pairwisenstatistics between local features computed over soft pixellevelnsegmentation the image into eight ingredient types nWe accumulate these statistics multi dimensional histogram nwhich then used feature vector for discriminativenclassifier Our experiments show that the proposednrepresentation significantly more accurate identifyingnfood than existing methods 
13027 en Proximate Sensing Inferring What Where From Georeferenced Photo Collections
13028 en Detecting Text Natural Scenes with Stroke Width Transform present novel image operator that seeks find the valuenof stroke width for each image pixel and demonstrate its use onnthe task text detection natural images The suggestednoperator local and data dependent which makes fast andnrobust enough eliminate the need for multi scale computationnor scanning windows Extensive testing shows that the suggestednscheme outperforms the latest published algorithms Itsnsimplicity allows the algorithm detect texts many fonts andnlanguages 
13029 en Reading Between The Lines Object Localization Using Implicit Cues from Image Tags Current uses tagged images typically exploit onlynthe most explicit information the link between the nounsnnamed and the objects present somewhere the image Wenpropose leverage “unspoken” cues that rest within annordered list image tags improve object localization nWe define three novel implicit features from image’sntags—the relative prominence each object signifiednby its order mention the scale constraints impliednby unnamed objects and the loose spatial links hinted bynthe proximity names the list learning conditionalndensity over the localization parameters positionnand scale given these cues show how improve bothnaccuracy and efficiency when detecting the tagged objects nWe validate our approach with object categories fromnthe PASCAL VOC and LabelMe datasets and demonstratenits effectiveness relative both traditional sliding windowsnas well visual context baseline 
13030 en Beyond Active Noun Tagging Modeling Contextual Interactions for Multi Class Active Learning present active learning framework simultaneouslynlearn appearance and contextual models for scene understandingntasks multi class classification Existing multi class active learningnapproaches have focused utilizing classification uncertaintynof regions select the most ambiguous region for labeling Thesenapproaches however ignore the contextual interactions betweenndifferent regions the image and the fact that knowing the labelnfor one region provides information about the labels othernregions For example the knowledge region being sea informativenabout regions satisfying the “ ” relationship with respectnto since they are highly likely boats explicitly modelnthe contextual interactions between regions and select the questionnwhich leads the maximum reduction the combined entropy ofnall the regions the image image entropy also introduce annew methodology posing labeling questions mimicking the waynhumans actively learn about their environment these questions nwe utilize the regions linked concept with high confidence asnanchors pose questions about the uncertain regions For example nif can recognize water image then can use the regionnassociated with water anchor pose questions such asn“what above water ” Our active learning framework also introducesnquestions which help actively learning contextual concepts nFor example our approach asks the annotator “What isnthe relationship between boat and water ” and utilizes the answernto reduce the image entropies throughout the training dataset andnobtain more relevant training examples for appearance models 
13032 en Rectilinear Parsing Architecture Urban Environment
13033 en Hybrid Multi view Reconstruction Jump Diffusion propose multi view stereo reconstruction algorithmnwhich recovers urban scenes combination meshesnand geometric primitives provides compact modelnwhile preserving details irregular elements such statuesnand ornaments are described meshes whereas regularnstructures such columns and walls are described primitivesn planes spheres cylinders cones and tori Jump nDiffusion process designed sample these two types ofnelements simultaneously The quality reconstructionnis measured multi object energy model which takesninto account both photo consistency and semantic considerationsn geometry and shape layout The sampler isnembedded into iterative refinement procedure which providesnan increasingly accurate hybrid representation Experimentalnresults complex urban structures and largenscenes are presented and compared multi view basednmeshing algorithms 
13034 en Building Reconstruction using Manhattan World Grammars present passive computer vision method thatnexploits existing mapping and navigation databases innorder automatically create building models Ournmethod defines grammar for representing changes innbuilding geometry that approximately follow thenManhattan world assumption which states there anpredominance three mutually orthogonal directions innthe scene using multiple calibrated aerial images wenextend previous Manhattan world methods robustlynproduce single coherent complete geometric model anbuilding with partial textures Our method uses annoptimization discover building geometry thatnproduces the same set façade orientation changesnobserved the captured images have applied ournmethod several real world buildings and have analyzednour approach using synthetic buildings 
13035 en Estimating Camera Pose from Single Urban Ground View Omnidirectional Image and Building Outline Map framework presented for estimating the pose ancamera based images extracted from single omnidirectionalnimage urban scene given map withnbuilding outlines with geometric information nor appearancendata The framework attempts identify verticalncorner edges buildings the query image whichnwe term VCLH well the neighboring plane normals nthrough vanishing point analysis bottom process furtherngroups VCLH into elemental planes and subsequentlyninto structural fragments modulo similarity transformation geometric hashing lookup allows rapidlynestablish multiple candidate correspondences between thenstructural fragments and the map building contours Anvoting based camera pose estimation method then employednto recover the correspondences admitting cameranpose solution with high consensus dataset that evennchallenging for humans the system returned top rankingnfor correct matches out 3600 camera pose hypothesesn selectivity for queries 
13037 en Monocular Pose Estimation and Tracking Detection Automatic recovery human pose from monocularnimage sequences challenging and important researchntopic with numerous applications Although current methodsnare able recover pose for single person controllednenvironments they are severely challenged realworldnscenarios such crowded street scenes addressnthis problem propose three stage process building onna number recent advances The first stage obtains initialnestimate the articulation and viewpoint the personnfrom single frames The second stage allows early datanassociation across frames based tracking detection nThese two stages successfully accumulate the available 2Dnimage evidence into robust estimates limb positionsnover short image sequences tracklets The third andnfinal stage uses those tracklet based estimates robust imagenobservations reliably recover pose demonstratenstate the art performance the HumanEva IInbenchmark and also show the applicability our approachnto articulated tracking realistic street conditions 
13038 en Dynamical Binary Latent Variable Models for Human Pose Tracking introduce new class probabilistic latent variablenmodel called the Implicit Mixture Conditional RestrictednBoltzmann Machines imCRBM for use humannpose tracking Key properties the imCRBM are follows learning linear the number training exemplarsnso can learned from large datasets learnsncoherent models multiple activities automaticallyndiscovers atomic “movemes” and can infer transitionsnbetween activities even when such transitions are notnpresent the training set describe the model and hownit learned and demonstrate its use the context ofnBayesian filtering for multi view and monocular pose tracking nThe model handles difficult scenarios including multiplenactivities and transitions among activities reportnstate the art results the HumanEva dataset 
13039 en Contour People Parameterized Model Articulated Human Shape define new “contour person” model the humannbody that has the expressive power detailed modelnand the computational benefits simple part basednmodel The contour person model learned from an3D SCAPE model the human body that captures naturalnshape and pose variations the projected contours thisnmodel along with their segmentation into parts forms thentraining set The model factors deformations the bodyninto three components shape variation viewpoint changenand part rotation This latter model also incorporates anlearned non rigid deformation model The result 2Dnarticulated model that compact represent simple toncompute with and more expressive than previous models nWe demonstrate the value such model pose ntimation and segmentation Given initial pose from anstandard pictorial structures method refine the pose andnshape using objective function that segments the sceneninto foreground and background regions The result anparametric human specific image segmentation 
13040 en Combining Discriminative and Generative Methods for Deformable Surface and Articulated Pose Reconstruction Historically non rigid shape recovery and articulatednpose estimation have evolved separate fields Recentnmethods for non rigid shape recovery have focused improvingnthe algorithmic formulation but have only considerednthe case reconstruction from point point correspondences nIn contrast many techniques for pose estimationnhave followed discriminative approach which allowsnfor the use more general image cues However thesentechniques typically require large training sets and suffernfrom the fact that standard discriminative methods notnenforce constraints between output dimensions this paper nwe combine ideas from both domains and propose anunified framework for articulated pose estimation and 3Dnsurface reconstruction address some the issues ofndiscriminative methods explicitly constraining their prediction nFurthermore our formulation allows for the combinationnof generative and discriminative methods into ansingle common framework 
13042 en Visual Tracking Decomposition propose novel tracking algorithm that can work robustly challenging scenario such that several kinds ofnappearance and motion changes object occur thensame time Our algorithm based visual tracking decomposition scheme for the efficient design observationnand motion models well trackers our scheme thenobservation model decomposed into multiple basic observation models that are constructed sparse principalncomponent analysis SPCA set feature templates nEach basic observation model covers specific appearancenof the object The motion model also represented thencombination multiple basic motion models each whichncovers different type motion Then the multiple basic trackers are designed associating the basic observation models and the basic motion models that each specific tracker takes charge certain change the object nAll basic trackers are then integrated into one compoundntracker through interactive Markov Chain Monte Carlon IMCMC framework which the basic trackers communicate with one another interactively while run parallel nBy exchanging information with others each tracker further improves its performance which results increasingnthe whole performance tracking Experimental resultsnshow that our method tracks the object accurately and reliably realistic videos where the appearance and motionnare drastically changing over time 
13043 en  Globally Optimal Data Driven Approach for Image Distortion Estimation Image alignment the presence non rigid distortionsnis challenging task Typically this involves estimatingnthe parameters dense deformation field thatnwarps distorted image back its undistorted template nGenerative approaches based parameter optimizationnsuch Lucas Kanade can get trapped within local minima nOn the other hand discriminative approaches likenNearest Neighbor require large number training samplesnthat grows exponentially with the desired accuracy Innthis work develop novel data driven iterative algorithmnthat combines the best both generative and discriminativenapproaches For this introduce the notion ofna “pull back” operation that enables predict the parametersnof the test image using training samples that arennot its neighborhood not close parameter space nWe prove that our algorithm converges the global optimumnusing significantly lower number training samplesnthat grows only logarithmically with the desired accuracy nWe analyze the behavior our algorithm extensively usingnsynthetic data and demonstrate successful results experimentsnwith complex deformations due water and clothing 
13044 en Tracking the Invisible Learning Where the Object Might Objects are usually embedded into context Visual contextnhas been successfully used object detection tasks nhowever often ignored object tracking propose anmethod learn supporters which are only temporally nuseful for determining the position the object interest nOur approach exploits the General Hough Transformnstrategy couples the supporters with the target and naturallyndistinguishes between strongly and weakly couplednmotions this the position object can estimatedneven when not seen directly fully occluded outsidenof the image region when changes its appearancenquickly and significantly Experiments show substantial improvementsnin model free tracking well the trackingnof “virtual” points medical applications 
13045 en Motion Detail Preserving Optical Flow Estimation discuss the cause severe optical flow estimation problem that fine motion structures cannot always bencorrectly reconstructed the commonly employed multi scale variational framework Our major finding that significant and abrupt displacement transition wrecks small scale motion structures the coarse fine refinement Annovel optical flow estimation method proposed thisnpaper address this issue which reduces the reliance ofnthe flow estimates their initial values propagated fromnthe coarser level and enables recovering many motion details each scale The contribution this paper also includes adaption the objective function and developmentnof new optimization procedure The effectiveness ournmethod borne out experiments for both large andnsmall displacement optical flow estimation 
13047 en What going Discovering Spatio Temporal Dependencies Dynamic Scenes present two novel methods automatically learnnspatio temporal dependencies moving agents complexndynamic scenes They allow discover temporal rules nsuch the right way between different lanes typicalntraffic light sequences extract them sequences ofnactivities need learned While the first method extractsnrules based learned topic model the secondnmodel called DDP HMM jointly learns occurring activitiesnand their time dependencies this end employ DependentnDirichlet Processes learn arbitrary numbernof infinite Hidden Markov Models contrast previousnwork build state the art topic models that allownto automatically infer all parameters such the optimalnnumber HMMs necessary explain the rules governingna scene The models are trained offline Gibbs Samplingnusing unlabeled training data 
13048 en Visual Event Recognition Videos Learning from Web Data propose visual event recognition framework fornconsumer domain videos leveraging large amount ofnloosely labeled web videos from YouTube First nwe propose new aligned space time pyramid matchingnmethod measure the distances between two video clips nwhere each video clip divided into space time volumesnover multiple levels calculate the pair wise distancesnbetween any two volumes and further integrate the informationnfrom different volumes with Integer flow Earth Mover’snDistance EMD explicitly align the volumes Second nwe propose new cross domain learning method ordernto fuse the information from multiple pyramid levels andnfeatures space time feature and static SIFT feature nand cope with the considerable variation feature distributionsnbetween videos from two domains web domainnand consumer domain For each pyramid level andneach type local features train set SVM classifiersnbased the combined training set from two domainsnusing multiple base kernels different kernel types andnparameters which are fused with equal weights obtainnan average classifier Finally propose cross domainnlearning method referred Adaptive Multiple KernelnLearning MKL learn adapted classifier based onnmultiple base kernels and the prelearned average classifiersnby minimizing both the structural risk functional andnthe mismatch between data distributions from two domains nExtensive experiments demonstrate the effectiveness ournproposed framework that requires only small number ofnlabeled consumer videos leveraging web data 
13050 en Anomaly Detection Crowded Scenes novel framework for anomaly detection crowdednscenes presented Three properties are identified importantnfor the design localized video representationnsuitable for anomaly detection such scenes joint modelingnof appearance and dynamics the scene and thenabilities detect temporal and spatial abnormalities nThe model for normal crowd behavior based mixturesnof dynamic textures and outliers under this model arenlabeled anomalies Temporal anomalies are equated tonevents low probability while spatial anomalies are handlednusing discriminant saliency experimental evaluationnis conducted with new dataset crowded scenes ncomposed 100 video sequences and five well defined abnormalityncategories The proposed representation shownnto outperform various state the art anomaly detectionntechniques 
13052 en Face Recognition Based Image Sets introduce novel method for face recognition fromnimage sets our setting each test and training examplenis set images individual’ face not just singlenimage recognition decisions need based comparisonsnof image sets Methods for this have two mainnaspects the models used represent the individual imagensets and the similarity metric used compare the models nHere represent images points linear ornaffine feature space and characterize each image set anconvex geometric region the affine convex hull spannednby its feature points Set dissimilarity measured geometricndistances distances closest approach betweennconvex models reduce the influence outliers usenrobust methods discard input points that are far from thenfitted model The kernel trick allows the approach extendednto implicit feature mappings thus handling complexnand nonlinear manifolds face images Experiments onntwo public face datasets show that our proposed methodsnoutperform number existing state the art ones 
13054 en  Morphable Model Construction for Robust Ear and Face Recognition Recent work suggests that the human ear varies significantlynbetween different subjects and can used for identification nIn principle therefore using ears addition tonthe face within recognition system could improve accuracynand robustness particularly for non frontal views Thenpaper describes work that investigates this hypothesis usingnan approach based the construction morphablenmodel the head and ear One issue with creating modelnthat includes the ear that existing training datasets containnnoise and partial occlusion Rather than exclude thesenregions manually classifier has been developed which automatesnthis process When combined with robust registrationnalgorithm the resulting system enables full headnmorphable models constructed efficiently using lessnconstrained datasets The algorithm has been evaluated usingnregistration consistency model coverage and minimalismnmetrics which together demonstrate the accuracy thenapproach make easier build this work the sourcencode has been made available online 
13056 en Interest Seam Image propose interest seam image efficient visual synopsisnfor video extract interest seam image spatiotemporalnenergy map constructed for the target videonshot Then optimal seam which encompasses the highestnenergy identified efficient dynamic programmingnalgorithm The optimal seam used extract seam ofnpixels from each video frame form one column image nbased which interest seam image finally composited nThe interest seam image efficient both terms ofncomputation and memory cost Therefore able powerna wide variety web scale video content analysis applications nsuch near duplicate video clip search video genrenrecognition and classification well video clustering netc The representation capacity the proposed interestnseam image demonstrated large scale video retrievalntask Its advantages are clearly exhibited when comparednwith previous works reported our experiments 
13057 en Aggregating local descriptors into compact image representation address the problem image search very largenscale where three constraints have considered jointly nthe accuracy the search its efficiency and the memorynusage the representation first propose simple yetnefficient way aggregating local image descriptors into anvector limited dimension which can viewed simplificationnof the Fisher kernel representation then shownhow jointly optimize the dimension reduction and the indexingnalgorithm that best preserves the quality vectorncomparison The evaluation shows that our approachnsignificantly outperforms the state the art the search accuracynis comparable the bag features approach fornan image representation that fits bytes Searching an10 million image dataset takes about 50ms 
13058 en Automatic Image Annotation Using Group Sparsity Automatically assigning relevant text keywords imagesnis important problem Many algorithms have been proposednin the past decade and achieved good performance nEfforts have focused upon model representations keywords nbut properties features have not been well investigated nIn most cases group features preselected nyet important feature properties are not well used selectnfeatures this paper introduce regularization basednfeature selection algorithm leverage both the sparsity andnclustering properties features and incorporate into thenimage annotation task novel approach also proposednto iteratively obtain similar and dissimilar pairs from bothnthe keyword similarity and the relevance feedback Thusnkeyword similarity modeled the annotation framework nNumerous experiments are designed compare the performancenbetween features feature combinations and regularizationnbased feature selection methods applied the imagenannotation task which gives insight into the propertiesnof features the image annotation task The experimentalnresults demonstrate that the group sparsity based method isnmore accurate and stable than others 
13060 en Polynomial Shape from Shading examine the shape from shading problem withoutnboundary conditions polynomial system This view allows nin generic cases complete solution for ideal polyhedralnobjects For the general case propose semidefinitenprogramming relaxation procedure and exact linensearch iterative procedure with new smoothness term thatnfavors folds edges use this numerical technique toninspect shading ambiguities 
13061 en Analysis Light Transport Scattering Media propose new method analyze light transport innhomogeneous scattering media The incident light undergoesnmultiple bounces translucent objects and producesna complex light field Our method analyzes the light transportnin two steps First single and multiple scatteringnare separated projecting high frequency stripe patterns nThen multiple scattering decomposed into each bouncencomponent based the light transport equation The lightnfield for each bounce recursively estimated Experimentalnresults show that light transport scattering media can bendecomposed and visualized for each bounce 
13062 en  New Texture Descriptor Using Multifractal Analysis Multi orientation Wavelet Pyramid Based multifractal analysis wavelet pyramids ofntexture images new texture descriptor proposed thisnpaper that implicitly combines information from both spatialnand frequency domains Beyond the traditional waveletntransform multi oriented wavelet leader pyramid usednin our approach that robustly encodes the multi scale informationnof texture edgels Moreover the resulting texturenmodel shows empirically strong power law relationshipnfor nature textures which can characterized well bynmultifractal analysis Combined with statistics affineninvariant local patches our proposed texture descriptor isnrobust scale and rotation changes more general geometricalntransforms and illumination variations addition nthe proposed texture descriptor computationally efficientnsince does not require many expensive processing steps texton generation and cross bin comparisons whichnare often used existing methods application thenproposed descriptor applied texture classification andnthe experimental results several public texture datasetsnverified the accuracy and efficiency our descriptor
13064 en  Theory Plenoptic Multiplexing Multiplexing common technique for encoding highdimensionalnimage data into single two dimensional image nExamples spatial multiplexing include Bayer patternsnto capture color channels and integral images encodenlight fields the Fourier domain optical heterodyningnhas been used acquire light fields nIn this paper develop general theory multiplexingnthe dimensions the plenoptic function onto imagensensor Our theory enables principled comparisonnof plenoptic multiplexing schemes including noise analysis nas well the development generic reconstruction algorithm nThe framework also aides the identification andnoptimization novel multiplexed imaging applications 
13065 en Non uniform Deblurring for Shaken Images Blur from camera shake mostly due the rotationnof the camera resulting blur kernel that can bensignificantly non uniform across the image However mostncurrent deblurring methods model the observed image asna convolution sharp image with uniform blur kernel nWe propose new parametrized geometric model ofnthe blurring process terms the rotational velocity ofnthe camera during exposure apply this model twondifferent algorithms for camera shake removal the first onenuses single blurry image blind deblurring while the secondnone uses both blurry image and sharp but noisy imagenof the same scene show that our approach makesnit possible model and remove wider class blurs thannprevious approaches including uniform blur specialncase and demonstrate its effectiveness with experiments onnreal images 
13066 en Axial Light Field for Curved Mirrors Reflect Your Perspective Widen Your View Mirrors have been used enable wide field viewn FOV catadioptric imaging The mapping between the incomingnand reflected light rays depends non linearly thenmirror shape and has been well studied using caustics Wenanalyze this mapping using two plane light field parameterization nwhich provides valuable insight into the geometricnstructure reflected rays Using this analysis study thenproblem generating single viewpoint virtual perspectivenimage for catadioptric systems which unachievablenfor several common configurations nInstead minimizing distortions appearing singlenimage propose capture all the rays required generatena virtual perspective capturing light field Wenconsider rotationally symmetric mirrors and show that antraditional planar light field results significant aliasingnartifacts propose axial light field captured movingnthe camera along the mirror rotation axis for efficientnsampling and remove aliasing artifacts This allows usnto computationally generate wide FOV virtual perspectivesnusing wider class mirrors than before without usingnscene priors depth estimation analyze the relationshipnbetween the axial light field parameters and thenFOV resolution the resulting virtual perspective Real resultsnusing spherical mirror demonstrate generating 140 nFOV virtual perspective using multiple FOV images 
13067 en Rectifying rolling shutter video from hand held devices This paper presents method for rectifying video sequencesnfrom rolling shutter cameras contrast tonprevious rectification attempts model distortions asnbeing caused the motion the camera The cameranmotion parametrised continuous curve with knotsnat the last row each frame Curve parameters are solvednfor using non linear least squares over inter frame correspondencesnobtained from KLT tracker have generatednsynthetic sequences with associated ground truthnto allow controlled evaluation Using these sequences wendemonstrate that our algorithm improves over two previouslynpublished methods The dataset available onnthe web allow comparison with other methods 
13069 en RASL Robust Alignment Sparse and Low rank Decomposition for Linearly Correlated Images This paper studies the problem simultaneously aligning batch linearly correlated images despite gross corruption such occlusion Our method seeks optimal set image domain transformations such that the matrix transformed images can decomposed the sum sparse matrix errors and low rank matrix recovered aligned images reduce this extremely challenging optimization problem sequence convex programs that minimize the sum norm and nuclear norm the two component matrices which can efficiently solved scalable convex optimization techniques with guaranteed fast convergence verify the efficacy the proposed robust alignment algorithm with extensive experiments with both controlled and uncontrolled real data demonstrating higher accuracy and efficiency than existing methods over wide range realistic misalignments and corruptions 
13071 en  the design robust classifiers for computer vision The design robust classifiers which can contend withnthe noisy and outlier ridden datasets typical computer vision nis studied argued that such robustness requiresnloss functions that penalize both large positive and negativenmargins The probability elicitation view classifier designnis adopted and set necessary conditions for the designnof such losses identified These conditions are used derivena novel robust Bayes consistent loss denoted Tangentnloss and associated boosting algorithm denoted TangentBoost nExperiments with data from the computer visionnproblems scene classification object tracking and multipleninstance learning show that TangentBoost consistentlynoutperforms previous boosting algorithms 
13072 en Online Batch Strongly Convex Multi Kernel Learning Several object categorization algorithms use kernelnmethods over multiple cues they offer principled approachnto combine multiple cues and obtain state theartnperformance general drawback these strategies isnthe high computational cost during training that preventsntheir application large scale problems They also notnprovide theoretical guarantees their convergence rate nHere present Multiclass Multi Kernel Learningn MKL algorithm that obtains state the art performancenin considerably lower training time generalize thenstandardMKL formulation introduce parameter that allowsnus decide the level sparsity the solution Thanksnto this new setting can directly solve the problem thenprimal formulation prove theoretically and experimentallynthat our algorithm has faster convergence rate asnthe number kernels grow the training complexity isnlinear the number training examples very few iterationsnare enough reach good solutions Experiments onnthree standard benchmark databases support our claims 
13074 en Using Cloud Shadows Infer Scene Structure and Camera Calibration explore the use clouds form structured lightingnto capture the structure outdoor scenes observednover time from static camera derive two cues that relaten3D distances changes pixel intensity due cloudsnshadows The first cue primarily spatial works with lownframe rate time lapses and supports estimating focal lengthnand scene structure scale ambiguity The secondncue depends cloud motion and has more complex butnstill linear ambiguity describe method that uses thenspatial cue estimate depth map and method that combinesnboth cues Results time lapses several outdoornscenes show that these cues enable estimating scene geometrynand camera focal length 
13075 en Depth from Diffusion optical diffuser element that scatters light and isncommonly used soften shape illumination this paper nwe propose novel depth estimation method that placesna diffuser the scene prior image capture call thisnapproach depth from diffusion DFDiff nWe show that DFDiff analogous conventional depthfrom ndefocus DFD where the scatter angle the diffuserndetermines the effective aperture the system The mainnbenefit DFDiff that while DFD requires very largenapertures improve depth sensitivity DFDiff only requiresnan increase the diffusion angle – much less expensivenproposition perform detailed analysis the imagenformation properties DFDiff system and show varietynof examples demonstrating greater precision depthnestimation when using DFDiff 
13076 en Self calibrating Photometric Stereo present self calibrating photometric stereo method nFrom set images taken from fixed viewpoint underndifferent and unknown lighting conditions our method automaticallyndetermines radiometric response function andnresolves the generalized bas relief ambiguity for estimatingnaccurate surface normals and albedos show that colornand intensity profiles which are obtained from registerednpixels across images serve effective cues for addressingnthese two calibration problems result developna complete auto calibration method for photometric stereo nThe proposed method useful many practical scenariosnwhere calibrations are difficult Experimental results validatenthe accuracy the proposed method using variousnreal world scenes 
13078 en Probabilistic Temporal Inference Reconstructed Scenes Modern structure from motion techniques are capablenof building city scale reconstructions from large imagencollections but have mostly ignored the problem largescalenstructural changes over time present generalnframework for estimating temporal variables structurenfrom motion problems including unknown date for eachncamera and unknown time interval for each structural element nGiven collection images with mostly unknown ornuncertain dates use this framework automatically recovernthe dates all images reasoning probabilisticallynabout the visibility and existence objects the scene Wenpresent results collection over 100 historical imagesnof city taken over decades time 
13079 en Piecewise Planar and Non Planar Stereo for Urban Scene Reconstruction Piecewise planar models for stereo have recently becomenpopular for modeling indoor and urban outdoornscenes The strong planarity assumption overcomes thenchallenges presented poorly textured surfaces and resultsnin low complexity models for rendering storage nand transmission However such model performs poorlynin the presence non planar objects for example bushes ntrees and other clutter present many scenes presentna stereo method capable handling more general scenesncontaining both planar and non planar regions Our proposedntechnique segments image into piecewise planarnregions well regions labeled non planar The nonplanarnregions are modeled the results standardnmulti view stereo algorithm The segmentation driven bynmulti view photoconsistency well the result colorandntexture based classifier learned from hand labeled planarnand non planar image regions Additionally our methodnlinks and fuses plane hypotheses across multiple overlappingnviews ensuring consistent reconstruction overnan arbitrary number images Using our system havenreconstructed thousands frames street level video Resultsnshow our method successfully recovers piecewise planarnsurfaces alongside general surfaces challengingnscenes containing large buildings well residentialnhouses 
13080 en Disambiguating Visual Relations Using Loop Constraints Repetitive and ambiguous visual structures generalnpose severe problem many computer vision applications nIdentification incorrect geometric relations betweennimages solely based low level features not alwaysnpossible and more global reasoning approach aboutnthe consistency the estimated relations required Wenpropose utilize the typically observed redundancy thenhypothesized relations for such reasoning and focus thengraph structure induced those relations Chaining then reversible transformations over cycles this graph allowsnto build suitable statistics for identifying inconsistentnloops the graph This data provides indirect evidence fornconflicting visual relations Inferring the set likely falsenpositive geometric relations from these non local observationsnis formulated Bayesian framework demonstratenthe utility the proposed method several applications nmost prominently the computation structure andnmotion from images 
13082 en Non Rigid Structure from Locally Rigid Motion introduce locally rigid motion general framework fornsolving the point view structure from motion problemnfor unknown bodies deforming under orthography Thenkey idea first solve many local point view rigidnproblems independently providing “soup” specific nplausibly rigid triangles The main advantage here isnthat the extraction triangles requires only very weaknassumptions deformations can locally approximatednby near rigid motion three points stretching notndominant and local motions involve some generic rotationnin depth Triangles from this soup are then groupedninto bodies and their depth flips and instantaneous relativendepths are determined Results several sequences nboth our own and from related work suggest these conditionsnapply diverse settings—including very challengingnones multiple deforming bodies Our starting pointnis novel linear solution point structure from motion problem for which general algorithms currently exist 
13083 en Bundled Depth Map Merging for Multi View Stereo
13084 en Multi View Structure Computation without Explicitly Estimating Motion
13086 en  Generative Perspective MRFs Low Level Vision Markov random fields MRFs are popular and genericnprobabilistic models prior knowledge low level vision nYet their generative properties are rarely examined whilenapplication specific models and non probabilistic learningnare gaining increased attention this paper revisitnthe generative aspects MRFs and analyze the quality ofncommon image priors fully application neutral setting nEnabled general class MRFs with flexible potentialsnand efficient Gibbs sampler find that common modelsndo not capture the statistics natural images well Wenshow how remedy this exploiting the efficient samplernfor learning better generative MRFs based flexible potentials nWe perform image restoration with these modelsnby computing the Bayesian minimum mean squared errornestimate MMSE using sampling This addresses numbernof shortcomings that have limited generative MRFs far nand leads substantially improved performance over maximumna posteriori MAP estimation demonstrate thatncombining our learned generative models with sampling basednMMSE estimation yields excellent application resultsnthat can compete with recent discriminative methods 
13087 en Manifold Blurring Mean Shift Algorithms for Manifold Denoising propose new family algorithms for denoisingndata assumed lie low dimensional manifold Thenalgorithms are based the blurring mean shift update nwhich moves each data point towards its neighbors but constrain the motion orthogonal the manifold Thenresulting algorithms are nonparametric simple implement and very effective removing noise while preservingnthe curvature the manifold and limiting shrinkage Theyndeal well with extreme outliers and with variations density along the manifold apply them preprocessing forndimensionality reduction and for nearest neighbor classification MNIST digits with consistent improvements upnto over the original data 
13088 en Increasing Depth Resolution Electron Microscopy Neural Circuits using Sparse Tomographic Reconstruction Future progress neuroscience hinges reconstructionnof neuronal circuits the level individual synapses nBecause the specifics neuronal architecture imagingnmust done with very high resolution and throughput nWhile Electron Microscopy achieves the required resolutionnin the transverse directions its depth resolution isna severe limitation Computed tomography may benused conjunction with electron microscopy improventhe depth resolution but this severely limits the throughputnsince several tens hundreds images need benacquired Here exploit recent advances signal processingnto obtain high depth resolution images computationally nFirst show that the brain tissue can representednas sparse linear combination local basis functionsnthat are thin membrane like structures oriented variousndirections then develop reconstruction techniquesninspired compressive sensing that can reconstruct thenbrain tissue from very few typically tomographic viewsnof each section This enables tracing neuronal connectionsnacross layers and hence high throughput reconstructionnof neural circuits the level individual synapses 
13090 en Visual Classification with Multi Task Joint Sparse Representation
13091 en Classification and Clustering via Dictionary Learning with Structured Incoherence and Shared Features
13092 en The Automatic Design Feature Spaces for Local Image Descriptors using Ensemble Non linear Feature Extractors The design feature spaces for local image descriptorsnis important research subject computer vision due tonits applicability several problems such visual classificationnand image matching order useful these descriptorsnhave present good trade off between discriminatingnpower and robustness typical image deformations nThe feature spaces the most useful local descriptors havenbeen manually designed based the goal above but thisndesign often limits the use these descriptors for some specificnmatching and visual classification problems Alternatively nthere has been growing interest producing featurenspaces automatic combination manually designednfeature spaces automatic selection featurenspaces and spatial pooling methods the use ofndistance metric learning methods While most these approachesnare usually applied specific matching classificationnproblems where test classes are the same trainingnclasses few works aim the general feature transformnproblem where the training classes are different fromnthe test classes The hope the latter works the automaticndesign universal feature space for local descriptornmatching which the topic our work this paper nwe propose new incremental method for learning automaticallynfeature spaces for local descriptors The methodnis based ensemble non linear feature extractorsntrained relatively small and random classification problemsnwith supervised distance metric learning techniques nResults two widely used public databases show that ourntechnique produces competitive results the field 
13095 en Parallel and Distributed Graph Cuts Dual Decomposition Graph cuts methods are the core many state theartnalgorithms computer vision due their efficiencynin computing globally optimal solutions this paper wensolve the maximum flow minimum cut problem parallelnby splitting the graph into multiple parts and hence furthernincrease the computational efficacy graph cuts Optimalitynof the solution guaranteed dual decomposition morenspecifically the solutions the subproblems are constrainednto equal the overlap with dual variables nWe demonstrate that our approach both allows fasternprocessing multi core computers and the capabilitynto handle larger problems splitting the graph across multiplencomputers distributed network Even though ournapproach does not give theoretical guarantee speedup nan extensive empirical evaluation several applicationsnwith many different data sets consistently shows goodnperformance open source implementation the dualndecomposition method also made publicly available 
13096 en Object Separation Ray Image Sets the segmentation natural images most algorithmsnrely the concept occlusion ray images however nthis assumption violated since ray photons penetratenmost materials this paper introduce SATIS anmethod for separating objects set ray images usingnthe property additivity log space where the logattenuationnat pixel the sum the log attenuationsnof all objects that the corresponding ray passes through nOur method leverages multiple projection views the samenscene from slightly different angles produce accuratenestimate attenuation properties objects thenscene These properties can used identify the materialncomposition these objects and are therefore crucialnfor applications like automatic threat detection evaluatenSATIS set collected ray scans showing that itnoutperforms standard image segmentation approach andnreduces the error material estimation 
13098 en Isoperimetric Cut Directed Graph
13100 en Tiered Scene Labeling with Dynamic Programming Dynamic programming has been useful tool for anvariety computer vision problems However its applicationnis usually limited problems with one dimensionalnor low treewidth structure whereas most domains visionnare least this paper show how apply DPnfor pixel labeling scenes with simple “tiered” structure nWhile there are many variations possible for the applicationsnwe consider the following tiered structure appropriate nAn image first divided horizontal curvesninto the top middle and bottom regions and the middle regionnis further subdivided vertically into subregions Undernthese constraints globally optimal labeling can foundnusing efficient dynamic programming algorithm applynthis algorithm two very different tasks The first isnthe problem geometric class labeling where the goal isnto assign each pixel label such “sky” “ground” andn“surface above ground” The second task involves incorporatingnsimple shape priors for segmentation imageninto the “foreground” and “background” regions 
13101 en Segmentation Building Facades Using Procedural Shape Priors this paper propose novel approach the perceptualninterpretation building facades that combines shapengrammars supervised classification and random walks nProcedural modeling used model the geometric andnthe photometric variation buildings This fused with visualnclassification techniques randomized forests that providena crude probabilistic interpretation the observationnspace order measure the appropriateness proceduralngeneration with respect the image random explorationnof the grammar space used optimize the sequencenof derivation rules towards semantico geometricninterpretation the observations Experiments conductednon complex architecture facades with ground truth validatenthe approach 
13102 en Layered Object Detection for Multi Class Segmentation formulate layered model for object detection andnmulti class segmentation Our system uses the output anbank object detectors order define shape priors fornsupport masks and then estimates appearance depth orderingnand labeling pixels the image train our systemnon the PASCAL segmentation challenge dataset and showngood test results with state the art performance severalncategories including segmenting humans 
13104 en Measuring Visual Saliency Site Entropy Rate
13105 en Context Aware Saliency Detection propose new type saliency – context aware saliencyn– which aims detecting the image regions that representnthe scene This definition differs from previous definitionsnwhose goal either identify fixation points detect thendominant object accordance with our saliency definition nwe present detection algorithm which based onnfour principles observed the psychological literature Thenbenefits the proposed approach are evaluated two applicationsnwhere the context the dominant objects justnas essential the objects themselves image retargetingnwe demonstrate that using our saliency prevents distortionsnin the important regions summarization show thatnour saliency helps produce compact appealing and informativensummaries 
13106 en Minimum length the tangent bundle model for curve completion
13114 en Reproducible Research Computational Science Problems and Solutions For Data and Code Sharing Scientific computation emerging absolutely central the scientific method but the prevalence very relaxed practices leading credibility crisis Reproducible computational research which all details computations—code and data—are made conveniently available others necessary response this crisis Results from 2009 survey the Machine Learning community NIPS participants designed elucidate factors that affect data and code sharing will presented Intellectual property concerns create significant barrier sharing and will also present work the “Reproducible Research Standard” giving open licensing options designed create intellectual property framework for scientists consonant with longstanding scientific norms and facilitating reproducible research 
13115 en Universal Java Matrix Package The Universal Java Matrix Package UJMP open source Java library which provides sparse and dense matrix classes well large number calculations for linear algebra like matrix multiplication matrix inverse Operations such mean correlation standard deviation replacement missing values the calculation mutual information are supported also nnThe Universal Java Matrix Package provides various visualization methods import and export filters for large number file formats and the possibility link tables JDBC databases Multi dimensional matrices well generic matrices with specified object type are supported and very large matrices with rows and columns can handled even when they not fit into memory nnA central concept UJMP the separation interfaces abstract classes and their implementations which makes very easy exchange the underlying data storage Thus matrix our framework can array values main memory file disk table SQL database fact the actual storage implementation becomes secondary and UJMP can even integrate other matrix libraries such JAMA Colt making UJMP’ visualization and import and export filters available these libraries nnOn the other hand UJMP can also decide redirect calculations other matrix libraries depending matrix size and computer hardware UJMP uses multiple threads for calculations which results much better performance compared JAMA Colt modern hardware nnUJMP also includes interfaces Matlab Octave and which makes easy perform calculations not available Java nnWhile some parts UJMP are pretty stable now lot development still going other parts Developers are welcome contribute 
13116 en Shogun The SHOGUN machine learning toolbox focus large scale kernel methods and especially Support Vector Machines SVM comes with generic interface for kernel machines and features different SVM implementations that all access features unified way via general kernel framework case linear SVMs called DotFeatures features providing minimalistic set operations like the dot product 
13117 en The next steps after UCI mldata org Recently mloss org has enabled machine learning researchers register their software and allow other researchers easily find download and reuse software matching their interests Currently more than 200 projects are listed Furthermore the Journal Machine Learning Research now accepts papers its special Open Source Software track which papers describing peer reviewed software can published further incentive for researchers publish their software under open source license Since its inception October 2007 seven papers have been published this track with more papers currently under review far the initiative has been highly successful but has focused mostly the ”method” side the problem make machine learning research more reproducible Hence see the need initiate companion project mloss org which focuses the free exchange and benchmarking datasets Additionally this new repository will emphasise the precise specification machine learning tasks detailed definitions datasets used possibly including feature extraction other preprocessing steps together with the desired operation performed and the relevant performance metric Finally solution such task would provide details how apply general software package such mloss org this particular problem instance well the obtained numerical performance measures This project will thus focus providing platform for publishing exchanging collecting and discussing such data sets tasks and solutions for challenging machine learning problems 
13119 en Libra The Libra machine learning toolkit includes implementations variety algorithms for learning and inference with Bayesian networks and arithmetic circuits nnLearning algorithms Structure learning for BNs and ACs Chow Liu algorithm weight learningnnInference algorithms Mean field belief propagation Gibbs sampling variable elimination exact inferencennLibra strength exploiting context specific independence such decision tree CPDs allow exact inference models with high treewidth 
13120 en FastInf The FastInf library designed perform memory and time efficient approximate inference large scale discrete undirected graphical models The focus the library propagation based approximate inference methods ranging from the basic loopy belief propagation algorithm propagation based convex free energies Various message scheduling schemes that improve the standard synchronous asynchronous approaches are included Also implemented are clique tree based exact inference Gibbs sampling and the mean field algorithm addition inference FastInf provides parameter estimation capabilities well representation and learning shared parameters offers rich interface that facilitates extension the basic classes other inference and learning methods 
13121 en PyBrain PyBrain versatile machine learning library for Python Its goal provide flexible easy use yet still powerful algorithms for machine learning tasks including variety predefined environments and benchmarks test and compare algorithms Implemented algorithms include Long Short Term Memory LSTM policy gradient methods multidimensional recurrent neural networks and evolution strategies like CMA NES FEM 
13122 en Jstacs Sequence analysis one the major subjects bioinformatics Several existing libraries combine the representation biological sequences with exact and approximate pattern matching well alignment algorithms present Jstacs open source Java library which focuses the statistical analysis biological sequences instead Jstacs comprises efficient representation sequence data and provides implementations many statistical models with generative and discriminative approaches for parameter learning Using Jstacs classifiers can assessed and compared test datasets cross validation experiments evaluating several performance measures Due its strictly object oriented design Jstacs easy use and readily extensible 
13123 en JBlas jblas fast linear algebra library for Java jblas based BLAS and LAPACK the facto industry standard for matrix computations and uses state the art implementations like ATLAS for all its computational routines making jBLAS very fast nnjblas can essentially light wight wrapper around the BLAS and LAPACK routines These packages have originated the Fortran community which explains their archaic API the other hand modern implementations are hard beat performance wise jblas aims make this functionality available Java programmers such that they not have worry about writing JNI interfaces and calling conventions Fortran code nnjblas the only actively developed matrix library which based native implementations The other such project netlib java which apparently not maintained anymore Therefore jblas much faster than other projects particular for large complex tasks like matrix matrix multiplication solving linear equations eigenproblems 
13124 en Scikitlearn Scikits learn Python module integrating classique machine learning algorithmes the tightly nit world scientific Python packagesnnIt aims provide simple and efficient solutions learning problems that are accessible everybody and reusable various contexts machine learning versatile tool for science and engineering 
13125 en Mulan Mulan Mulan open source Java library for learning from multi label datasets Multi label datasets consist training examples target function that has multiple binary target variables This means that each item multi label dataset can member multiple categories annotated many labels classes This actually the nature many real world problems such semantic annotation images and video web page categorization direct marketing functional genomics and music categorization into genres and emotions introduction mining multi label data provided Tsoumakas 2010 nnCurrently the library includes variety state the art algorithms for performing the following major multi label learning tasks nnClassification This task concerned with outputting bipartition the labels into relevant and irrelevant ones for given input instance nRanking This task concerned with outputting ordering the labels according their relevance for given data itemnClassification and ranking combination the two tasks mentioned above nIn addition the library offers the following features nnFeature selection Simple baseline methods are currently supported nEvaluation Classes that calculate large variety evaluation measures through hold out evaluation and cross validation nAs already mentioned Mulan library such offers only programmatic API the library users There graphical user interface GUI available The possibility use the library via command line also currently not supported The Getting Started page the Documentation section the ideal place start exploring Mulan 
13126 en OpenKernel The OpenKernel library open source software library for designing combining learning and using kernels for machine learning applicationsnnThe library supports the design and use kernels defined over dense and sparse real vectors well over sequences distributions sequences nnFor dense and sparse features the library provides implementation the classical kernels linear polynomial Gaussian and sigmoid nnFor sequences and distributions sequences the library implements the rational kernel framework Cortes JMLR 2004 The library supplies the following sequence kernels nnn gram kernels ngappy gram kernels nmismatch kernels Leslie 2004 nand gives the utilities for creating arbitrary rational kernels simply providing the weighted finite state transducers they are based nnKernels can combined taking their sum their product and can composed with polynomial Gaussian sigmoid They support demand evaluation and caching addition its own binary format the library uses the ASCII format LIBSVM LIBLINEAR SVMlight for representing features and precomputed kernels for LIBSVM nnFinally the OpenKernel library also includes several options for using training data automatically combine multiple kernels This particularly useful when the single best kernel for the task not known The algorithms implemented includennL1 regularized linear combinations Lanckriet JMLR 2004 nL2 regularized linear combinations Cortes UAI 2009 nL2 regularized quadratic combinations Cortes NIPS 2009 nas well kernel correlation alignment Cortes ICML 2010 based combinations Specialized efficient versions these algorithms are also made available for weighting features and sparseness and can used further improve efficiency The output kernels can easily used conjunction with LIBSVM SVMlight and included kernel ridge regression implementations Full reference documentation tutorials and examples with formatted datasets are included nnThe library open source project distributed under the Apache license This work has been partially supported Google Inc The library uses the OpenFst library for representing and manipulating weighted finite state transducers 
13127 en MultiBoost AdaBoost Freund Schapire 1997 one the best off the shelf supervised classification methods developed the last fifteen years Despite perhaps due its simplicity and versatility suprisingly under represented the family open softwares The goal this submission fill this gap nnOur implementation based the AdaBoost algorithm Schapire Singer 1999 intrinsically multi class classification method unlike SVM for example and was easy extend multi label multi task classification when one item can belong several classes The program package can divided into four modules that can changed more less independently depending the application nnThe strong learner tells you how boost The main boosting engine AdaBoost but have also implemented FilterBoost for research project Other possible strong learners could LogitBoost and ADTrees nnThe base weak learner tells you what features boost Right now have two basic feature wise base learners decision stumps for real valued features and indicators for nominal features have two meta base learners trees and products They can use any base learner and construct generic complex base learner using classic tree structure decision trees using the product simple base learners self advertisement boosting products stumps the best reported domain knowledge algorithm MNIST after Hinton and Salakhutdinov deep belief nets have also implemented Haar filters Viola Jones 2004 for image classification meta base learner that uses stumps over high dimensional feature space computed the fly nice example domain dependent base learner that works hand hand with its appropriate data structure nnThe data representation The basic data structure matrix observations with vector labels also have multi label classification when the label data also full matrix addition have sparse data representation for both the observation matrix and the label matrix general base learners are implemented work with their own data representation for example sparse stumps work sparse observation matrices Haar filters work integral image data representation nnData parser can read data arff and svmlight formats nnThe base learner data structure combinations cover large spectrum possible applications but the main advantage the package that easy for the advanced user adapt MultiBoost specific non standard application implementing the base learner and data structure interfaces that work together nnThe source code available from the website multiboost org can compiled Mac Linux and Microsoft Windows The interface command line execution with switches 
13128 en Gidoc Transcription handwritten text old documents important time consuming task for digital libraries might carried out first processing all document images off line and then manually supervising system transcriptions edit incorrect parts However current techniques for automatic page layout analysis text line detection and handwriting recognition are still far from perfect and thus post editing system output not clearly better than simply ignoring nnA more effective approach transcribe old text documents follow interactive predictive paradigm which both the system guided the user and the user assisted the system complete the transcription task efficiently possible Following this approach system prototype called GIDOC Gimp based Interactive transcription old text DOCuments has been developed provide user friendly integrated support for interactive predictive layout analysis line detection and handwriting transcription nnGIDOC designed work with large collections homogeneous documents that similar structure and writing styles They are annotated sequentially par tially supervising hypotheses drawn from statistical models that are constantly updated with increasing number available annotated documents And this done different annotation levels For instance the level page layout analysis GIDOC uses novel text block detection method which conventional memoryless techniques are improved with “history” model text block positions Similarly the level text line image transcription GIDOC includes handwriting recognizer which steadily improved with growing number partially supervised transcriptions 
13129 en Dependency Modelling Toolbox Investigation dependencies between multiple data sources allows the discovery regularities and interactions that are not seen individual data sets The increasing availability occurring measurement data computational biology social sciences and other domains emphasizes the need for practical implementations general purpose dependency modeling algorithms nnThe project collects various dependency modeling approaches into unified toolbox The techniques for the discovery and analysis statistical dependencies are based well established models such probabilistic canonical correlation analysis and multi task learning whose applicability has been demonstrated previous case studies 
13131 en Introduction and overview the SIMBAD project
13132 en Clustering without any subjective similarity information Consider the task clustering university web pages based the graph links between these pages Can clusters functionally similar pages detected from just this link structure Note that this clustering task which one starts without any prior knowledge any similarity distance measure between the domain elements All the information the input comes objective observed binary relations among the objects These relations are not similarity links For example the cluster professors pages have very internal links whereas the cluster service pages have lots internal links What are looking for are clusters whose members share similar link patterns with respect the other clusters nWe propose formal model for such clustering tasks Our model based objective function that measures the homogeneity between clusters links shall discuss the computational complexity finding clustering with minimal objective cost and describe some hardness results well efficient approximation algorithms nThe talk partly based work with Sharon Wulff 
13133 en Learning with similarity functions Kernel functions have become extremely popular tool machine learning with many applications and attractive theory This theory views kernel performing implicit mapping data points into possibly very high dimensional space and describes kernel function being good for given learning problem data separable large margin that implicit space this talk will describe alternative more general theory learning with similarity functions sufficient conditions for similarity function allow one learn well that does not require reference implicit spaces and does not require the function positive semi definite even symmetric nIn particular will describe notion good similarity function for given learning problem that fairly natural and intuitive does not require implicit space and allows for functions that are not positive semi definite sufficient condition for learning well and strictly generalizes the notion large margin kernel function that any such kernel also good similarity function though not necessarily vice versa 
13134 en From collaborative filtering multitask learning Recent work collaborative filtering has led large number both scalable and theoretically well founded algorithms this paper show that collaborative filtering and multitask learning are innately closely connected particular the learning the kernel paradigm multitask learning turns out identical Fan norm minimization This allows “import” collaborative filtering techniques into multitask learning and vice versa particular solve multitask learning problem where the tasks also have features show the feasibility our approach two large real world multitask learning applications nJoint work with Markus Weimer Wei Chu Deepayan Chakrabarti 
13135 en  probabilistic hypergraph matching consider the problem finding matching between two sets features given complex relations among them going beyond pairwise derive the hyper graph matching problem probabilistic setting represented convex optimization First formalize soft matching criterion that emerges from probabilistic interpretation the problem input and output opposed previous methods that treat soft matching mere relaxation the hard matching problem Second the model induces algebraic relation between the hyper edge weight matrix and the desired vertex vertex probabilistic matching Third the model explains some the graph matching normalization proposed the past heuristic basis such doubly stochastic normalizations the edge weights key benefit the model that the global optimum the matching criteria can found via iterative successive projection algorithm The algorithm reduces the well known Sinkhorn row column matrix normalization procedure the special case when the two graphs have the same number vertices and complete matching desired Another benefit our model the straightforward scalability from graphs hyper graphs nThe work was done with Ron Zass and made its debut CVPR 2008 
13136 en  metric notion dimension and its applications learning Let define the dimension metric space the minimum such that every ball the metric space can covered balls half the radius This definition has several attractive features besides being applicable every metric space For instance coincides with the standard notion dimension Euclidean spaces but captures also nonlinear structures such manifolds nMetric spaces low dimension under the above definition occur naturally many contexts will discuss recent theoretical results regarding such metric spaces including questions such embeddability dimension reduction Nearest Neighbor Search and large margin classification the common thread being that low dimension implies algorithmic efficiency 
13137 en  note caution regarding distances graphs Non geometric data often represented form graph where edges represent similarity local relationships between instances One elegant way exploit the global structure the graph implemented the commute distance also known resistance distance Supposedly has the property that vertices from the same cluster are close each other whereas vertices from different clusters are far from each other study the behavior the commute distance the size the underlying graph increases prove that the commute distance converges expression that does not take into account the structure the graph and that completely meaningless distance function the graph Consequently the use the raw commute distance for machine learning purposes strongly discouraged for large graphs and high dimensions suspect that similar behavior holds for several other distances graphs 
13138 en  non geo metricity issue for machine learning 
13139 en Scalable algorithms for learning graphs Networked data are found variety domains Web social networks biological networks and many others learning tasks networked data are often represented weighted graph whose edge weights reflect the similarity between incident nodes this talk consider the problem classifying the nodes arbitrary given graph the game theoretic mistake bound model characterize the optimal predictive performance terms the cutsize the graph random spanning tree and describe randomized prediction algorithm achieving the optimal performance while running expected time sublinear the graph size most graphs These results are then extended the active learning model where training labels are obtained querying nodes selected the algorithm describe fast query placement strategy that the special case trees achieves the optimal number mistakes when classifying the non queried nodes nJoint work with Claudio Gentile Fabio Vitale and Giovanni Zappella 
13167 en Introduction Machine Learning How can represent data computer and use learn performnuseful tasks This lecture reviews some simple classification andnregression rules discusses under and over fitting and emphasises thenutility defining objective functions for learning There also anshort overview Bayesian learning and some practical tips fornpre processing and visualizing data The lecture ends with briefnmention unsupervised learning and related topics 
13168 en Probability and Mathematical Needs This lectures covers basics linear algebra and probabilities well anbrief introduction optimization nIn linear algebra the lecture starts with the definition vectors spaces ndimension basis span vectors and forth Norms and dot products wellnas Hilbert spaces are introduced Then the problem solving linear system isntackled introducing matrices eigenvalues and some common factorizationn SVD Choleski nIn probabilities start from the definition discrete and continuous randomnvariables give common examples introduce the concepts independence andnconditional probabilities tackle estimation through Bayes framework giventhe basic definitions information theory entropy Kullback Leiblerndivergence and introduce error bounds Hoeffding bounds nOptimization briefly introduced defining extrema and convex functions Annexample constrained minimization demonstrated 
13169 en Graphical Models will discuss probabilistic graphical models associated directed andnundirected graphs will introduce exact inference algorithms such thensum product algorithm and apply hidden Markov models will alsondiscuss elements learning graphical models including maximum likelihood nmaximum posteriori and the expectation maximisation algorithm 
13170 en Introduction Kernel Methods this talk are going see the basics kernels methods After briefnpresentation very simple kernel classifier give the definition anpostive definite kernel and explain Support vector machine learning Then fewnkernels for structured data namely sequences and graphs will described Thenrepresenter theorem presented which explains the rationale for the usualnkernel expansion encountered when working with kernel methods Finally fewnelements from statistical learning theory are given 
13171 en Machine Learning for Natural Languages Processing Probabilistic Context Free Grammars PCFG powerful formalismnthat has been used for several applications Computational Linguistics Onenimportant problem these models the probabilistic estimation thenprobabilistic part the models This probabilistic estimation based onntabular algorithms similar the CKY algorithm review these estimationnalgorithms and their properties The use these models for Language Modelingnand Machine Translation also introduced Finally interactive predictivenframework for parsing explained that can used for developing both linenlearning techniques and active learning techniques 
13172 en Speech Processing The lecture presents various aspects automatic speech processingn from spoken contents extraction high level categorization ofnspeech signals show how machine learning provides solutions thenmain issues that the speech processing systems have deal with nSpeech one the main way that humans communicate together ancomplex process that involves highly integrated way perceptionnabilities and cognitive processes spite the efforts produced bynthe scientific community for simulating these abilities knowledge basednapproaches failed modeling speech nNowadays most the methods relies statistical modeling ofnspeech The lecture presents this theorical framework which the majornissues speech processing are formulated Then the main tasks SPnare overviewed especially speaker identification and speech recognitionnand understanding 
13174 en Online Learning This talk aim presenting first approaching the Online Learningnmethodology starts presenting the linear Perceptron algorithm and severalnderivations The kernel Perceptron algorithm also motivated The Passive nAggressive Online Learning algorithm then presented for binarynclassification regression and multi class problems well Linear and kernelnversion are presented and discussed playing especial attention thenupdate rules derivation important issue able control the modelncomplexity this end different budgeted online algorithms are proposed firstnfor the conventional Perceptron and derivations and second for the PAnalgorithm Finally some examples online learning applications are presentednin order motivate the audience the application these techniques inndifferent real scenarios 
13175 en Grammatical Inference Grammatical inference about learning automata and grammars givenninformation about the language nDuring this tutorial will introduce the problem and its applications nstudy the various paradigms andnrelated learnability results and discuss some the most importantnalgorithms the field 
